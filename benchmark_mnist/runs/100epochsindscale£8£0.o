dataset: MNIST
dtype: float64
dof: 0.01
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2574462120106347', 'Train Acc: 0.56295', 'Test Acc: 0.8501', 'Train LL: -1.2256328448713656', 'Test LL: -0.45633735318524477', 'Epoch Time (s): 171.46991590783')
('Epoch 1', 'Objective: -0.3882532991363232', 'Train Acc: 0.8798666666666667', 'Test Acc: 0.9124', 'Train LL: -0.37010993149537186', 'Test LL: -0.2719756000573203', 'Epoch Time (s): 171.52693715598434')
('Epoch 2', 'Objective: -0.23402501067989243', 'Train Acc: 0.9319166666666666', 'Test Acc: 0.9412', 'Train LL: -0.21975566137412997', 'Test LL: -0.18388849602721985', 'Epoch Time (s): 171.6248153699562')
('Epoch 3', 'Objective: -0.1834518947349477', 'Train Acc: 0.9472833333333334', 'Test Acc: 0.9354', 'Train LL: -0.17066854509781082', 'Test LL: -0.20054057805906605', 'Epoch Time (s): 170.95034011499956')
('Epoch 4', 'Objective: -0.15692559217109894', 'Train Acc: 0.9540333333333333', 'Test Acc: 0.9489', 'Train LL: -0.14465489203396853', 'Test LL: -0.1594576818734221', 'Epoch Time (s): 171.57510040607303')
('Epoch 5', 'Objective: -0.1394268632158321', 'Train Acc: 0.9602833333333334', 'Test Acc: 0.9709', 'Train LL: -0.12767178418274566', 'Test LL: -0.08437288135201769', 'Epoch Time (s): 171.4268874898553')
('Epoch 6', 'Objective: -0.1217436489722464', 'Train Acc: 0.9653666666666667', 'Test Acc: 0.9632', 'Train LL: -0.11065600903142661', 'Test LL: -0.10740595008067055', 'Epoch Time (s): 171.51779918000102')
('Epoch 7', 'Objective: -0.11449990760548835', 'Train Acc: 0.9674', 'Test Acc: 0.9702', 'Train LL: -0.1038814285586188', 'Test LL: -0.08763706184410125', 'Epoch Time (s): 171.5388490059413')
('Epoch 8', 'Objective: -0.10597313250902539', 'Train Acc: 0.97025', 'Test Acc: 0.9739', 'Train LL: -0.09581973662232172', 'Test LL: -0.08126462747146909', 'Epoch Time (s): 171.58894974784926')
('Epoch 9', 'Objective: -0.09848220710216343', 'Train Acc: 0.97215', 'Test Acc: 0.9745', 'Train LL: -0.08875995067584849', 'Test LL: -0.07615268180769967', 'Epoch Time (s): 171.21776239713654')
('Epoch 10', 'Objective: -0.09122753723010489', 'Train Acc: 0.9739', 'Test Acc: 0.9729', 'Train LL: -0.08188283476076251', 'Test LL: -0.08968383500933619', 'Epoch Time (s): 171.3526721810922')
('Epoch 11', 'Objective: -0.0881020000775248', 'Train Acc: 0.9748', 'Test Acc: 0.9782', 'Train LL: -0.07915288521637798', 'Test LL: -0.07128892391959812', 'Epoch Time (s): 171.43712966889143')
('Epoch 12', 'Objective: -0.08430986252556988', 'Train Acc: 0.9762166666666666', 'Test Acc: 0.9781', 'Train LL: -0.07564854134177194', 'Test LL: -0.064246711450017', 'Epoch Time (s): 171.54544758610427')
('Epoch 13', 'Objective: -0.08110187377599738', 'Train Acc: 0.97705', 'Test Acc: 0.9788', 'Train LL: -0.07270793859571938', 'Test LL: -0.0652446223499227', 'Epoch Time (s): 171.56368939299136')
('Epoch 14', 'Objective: -0.07851745094798634', 'Train Acc: 0.97755', 'Test Acc: 0.9783', 'Train LL: -0.07045957408343889', 'Test LL: -0.06798383427789613', 'Epoch Time (s): 171.4392436821945')
('Epoch 15', 'Objective: -0.07302081719723942', 'Train Acc: 0.9789166666666667', 'Test Acc: 0.9814', 'Train LL: -0.06511293233309041', 'Test LL: -0.058926056910133584', 'Epoch Time (s): 171.4206213876605')
('Epoch 16', 'Objective: -0.07162424401435243', 'Train Acc: 0.9793666666666667', 'Test Acc: 0.9823', 'Train LL: -0.0640497428708703', 'Test LL: -0.05427551689379967', 'Epoch Time (s): 171.01846970012411')
('Epoch 17', 'Objective: -0.07076439366414364', 'Train Acc: 0.9801333333333333', 'Test Acc: 0.9857', 'Train LL: -0.06332054477902785', 'Test LL: -0.04466258272630434', 'Epoch Time (s): 171.65636602323502')
('Epoch 18', 'Objective: -0.0680866338369315', 'Train Acc: 0.9807', 'Test Acc: 0.9806', 'Train LL: -0.060960161045484476', 'Test LL: -0.05944889075194375', 'Epoch Time (s): 171.36909962678328')
('Epoch 19', 'Objective: -0.06744373339622461', 'Train Acc: 0.9808833333333333', 'Test Acc: 0.9733', 'Train LL: -0.0604540796496534', 'Test LL: -0.07929248278914643', 'Epoch Time (s): 171.60233642719686')
('Epoch 20', 'Objective: -0.06488383915298693', 'Train Acc: 0.9815333333333334', 'Test Acc: 0.9757', 'Train LL: -0.058119620019271276', 'Test LL: -0.07565986917532586', 'Epoch Time (s): 171.43546005431563')
('Epoch 21', 'Objective: -0.06327229516679371', 'Train Acc: 0.9818166666666667', 'Test Acc: 0.9886', 'Train LL: -0.056600698502090575', 'Test LL: -0.03798859047917921', 'Epoch Time (s): 171.4575688317418')
('Epoch 22', 'Objective: -0.060303275278957534', 'Train Acc: 0.9831166666666666', 'Test Acc: 0.9857', 'Train LL: -0.05383654899693637', 'Test LL: -0.04812138446567899', 'Epoch Time (s): 171.5765279480256')
('Epoch 23', 'Objective: -0.0598414292139748', 'Train Acc: 0.98315', 'Test Acc: 0.9811', 'Train LL: -0.05353866395453441', 'Test LL: -0.0562826442495498', 'Epoch Time (s): 170.64695810200647')
('Epoch 24', 'Objective: -0.059381563411631116', 'Train Acc: 0.9832833333333333', 'Test Acc: 0.9789', 'Train LL: -0.05313934391865886', 'Test LL: -0.06248781979052426', 'Epoch Time (s): 171.4715396030806')
('Epoch 25', 'Objective: -0.056989358858216245', 'Train Acc: 0.9838333333333333', 'Test Acc: 0.9836', 'Train LL: -0.0509546678674222', 'Test LL: -0.050625262701964484', 'Epoch Time (s): 171.38771524792537')
('Epoch 26', 'Objective: -0.05674900662318166', 'Train Acc: 0.9838833333333333', 'Test Acc: 0.9865', 'Train LL: -0.050783830701468614', 'Test LL: -0.042124189338706965', 'Epoch Time (s): 171.20608245395124')
('Epoch 27', 'Objective: -0.05448621559197602', 'Train Acc: 0.9843166666666666', 'Test Acc: 0.9893', 'Train LL: -0.04867987640883918', 'Test LL: -0.034840460344493895', 'Epoch Time (s): 171.14434512192383')
('Epoch 28', 'Objective: -0.05378842746730077', 'Train Acc: 0.9848666666666667', 'Test Acc: 0.9814', 'Train LL: -0.04801569075168838', 'Test LL: -0.05470808128322466', 'Epoch Time (s): 170.9957722988911')
('Epoch 29', 'Objective: -0.05447051762459735', 'Train Acc: 0.9845', 'Test Acc: 0.9843', 'Train LL: -0.04878575968546611', 'Test LL: -0.05303200729542617', 'Epoch Time (s): 170.98202069103718')
('Epoch 30', 'Objective: -0.052792727099060556', 'Train Acc: 0.9851333333333333', 'Test Acc: 0.9869', 'Train LL: -0.04719362480351764', 'Test LL: -0.040900000766801156', 'Epoch Time (s): 171.0146057489328')
('Epoch 31', 'Objective: -0.05133192985430448', 'Train Acc: 0.98475', 'Test Acc: 0.9832', 'Train LL: -0.04575570279136673', 'Test LL: -0.053665419231107785', 'Epoch Time (s): 170.9992112228647')
('Epoch 32', 'Objective: -0.05127866457723482', 'Train Acc: 0.9856', 'Test Acc: 0.9878', 'Train LL: -0.04582615386581014', 'Test LL: -0.038205145243133246', 'Epoch Time (s): 170.98683404689655')
('Epoch 33', 'Objective: -0.05062449679020336', 'Train Acc: 0.9854', 'Test Acc: 0.9872', 'Train LL: -0.045247167399007394', 'Test LL: -0.04208816315836001', 'Epoch Time (s): 171.01515489723533')
('Epoch 34', 'Objective: -0.04913968251778092', 'Train Acc: 0.9856166666666667', 'Test Acc: 0.9893', 'Train LL: -0.0438634174972814', 'Test LL: -0.0348498675261549', 'Epoch Time (s): 170.98207646096125')
('Epoch 35', 'Objective: -0.04846865701110969', 'Train Acc: 0.9862666666666666', 'Test Acc: 0.9807', 'Train LL: -0.0432765239403489', 'Test LL: -0.06160839529862959', 'Epoch Time (s): 171.06235453486443')
('Epoch 36', 'Objective: -0.04736003623831504', 'Train Acc: 0.9860333333333333', 'Test Acc: 0.9849', 'Train LL: -0.042220013179491284', 'Test LL: -0.04437511022558926', 'Epoch Time (s): 170.96353179495782')
('Epoch 37', 'Objective: -0.048080550810145825', 'Train Acc: 0.9861166666666666', 'Test Acc: 0.9841', 'Train LL: -0.043025615693569316', 'Test LL: -0.04693823993431011', 'Epoch Time (s): 170.9473669710569')
('Epoch 38', 'Objective: -0.04627153184672643', 'Train Acc: 0.9867333333333334', 'Test Acc: 0.9845', 'Train LL: -0.041299163323386234', 'Test LL: -0.045322060997500066', 'Epoch Time (s): 171.0521838348359')
('Epoch 39', 'Objective: -0.04531402016963716', 'Train Acc: 0.9870333333333333', 'Test Acc: 0.987', 'Train LL: -0.040409167102338384', 'Test LL: -0.04070774009225752', 'Epoch Time (s): 170.96954043395817')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.02920473284468354', 'Train Acc: 0.9921', 'Test Acc: 0.9919', 'Train LL: -0.024714019981737646', 'Test LL: -0.02444584878874051', 'Epoch Time (s): 170.99525105999783')
('Epoch 41', 'Objective: -0.02442612321797557', 'Train Acc: 0.9933333333333333', 'Test Acc: 0.9925', 'Train LL: -0.020199518683890524', 'Test LL: -0.023035836611883218', 'Epoch Time (s): 171.05089059006423')
('Epoch 42', 'Objective: -0.022588508005756725', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.9921', 'Train LL: -0.018471401834307313', 'Test LL: -0.024163689967099385', 'Epoch Time (s): 171.05111932987347')
('Epoch 43', 'Objective: -0.022083197589506803', 'Train Acc: 0.9944', 'Test Acc: 0.993', 'Train LL: -0.01802497250195711', 'Test LL: -0.022317169934543222', 'Epoch Time (s): 171.08219745894894')
('Epoch 44', 'Objective: -0.02145194202155202', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9921', 'Train LL: -0.017461003672055476', 'Test LL: -0.022052198228847304', 'Epoch Time (s): 171.47613921528682')
('Epoch 45', 'Objective: -0.020036513573914956', 'Train Acc: 0.99475', 'Test Acc: 0.9919', 'Train LL: -0.016124604252293458', 'Test LL: -0.02329480123786258', 'Epoch Time (s): 171.40669542877004')
('Epoch 46', 'Objective: -0.019876631639832328', 'Train Acc: 0.99485', 'Test Acc: 0.9912', 'Train LL: -0.016006408911497856', 'Test LL: -0.02676556217159869', 'Epoch Time (s): 171.4517476791516')
('Epoch 47', 'Objective: -0.020084086489109556', 'Train Acc: 0.99505', 'Test Acc: 0.993', 'Train LL: -0.0162308276434033', 'Test LL: -0.02195674950917596', 'Epoch Time (s): 171.4952237070538')
('Epoch 48', 'Objective: -0.01930315983226261', 'Train Acc: 0.99495', 'Test Acc: 0.993', 'Train LL: -0.015471099500109628', 'Test LL: -0.02190719899660731', 'Epoch Time (s): 171.42614567792043')
('Epoch 49', 'Objective: -0.01851015922656255', 'Train Acc: 0.9954666666666667', 'Test Acc: 0.9917', 'Train LL: -0.014758685952892165', 'Test LL: -0.02482275781600327', 'Epoch Time (s): 171.54850247502327')
('Epoch 50', 'Objective: -0.01825035734782357', 'Train Acc: 0.9957333333333334', 'Test Acc: 0.9931', 'Train LL: -0.014508004929080968', 'Test LL: -0.021088690267337153', 'Epoch Time (s): 171.5110661876388')
('Epoch 51', 'Objective: -0.017432201261234265', 'Train Acc: 0.99545', 'Test Acc: 0.9916', 'Train LL: -0.01371472473517466', 'Test LL: -0.026309391794248967', 'Epoch Time (s): 171.45829437067732')
('Epoch 52', 'Objective: -0.016954169734601645', 'Train Acc: 0.99575', 'Test Acc: 0.9921', 'Train LL: -0.013205369280972185', 'Test LL: -0.023603643290295934', 'Epoch Time (s): 171.49313344294205')
('Epoch 53', 'Objective: -0.016643808601621787', 'Train Acc: 0.9957166666666667', 'Test Acc: 0.9932', 'Train LL: -0.012950887838166426', 'Test LL: -0.022434878657448587', 'Epoch Time (s): 171.38243171293288')
('Epoch 54', 'Objective: -0.016571686021990592', 'Train Acc: 0.9956', 'Test Acc: 0.9929', 'Train LL: -0.012860284267068115', 'Test LL: -0.024212859406663872', 'Epoch Time (s): 171.4143492449075')
('Epoch 55', 'Objective: -0.015565795170389985', 'Train Acc: 0.996', 'Test Acc: 0.993', 'Train LL: -0.011856473636511627', 'Test LL: -0.02277208966252363', 'Epoch Time (s): 171.52565930690616')
('Epoch 56', 'Objective: -0.015948458821896574', 'Train Acc: 0.9959', 'Test Acc: 0.9922', 'Train LL: -0.012290539102821624', 'Test LL: -0.024170966423864352', 'Epoch Time (s): 171.48450935585424')
('Epoch 57', 'Objective: -0.015441562724020853', 'Train Acc: 0.9959833333333333', 'Test Acc: 0.9919', 'Train LL: -0.011793629694792621', 'Test LL: -0.025571453931210773', 'Epoch Time (s): 171.46519192727283')
('Epoch 58', 'Objective: -0.015270612532874284', 'Train Acc: 0.9962833333333333', 'Test Acc: 0.9923', 'Train LL: -0.011616233992504143', 'Test LL: -0.025709406361227195', 'Epoch Time (s): 171.49708869028836')
('Epoch 59', 'Objective: -0.01508490794264365', 'Train Acc: 0.9960166666666667', 'Test Acc: 0.9928', 'Train LL: -0.011457206167305558', 'Test LL: -0.024694738943051908', 'Epoch Time (s): 171.43829008284956')
('Epoch 60', 'Objective: -0.015431802326148812', 'Train Acc: 0.9961666666666666', 'Test Acc: 0.9924', 'Train LL: -0.011839906592530288', 'Test LL: -0.02778777660410858', 'Epoch Time (s): 171.4231130061671')
('Epoch 61', 'Objective: -0.014645739367085417', 'Train Acc: 0.9963666666666666', 'Test Acc: 0.992', 'Train LL: -0.011038058387068124', 'Test LL: -0.02499606210070799', 'Epoch Time (s): 171.35082170693204')
('Epoch 62', 'Objective: -0.013901906466612114', 'Train Acc: 0.9964', 'Test Acc: 0.9911', 'Train LL: -0.010309092751283186', 'Test LL: -0.027507239972009392', 'Epoch Time (s): 171.28849976323545')
('Epoch 63', 'Objective: -0.014898775326535859', 'Train Acc: 0.9961166666666667', 'Test Acc: 0.9911', 'Train LL: -0.011257292258827108', 'Test LL: -0.02822898281179216', 'Epoch Time (s): 171.27382796490565')
('Epoch 64', 'Objective: -0.014081026970306247', 'Train Acc: 0.9965166666666667', 'Test Acc: 0.9929', 'Train LL: -0.01049781627558722', 'Test LL: -0.023856002209258664', 'Epoch Time (s): 171.3203296000138')
('Epoch 65', 'Objective: -0.014162607186806907', 'Train Acc: 0.9963833333333333', 'Test Acc: 0.9922', 'Train LL: -0.010570496116936992', 'Test LL: -0.02682505538054844', 'Epoch Time (s): 171.43783950200304')
('Epoch 66', 'Objective: -0.013571962868777359', 'Train Acc: 0.9966', 'Test Acc: 0.9926', 'Train LL: -0.009981190838849376', 'Test LL: -0.02835294114000326', 'Epoch Time (s): 171.51658636471257')
('Epoch 67', 'Objective: -0.013589755502272123', 'Train Acc: 0.9964833333333334', 'Test Acc: 0.9923', 'Train LL: -0.009988907385785459', 'Test LL: -0.02711714464759218', 'Epoch Time (s): 171.47180724982172')
('Epoch 68', 'Objective: -0.013262262522158433', 'Train Acc: 0.9965', 'Test Acc: 0.9917', 'Train LL: -0.009648065847034176', 'Test LL: -0.030860617093607545', 'Epoch Time (s): 171.4218001542613')
('Epoch 69', 'Objective: -0.012562511472032793', 'Train Acc: 0.9972333333333333', 'Test Acc: 0.9927', 'Train LL: -0.008978457348680365', 'Test LL: -0.025396432723127686', 'Epoch Time (s): 171.30064551671967')
('Epoch 70', 'Objective: -0.012883568821917038', 'Train Acc: 0.99685', 'Test Acc: 0.9923', 'Train LL: -0.009310823327790319', 'Test LL: -0.025901439827126206', 'Epoch Time (s): 171.36005222983658')
('Epoch 71', 'Objective: -0.01337063461834853', 'Train Acc: 0.99675', 'Test Acc: 0.9922', 'Train LL: -0.009779737484933658', 'Test LL: -0.02788011191045323', 'Epoch Time (s): 171.26442507468164')
('Epoch 72', 'Objective: -0.012238334345223128', 'Train Acc: 0.9971', 'Test Acc: 0.9917', 'Train LL: -0.008758321816482704', 'Test LL: -0.02976409512751178', 'Epoch Time (s): 171.34215130005032')
('Epoch 73', 'Objective: -0.011840970474936381', 'Train Acc: 0.9971166666666667', 'Test Acc: 0.9915', 'Train LL: -0.008315129339134156', 'Test LL: -0.030149258047339207', 'Epoch Time (s): 171.3033426250331')
('Epoch 74', 'Objective: -0.012198481220110358', 'Train Acc: 0.9970666666666667', 'Test Acc: 0.9923', 'Train LL: -0.008641350438061237', 'Test LL: -0.02825626279983684', 'Epoch Time (s): 171.3928090101108')
('Epoch 75', 'Objective: -0.011260074327539804', 'Train Acc: 0.9974166666666666', 'Test Acc: 0.9915', 'Train LL: -0.007764775181675991', 'Test LL: -0.03268399711354453', 'Epoch Time (s): 171.32468098262325')
('Epoch 76', 'Objective: -0.012190559236687697', 'Train Acc: 0.9968833333333333', 'Test Acc: 0.9923', 'Train LL: -0.008635431000597485', 'Test LL: -0.03069696995484831', 'Epoch Time (s): 171.31825398188084')
('Epoch 77', 'Objective: -0.011817941073386445', 'Train Acc: 0.9970833333333333', 'Test Acc: 0.9908', 'Train LL: -0.008268646209163148', 'Test LL: -0.03282824841563068', 'Epoch Time (s): 171.29596203193069')
('Epoch 78', 'Objective: -0.011837328561012914', 'Train Acc: 0.9970166666666667', 'Test Acc: 0.992', 'Train LL: -0.008299673349032949', 'Test LL: -0.030520631628768103', 'Epoch Time (s): 171.32862645201385')
('Epoch 79', 'Objective: -0.011896830797946274', 'Train Acc: 0.9971833333333333', 'Test Acc: 0.9926', 'Train LL: -0.00840940507284189', 'Test LL: -0.029370117017239687', 'Epoch Time (s): 171.3544945968315')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.0097074030751359', 'Train Acc: 0.9977833333333334', 'Test Acc: 0.9921', 'Train LL: -0.006350776148540157', 'Test LL: -0.030907623681059385', 'Epoch Time (s): 171.28914375323802')
('Epoch 81', 'Objective: -0.009049127341132305', 'Train Acc: 0.9983333333333333', 'Test Acc: 0.9922', 'Train LL: -0.005729708526260959', 'Test LL: -0.030124313114655233', 'Epoch Time (s): 171.23407697770745')
('Epoch 82', 'Objective: -0.00860925218144047', 'Train Acc: 0.9982', 'Test Acc: 0.9925', 'Train LL: -0.005303892249053742', 'Test LL: -0.029889517714334055', 'Epoch Time (s): 171.39847271889448')
('Epoch 83', 'Objective: -0.00841670149592019', 'Train Acc: 0.9982833333333333', 'Test Acc: 0.9923', 'Train LL: -0.005107342111257877', 'Test LL: -0.0313797317486706', 'Epoch Time (s): 171.42134047159925')
('Epoch 84', 'Objective: -0.008050927936537049', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9922', 'Train LL: -0.004734872679408921', 'Test LL: -0.0316205188017872', 'Epoch Time (s): 171.39713867008686')
('Epoch 85', 'Objective: -0.008606636511218967', 'Train Acc: 0.9981833333333333', 'Test Acc: 0.9919', 'Train LL: -0.005230438161124795', 'Test LL: -0.03194559227875547', 'Epoch Time (s): 171.35863907681778')
('Epoch 86', 'Objective: -0.007759068003705335', 'Train Acc: 0.9987', 'Test Acc: 0.9925', 'Train LL: -0.0044577800356799206', 'Test LL: -0.031774584556252525', 'Epoch Time (s): 171.34902150882408')
('Epoch 87', 'Objective: -0.008072947530187316', 'Train Acc: 0.9983666666666666', 'Test Acc: 0.9921', 'Train LL: -0.0046934472654048005', 'Test LL: -0.032221906174607774', 'Epoch Time (s): 171.28767062304541')
('Epoch 88', 'Objective: -0.007692816699255777', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9917', 'Train LL: -0.00434639568228796', 'Test LL: -0.03244995692289644', 'Epoch Time (s): 171.23870273213834')
('Epoch 89', 'Objective: -0.00801808269425557', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.9917', 'Train LL: -0.0046363171690160946', 'Test LL: -0.0332173186186485', 'Epoch Time (s): 171.27839205274358')
('Epoch 90', 'Objective: -0.007790657993953024', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.9923', 'Train LL: -0.004418166329546303', 'Test LL: -0.0322950538366205', 'Epoch Time (s): 171.2569451276213')
('Epoch 91', 'Objective: -0.007948330577110394', 'Train Acc: 0.9985333333333334', 'Test Acc: 0.9922', 'Train LL: -0.0045433052131020075', 'Test LL: -0.033686552577462496', 'Epoch Time (s): 171.26801482914016')
('Epoch 92', 'Objective: -0.007373731957462456', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9921', 'Train LL: -0.004021354378847028', 'Test LL: -0.03506131950335008', 'Epoch Time (s): 171.28180796513334')
('Epoch 93', 'Objective: -0.007682318946937162', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9918', 'Train LL: -0.004297260762157543', 'Test LL: -0.03508519475008654', 'Epoch Time (s): 171.27215308696032')
('Epoch 94', 'Objective: -0.00758970890825235', 'Train Acc: 0.99855', 'Test Acc: 0.9921', 'Train LL: -0.0042066292899917415', 'Test LL: -0.03534592313630446', 'Epoch Time (s): 171.30631508911029')
('Epoch 95', 'Objective: -0.007357742542891448', 'Train Acc: 0.9986166666666667', 'Test Acc: 0.9925', 'Train LL: -0.003998713948108369', 'Test LL: -0.03509293287335879', 'Epoch Time (s): 171.32651026826352')
('Epoch 96', 'Objective: -0.007602828687089367', 'Train Acc: 0.9986166666666667', 'Test Acc: 0.9916', 'Train LL: -0.0042100135456730695', 'Test LL: -0.03680719284891624', 'Epoch Time (s): 171.34762986190617')
('Epoch 97', 'Objective: -0.007350646377068754', 'Train Acc: 0.9985833333333334', 'Test Acc: 0.9922', 'Train LL: -0.003955762763605524', 'Test LL: -0.03459951972766917', 'Epoch Time (s): 171.27616238920018')
('Epoch 98', 'Objective: -0.007735518063392453', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9923', 'Train LL: -0.004320453496297754', 'Test LL: -0.03483805954038121', 'Epoch Time (s): 171.18556802580133')
('Epoch 99', 'Objective: -0.007393374515362802', 'Train Acc: 0.9987333333333334', 'Test Acc: 0.993', 'Train LL: -0.004005352033232564', 'Test LL: -0.03381728674079808', 'Epoch Time (s): 171.16871413588524')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.007161068810017462
Final Train Accuracy: £0.9989166666666667
Final Train LL: £-0.003799744412491207
Final Test Accuracy: £0.9929
Final Test LL: £-0.03402945972248071
