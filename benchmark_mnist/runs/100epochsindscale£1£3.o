dataset: MNIST
dtype: float64
dof: 0.01
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 1
x_ind shape: torch.Size([16, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.8040683429874897', 'Train Acc: 0.3264', 'Test Acc: 0.5759', 'Train LL: -1.7788336182288766', 'Test LL: -1.1734843842428502', 'Epoch Time (s): 50.18571690702811')
('Epoch 1', 'Objective: -1.1279074038800778', 'Train Acc: 0.59215', 'Test Acc: 0.6838', 'Train LL: -1.111695054949547', 'Test LL: -0.8450985241098257', 'Epoch Time (s): 50.01985053811222')
('Epoch 2', 'Objective: -0.8463454945309473', 'Train Acc: 0.70265', 'Test Acc: 0.803', 'Train LL: -0.8316029425458895', 'Test LL: -0.6060314812735058', 'Epoch Time (s): 49.9526104289107')
('Epoch 3', 'Objective: -0.6127285219100626', 'Train Acc: 0.7953333333333333', 'Test Acc: 0.8233', 'Train LL: -0.5987566138862531', 'Test LL: -0.5108764650538294', 'Epoch Time (s): 49.9453196907416')
('Epoch 4', 'Objective: -0.465278225379015', 'Train Acc: 0.8496333333333334', 'Test Acc: 0.8209', 'Train LL: -0.4520441235472136', 'Test LL: -0.5225544784101741', 'Epoch Time (s): 49.937387069221586')
('Epoch 5', 'Objective: -0.38399657888314526', 'Train Acc: 0.8778166666666667', 'Test Acc: 0.8607', 'Train LL: -0.37137497942211994', 'Test LL: -0.4191089062370232', 'Epoch Time (s): 49.881472148001194')
('Epoch 6', 'Objective: -0.3265031190832962', 'Train Acc: 0.8970666666666667', 'Test Acc: 0.9257', 'Train LL: -0.31449421943249417', 'Test LL: -0.23226447155445867', 'Epoch Time (s): 49.95947227394208')
('Epoch 7', 'Objective: -0.28505974048893806', 'Train Acc: 0.9119833333333334', 'Test Acc: 0.9117', 'Train LL: -0.27345437030671305', 'Test LL: -0.2796333955368184', 'Epoch Time (s): 49.93722697580233')
('Epoch 8', 'Objective: -0.25504157108536135', 'Train Acc: 0.92305', 'Test Acc: 0.9367', 'Train LL: -0.24370759662879565', 'Test LL: -0.19379407807686203', 'Epoch Time (s): 49.91626004781574')
('Epoch 9', 'Objective: -0.22847122135001982', 'Train Acc: 0.9316166666666666', 'Test Acc: 0.9431', 'Train LL: -0.2173506840486476', 'Test LL: -0.18659233933251426', 'Epoch Time (s): 49.921349038835615')
('Epoch 10', 'Objective: -0.21400177828928643', 'Train Acc: 0.9369833333333333', 'Test Acc: 0.9409', 'Train LL: -0.20317395017812293', 'Test LL: -0.1892606557320969', 'Epoch Time (s): 49.86090663727373')
('Epoch 11', 'Objective: -0.18970054962686247', 'Train Acc: 0.94375', 'Test Acc: 0.9584', 'Train LL: -0.1792108134124068', 'Test LL: -0.13597443921941668', 'Epoch Time (s): 49.908666542265564')
('Epoch 12', 'Objective: -0.18229238584185037', 'Train Acc: 0.9455', 'Test Acc: 0.9529', 'Train LL: -0.17197108396669308', 'Test LL: -0.14408126064258', 'Epoch Time (s): 49.93466940987855')
('Epoch 13', 'Objective: -0.16786599959859608', 'Train Acc: 0.9518', 'Test Acc: 0.9626', 'Train LL: -0.15803577961272033', 'Test LL: -0.11777100247064445', 'Epoch Time (s): 49.97836945485324')
('Epoch 14', 'Objective: -0.15924892978968846', 'Train Acc: 0.954', 'Test Acc: 0.9583', 'Train LL: -0.14961542425033583', 'Test LL: -0.1298285373802346', 'Epoch Time (s): 49.8805266181007')
('Epoch 15', 'Objective: -0.14980125838459743', 'Train Acc: 0.95555', 'Test Acc: 0.9544', 'Train LL: -0.14042176471515153', 'Test LL: -0.14051762858630146', 'Epoch Time (s): 49.892324957065284')
('Epoch 16', 'Objective: -0.1428528692581464', 'Train Acc: 0.9586', 'Test Acc: 0.95', 'Train LL: -0.133603691233973', 'Test LL: -0.15010206385049277', 'Epoch Time (s): 49.982886713929474')
('Epoch 17', 'Objective: -0.13872072182360937', 'Train Acc: 0.95915', 'Test Acc: 0.9618', 'Train LL: -0.12971032123533482', 'Test LL: -0.11890657367954155', 'Epoch Time (s): 49.98622861877084')
('Epoch 18', 'Objective: -0.1341606696161864', 'Train Acc: 0.96055', 'Test Acc: 0.9643', 'Train LL: -0.12540802166733117', 'Test LL: -0.10561883618492358', 'Epoch Time (s): 49.90867434674874')
('Epoch 19', 'Objective: -0.12843366963117997', 'Train Acc: 0.96205', 'Test Acc: 0.9568', 'Train LL: -0.11982102865937881', 'Test LL: -0.1318771321416857', 'Epoch Time (s): 49.95410221070051')
('Epoch 20', 'Objective: -0.12139677260600805', 'Train Acc: 0.9648333333333333', 'Test Acc: 0.9656', 'Train LL: -0.11290659930606867', 'Test LL: -0.10529886981586269', 'Epoch Time (s): 49.97148427693173')
('Epoch 21', 'Objective: -0.11730307745183655', 'Train Acc: 0.9661333333333333', 'Test Acc: 0.968', 'Train LL: -0.10899567908460973', 'Test LL: -0.09751369549115846', 'Epoch Time (s): 49.867497412953526')
('Epoch 22', 'Objective: -0.11262474128739262', 'Train Acc: 0.9668833333333333', 'Test Acc: 0.9696', 'Train LL: -0.10441162390189197', 'Test LL: -0.09383425863249033', 'Epoch Time (s): 49.89693598123267')
('Epoch 23', 'Objective: -0.11078081623024426', 'Train Acc: 0.9674333333333334', 'Test Acc: 0.973', 'Train LL: -0.10279785883958391', 'Test LL: -0.08559182854741554', 'Epoch Time (s): 49.949122325051576')
('Epoch 24', 'Objective: -0.10896088562578563', 'Train Acc: 0.9684666666666667', 'Test Acc: 0.9688', 'Train LL: -0.10112536799842804', 'Test LL: -0.09663751421206462', 'Epoch Time (s): 49.93577138567343')
('Epoch 25', 'Objective: -0.10517996908559218', 'Train Acc: 0.9690833333333333', 'Test Acc: 0.9693', 'Train LL: -0.09739205457651924', 'Test LL: -0.08771464631727852', 'Epoch Time (s): 49.86157499998808')
('Epoch 26', 'Objective: -0.1035396513413457', 'Train Acc: 0.9693166666666667', 'Test Acc: 0.9753', 'Train LL: -0.09580480436665002', 'Test LL: -0.0720456884092778', 'Epoch Time (s): 49.96948744589463')
('Epoch 27', 'Objective: -0.10022826020442682', 'Train Acc: 0.9704', 'Test Acc: 0.9749', 'Train LL: -0.09263825759218793', 'Test LL: -0.0802157470081098', 'Epoch Time (s): 49.971748342271894')
('Epoch 28', 'Objective: -0.09878606291176457', 'Train Acc: 0.9714166666666667', 'Test Acc: 0.9585', 'Train LL: -0.09131738295918573', 'Test LL: -0.12733512415114642', 'Epoch Time (s): 49.879198384005576')
('Epoch 29', 'Objective: -0.09362667450302076', 'Train Acc: 0.9721333333333333', 'Test Acc: 0.9768', 'Train LL: -0.08629027875892703', 'Test LL: -0.07033916828252787', 'Epoch Time (s): 49.847758647985756')
('Epoch 30', 'Objective: -0.09431777470464821', 'Train Acc: 0.9729', 'Test Acc: 0.9705', 'Train LL: -0.0870948070073166', 'Test LL: -0.09147151883320032', 'Epoch Time (s): 49.96127120172605')
('Epoch 31', 'Objective: -0.09141617916416671', 'Train Acc: 0.9731833333333333', 'Test Acc: 0.9765', 'Train LL: -0.08423473267582297', 'Test LL: -0.07347422264596623', 'Epoch Time (s): 49.92938727512956')
('Epoch 32', 'Objective: -0.0889813593315989', 'Train Acc: 0.9741', 'Test Acc: 0.9819', 'Train LL: -0.08186706349585957', 'Test LL: -0.059106239020093924', 'Epoch Time (s): 49.91061867168173')
('Epoch 33', 'Objective: -0.08823462886019728', 'Train Acc: 0.9749333333333333', 'Test Acc: 0.9777', 'Train LL: -0.08126803292791157', 'Test LL: -0.07381650993788082', 'Epoch Time (s): 49.94474135711789')
('Epoch 34', 'Objective: -0.0865755698700581', 'Train Acc: 0.9747333333333333', 'Test Acc: 0.967', 'Train LL: -0.07974892775969368', 'Test LL: -0.0929385991475937', 'Epoch Time (s): 49.890623239800334')
('Epoch 35', 'Objective: -0.08493495060947856', 'Train Acc: 0.97545', 'Test Acc: 0.9793', 'Train LL: -0.07804501014926796', 'Test LL: -0.06271417398941392', 'Epoch Time (s): 49.93867918336764')
('Epoch 36', 'Objective: -0.08389775843070928', 'Train Acc: 0.9753666666666667', 'Test Acc: 0.974', 'Train LL: -0.07703203069663325', 'Test LL: -0.07581038422299775', 'Epoch Time (s): 49.88280556583777')
('Epoch 37', 'Objective: -0.08377576826774678', 'Train Acc: 0.9757333333333333', 'Test Acc: 0.9778', 'Train LL: -0.07700756894968701', 'Test LL: -0.0662649026776607', 'Epoch Time (s): 49.969254387076944')
('Epoch 38', 'Objective: -0.08200128472791995', 'Train Acc: 0.97565', 'Test Acc: 0.9733', 'Train LL: -0.07538767153073622', 'Test LL: -0.08300625638015295', 'Epoch Time (s): 49.870801103301346')
('Epoch 39', 'Objective: -0.08061854979567827', 'Train Acc: 0.9763166666666667', 'Test Acc: 0.9795', 'Train LL: -0.0740004554230979', 'Test LL: -0.0654309558382127', 'Epoch Time (s): 49.94496707897633')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.054403300236607215', 'Train Acc: 0.9847166666666667', 'Test Acc: 0.9863', 'Train LL: -0.04846662864989189', 'Test LL: -0.03962537977190678', 'Epoch Time (s): 49.91172475600615')
('Epoch 41', 'Objective: -0.04865381956059843', 'Train Acc: 0.98635', 'Test Acc: 0.9863', 'Train LL: -0.04292315348294232', 'Test LL: -0.03812797384348853', 'Epoch Time (s): 49.91254630498588')
('Epoch 42', 'Objective: -0.047045739605629716', 'Train Acc: 0.9867666666666667', 'Test Acc: 0.9874', 'Train LL: -0.04149127050310355', 'Test LL: -0.036852226694992156', 'Epoch Time (s): 49.92962162382901')
('Epoch 43', 'Objective: -0.04627861258213337', 'Train Acc: 0.9866333333333334', 'Test Acc: 0.9863', 'Train LL: -0.040866967588477555', 'Test LL: -0.041949444499381525', 'Epoch Time (s): 49.9786280291155')
('Epoch 44', 'Objective: -0.044313539734805264', 'Train Acc: 0.9870166666666667', 'Test Acc: 0.9878', 'Train LL: -0.03898993920761957', 'Test LL: -0.038760083264926505', 'Epoch Time (s): 49.95561042102054')
('Epoch 45', 'Objective: -0.043258445886952754', 'Train Acc: 0.9872833333333333', 'Test Acc: 0.988', 'Train LL: -0.0380000674792085', 'Test LL: -0.03628024630735927', 'Epoch Time (s): 49.893865378107876')
('Epoch 46', 'Objective: -0.043510729277174476', 'Train Acc: 0.9874666666666667', 'Test Acc: 0.9873', 'Train LL: -0.03832716010354327', 'Test LL: -0.036894994895160335', 'Epoch Time (s): 50.008148225955665')
('Epoch 47', 'Objective: -0.043177500712119385', 'Train Acc: 0.9879166666666667', 'Test Acc: 0.9867', 'Train LL: -0.038071873408983686', 'Test LL: -0.04312387368229453', 'Epoch Time (s): 49.85769479488954')
('Epoch 48', 'Objective: -0.042678515300644516', 'Train Acc: 0.9878833333333333', 'Test Acc: 0.9878', 'Train LL: -0.037665639120130226', 'Test LL: -0.03761448380334768', 'Epoch Time (s): 49.86002536397427')
('Epoch 49', 'Objective: -0.043264108161069625', 'Train Acc: 0.9878166666666667', 'Test Acc: 0.9874', 'Train LL: -0.038268600196958186', 'Test LL: -0.03701381970160352', 'Epoch Time (s): 49.905122513417155')
('Epoch 50', 'Objective: -0.04274972434915474', 'Train Acc: 0.9881', 'Test Acc: 0.9878', 'Train LL: -0.037815814534780466', 'Test LL: -0.03640460778136341', 'Epoch Time (s): 49.91329786879942')
('Epoch 51', 'Objective: -0.04148361343454053', 'Train Acc: 0.9882666666666666', 'Test Acc: 0.9879', 'Train LL: -0.03663828998766567', 'Test LL: -0.035675629520036056', 'Epoch Time (s): 49.901376080233604')
('Epoch 52', 'Objective: -0.041373130428667915', 'Train Acc: 0.9885833333333334', 'Test Acc: 0.9884', 'Train LL: -0.03652373085043047', 'Test LL: -0.035744242480877986', 'Epoch Time (s): 49.96419306797907')
('Epoch 53', 'Objective: -0.04065396557984845', 'Train Acc: 0.9882', 'Test Acc: 0.9871', 'Train LL: -0.035806978935996346', 'Test LL: -0.03857384804863315', 'Epoch Time (s): 49.99305266793817')
('Epoch 54', 'Objective: -0.04115725075119807', 'Train Acc: 0.988', 'Test Acc: 0.9868', 'Train LL: -0.03635138594196635', 'Test LL: -0.03820512673316698', 'Epoch Time (s): 49.89574306970462')
('Epoch 55', 'Objective: -0.039902524705822714', 'Train Acc: 0.9885333333333334', 'Test Acc: 0.988', 'Train LL: -0.03516764751558646', 'Test LL: -0.03535377770040255', 'Epoch Time (s): 49.621794232167304')
('Epoch 56', 'Objective: -0.04049675053851498', 'Train Acc: 0.9881166666666666', 'Test Acc: 0.9868', 'Train LL: -0.03572747369220821', 'Test LL: -0.04032175533427489', 'Epoch Time (s): 49.9626640509814')
('Epoch 57', 'Objective: -0.04032890890331434', 'Train Acc: 0.9881', 'Test Acc: 0.9855', 'Train LL: -0.03558004677437201', 'Test LL: -0.04099735276941697', 'Epoch Time (s): 49.84945268323645')
('Epoch 58', 'Objective: -0.0398502733089024', 'Train Acc: 0.9884666666666667', 'Test Acc: 0.9874', 'Train LL: -0.03513597020123365', 'Test LL: -0.0367829595098356', 'Epoch Time (s): 49.89299494866282')
('Epoch 59', 'Objective: -0.04109281368841771', 'Train Acc: 0.9883', 'Test Acc: 0.9882', 'Train LL: -0.03639869278617623', 'Test LL: -0.03473862669433298', 'Epoch Time (s): 49.9253099556081')
('Epoch 60', 'Objective: -0.04038334306790409', 'Train Acc: 0.9888', 'Test Acc: 0.9881', 'Train LL: -0.03576618907624857', 'Test LL: -0.03633949195182028', 'Epoch Time (s): 50.037348405923694')
('Epoch 61', 'Objective: -0.0392029729925479', 'Train Acc: 0.989', 'Test Acc: 0.9875', 'Train LL: -0.034611249353555196', 'Test LL: -0.0378826083191241', 'Epoch Time (s): 49.940255974885076')
('Epoch 62', 'Objective: -0.03989563922268715', 'Train Acc: 0.9883166666666666', 'Test Acc: 0.9887', 'Train LL: -0.03528885249130034', 'Test LL: -0.03612185348286314', 'Epoch Time (s): 49.96346216695383')
('Epoch 63', 'Objective: -0.0394799565964945', 'Train Acc: 0.9887666666666667', 'Test Acc: 0.9882', 'Train LL: -0.03497864414262702', 'Test LL: -0.034998583082039986', 'Epoch Time (s): 50.026493387296796')
('Epoch 64', 'Objective: -0.03950100340362109', 'Train Acc: 0.98825', 'Test Acc: 0.9882', 'Train LL: -0.03499594613326671', 'Test LL: -0.035837165748541795', 'Epoch Time (s): 49.8706766711548')
('Epoch 65', 'Objective: -0.038691379922222664', 'Train Acc: 0.9888666666666667', 'Test Acc: 0.9874', 'Train LL: -0.034209758456616626', 'Test LL: -0.036278668110715444', 'Epoch Time (s): 49.90314245223999')
('Epoch 66', 'Objective: -0.03836670440322855', 'Train Acc: 0.9886166666666667', 'Test Acc: 0.989', 'Train LL: -0.03386348568064305', 'Test LL: -0.03294021349049225', 'Epoch Time (s): 49.85151514504105')
('Epoch 67', 'Objective: -0.03752393602604912', 'Train Acc: 0.9891333333333333', 'Test Acc: 0.9887', 'Train LL: -0.03303480489207862', 'Test LL: -0.03241242387280401', 'Epoch Time (s): 50.09396129893139')
('Epoch 68', 'Objective: -0.03749334872762094', 'Train Acc: 0.9891333333333333', 'Test Acc: 0.9891', 'Train LL: -0.033048617461148344', 'Test LL: -0.03571133644875943', 'Epoch Time (s): 49.94174211565405')
('Epoch 69', 'Objective: -0.037851800898002635', 'Train Acc: 0.98905', 'Test Acc: 0.9888', 'Train LL: -0.0334170713401188', 'Test LL: -0.03512841779119625', 'Epoch Time (s): 49.89590183319524')
('Epoch 70', 'Objective: -0.038593963629558956', 'Train Acc: 0.9885166666666667', 'Test Acc: 0.9876', 'Train LL: -0.034171505941380007', 'Test LL: -0.038637664204539894', 'Epoch Time (s): 49.93985519791022')
('Epoch 71', 'Objective: -0.0378108357138582', 'Train Acc: 0.9890666666666666', 'Test Acc: 0.9876', 'Train LL: -0.03343519013028403', 'Test LL: -0.03801990257532286', 'Epoch Time (s): 49.87669333489612')
('Epoch 72', 'Objective: -0.03730156138084143', 'Train Acc: 0.98895', 'Test Acc: 0.9873', 'Train LL: -0.032915772122533514', 'Test LL: -0.038141430158796855', 'Epoch Time (s): 49.96082049096003')
('Epoch 73', 'Objective: -0.03797335593339006', 'Train Acc: 0.98905', 'Test Acc: 0.987', 'Train LL: -0.0336116440675839', 'Test LL: -0.0375710092725099', 'Epoch Time (s): 49.91018987772986')
('Epoch 74', 'Objective: -0.03734305991791456', 'Train Acc: 0.9890666666666666', 'Test Acc: 0.9878', 'Train LL: -0.0329606163568324', 'Test LL: -0.037697982697434476', 'Epoch Time (s): 49.94187053665519')
('Epoch 75', 'Objective: -0.03664161447914403', 'Train Acc: 0.9891166666666666', 'Test Acc: 0.9876', 'Train LL: -0.03230313315311181', 'Test LL: -0.038959638321968325', 'Epoch Time (s): 49.914376405999064')
('Epoch 76', 'Objective: -0.037486287653735136', 'Train Acc: 0.9889666666666667', 'Test Acc: 0.9875', 'Train LL: -0.033130339937632', 'Test LL: -0.03635948625147125', 'Epoch Time (s): 49.99798096297309')
('Epoch 77', 'Objective: -0.03675692098774032', 'Train Acc: 0.989', 'Test Acc: 0.9885', 'Train LL: -0.03245758668486333', 'Test LL: -0.034411626217064166', 'Epoch Time (s): 49.97215633187443')
('Epoch 78', 'Objective: -0.03706353623719401', 'Train Acc: 0.9891166666666666', 'Test Acc: 0.9883', 'Train LL: -0.032742044675683764', 'Test LL: -0.036098524670731616', 'Epoch Time (s): 49.989031756296754')
('Epoch 79', 'Objective: -0.037573204559099134', 'Train Acc: 0.9892333333333333', 'Test Acc: 0.9883', 'Train LL: -0.03327822574978555', 'Test LL: -0.03573575344399832', 'Epoch Time (s): 49.86220705835149')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.033922338726445185', 'Train Acc: 0.9900666666666667', 'Test Acc: 0.9884', 'Train LL: -0.02969365780148093', 'Test LL: -0.03427643370010941', 'Epoch Time (s): 50.009223859291524')
('Epoch 81', 'Objective: -0.03363484046462762', 'Train Acc: 0.9904333333333334', 'Test Acc: 0.9886', 'Train LL: -0.029419937912381084', 'Test LL: -0.033477192591354406', 'Epoch Time (s): 50.013982941396534')
('Epoch 82', 'Objective: -0.03285303260286733', 'Train Acc: 0.9909', 'Test Acc: 0.9889', 'Train LL: -0.028677248243807775', 'Test LL: -0.03356163594915178', 'Epoch Time (s): 49.9103818773292')
('Epoch 83', 'Objective: -0.032949781954928536', 'Train Acc: 0.9908333333333333', 'Test Acc: 0.9878', 'Train LL: -0.02874768362740406', 'Test LL: -0.03520188664391972', 'Epoch Time (s): 49.962514056358486')
('Epoch 84', 'Objective: -0.032957895742906175', 'Train Acc: 0.9905', 'Test Acc: 0.9885', 'Train LL: -0.028760137527642768', 'Test LL: -0.03425972807573664', 'Epoch Time (s): 49.97378982370719')
('Epoch 85', 'Objective: -0.032202670093777745', 'Train Acc: 0.9909833333333333', 'Test Acc: 0.9888', 'Train LL: -0.028030258517134858', 'Test LL: -0.033362790199592186', 'Epoch Time (s): 50.02039114898071')
('Epoch 86', 'Objective: -0.03279117452804787', 'Train Acc: 0.9904166666666666', 'Test Acc: 0.9886', 'Train LL: -0.028600362858834143', 'Test LL: -0.033706444775813416', 'Epoch Time (s): 49.94593313476071')
('Epoch 87', 'Objective: -0.032675462308611736', 'Train Acc: 0.9906833333333334', 'Test Acc: 0.9886', 'Train LL: -0.028501589624379747', 'Test LL: -0.034113400589183426', 'Epoch Time (s): 49.8506556879729')
('Epoch 88', 'Objective: -0.03204382114117415', 'Train Acc: 0.9909166666666667', 'Test Acc: 0.9878', 'Train LL: -0.027870408520267967', 'Test LL: -0.035001290393307134', 'Epoch Time (s): 49.86987544503063')
('Epoch 89', 'Objective: -0.03273552098041564', 'Train Acc: 0.9905166666666667', 'Test Acc: 0.9885', 'Train LL: -0.02854861758672731', 'Test LL: -0.03468587109377234', 'Epoch Time (s): 49.80836887797341')
('Epoch 90', 'Objective: -0.03232048742574941', 'Train Acc: 0.9904833333333334', 'Test Acc: 0.9888', 'Train LL: -0.028122435514434146', 'Test LL: -0.03441542934194573', 'Epoch Time (s): 49.91957074403763')
('Epoch 91', 'Objective: -0.031090568970352356', 'Train Acc: 0.9912833333333333', 'Test Acc: 0.9886', 'Train LL: -0.026933494698549353', 'Test LL: -0.034121822113696215', 'Epoch Time (s): 49.99082138063386')
('Epoch 92', 'Objective: -0.03257493851074221', 'Train Acc: 0.9910166666666667', 'Test Acc: 0.9892', 'Train LL: -0.028399569654124428', 'Test LL: -0.03386071712780339', 'Epoch Time (s): 49.94981227768585')
('Epoch 93', 'Objective: -0.03171562875616459', 'Train Acc: 0.9904666666666667', 'Test Acc: 0.9894', 'Train LL: -0.02754748700109412', 'Test LL: -0.03448132081597444', 'Epoch Time (s): 49.89621781790629')
('Epoch 94', 'Objective: -0.031373990343934934', 'Train Acc: 0.9907833333333333', 'Test Acc: 0.9887', 'Train LL: -0.02720534479274914', 'Test LL: -0.03431814978740025', 'Epoch Time (s): 49.99444903386757')
('Epoch 95', 'Objective: -0.03171680751926757', 'Train Acc: 0.99105', 'Test Acc: 0.9882', 'Train LL: -0.027536066301147157', 'Test LL: -0.03533478617649867', 'Epoch Time (s): 49.96882199216634')
('Epoch 96', 'Objective: -0.0322221289747824', 'Train Acc: 0.9909333333333333', 'Test Acc: 0.9888', 'Train LL: -0.028053176888625263', 'Test LL: -0.03375857096981493', 'Epoch Time (s): 50.094205289147794')
('Epoch 97', 'Objective: -0.031477204038317635', 'Train Acc: 0.9909', 'Test Acc: 0.9888', 'Train LL: -0.02730634173203727', 'Test LL: -0.03474321587760161', 'Epoch Time (s): 49.89526366814971')
('Epoch 98', 'Objective: -0.03286153000851244', 'Train Acc: 0.9905833333333334', 'Test Acc: 0.9886', 'Train LL: -0.028646892682429773', 'Test LL: -0.03470644782017435', 'Epoch Time (s): 50.02228646911681')
('Epoch 99', 'Objective: -0.0322244904053887', 'Train Acc: 0.99085', 'Test Acc: 0.9889', 'Train LL: -0.028018524185748097', 'Test LL: -0.0348556589797578', 'Epoch Time (s): 49.970780053175986')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03131082292016323
Final Train Accuracy: £0.9911666666666666
Final Train LL: £-0.027158348690529528
Final Test Accuracy: £0.9887
Final Test LL: £-0.034989784098486715
