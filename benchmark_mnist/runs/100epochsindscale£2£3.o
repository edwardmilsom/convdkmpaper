dataset: MNIST
dtype: float64
dof: 0.01
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 2
x_ind shape: torch.Size([32, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.6665819196784761', 'Train Acc: 0.3851833333333333', 'Test Acc: 0.653', 'Train LL: -1.6416757559468478', 'Test LL: -1.0080761689628512', 'Epoch Time (s): 58.844244921114296')
('Epoch 1', 'Objective: -0.8809482911978063', 'Train Acc: 0.6969166666666666', 'Test Acc: 0.7515', 'Train LL: -0.864533281098904', 'Test LL: -0.7367357547609266', 'Epoch Time (s): 58.81811709376052')
('Epoch 2', 'Objective: -0.633230203725156', 'Train Acc: 0.7930833333333334', 'Test Acc: 0.8417', 'Train LL: -0.6182326826726272', 'Test LL: -0.4710534674042408', 'Epoch Time (s): 58.84705530339852')
('Epoch 3', 'Objective: -0.43926910976476957', 'Train Acc: 0.8584166666666667', 'Test Acc: 0.8576', 'Train LL: -0.4252854757303648', 'Test LL: -0.41328794296159904', 'Epoch Time (s): 58.81560473330319')
('Epoch 4', 'Objective: -0.32783241039194333', 'Train Acc: 0.8985666666666666', 'Test Acc: 0.9129', 'Train LL: -0.3145503498287687', 'Test LL: -0.26836230777238523', 'Epoch Time (s): 58.79002325376496')
('Epoch 5', 'Objective: -0.2615973857912679', 'Train Acc: 0.9219333333333334', 'Test Acc: 0.9194', 'Train LL: -0.2488073743926982', 'Test LL: -0.2520047057563357', 'Epoch Time (s): 58.81117955595255')
('Epoch 6', 'Objective: -0.2252546519438486', 'Train Acc: 0.9340333333333334', 'Test Acc: 0.9492', 'Train LL: -0.21291547957806536', 'Test LL: -0.16263373477547904', 'Epoch Time (s): 58.794828824698925')
('Epoch 7', 'Objective: -0.20493761583376263', 'Train Acc: 0.9385', 'Test Acc: 0.9402', 'Train LL: -0.19298546046275503', 'Test LL: -0.1763756862645551', 'Epoch Time (s): 58.78671408398077')
('Epoch 8', 'Objective: -0.17914484215134993', 'Train Acc: 0.9466333333333333', 'Test Acc: 0.9562', 'Train LL: -0.1677295380772022', 'Test LL: -0.13240582837706721', 'Epoch Time (s): 58.798288066871464')
('Epoch 9', 'Objective: -0.15959810452959944', 'Train Acc: 0.9533166666666667', 'Test Acc: 0.9618', 'Train LL: -0.14880880640523353', 'Test LL: -0.12231892462879575', 'Epoch Time (s): 58.7979651899077')
('Epoch 10', 'Objective: -0.1497935037502762', 'Train Acc: 0.9558', 'Test Acc: 0.9413', 'Train LL: -0.13939527515792813', 'Test LL: -0.18193681906193102', 'Epoch Time (s): 58.80542927887291')
('Epoch 11', 'Objective: -0.1368291739792408', 'Train Acc: 0.96025', 'Test Acc: 0.9756', 'Train LL: -0.12696284142705336', 'Test LL: -0.07837375653701277', 'Epoch Time (s): 58.767273993231356')
('Epoch 12', 'Objective: -0.12849064451955075', 'Train Acc: 0.9622', 'Test Acc: 0.9721', 'Train LL: -0.11889397928340446', 'Test LL: -0.08737132233086711', 'Epoch Time (s): 58.78926132665947')
('Epoch 13', 'Objective: -0.11988963466250173', 'Train Acc: 0.9647666666666667', 'Test Acc: 0.9716', 'Train LL: -0.11065461954103077', 'Test LL: -0.0876439112132051', 'Epoch Time (s): 58.76133970590308')
('Epoch 14', 'Objective: -0.11451151871765737', 'Train Acc: 0.9664666666666667', 'Test Acc: 0.9683', 'Train LL: -0.10568501659071321', 'Test LL: -0.09915203401417345', 'Epoch Time (s): 58.79938759095967')
('Epoch 15', 'Objective: -0.10615486392585854', 'Train Acc: 0.9686333333333333', 'Test Acc: 0.9694', 'Train LL: -0.09754064796338821', 'Test LL: -0.09921482996325426', 'Epoch Time (s): 58.771201683208346')
('Epoch 16', 'Objective: -0.10218341786722322', 'Train Acc: 0.9701666666666666', 'Test Acc: 0.9763', 'Train LL: -0.09383560579135113', 'Test LL: -0.07686272906610778', 'Epoch Time (s): 58.75588775891811')
('Epoch 17', 'Objective: -0.09875791909415688', 'Train Acc: 0.9717', 'Test Acc: 0.9737', 'Train LL: -0.09064123853838336', 'Test LL: -0.08338931969597753', 'Epoch Time (s): 58.793351856060326')
('Epoch 18', 'Objective: -0.09614120795697544', 'Train Acc: 0.97245', 'Test Acc: 0.9724', 'Train LL: -0.08820119128545818', 'Test LL: -0.08529500748552078', 'Epoch Time (s): 58.78959630802274')
('Epoch 19', 'Objective: -0.0928230991577976', 'Train Acc: 0.9730166666666666', 'Test Acc: 0.971', 'Train LL: -0.08510709675997272', 'Test LL: -0.09284794900770796', 'Epoch Time (s): 58.7833784413524')
('Epoch 20', 'Objective: -0.08927525206659699', 'Train Acc: 0.9741166666666666', 'Test Acc: 0.9759', 'Train LL: -0.08178654671423741', 'Test LL: -0.0773417054271097', 'Epoch Time (s): 58.78848170302808')
('Epoch 21', 'Objective: -0.08551883468842719', 'Train Acc: 0.9750666666666666', 'Test Acc: 0.9751', 'Train LL: -0.07812066228010836', 'Test LL: -0.07315542777025318', 'Epoch Time (s): 58.773027344141155')
('Epoch 22', 'Objective: -0.0826376014862277', 'Train Acc: 0.9758166666666667', 'Test Acc: 0.9773', 'Train LL: -0.07539913873755849', 'Test LL: -0.0698946054150844', 'Epoch Time (s): 58.79054827708751')
('Epoch 23', 'Objective: -0.08074630206196981', 'Train Acc: 0.9761333333333333', 'Test Acc: 0.9762', 'Train LL: -0.0737265370960854', 'Test LL: -0.07058868622080813', 'Epoch Time (s): 58.8068574918434')
('Epoch 24', 'Objective: -0.07792018220508988', 'Train Acc: 0.9767666666666667', 'Test Acc: 0.9791', 'Train LL: -0.07099648405469876', 'Test LL: -0.06656488896849908', 'Epoch Time (s): 58.791616164147854')
('Epoch 25', 'Objective: -0.07659250739130131', 'Train Acc: 0.9776833333333333', 'Test Acc: 0.9768', 'Train LL: -0.06983792634296318', 'Test LL: -0.06871349258783796', 'Epoch Time (s): 58.78440922824666')
('Epoch 26', 'Objective: -0.07706542142735479', 'Train Acc: 0.97775', 'Test Acc: 0.9815', 'Train LL: -0.07040523549779544', 'Test LL: -0.05630866339807218', 'Epoch Time (s): 58.80041686585173')
('Epoch 27', 'Objective: -0.07292038768802314', 'Train Acc: 0.9789333333333333', 'Test Acc: 0.9802', 'Train LL: -0.06642166827064439', 'Test LL: -0.062455362360087134', 'Epoch Time (s): 58.79896342381835')
('Epoch 28', 'Objective: -0.07281054630128837', 'Train Acc: 0.9786833333333333', 'Test Acc: 0.9789', 'Train LL: -0.06640265246935477', 'Test LL: -0.06647040912821994', 'Epoch Time (s): 58.79622660204768')
('Epoch 29', 'Objective: -0.07030859274511594', 'Train Acc: 0.9794666666666667', 'Test Acc: 0.9848', 'Train LL: -0.06402789866245345', 'Test LL: -0.047532210941686526', 'Epoch Time (s): 58.81500511104241')
('Epoch 30', 'Objective: -0.07046731768453093', 'Train Acc: 0.9793', 'Test Acc: 0.9768', 'Train LL: -0.06428239941708215', 'Test LL: -0.07271731648089272', 'Epoch Time (s): 58.77409409219399')
('Epoch 31', 'Objective: -0.06673612728697469', 'Train Acc: 0.9806166666666667', 'Test Acc: 0.976', 'Train LL: -0.06066717155947615', 'Test LL: -0.07805703008747746', 'Epoch Time (s): 58.77343639591709')
('Epoch 32', 'Objective: -0.06717335427815957', 'Train Acc: 0.98015', 'Test Acc: 0.9824', 'Train LL: -0.06110416915071752', 'Test LL: -0.055765574426482035', 'Epoch Time (s): 58.79672695416957')
('Epoch 33', 'Objective: -0.06621283261219946', 'Train Acc: 0.9808166666666667', 'Test Acc: 0.9879', 'Train LL: -0.06025149859430773', 'Test LL: -0.0392063668868804', 'Epoch Time (s): 58.780182626098394')
('Epoch 34', 'Objective: -0.0638137102830587', 'Train Acc: 0.9814333333333334', 'Test Acc: 0.978', 'Train LL: -0.05792931579513599', 'Test LL: -0.06547157721757067', 'Epoch Time (s): 58.78500409889966')
('Epoch 35', 'Objective: -0.06506283629901678', 'Train Acc: 0.9810833333333333', 'Test Acc: 0.9778', 'Train LL: -0.05930850646115702', 'Test LL: -0.06857828487928615', 'Epoch Time (s): 58.797352210152894')
('Epoch 36', 'Objective: -0.062305215869212116', 'Train Acc: 0.9818666666666667', 'Test Acc: 0.9777', 'Train LL: -0.0566268323117965', 'Test LL: -0.06476298815290261', 'Epoch Time (s): 58.817407296039164')
('Epoch 37', 'Objective: -0.06120777577311289', 'Train Acc: 0.98195', 'Test Acc: 0.9831', 'Train LL: -0.055662599646622166', 'Test LL: -0.04818902127118007', 'Epoch Time (s): 58.783420713152736')
('Epoch 38', 'Objective: -0.059727230761810406', 'Train Acc: 0.9825833333333334', 'Test Acc: 0.9809', 'Train LL: -0.05421817578188676', 'Test LL: -0.05674034375498418', 'Epoch Time (s): 58.81023040600121')
('Epoch 39', 'Objective: -0.0612610654072626', 'Train Acc: 0.9819', 'Test Acc: 0.9853', 'Train LL: -0.05574778073935606', 'Test LL: -0.04476378335514074', 'Epoch Time (s): 58.80360301909968')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.04027665059612278', 'Train Acc: 0.9882833333333333', 'Test Acc: 0.989', 'Train LL: -0.035394586633809705', 'Test LL: -0.03265280787452881', 'Epoch Time (s): 58.779082999099046')
('Epoch 41', 'Objective: -0.035543831634201085', 'Train Acc: 0.9900333333333333', 'Test Acc: 0.9883', 'Train LL: -0.03083950998347125', 'Test LL: -0.03503955923726917', 'Epoch Time (s): 58.804640769958496')
('Epoch 42', 'Objective: -0.03386023929015635', 'Train Acc: 0.9907333333333334', 'Test Acc: 0.988', 'Train LL: -0.029283801775949456', 'Test LL: -0.0373718822826081', 'Epoch Time (s): 58.78775744466111')
('Epoch 43', 'Objective: -0.03245743296681683', 'Train Acc: 0.9912166666666666', 'Test Acc: 0.9881', 'Train LL: -0.02799129370827261', 'Test LL: -0.03296849672557877', 'Epoch Time (s): 58.754719683900476')
('Epoch 44', 'Objective: -0.03142100383811669', 'Train Acc: 0.99105', 'Test Acc: 0.9899', 'Train LL: -0.0269808317926246', 'Test LL: -0.03191176937867909', 'Epoch Time (s): 58.734076985158026')
('Epoch 45', 'Objective: -0.03103449489970268', 'Train Acc: 0.99075', 'Test Acc: 0.9892', 'Train LL: -0.02666066524618755', 'Test LL: -0.032971172797003484', 'Epoch Time (s): 58.80951449414715')
('Epoch 46', 'Objective: -0.030244124509452065', 'Train Acc: 0.9911333333333333', 'Test Acc: 0.9898', 'Train LL: -0.02594614958953856', 'Test LL: -0.03137203158477783', 'Epoch Time (s): 58.767703695222735')
('Epoch 47', 'Objective: -0.030275441017918577', 'Train Acc: 0.9916333333333334', 'Test Acc: 0.9894', 'Train LL: -0.0260501266247543', 'Test LL: -0.03145176063287413', 'Epoch Time (s): 58.76152857672423')
('Epoch 48', 'Objective: -0.02941120277225824', 'Train Acc: 0.9915833333333334', 'Test Acc: 0.9883', 'Train LL: -0.025253220546734994', 'Test LL: -0.03534077741663246', 'Epoch Time (s): 58.793486376758665')
('Epoch 49', 'Objective: -0.030750653894351356', 'Train Acc: 0.9912333333333333', 'Test Acc: 0.9901', 'Train LL: -0.026592769558079446', 'Test LL: -0.03212419954958102', 'Epoch Time (s): 58.763282102998346')
('Epoch 50', 'Objective: -0.029637906990679044', 'Train Acc: 0.9916333333333334', 'Test Acc: 0.9898', 'Train LL: -0.025504529749271917', 'Test LL: -0.03207236708764495', 'Epoch Time (s): 58.772470333613455')
('Epoch 51', 'Objective: -0.028852258064500418', 'Train Acc: 0.992', 'Test Acc: 0.9885', 'Train LL: -0.02473371116167401', 'Test LL: -0.03522491342429914', 'Epoch Time (s): 58.78802266670391')
('Epoch 52', 'Objective: -0.028972538388858937', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.99', 'Train LL: -0.02489751716086135', 'Test LL: -0.03114881708729399', 'Epoch Time (s): 58.771439276169986')
('Epoch 53', 'Objective: -0.028400484251019008', 'Train Acc: 0.99225', 'Test Acc: 0.9905', 'Train LL: -0.02438242097207872', 'Test LL: -0.028653943362407494', 'Epoch Time (s): 58.795316125731915')
('Epoch 54', 'Objective: -0.028004115281887502', 'Train Acc: 0.9922333333333333', 'Test Acc: 0.9908', 'Train LL: -0.024026012368764157', 'Test LL: -0.029048068861303535', 'Epoch Time (s): 58.76805531606078')
('Epoch 55', 'Objective: -0.027726535198194745', 'Train Acc: 0.99225', 'Test Acc: 0.9884', 'Train LL: -0.023763913307468007', 'Test LL: -0.0329023065069845', 'Epoch Time (s): 58.79771472513676')
('Epoch 56', 'Objective: -0.02736124997417988', 'Train Acc: 0.99225', 'Test Acc: 0.9912', 'Train LL: -0.023394051274827975', 'Test LL: -0.027100968300533317', 'Epoch Time (s): 58.800578858703375')
('Epoch 57', 'Objective: -0.027970762181079942', 'Train Acc: 0.9920833333333333', 'Test Acc: 0.9906', 'Train LL: -0.02401876474156297', 'Test LL: -0.030185863478504427', 'Epoch Time (s): 58.780120875220746')
('Epoch 58', 'Objective: -0.02626404363779635', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9898', 'Train LL: -0.02237396164462773', 'Test LL: -0.03261305002125664', 'Epoch Time (s): 58.77674604114145')
('Epoch 59', 'Objective: -0.02684058992979184', 'Train Acc: 0.99245', 'Test Acc: 0.9908', 'Train LL: -0.022937457007412426', 'Test LL: -0.02966933226542919', 'Epoch Time (s): 58.774506581015885')
('Epoch 60', 'Objective: -0.026603792136012543', 'Train Acc: 0.99215', 'Test Acc: 0.9899', 'Train LL: -0.02272159299381376', 'Test LL: -0.031177582805470058', 'Epoch Time (s): 58.80772432871163')
('Epoch 61', 'Objective: -0.02600523228052139', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9908', 'Train LL: -0.022154485906786977', 'Test LL: -0.02905849106396368', 'Epoch Time (s): 58.79679162893444')
('Epoch 62', 'Objective: -0.026381648488656397', 'Train Acc: 0.9924', 'Test Acc: 0.9903', 'Train LL: -0.022534087734236444', 'Test LL: -0.03008788987349091', 'Epoch Time (s): 58.78543764166534')
('Epoch 63', 'Objective: -0.02650498401777222', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9905', 'Train LL: -0.02263663680852172', 'Test LL: -0.029735958709080905', 'Epoch Time (s): 58.75930007779971')
('Epoch 64', 'Objective: -0.02539531362068544', 'Train Acc: 0.9929', 'Test Acc: 0.9909', 'Train LL: -0.021554142808809535', 'Test LL: -0.031860206284363826', 'Epoch Time (s): 58.77865842729807')
('Epoch 65', 'Objective: -0.0256763631522652', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9904', 'Train LL: -0.021868324729136437', 'Test LL: -0.02795580372810777', 'Epoch Time (s): 58.810918857343495')
('Epoch 66', 'Objective: -0.02482907807604144', 'Train Acc: 0.9935', 'Test Acc: 0.9901', 'Train LL: -0.0210661877664769', 'Test LL: -0.0309978019803003', 'Epoch Time (s): 58.76189777208492')
('Epoch 67', 'Objective: -0.025757876503453667', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9894', 'Train LL: -0.021971715093668426', 'Test LL: -0.03152545626272206', 'Epoch Time (s): 58.79760186513886')
('Epoch 68', 'Objective: -0.025604190543444535', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9888', 'Train LL: -0.02182332060390514', 'Test LL: -0.03248879737005497', 'Epoch Time (s): 58.79398117866367')
('Epoch 69', 'Objective: -0.02570109154497057', 'Train Acc: 0.99275', 'Test Acc: 0.9904', 'Train LL: -0.021933940562223454', 'Test LL: -0.030810470344564266', 'Epoch Time (s): 58.81632203375921')
('Epoch 70', 'Objective: -0.024430460283641466', 'Train Acc: 0.9931', 'Test Acc: 0.9901', 'Train LL: -0.02066450032406205', 'Test LL: -0.033220342530252585', 'Epoch Time (s): 58.816976823844016')
('Epoch 71', 'Objective: -0.02450878111091023', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9887', 'Train LL: -0.020752590160079906', 'Test LL: -0.03387429345973058', 'Epoch Time (s): 58.80688862223178')
('Epoch 72', 'Objective: -0.02459582492589376', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9913', 'Train LL: -0.02085232213396577', 'Test LL: -0.028911343816782255', 'Epoch Time (s): 58.78459117887542')
('Epoch 73', 'Objective: -0.02464088349725287', 'Train Acc: 0.9931833333333333', 'Test Acc: 0.9895', 'Train LL: -0.020925582811654575', 'Test LL: -0.03232523224887601', 'Epoch Time (s): 58.78198872692883')
('Epoch 74', 'Objective: -0.02445681449005056', 'Train Acc: 0.9932', 'Test Acc: 0.9902', 'Train LL: -0.020766290203421994', 'Test LL: -0.029726205578877837', 'Epoch Time (s): 58.79509286908433')
('Epoch 75', 'Objective: -0.025081224059064478', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9917', 'Train LL: -0.021361852726937514', 'Test LL: -0.026853960296525405', 'Epoch Time (s): 58.79860334703699')
('Epoch 76', 'Objective: -0.024322350790395495', 'Train Acc: 0.9930666666666667', 'Test Acc: 0.9902', 'Train LL: -0.02063920613215619', 'Test LL: -0.031584916677884024', 'Epoch Time (s): 58.80187483690679')
('Epoch 77', 'Objective: -0.02402579941148901', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.9905', 'Train LL: -0.02035848599465957', 'Test LL: -0.029652723912610004', 'Epoch Time (s): 58.762661792803556')
('Epoch 78', 'Objective: -0.023911127791578925', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.99', 'Train LL: -0.02025834200598488', 'Test LL: -0.03267278501448247', 'Epoch Time (s): 58.76434348896146')
('Epoch 79', 'Objective: -0.0233472091447118', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.9904', 'Train LL: -0.019711812623197194', 'Test LL: -0.031058281355938425', 'Epoch Time (s): 58.73978519998491')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.021600517318670576', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.9901', 'Train LL: -0.018048259570861185', 'Test LL: -0.03040647244209897', 'Epoch Time (s): 58.79094473225996')
('Epoch 81', 'Objective: -0.02122460654830717', 'Train Acc: 0.99425', 'Test Acc: 0.99', 'Train LL: -0.017670553916570252', 'Test LL: -0.029759152078895294', 'Epoch Time (s): 58.750508876983076')
('Epoch 82', 'Objective: -0.021297895461693098', 'Train Acc: 0.9946166666666667', 'Test Acc: 0.9901', 'Train LL: -0.017741698421938665', 'Test LL: -0.03020589873337609', 'Epoch Time (s): 58.76658837078139')
('Epoch 83', 'Objective: -0.020595866781634387', 'Train Acc: 0.99455', 'Test Acc: 0.9903', 'Train LL: -0.01706625513388695', 'Test LL: -0.029619561267910592', 'Epoch Time (s): 58.81257201405242')
('Epoch 84', 'Objective: -0.0199100500922637', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9901', 'Train LL: -0.016382143377447204', 'Test LL: -0.029962343394832305', 'Epoch Time (s): 58.79656535666436')
('Epoch 85', 'Objective: -0.020389819194097988', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9902', 'Train LL: -0.01682913685847269', 'Test LL: -0.030268775508244066', 'Epoch Time (s): 58.754648368339986')
('Epoch 86', 'Objective: -0.019546000413127956', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.99', 'Train LL: -0.016023438202401447', 'Test LL: -0.03078137161285621', 'Epoch Time (s): 58.77314320206642')
('Epoch 87', 'Objective: -0.02048608300509417', 'Train Acc: 0.9944833333333334', 'Test Acc: 0.9906', 'Train LL: -0.016908702840660886', 'Test LL: -0.030342971062543512', 'Epoch Time (s): 58.769025661982596')
('Epoch 88', 'Objective: -0.020438134082527638', 'Train Acc: 0.9948833333333333', 'Test Acc: 0.9903', 'Train LL: -0.01686688623014235', 'Test LL: -0.03073460929344268', 'Epoch Time (s): 58.79355490906164')
('Epoch 89', 'Objective: -0.02034033244058953', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9899', 'Train LL: -0.016752729614848527', 'Test LL: -0.031658004559337226', 'Epoch Time (s): 58.76810821797699')
('Epoch 90', 'Objective: -0.01953729386101237', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.991', 'Train LL: -0.015981234317442087', 'Test LL: -0.02818866496112007', 'Epoch Time (s): 58.76713700219989')
('Epoch 91', 'Objective: -0.0203149097550765', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.99', 'Train LL: -0.016733220722207582', 'Test LL: -0.03028470038940298', 'Epoch Time (s): 58.76393153704703')
('Epoch 92', 'Objective: -0.019826911066673246', 'Train Acc: 0.99495', 'Test Acc: 0.9905', 'Train LL: -0.016268485166962905', 'Test LL: -0.03000641516324567', 'Epoch Time (s): 58.75899885594845')
('Epoch 93', 'Objective: -0.019729433490146706', 'Train Acc: 0.99475', 'Test Acc: 0.9905', 'Train LL: -0.01614964120603494', 'Test LL: -0.03023227440046087', 'Epoch Time (s): 58.79564910521731')
('Epoch 94', 'Objective: -0.019545089445015335', 'Train Acc: 0.9951', 'Test Acc: 0.9901', 'Train LL: -0.01599036946078564', 'Test LL: -0.03126904536204709', 'Epoch Time (s): 58.78907302394509')
('Epoch 95', 'Objective: -0.019551780546057513', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.9902', 'Train LL: -0.015985337157627476', 'Test LL: -0.029657164775913496', 'Epoch Time (s): 58.786674971692264')
('Epoch 96', 'Objective: -0.019337759926778518', 'Train Acc: 0.99525', 'Test Acc: 0.9909', 'Train LL: -0.015795049562479846', 'Test LL: -0.029229002941274167', 'Epoch Time (s): 58.79981104377657')
('Epoch 97', 'Objective: -0.019714872651361504', 'Train Acc: 0.99475', 'Test Acc: 0.9901', 'Train LL: -0.016127140120374906', 'Test LL: -0.030488135073255148', 'Epoch Time (s): 58.81113852607086')
('Epoch 98', 'Objective: -0.020490452305187434', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9896', 'Train LL: -0.01687666677158822', 'Test LL: -0.029887959825774833', 'Epoch Time (s): 58.80737060401589')
('Epoch 99', 'Objective: -0.019730020533684802', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.9901', 'Train LL: -0.016156862129821804', 'Test LL: -0.030769559709074287', 'Epoch Time (s): 58.81407621689141')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.01935674635904079
Final Train Accuracy: £0.9947166666666667
Final Train LL: £-0.01579535672981543
Final Test Accuracy: £0.99
Final Test LL: £-0.030695416480352167
