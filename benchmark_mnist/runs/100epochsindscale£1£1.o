dataset: MNIST
dtype: float64
dof: 0.01
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 1
x_ind shape: torch.Size([16, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.8233846030480843', 'Train Acc: 0.31816666666666665', 'Test Acc: 0.5754', 'Train LL: -1.7998994218133695', 'Test LL: -1.163296582437974', 'Epoch Time (s): 50.85877288132906')
('Epoch 1', 'Objective: -1.1486158853781119', 'Train Acc: 0.5908833333333333', 'Test Acc: 0.6554', 'Train LL: -1.1324600914330438', 'Test LL: -0.9966459665965512', 'Epoch Time (s): 50.71981804491952')
('Epoch 2', 'Objective: -0.7810027631250187', 'Train Acc: 0.7329833333333333', 'Test Acc: 0.772', 'Train LL: -0.7658567645906524', 'Test LL: -0.6730234884215394', 'Epoch Time (s): 50.72773639811203')
('Epoch 3', 'Objective: -0.6025412946936962', 'Train Acc: 0.7961333333333334', 'Test Acc: 0.8511', 'Train LL: -0.588825742366813', 'Test LL: -0.4468606088904669', 'Epoch Time (s): 50.64107202133164')
('Epoch 4', 'Objective: -0.4966818182956331', 'Train Acc: 0.83345', 'Test Acc: 0.8188', 'Train LL: -0.4833358098191528', 'Test LL: -0.519808597036987', 'Epoch Time (s): 50.76105217402801')
('Epoch 5', 'Objective: -0.43152435683260665', 'Train Acc: 0.85715', 'Test Acc: 0.8922', 'Train LL: -0.41854630544366245', 'Test LL: -0.3335503173395736', 'Epoch Time (s): 50.65715633099899')
('Epoch 6', 'Objective: -0.3451681666375707', 'Train Acc: 0.8940666666666667', 'Test Acc: 0.9047', 'Train LL: -0.3323332093334891', 'Test LL: -0.2829019493042444', 'Epoch Time (s): 50.69256737688556')
('Epoch 7', 'Objective: -0.28615322436698803', 'Train Acc: 0.9144', 'Test Acc: 0.9379', 'Train LL: -0.2741028714538642', 'Test LL: -0.19911350873664196', 'Epoch Time (s): 50.73256838880479')
('Epoch 8', 'Objective: -0.24935356540786302', 'Train Acc: 0.92615', 'Test Acc: 0.9507', 'Train LL: -0.2378611337684479', 'Test LL: -0.16039794928399864', 'Epoch Time (s): 50.6767667485401')
('Epoch 9', 'Objective: -0.23054289441345988', 'Train Acc: 0.9322833333333334', 'Test Acc: 0.948', 'Train LL: -0.21951002865065355', 'Test LL: -0.1697121941278181', 'Epoch Time (s): 50.709186252206564')
('Epoch 10', 'Objective: -0.21155728226890164', 'Train Acc: 0.9375166666666667', 'Test Acc: 0.9428', 'Train LL: -0.2008897706681752', 'Test LL: -0.16996130599278625', 'Epoch Time (s): 50.658122999127954')
('Epoch 11', 'Objective: -0.19723917460261275', 'Train Acc: 0.9413666666666667', 'Test Acc: 0.9477', 'Train LL: -0.18698740907101397', 'Test LL: -0.16368879030616146', 'Epoch Time (s): 50.709082366898656')
('Epoch 12', 'Objective: -0.1857597645626721', 'Train Acc: 0.9449333333333333', 'Test Acc: 0.9549', 'Train LL: -0.17582792220341295', 'Test LL: -0.14219124504994266', 'Epoch Time (s): 50.73442661110312')
('Epoch 13', 'Objective: -0.17884925770013624', 'Train Acc: 0.94655', 'Test Acc: 0.9556', 'Train LL: -0.16917228523137176', 'Test LL: -0.1408405242757202', 'Epoch Time (s): 50.67643135925755')
('Epoch 14', 'Objective: -0.1642735745419745', 'Train Acc: 0.9519833333333333', 'Test Acc: 0.9649', 'Train LL: -0.15501418657031305', 'Test LL: -0.10118487862476742', 'Epoch Time (s): 50.69166979007423')
('Epoch 15', 'Objective: -0.15566266834081255', 'Train Acc: 0.9541', 'Test Acc: 0.9686', 'Train LL: -0.14673522823875845', 'Test LL: -0.0998328690534311', 'Epoch Time (s): 50.7833874868229')
('Epoch 16', 'Objective: -0.14689612224855927', 'Train Acc: 0.9566666666666667', 'Test Acc: 0.9553', 'Train LL: -0.13826161698040074', 'Test LL: -0.13289905001568672', 'Epoch Time (s): 50.72393311699852')
('Epoch 17', 'Objective: -0.1396975677122541', 'Train Acc: 0.9583333333333334', 'Test Acc: 0.9745', 'Train LL: -0.13140794924305127', 'Test LL: -0.08408068654710917', 'Epoch Time (s): 50.68627401674166')
('Epoch 18', 'Objective: -0.13492904970597455', 'Train Acc: 0.9601666666666666', 'Test Acc: 0.968', 'Train LL: -0.12685101173640118', 'Test LL: -0.09523960437530882', 'Epoch Time (s): 50.73172981105745')
('Epoch 19', 'Objective: -0.13149504189322114', 'Train Acc: 0.9614833333333334', 'Test Acc: 0.9618', 'Train LL: -0.12362846087418461', 'Test LL: -0.11150256299436782', 'Epoch Time (s): 50.71405897894874')
('Epoch 20', 'Objective: -0.12474863882855786', 'Train Acc: 0.9627833333333333', 'Test Acc: 0.9598', 'Train LL: -0.11713722133148688', 'Test LL: -0.12708015933670738', 'Epoch Time (s): 50.71601254073903')
('Epoch 21', 'Objective: -0.1222988079359068', 'Train Acc: 0.9637', 'Test Acc: 0.9682', 'Train LL: -0.1147847616268191', 'Test LL: -0.09776439390945584', 'Epoch Time (s): 50.699889526702464')
('Epoch 22', 'Objective: -0.11636518256327023', 'Train Acc: 0.96565', 'Test Acc: 0.9737', 'Train LL: -0.10907412783083956', 'Test LL: -0.08441911175132197', 'Epoch Time (s): 50.75851232931018')
('Epoch 23', 'Objective: -0.11166084954772165', 'Train Acc: 0.96645', 'Test Acc: 0.9536', 'Train LL: -0.10454401231966544', 'Test LL: -0.1389648247311131', 'Epoch Time (s): 50.71692764107138')
('Epoch 24', 'Objective: -0.11074127230487231', 'Train Acc: 0.96765', 'Test Acc: 0.9708', 'Train LL: -0.10379446527638381', 'Test LL: -0.08534669729782286', 'Epoch Time (s): 50.69259689003229')
('Epoch 25', 'Objective: -0.1042970646169633', 'Train Acc: 0.9692166666666666', 'Test Acc: 0.974', 'Train LL: -0.09752606448898944', 'Test LL: -0.08764062513414202', 'Epoch Time (s): 50.67080007400364')
('Epoch 26', 'Objective: -0.10453144713281225', 'Train Acc: 0.9695', 'Test Acc: 0.9681', 'Train LL: -0.09793144677485965', 'Test LL: -0.09761099124659987', 'Epoch Time (s): 50.68820965476334')
('Epoch 27', 'Objective: -0.10152812539573224', 'Train Acc: 0.9703666666666667', 'Test Acc: 0.9783', 'Train LL: -0.09509150650502846', 'Test LL: -0.06746853402179057', 'Epoch Time (s): 50.712272891774774')
('Epoch 28', 'Objective: -0.09716309835192968', 'Train Acc: 0.9708666666666667', 'Test Acc: 0.9787', 'Train LL: -0.09081601719532563', 'Test LL: -0.06811651207101023', 'Epoch Time (s): 50.70783503120765')
('Epoch 29', 'Objective: -0.09546281495309701', 'Train Acc: 0.9721666666666666', 'Test Acc: 0.9802', 'Train LL: -0.08919598065559677', 'Test LL: -0.06273441554401885', 'Epoch Time (s): 50.738904105033726')
('Epoch 30', 'Objective: -0.0912318735871462', 'Train Acc: 0.9735166666666667', 'Test Acc: 0.9794', 'Train LL: -0.08506977289203749', 'Test LL: -0.06529917297150331', 'Epoch Time (s): 50.75732475705445')
('Epoch 31', 'Objective: -0.09069289219748153', 'Train Acc: 0.9723', 'Test Acc: 0.9695', 'Train LL: -0.08458553310992349', 'Test LL: -0.08742132757819034', 'Epoch Time (s): 50.742221761029214')
('Epoch 32', 'Objective: -0.0900956999600107', 'Train Acc: 0.9736666666666667', 'Test Acc: 0.9747', 'Train LL: -0.08412534741876179', 'Test LL: -0.07996775567876323', 'Epoch Time (s): 50.69585447292775')
('Epoch 33', 'Objective: -0.08857708409751945', 'Train Acc: 0.9742666666666666', 'Test Acc: 0.972', 'Train LL: -0.0826976640935355', 'Test LL: -0.08401965529527065', 'Epoch Time (s): 50.7114612669684')
('Epoch 34', 'Objective: -0.0860463662106743', 'Train Acc: 0.9746666666666667', 'Test Acc: 0.9668', 'Train LL: -0.08024659273665705', 'Test LL: -0.10185551468842423', 'Epoch Time (s): 50.789057057816535')
('Epoch 35', 'Objective: -0.08315514453232282', 'Train Acc: 0.9758166666666667', 'Test Acc: 0.9776', 'Train LL: -0.07742047140378984', 'Test LL: -0.06782570349831817', 'Epoch Time (s): 50.69276567874476')
('Epoch 36', 'Objective: -0.08349038801532666', 'Train Acc: 0.9754333333333334', 'Test Acc: 0.9781', 'Train LL: -0.0777855759262709', 'Test LL: -0.0655294945202285', 'Epoch Time (s): 50.354373078327626')
('Epoch 37', 'Objective: -0.08118623871000458', 'Train Acc: 0.9765', 'Test Acc: 0.9804', 'Train LL: -0.07548537333346145', 'Test LL: -0.0613439042598083', 'Epoch Time (s): 50.62536943797022')
('Epoch 38', 'Objective: -0.08160376052698641', 'Train Acc: 0.97625', 'Test Acc: 0.9728', 'Train LL: -0.07602694746057327', 'Test LL: -0.07574019775237141', 'Epoch Time (s): 50.692405472975224')
('Epoch 39', 'Objective: -0.08054656227803796', 'Train Acc: 0.9762166666666666', 'Test Acc: 0.9795', 'Train LL: -0.07497381450618602', 'Test LL: -0.06756515849538484', 'Epoch Time (s): 50.78433692781255')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.05387358902831312', 'Train Acc: 0.9850333333333333', 'Test Acc: 0.9849', 'Train LL: -0.04885399644002562', 'Test LL: -0.04539940904576928', 'Epoch Time (s): 50.70376385981217')
('Epoch 41', 'Objective: -0.04775840011711427', 'Train Acc: 0.98685', 'Test Acc: 0.9867', 'Train LL: -0.04288576885003772', 'Test LL: -0.04240317876377971', 'Epoch Time (s): 50.72750154603273')
('Epoch 42', 'Objective: -0.04836935806303891', 'Train Acc: 0.9864333333333334', 'Test Acc: 0.9868', 'Train LL: -0.04356296504518564', 'Test LL: -0.03857341646472332', 'Epoch Time (s): 50.71306676603854')
('Epoch 43', 'Objective: -0.045081862080120536', 'Train Acc: 0.98735', 'Test Acc: 0.988', 'Train LL: -0.04039806746629701', 'Test LL: -0.039431563459781924', 'Epoch Time (s): 50.63561229920015')
('Epoch 44', 'Objective: -0.045323412250766165', 'Train Acc: 0.9870166666666667', 'Test Acc: 0.9881', 'Train LL: -0.04067418690759026', 'Test LL: -0.03862130433124225', 'Epoch Time (s): 50.67671450134367')
('Epoch 45', 'Objective: -0.04480277426887526', 'Train Acc: 0.98745', 'Test Acc: 0.9856', 'Train LL: -0.04024349945099739', 'Test LL: -0.04475665000742514', 'Epoch Time (s): 50.67423995072022')
('Epoch 46', 'Objective: -0.04365846269365039', 'Train Acc: 0.9876666666666667', 'Test Acc: 0.9871', 'Train LL: -0.03913859298354767', 'Test LL: -0.03894711172967628', 'Epoch Time (s): 50.673928345087916')
('Epoch 47', 'Objective: -0.04353383091985648', 'Train Acc: 0.9875833333333334', 'Test Acc: 0.9879', 'Train LL: -0.0390279041681795', 'Test LL: -0.03622873362229187', 'Epoch Time (s): 50.6886246567592')
('Epoch 48', 'Objective: -0.04353488931089118', 'Train Acc: 0.9874333333333334', 'Test Acc: 0.9875', 'Train LL: -0.03909060030845579', 'Test LL: -0.03758941603600542', 'Epoch Time (s): 50.73203787161037')
('Epoch 49', 'Objective: -0.042706501287620095', 'Train Acc: 0.9879', 'Test Acc: 0.9885', 'Train LL: -0.03823940618130587', 'Test LL: -0.036452945271873045', 'Epoch Time (s): 50.7254329379648')
('Epoch 50', 'Objective: -0.04376816341392575', 'Train Acc: 0.9872666666666666', 'Test Acc: 0.9882', 'Train LL: -0.039356139751771116', 'Test LL: -0.03725285637764192', 'Epoch Time (s): 50.726980837993324')
('Epoch 51', 'Objective: -0.042345969778411464', 'Train Acc: 0.9879833333333333', 'Test Acc: 0.989', 'Train LL: -0.03799009348925895', 'Test LL: -0.03674851849812327', 'Epoch Time (s): 50.76123781315982')
('Epoch 52', 'Objective: -0.04245628909019913', 'Train Acc: 0.9881333333333333', 'Test Acc: 0.9875', 'Train LL: -0.038126680550189945', 'Test LL: -0.03740844982649926', 'Epoch Time (s): 50.68427260685712')
('Epoch 53', 'Objective: -0.041631166913765685', 'Train Acc: 0.9880333333333333', 'Test Acc: 0.9866', 'Train LL: -0.03734424082844738', 'Test LL: -0.03950604747737428', 'Epoch Time (s): 50.679967214819044')
('Epoch 54', 'Objective: -0.04108087583809657', 'Train Acc: 0.9881666666666666', 'Test Acc: 0.9872', 'Train LL: -0.03677396124064936', 'Test LL: -0.03826692977024355', 'Epoch Time (s): 50.76356513472274')
('Epoch 55', 'Objective: -0.04207907011145774', 'Train Acc: 0.9877333333333334', 'Test Acc: 0.9876', 'Train LL: -0.03778505212947844', 'Test LL: -0.039436874586966986', 'Epoch Time (s): 50.70852911891416')
('Epoch 56', 'Objective: -0.04001361961589892', 'Train Acc: 0.9886333333333334', 'Test Acc: 0.9885', 'Train LL: -0.035792594611268796', 'Test LL: -0.03504616664032432', 'Epoch Time (s): 50.646567144431174')
('Epoch 57', 'Objective: -0.04008475488305104', 'Train Acc: 0.9886833333333334', 'Test Acc: 0.9867', 'Train LL: -0.03586506048969097', 'Test LL: -0.03899336021265862', 'Epoch Time (s): 50.72624713880941')
('Epoch 58', 'Objective: -0.04107456477371551', 'Train Acc: 0.98845', 'Test Acc: 0.9879', 'Train LL: -0.03685590281663396', 'Test LL: -0.03899439274250271', 'Epoch Time (s): 50.747335764113814')
('Epoch 59', 'Objective: -0.04030213414090959', 'Train Acc: 0.9886166666666667', 'Test Acc: 0.989', 'Train LL: -0.03608345458986611', 'Test LL: -0.03406691900300616', 'Epoch Time (s): 50.75996272685006')
('Epoch 60', 'Objective: -0.040644229653162306', 'Train Acc: 0.98855', 'Test Acc: 0.9874', 'Train LL: -0.03645992685913522', 'Test LL: -0.035961909686385914', 'Epoch Time (s): 50.762447697110474')
('Epoch 61', 'Objective: -0.039782245746810316', 'Train Acc: 0.9889166666666667', 'Test Acc: 0.9873', 'Train LL: -0.035605406648251056', 'Test LL: -0.039064613855091954', 'Epoch Time (s): 50.731015691999346')
('Epoch 62', 'Objective: -0.03944062848232816', 'Train Acc: 0.9886166666666667', 'Test Acc: 0.9877', 'Train LL: -0.035270397352852374', 'Test LL: -0.037981322635174945', 'Epoch Time (s): 50.761393745895475')
('Epoch 63', 'Objective: -0.03965841975125025', 'Train Acc: 0.9886666666666667', 'Test Acc: 0.9887', 'Train LL: -0.0355057153691965', 'Test LL: -0.036085574100493505', 'Epoch Time (s): 50.684052537195385')
('Epoch 64', 'Objective: -0.038271871011443824', 'Train Acc: 0.9893333333333333', 'Test Acc: 0.9868', 'Train LL: -0.03413791349329863', 'Test LL: -0.03841703276380893', 'Epoch Time (s): 50.71698635444045')
('Epoch 65', 'Objective: -0.03839007153170946', 'Train Acc: 0.9889666666666667', 'Test Acc: 0.9869', 'Train LL: -0.034265368527622304', 'Test LL: -0.03995069816523833', 'Epoch Time (s): 50.730082887690514')
('Epoch 66', 'Objective: -0.03871257821002586', 'Train Acc: 0.9888833333333333', 'Test Acc: 0.9883', 'Train LL: -0.034594702806723034', 'Test LL: -0.0342232707653379', 'Epoch Time (s): 50.72732132766396')
('Epoch 67', 'Objective: -0.03796914706473739', 'Train Acc: 0.989', 'Test Acc: 0.9887', 'Train LL: -0.033887799826586164', 'Test LL: -0.03501277084877586', 'Epoch Time (s): 50.72893798677251')
('Epoch 68', 'Objective: -0.03872164116726155', 'Train Acc: 0.9890666666666666', 'Test Acc: 0.9889', 'Train LL: -0.03461694744818905', 'Test LL: -0.034425850981346665', 'Epoch Time (s): 50.703777628950775')
('Epoch 69', 'Objective: -0.0388953682172873', 'Train Acc: 0.9886666666666667', 'Test Acc: 0.9884', 'Train LL: -0.03479497405481584', 'Test LL: -0.03840734606918846', 'Epoch Time (s): 50.68965162988752')
('Epoch 70', 'Objective: -0.03828786137308983', 'Train Acc: 0.9888666666666667', 'Test Acc: 0.9883', 'Train LL: -0.03421887695388262', 'Test LL: -0.0355146872492498', 'Epoch Time (s): 50.666059678886086')
('Epoch 71', 'Objective: -0.03712131809672272', 'Train Acc: 0.9894166666666667', 'Test Acc: 0.9872', 'Train LL: -0.03306931046905059', 'Test LL: -0.03665600364391354', 'Epoch Time (s): 50.68296517338604')
('Epoch 72', 'Objective: -0.03740039573653641', 'Train Acc: 0.9892', 'Test Acc: 0.9877', 'Train LL: -0.03335342098919684', 'Test LL: -0.03714359869969731', 'Epoch Time (s): 50.74396414775401')
('Epoch 73', 'Objective: -0.03725767987334012', 'Train Acc: 0.9895', 'Test Acc: 0.9888', 'Train LL: -0.03324362391454691', 'Test LL: -0.03378503193653888', 'Epoch Time (s): 50.765344431158155')
('Epoch 74', 'Objective: -0.0381061651922075', 'Train Acc: 0.98915', 'Test Acc: 0.9888', 'Train LL: -0.03410061865717741', 'Test LL: -0.034629549930398566', 'Epoch Time (s): 50.687592873349786')
('Epoch 75', 'Objective: -0.036681506679322025', 'Train Acc: 0.9891', 'Test Acc: 0.9875', 'Train LL: -0.03267618463020823', 'Test LL: -0.037562919464951994', 'Epoch Time (s): 50.678339682053775')
('Epoch 76', 'Objective: -0.036493626019331205', 'Train Acc: 0.9895166666666667', 'Test Acc: 0.9871', 'Train LL: -0.03247025990089451', 'Test LL: -0.039721355597425324', 'Epoch Time (s): 50.65575108630583')
('Epoch 77', 'Objective: -0.03715261211136226', 'Train Acc: 0.9895166666666667', 'Test Acc: 0.9886', 'Train LL: -0.03313377122084354', 'Test LL: -0.03429019317538865', 'Epoch Time (s): 50.73551886109635')
('Epoch 78', 'Objective: -0.03734632977754614', 'Train Acc: 0.98905', 'Test Acc: 0.9884', 'Train LL: -0.033306771870429075', 'Test LL: -0.03676645698719063', 'Epoch Time (s): 50.727904910221696')
('Epoch 79', 'Objective: -0.036413591958476814', 'Train Acc: 0.9895833333333334', 'Test Acc: 0.9862', 'Train LL: -0.03243510656411732', 'Test LL: -0.04123554542328309', 'Epoch Time (s): 50.727223058696836')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.034281686858627654', 'Train Acc: 0.99015', 'Test Acc: 0.9885', 'Train LL: -0.03033893256306665', 'Test LL: -0.03484782748848469', 'Epoch Time (s): 50.73986389674246')
('Epoch 81', 'Objective: -0.033183803358281826', 'Train Acc: 0.9905333333333334', 'Test Acc: 0.9884', 'Train LL: -0.029249157397705013', 'Test LL: -0.03381941024224355', 'Epoch Time (s): 50.75682118907571')
('Epoch 82', 'Objective: -0.033187383883243764', 'Train Acc: 0.9906833333333334', 'Test Acc: 0.9887', 'Train LL: -0.029266691268964588', 'Test LL: -0.034683494405299595', 'Epoch Time (s): 50.56792000634596')
('Epoch 83', 'Objective: -0.03269672565213581', 'Train Acc: 0.9906333333333334', 'Test Acc: 0.9886', 'Train LL: -0.028790241859560667', 'Test LL: -0.03476686288451434', 'Epoch Time (s): 50.68543931469321')
('Epoch 84', 'Objective: -0.0323975812588946', 'Train Acc: 0.9909', 'Test Acc: 0.9889', 'Train LL: -0.028473992381435876', 'Test LL: -0.03302490554545807', 'Epoch Time (s): 50.6775679718703')
('Epoch 85', 'Objective: -0.03357980563853111', 'Train Acc: 0.9903666666666666', 'Test Acc: 0.9888', 'Train LL: -0.029639893446648254', 'Test LL: -0.03430174087958211', 'Epoch Time (s): 50.69624454434961')
('Epoch 86', 'Objective: -0.0332129586858813', 'Train Acc: 0.9902833333333333', 'Test Acc: 0.9883', 'Train LL: -0.02925615769191895', 'Test LL: -0.03518414774609642', 'Epoch Time (s): 50.66317808488384')
('Epoch 87', 'Objective: -0.03353563978711963', 'Train Acc: 0.9906666666666667', 'Test Acc: 0.9887', 'Train LL: -0.0295918259816358', 'Test LL: -0.03397935178521417', 'Epoch Time (s): 50.74162667058408')
('Epoch 88', 'Objective: -0.033101969456025504', 'Train Acc: 0.99065', 'Test Acc: 0.9888', 'Train LL: -0.02918380724028335', 'Test LL: -0.03345412938177836', 'Epoch Time (s): 50.75932020600885')
('Epoch 89', 'Objective: -0.032676012518427874', 'Train Acc: 0.9907833333333333', 'Test Acc: 0.9886', 'Train LL: -0.028756941408251746', 'Test LL: -0.03449165445167251', 'Epoch Time (s): 50.660946681164205')
('Epoch 90', 'Objective: -0.031896343596401165', 'Train Acc: 0.991', 'Test Acc: 0.9886', 'Train LL: -0.02799780444066516', 'Test LL: -0.03382453810303658', 'Epoch Time (s): 50.663790225982666')
('Epoch 91', 'Objective: -0.03304982711956482', 'Train Acc: 0.9909166666666667', 'Test Acc: 0.9893', 'Train LL: -0.02911404522411156', 'Test LL: -0.0335985929907189', 'Epoch Time (s): 50.780170884914696')
('Epoch 92', 'Objective: -0.032025382147131194', 'Train Acc: 0.9907833333333333', 'Test Acc: 0.988', 'Train LL: -0.028118302898680756', 'Test LL: -0.03594280845617918', 'Epoch Time (s): 50.654524540994316')
('Epoch 93', 'Objective: -0.03223603754656879', 'Train Acc: 0.9913666666666666', 'Test Acc: 0.9886', 'Train LL: -0.028330821774518223', 'Test LL: -0.03406595438281304', 'Epoch Time (s): 50.665068140253425')
('Epoch 94', 'Objective: -0.03207520940855974', 'Train Acc: 0.99145', 'Test Acc: 0.9891', 'Train LL: -0.028187205130277605', 'Test LL: -0.03406566963573669', 'Epoch Time (s): 50.71797890635207')
('Epoch 95', 'Objective: -0.03176136313546769', 'Train Acc: 0.99095', 'Test Acc: 0.9886', 'Train LL: -0.027843232465706313', 'Test LL: -0.034907852648577764', 'Epoch Time (s): 50.697365102823824')
('Epoch 96', 'Objective: -0.0335873290341713', 'Train Acc: 0.99035', 'Test Acc: 0.9888', 'Train LL: -0.029634889981731326', 'Test LL: -0.033859699224558816', 'Epoch Time (s): 50.72717274585739')
('Epoch 97', 'Objective: -0.032229008925516694', 'Train Acc: 0.991', 'Test Acc: 0.988', 'Train LL: -0.02830787572126022', 'Test LL: -0.03536981045131612', 'Epoch Time (s): 50.740786192938685')
('Epoch 98', 'Objective: -0.03150572150976355', 'Train Acc: 0.9913333333333333', 'Test Acc: 0.9884', 'Train LL: -0.027594390201919707', 'Test LL: -0.03450268259908931', 'Epoch Time (s): 50.72086233505979')
('Epoch 99', 'Objective: -0.03259022994865523', 'Train Acc: 0.9905666666666667', 'Test Acc: 0.989', 'Train LL: -0.02866689682539311', 'Test LL: -0.033697973535730764', 'Epoch Time (s): 50.56926743220538')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03209198835481621
Final Train Accuracy: £0.9911
Final Train LL: £-0.028183477988820396
Final Test Accuracy: £0.9884
Final Test LL: £-0.033283891785067084
