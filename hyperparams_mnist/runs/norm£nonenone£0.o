dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: none
bn_tnorm: none
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.567322611401935', 'Train Acc: 0.43615', 'Test Acc: 0.7776', 'Train LL: -1.5270817436228705', 'Test LL: -0.7948434123561468', 'Epoch Time (s): 162.2531762921717')
('Epoch 1', 'Objective: -0.6151015970204421', 'Train Acc: 0.8118666666666666', 'Test Acc: 0.887', 'Train LL: -0.561822231038055', 'Test LL: -0.3547890239672836', 'Epoch Time (s): 162.37145466986112')
('Epoch 2', 'Objective: -0.3818747942252953', 'Train Acc: 0.8942333333333333', 'Test Acc: 0.9092', 'Train LL: -0.33071742077013755', 'Test LL: -0.2919380382645974', 'Epoch Time (s): 162.34418300306424')
('Epoch 3', 'Objective: -0.30442112296887774', 'Train Acc: 0.9198833333333334', 'Test Acc: 0.9401', 'Train LL: -0.2563359081719749', 'Test LL: -0.20115697145149938', 'Epoch Time (s): 162.3282208291348')
('Epoch 4', 'Objective: -0.2592785556808213', 'Train Acc: 0.9336166666666667', 'Test Acc: 0.8899', 'Train LL: -0.21354901319495528', 'Test LL: -0.33708017159604403', 'Epoch Time (s): 162.3196016009897')
('Epoch 5', 'Objective: -0.23170214134784234', 'Train Acc: 0.9409333333333333', 'Test Acc: 0.9558', 'Train LL: -0.18790492806187026', 'Test LL: -0.136967739622171', 'Epoch Time (s): 162.35469499812461')
('Epoch 6', 'Objective: -0.20231911862741525', 'Train Acc: 0.9507833333333333', 'Test Acc: 0.9597', 'Train LL: -0.1600510775872655', 'Test LL: -0.12887536685597534', 'Epoch Time (s): 162.34334969590418')
('Epoch 7', 'Objective: -0.18597274338107253', 'Train Acc: 0.95495', 'Test Acc: 0.9616', 'Train LL: -0.14481209721215493', 'Test LL: -0.11590849038395', 'Epoch Time (s): 162.30473647685722')
('Epoch 8', 'Objective: -0.1683667355183388', 'Train Acc: 0.9601666666666666', 'Test Acc: 0.96', 'Train LL: -0.12866942963842162', 'Test LL: -0.11913026150856454', 'Epoch Time (s): 162.35063528292812')
('Epoch 9', 'Objective: -0.16060299026041733', 'Train Acc: 0.9622333333333334', 'Test Acc: 0.9698', 'Train LL: -0.12169028985685564', 'Test LL: -0.09270751646576482', 'Epoch Time (s): 162.35168437100947')
('Epoch 10', 'Objective: -0.1497026768099585', 'Train Acc: 0.9655333333333334', 'Test Acc: 0.9645', 'Train LL: -0.11140288075546848', 'Test LL: -0.11013833604736631', 'Epoch Time (s): 162.3512193490751')
('Epoch 11', 'Objective: -0.1432866398170224', 'Train Acc: 0.9673833333333334', 'Test Acc: 0.9677', 'Train LL: -0.10567953998439718', 'Test LL: -0.10153118140933082', 'Epoch Time (s): 162.40446861484088')
('Epoch 12', 'Objective: -0.14043414995637066', 'Train Acc: 0.9682166666666666', 'Test Acc: 0.9776', 'Train LL: -0.10338542345421013', 'Test LL: -0.0907776934136854', 'Epoch Time (s): 162.45713178091682')
('Epoch 13', 'Objective: -0.13256385687715297', 'Train Acc: 0.97025', 'Test Acc: 0.9732', 'Train LL: -0.09638500298421185', 'Test LL: -0.08596707216949603', 'Epoch Time (s): 162.4349354810547')
('Epoch 14', 'Objective: -0.1285253632186331', 'Train Acc: 0.97105', 'Test Acc: 0.973', 'Train LL: -0.09228442015174156', 'Test LL: -0.08267513241953632', 'Epoch Time (s): 162.34358957898803')
('Epoch 15', 'Objective: -0.12248470893676121', 'Train Acc: 0.9734', 'Test Acc: 0.9763', 'Train LL: -0.08689769062945533', 'Test LL: -0.06892700694333978', 'Epoch Time (s): 162.4757778958883')
('Epoch 16', 'Objective: -0.11824419001267959', 'Train Acc: 0.97385', 'Test Acc: 0.9777', 'Train LL: -0.08328622816720739', 'Test LL: -0.067413266136735', 'Epoch Time (s): 162.8511988071259')
('Epoch 17', 'Objective: -0.11855893352598261', 'Train Acc: 0.9735333333333334', 'Test Acc: 0.9804', 'Train LL: -0.08405546587293695', 'Test LL: -0.06404366306718881', 'Epoch Time (s): 162.7942364970222')
('Epoch 18', 'Objective: -0.11237874856680226', 'Train Acc: 0.9752333333333333', 'Test Acc: 0.9769', 'Train LL: -0.07827685392370726', 'Test LL: -0.0777125117925408', 'Epoch Time (s): 162.81893061986193')
('Epoch 19', 'Objective: -0.1121099228491716', 'Train Acc: 0.9758166666666667', 'Test Acc: 0.9743', 'Train LL: -0.07826382211094839', 'Test LL: -0.08752215144475031', 'Epoch Time (s): 162.75370202609338')
('Epoch 20', 'Objective: -0.10629349557916083', 'Train Acc: 0.9777333333333333', 'Test Acc: 0.9738', 'Train LL: -0.07296829685938847', 'Test LL: -0.0861802121586121', 'Epoch Time (s): 162.8003983281087')
('Epoch 21', 'Objective: -0.10668954478859212', 'Train Acc: 0.9768166666666667', 'Test Acc: 0.9811', 'Train LL: -0.0737332423597917', 'Test LL: -0.061131968857369205', 'Epoch Time (s): 162.80872232280672')
('Epoch 22', 'Objective: -0.10278897423440822', 'Train Acc: 0.97825', 'Test Acc: 0.9771', 'Train LL: -0.0702358293188057', 'Test LL: -0.07657441682096867', 'Epoch Time (s): 162.7575650778599')
('Epoch 23', 'Objective: -0.10179427442381098', 'Train Acc: 0.9789833333333333', 'Test Acc: 0.978', 'Train LL: -0.0694800140707478', 'Test LL: -0.06312488334620277', 'Epoch Time (s): 162.50785406096838')
('Epoch 24', 'Objective: -0.09942764394778232', 'Train Acc: 0.9795', 'Test Acc: 0.9789', 'Train LL: -0.06736278092147388', 'Test LL: -0.06586232439567355', 'Epoch Time (s): 162.29596850113012')
('Epoch 25', 'Objective: -0.09862749203623739', 'Train Acc: 0.9793166666666666', 'Test Acc: 0.9798', 'Train LL: -0.06700663933692973', 'Test LL: -0.06126142582271794', 'Epoch Time (s): 162.41048496519215')
('Epoch 26', 'Objective: -0.09845452974894169', 'Train Acc: 0.97855', 'Test Acc: 0.9835', 'Train LL: -0.06700205008659936', 'Test LL: -0.05196114741921724', 'Epoch Time (s): 162.33232568996027')
('Epoch 27', 'Objective: -0.09409596386172481', 'Train Acc: 0.9809333333333333', 'Test Acc: 0.984', 'Train LL: -0.06301916011401189', 'Test LL: -0.04728153459443745', 'Epoch Time (s): 162.26727789500728')
('Epoch 28', 'Objective: -0.09201246340223615', 'Train Acc: 0.9809', 'Test Acc: 0.9814', 'Train LL: -0.06136984755534671', 'Test LL: -0.05747143993862161', 'Epoch Time (s): 162.3309601598885')
('Epoch 29', 'Objective: -0.09167000079801614', 'Train Acc: 0.9807666666666667', 'Test Acc: 0.9817', 'Train LL: -0.061315761098352926', 'Test LL: -0.05775765910427464', 'Epoch Time (s): 162.32180432905443')
('Epoch 30', 'Objective: -0.09207175163802854', 'Train Acc: 0.9806833333333334', 'Test Acc: 0.982', 'Train LL: -0.0617584825274865', 'Test LL: -0.05691534494876413', 'Epoch Time (s): 162.29855237109587')
('Epoch 31', 'Objective: -0.08914352791159669', 'Train Acc: 0.9811333333333333', 'Test Acc: 0.9827', 'Train LL: -0.05916351077092847', 'Test LL: -0.05639643354183484', 'Epoch Time (s): 162.24516079993919')
('Epoch 32', 'Objective: -0.08904889256520805', 'Train Acc: 0.9816666666666667', 'Test Acc: 0.9817', 'Train LL: -0.059224145591528485', 'Test LL: -0.05166406500099381', 'Epoch Time (s): 162.23291196720675')
('Epoch 33', 'Objective: -0.08750218986441995', 'Train Acc: 0.9815166666666667', 'Test Acc: 0.9817', 'Train LL: -0.05800592367134411', 'Test LL: -0.05589029296212584', 'Epoch Time (s): 162.25211382377893')
('Epoch 34', 'Objective: -0.08585737443052727', 'Train Acc: 0.98215', 'Test Acc: 0.9855', 'Train LL: -0.05657107927876184', 'Test LL: -0.04500757029960241', 'Epoch Time (s): 162.25385887594894')
('Epoch 35', 'Objective: -0.0851795827110531', 'Train Acc: 0.98245', 'Test Acc: 0.9825', 'Train LL: -0.05583246149444303', 'Test LL: -0.05764687272848308', 'Epoch Time (s): 162.2368402441498')
('Epoch 36', 'Objective: -0.08346813436660637', 'Train Acc: 0.9830333333333333', 'Test Acc: 0.9842', 'Train LL: -0.054486893255439706', 'Test LL: -0.050861277339683854', 'Epoch Time (s): 162.2805114351213')
('Epoch 37', 'Objective: -0.084660857596469', 'Train Acc: 0.9823333333333333', 'Test Acc: 0.9792', 'Train LL: -0.055968087481939835', 'Test LL: -0.06660273095878433', 'Epoch Time (s): 162.22577234497294')
('Epoch 38', 'Objective: -0.08351404390822097', 'Train Acc: 0.9831', 'Test Acc: 0.9884', 'Train LL: -0.05472801206739772', 'Test LL: -0.036151690432756914', 'Epoch Time (s): 162.2723870340269')
('Epoch 39', 'Objective: -0.07975687857010164', 'Train Acc: 0.98395', 'Test Acc: 0.985', 'Train LL: -0.05134320987189662', 'Test LL: -0.048884310621024454', 'Epoch Time (s): 162.2067311690189')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06072795148970004', 'Train Acc: 0.9893166666666666', 'Test Acc: 0.9906', 'Train LL: -0.03385246964198228', 'Test LL: -0.030243273555949895', 'Epoch Time (s): 162.1847113079857')
('Epoch 41', 'Objective: -0.05516225501515003', 'Train Acc: 0.99055', 'Test Acc: 0.9913', 'Train LL: -0.029252730181295098', 'Test LL: -0.027589115249311624', 'Epoch Time (s): 162.20818428392522')
('Epoch 42', 'Objective: -0.052946289120708666', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9898', 'Train LL: -0.027490331549725782', 'Test LL: -0.029331181147814932', 'Epoch Time (s): 162.25173454522155')
('Epoch 43', 'Objective: -0.0524212198620154', 'Train Acc: 0.99135', 'Test Acc: 0.9904', 'Train LL: -0.027036539266725754', 'Test LL: -0.02864165642802508', 'Epoch Time (s): 162.19839770393446')
('Epoch 44', 'Objective: -0.051329952603957514', 'Train Acc: 0.9914666666666667', 'Test Acc: 0.9907', 'Train LL: -0.02618102119653247', 'Test LL: -0.027484423545038134', 'Epoch Time (s): 162.22304225619882')
('Epoch 45', 'Objective: -0.049563984803561334', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.9906', 'Train LL: -0.024695142530164936', 'Test LL: -0.02826109087609934', 'Epoch Time (s): 162.17975990404375')
('Epoch 46', 'Objective: -0.04937227152457821', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.99', 'Train LL: -0.024649625882718556', 'Test LL: -0.03163717770457679', 'Epoch Time (s): 162.22785763186403')
('Epoch 47', 'Objective: -0.05069881848527201', 'Train Acc: 0.9918', 'Test Acc: 0.9909', 'Train LL: -0.02609496486177419', 'Test LL: -0.028279079549575436', 'Epoch Time (s): 162.2157133759465')
('Epoch 48', 'Objective: -0.04940316358837664', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9911', 'Train LL: -0.025107332450482356', 'Test LL: -0.02787328822407468', 'Epoch Time (s): 162.1591431631241')
('Epoch 49', 'Objective: -0.04891045526878159', 'Train Acc: 0.9921', 'Test Acc: 0.9894', 'Train LL: -0.024678280098430417', 'Test LL: -0.031394521807829916', 'Epoch Time (s): 162.1516301089432')
('Epoch 50', 'Objective: -0.04867588233167506', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9915', 'Train LL: -0.024598603415736667', 'Test LL: -0.027351529617537552', 'Epoch Time (s): 162.25435196398757')
('Epoch 51', 'Objective: -0.0479403911703374', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9914', 'Train LL: -0.023922585270005608', 'Test LL: -0.030107492796060616', 'Epoch Time (s): 162.26186981797218')
('Epoch 52', 'Objective: -0.04749788623074347', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9914', 'Train LL: -0.0236154300071722', 'Test LL: -0.027197279672322282', 'Epoch Time (s): 162.34970772801898')
('Epoch 53', 'Objective: -0.04688820422778511', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9917', 'Train LL: -0.023157647483269806', 'Test LL: -0.026110518101466477', 'Epoch Time (s): 162.32706894678995')
('Epoch 54', 'Objective: -0.04684970829212941', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.992', 'Train LL: -0.023201912100017194', 'Test LL: -0.025914499402042167', 'Epoch Time (s): 162.3136106529273')
('Epoch 55', 'Objective: -0.04627737685481261', 'Train Acc: 0.9925', 'Test Acc: 0.991', 'Train LL: -0.022634570100127104', 'Test LL: -0.027976740338867274', 'Epoch Time (s): 162.3436989269685')
('Epoch 56', 'Objective: -0.04577877852044161', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9911', 'Train LL: -0.02229034115241632', 'Test LL: -0.027330746953100914', 'Epoch Time (s): 162.35899128601886')
('Epoch 57', 'Objective: -0.04620741002736223', 'Train Acc: 0.99275', 'Test Acc: 0.991', 'Train LL: -0.022845280083343536', 'Test LL: -0.027929933444224724', 'Epoch Time (s): 162.3735066091176')
('Epoch 58', 'Objective: -0.045810867096277914', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9911', 'Train LL: -0.02247341160075229', 'Test LL: -0.026555382043333374', 'Epoch Time (s): 162.36587390000932')
('Epoch 59', 'Objective: -0.045906570332515106', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9906', 'Train LL: -0.02267140180017904', 'Test LL: -0.027316728971400566', 'Epoch Time (s): 162.316202289192')
('Epoch 60', 'Objective: -0.04573728278341434', 'Train Acc: 0.99265', 'Test Acc: 0.9901', 'Train LL: -0.02259321048014962', 'Test LL: -0.029261366247374174', 'Epoch Time (s): 162.15018470096402')
('Epoch 61', 'Objective: -0.04519369108319969', 'Train Acc: 0.9929', 'Test Acc: 0.9902', 'Train LL: -0.022116233341959203', 'Test LL: -0.028748290873203745', 'Epoch Time (s): 161.99641916295514')
('Epoch 62', 'Objective: -0.04532512458882635', 'Train Acc: 0.99265', 'Test Acc: 0.9913', 'Train LL: -0.022322041420870537', 'Test LL: -0.027286758184601696', 'Epoch Time (s): 162.26405727793463')
('Epoch 63', 'Objective: -0.04453246682311843', 'Train Acc: 0.99315', 'Test Acc: 0.991', 'Train LL: -0.021614114671238405', 'Test LL: -0.029517536847847085', 'Epoch Time (s): 162.05184444901533')
('Epoch 64', 'Objective: -0.044268447697839934', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9916', 'Train LL: -0.02146127444914229', 'Test LL: -0.027115334429685656', 'Epoch Time (s): 162.17695523705333')
('Epoch 65', 'Objective: -0.04486536815179654', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9917', 'Train LL: -0.02213517994639211', 'Test LL: -0.025275859349363265', 'Epoch Time (s): 162.18084085104056')
('Epoch 66', 'Objective: -0.04446333320394434', 'Train Acc: 0.9929', 'Test Acc: 0.9921', 'Train LL: -0.021683656671880294', 'Test LL: -0.027199668116970332', 'Epoch Time (s): 162.06314033805393')
('Epoch 67', 'Objective: -0.04464035492479551', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9918', 'Train LL: -0.021945581846095907', 'Test LL: -0.02704991887992536', 'Epoch Time (s): 162.0481808029581')
('Epoch 68', 'Objective: -0.0443465207918356', 'Train Acc: 0.99285', 'Test Acc: 0.9898', 'Train LL: -0.021734371833090946', 'Test LL: -0.02915818495836235', 'Epoch Time (s): 162.06424144189805')
('Epoch 69', 'Objective: -0.043730774855430844', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9897', 'Train LL: -0.021077846339331564', 'Test LL: -0.028882392846500318', 'Epoch Time (s): 162.11607256997377')
('Epoch 70', 'Objective: -0.04339411860983464', 'Train Acc: 0.99335', 'Test Acc: 0.9906', 'Train LL: -0.02084033791344225', 'Test LL: -0.02930894955814478', 'Epoch Time (s): 162.10066878213547')
('Epoch 71', 'Objective: -0.04404678410665005', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9906', 'Train LL: -0.02156315109857836', 'Test LL: -0.02915054755642361', 'Epoch Time (s): 162.00809563416988')
('Epoch 72', 'Objective: -0.04235416256478525', 'Train Acc: 0.9937333333333334', 'Test Acc: 0.9899', 'Train LL: -0.01998023656286771', 'Test LL: -0.030518116815104884', 'Epoch Time (s): 162.03999512293376')
('Epoch 73', 'Objective: -0.042718435594585664', 'Train Acc: 0.9934333333333333', 'Test Acc: 0.99', 'Train LL: -0.02039129571022936', 'Test LL: -0.030819026422138886', 'Epoch Time (s): 162.03279507998377')
('Epoch 74', 'Objective: -0.042470224632252175', 'Train Acc: 0.9933', 'Test Acc: 0.9921', 'Train LL: -0.020250856433393798', 'Test LL: -0.026583737280309685', 'Epoch Time (s): 162.04461676208302')
('Epoch 75', 'Objective: -0.04241668703544361', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.9906', 'Train LL: -0.02012631069513392', 'Test LL: -0.02789700973232889', 'Epoch Time (s): 162.1177558458876')
('Epoch 76', 'Objective: -0.04274923419911726', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9897', 'Train LL: -0.020504213202952207', 'Test LL: -0.02889180035287689', 'Epoch Time (s): 162.11822683899663')
('Epoch 77', 'Objective: -0.042867964154149764', 'Train Acc: 0.993', 'Test Acc: 0.9898', 'Train LL: -0.020692311599053534', 'Test LL: -0.03196993445215889', 'Epoch Time (s): 162.05785528104752')
('Epoch 78', 'Objective: -0.04233732273737196', 'Train Acc: 0.9935', 'Test Acc: 0.9912', 'Train LL: -0.02026724076979458', 'Test LL: -0.026934472167636794', 'Epoch Time (s): 162.05723748495802')
('Epoch 79', 'Objective: -0.04274537209209916', 'Train Acc: 0.993', 'Test Acc: 0.9908', 'Train LL: -0.02066397583060615', 'Test LL: -0.02720167910167408', 'Epoch Time (s): 162.07258324581198')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04018637151661624', 'Train Acc: 0.99415', 'Test Acc: 0.9912', 'Train LL: -0.018492832377681706', 'Test LL: -0.026902220543526822', 'Epoch Time (s): 162.1784463878721')
('Epoch 81', 'Objective: -0.03917036786383232', 'Train Acc: 0.9947', 'Test Acc: 0.991', 'Train LL: -0.01733788438974438', 'Test LL: -0.026770190407876975', 'Epoch Time (s): 162.13592727691866')
('Epoch 82', 'Objective: -0.03873803280072625', 'Train Acc: 0.99475', 'Test Acc: 0.9914', 'Train LL: -0.01692295329895351', 'Test LL: -0.026289970114452034', 'Epoch Time (s): 162.07570558902808')
('Epoch 83', 'Objective: -0.038594190893180204', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9908', 'Train LL: -0.016790462137042435', 'Test LL: -0.026982650040667504', 'Epoch Time (s): 162.13303327187896')
('Epoch 84', 'Objective: -0.03845851149165946', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9915', 'Train LL: -0.0166147160477047', 'Test LL: -0.02724387722741834', 'Epoch Time (s): 162.04827562812716')
('Epoch 85', 'Objective: -0.0384769662937671', 'Train Acc: 0.99465', 'Test Acc: 0.9911', 'Train LL: -0.016646501502368682', 'Test LL: -0.026810099182357952', 'Epoch Time (s): 162.14966719201766')
('Epoch 86', 'Objective: -0.03852114007881979', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.991', 'Train LL: -0.016653531587767386', 'Test LL: -0.027196833431951905', 'Epoch Time (s): 162.15896646492183')
('Epoch 87', 'Objective: -0.03839103524873122', 'Train Acc: 0.9947', 'Test Acc: 0.9917', 'Train LL: -0.016550419508403927', 'Test LL: -0.02636261178693997', 'Epoch Time (s): 162.05729892896488')
('Epoch 88', 'Objective: -0.03774424999116212', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9914', 'Train LL: -0.015983177342735196', 'Test LL: -0.026852927096093066', 'Epoch Time (s): 162.11449519498274')
('Epoch 89', 'Objective: -0.03789669656846748', 'Train Acc: 0.9947333333333334', 'Test Acc: 0.9916', 'Train LL: -0.016076273284050698', 'Test LL: -0.02634449449053049', 'Epoch Time (s): 162.0117239409592')
('Epoch 90', 'Objective: -0.038607641521299994', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9919', 'Train LL: -0.016722958039328217', 'Test LL: -0.02580601766686799', 'Epoch Time (s): 162.13298062887043')
('Epoch 91', 'Objective: -0.03817663103467057', 'Train Acc: 0.9943', 'Test Acc: 0.9916', 'Train LL: -0.016345853584760373', 'Test LL: -0.026259247749279613', 'Epoch Time (s): 162.08541747299023')
('Epoch 92', 'Objective: -0.0374623064094319', 'Train Acc: 0.9950333333333333', 'Test Acc: 0.9913', 'Train LL: -0.015727642810173307', 'Test LL: -0.02721612104190734', 'Epoch Time (s): 162.0846878341399')
('Epoch 93', 'Objective: -0.038243936502509596', 'Train Acc: 0.99485', 'Test Acc: 0.9914', 'Train LL: -0.016476412131718528', 'Test LL: -0.026956898599464558', 'Epoch Time (s): 162.2435162588954')
('Epoch 94', 'Objective: -0.03831110573897734', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.991', 'Train LL: -0.016511077529603933', 'Test LL: -0.0272591970258064', 'Epoch Time (s): 162.13606934901327')
('Epoch 95', 'Objective: -0.0377985725239612', 'Train Acc: 0.99495', 'Test Acc: 0.9915', 'Train LL: -0.015998668180581113', 'Test LL: -0.02657552032878388', 'Epoch Time (s): 162.19612055597827')
('Epoch 96', 'Objective: -0.03795476540021136', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9914', 'Train LL: -0.016199129908355897', 'Test LL: -0.02751298745353527', 'Epoch Time (s): 162.0400137018878')
('Epoch 97', 'Objective: -0.037401441863228', 'Train Acc: 0.9949', 'Test Acc: 0.9912', 'Train LL: -0.015704289401253513', 'Test LL: -0.026758160588296692', 'Epoch Time (s): 162.16924931597896')
('Epoch 98', 'Objective: -0.03813954820957852', 'Train Acc: 0.9951166666666666', 'Test Acc: 0.9916', 'Train LL: -0.016393871319388527', 'Test LL: -0.02628064871407682', 'Epoch Time (s): 162.15861400892027')
('Epoch 99', 'Objective: -0.037877604625679163', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.9919', 'Train LL: -0.016098753794732024', 'Test LL: -0.0259845656395775', 'Epoch Time (s): 162.2025879668072')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03757976639854223
Final Train Accuracy: £0.9947666666666667
Final Train LL: £-0.01584388404178362
Final Test Accuracy: £0.9919
Final Test LL: £-0.026005041945821768
