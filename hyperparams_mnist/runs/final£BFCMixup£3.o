dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: BFCMixup
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.1741382981271447', 'Train Acc: 0.63055', 'Test Acc: 0.8379', 'Train LL: -1.0618325786856506', 'Test LL: -0.48275128717920024', 'Epoch Time (s): 163.481033151038')
('Epoch 1', 'Objective: -0.4923228282920549', 'Train Acc: 0.8643333333333333', 'Test Acc: 0.9231', 'Train LL: -0.4137812593228316', 'Test LL: -0.22630289267059225', 'Epoch Time (s): 163.57741626398638')
('Epoch 2', 'Objective: -0.34724021880190953', 'Train Acc: 0.91265', 'Test Acc: 0.9454', 'Train LL: -0.27550776102205515', 'Test LL: -0.16364889722708068', 'Epoch Time (s): 163.63932143501006')
('Epoch 3', 'Objective: -0.2804723195377056', 'Train Acc: 0.93295', 'Test Acc: 0.9359', 'Train LL: -0.2130437877603328', 'Test LL: -0.1958965694846705', 'Epoch Time (s): 163.5797316050157')
('Epoch 4', 'Objective: -0.24201004472434093', 'Train Acc: 0.9451833333333334', 'Test Acc: 0.9598', 'Train LL: -0.17830937444194744', 'Test LL: -0.1258160780084298', 'Epoch Time (s): 163.64768033497967')
('Epoch 5', 'Objective: -0.21765426664956852', 'Train Acc: 0.9515833333333333', 'Test Acc: 0.9434', 'Train LL: -0.1567075961598721', 'Test LL: -0.17316127132154593', 'Epoch Time (s): 163.6238437788561')
('Epoch 6', 'Objective: -0.1994911013918647', 'Train Acc: 0.9566', 'Test Acc: 0.9633', 'Train LL: -0.1410659621573869', 'Test LL: -0.11154441984749394', 'Epoch Time (s): 163.57054842985235')
('Epoch 7', 'Objective: -0.1848858838187133', 'Train Acc: 0.9601166666666666', 'Test Acc: 0.9626', 'Train LL: -0.12837664000526508', 'Test LL: -0.11487905394701167', 'Epoch Time (s): 163.60979386908002')
('Epoch 8', 'Objective: -0.1740950583593961', 'Train Acc: 0.9633833333333334', 'Test Acc: 0.9573', 'Train LL: -0.11920759399654376', 'Test LL: -0.12256921618043072', 'Epoch Time (s): 163.64523048116826')
('Epoch 9', 'Objective: -0.1659177503870079', 'Train Acc: 0.96565', 'Test Acc: 0.9678', 'Train LL: -0.11230844045537648', 'Test LL: -0.10299972798386653', 'Epoch Time (s): 163.67217711592093')
('Epoch 10', 'Objective: -0.16011299162283846', 'Train Acc: 0.9664833333333334', 'Test Acc: 0.9749', 'Train LL: -0.10752732682959232', 'Test LL: -0.07787801713367491', 'Epoch Time (s): 163.6539221040439')
('Epoch 11', 'Objective: -0.15246419018183924', 'Train Acc: 0.9679666666666666', 'Test Acc: 0.9761', 'Train LL: -0.10168074555122603', 'Test LL: -0.07119964579273103', 'Epoch Time (s): 163.64415557589382')
('Epoch 12', 'Objective: -0.14501168438117099', 'Train Acc: 0.9706333333333333', 'Test Acc: 0.9703', 'Train LL: -0.0955452588775206', 'Test LL: -0.08837770161077504', 'Epoch Time (s): 163.6746689879801')
('Epoch 13', 'Objective: -0.14068670845834574', 'Train Acc: 0.9713833333333334', 'Test Acc: 0.9736', 'Train LL: -0.09170105757006443', 'Test LL: -0.08199466204144322', 'Epoch Time (s): 163.56569073116407')
('Epoch 14', 'Objective: -0.13894572115607412', 'Train Acc: 0.9721', 'Test Acc: 0.9766', 'Train LL: -0.0907306280375269', 'Test LL: -0.0675938325907113', 'Epoch Time (s): 163.62424560985528')
('Epoch 15', 'Objective: -0.1326453491011078', 'Train Acc: 0.97335', 'Test Acc: 0.9719', 'Train LL: -0.08543371803142197', 'Test LL: -0.08326381853340403', 'Epoch Time (s): 163.66469925898127')
('Epoch 16', 'Objective: -0.1304198564626924', 'Train Acc: 0.9738333333333333', 'Test Acc: 0.9789', 'Train LL: -0.0834087594578116', 'Test LL: -0.0671043646063531', 'Epoch Time (s): 163.57192256115377')
('Epoch 17', 'Objective: -0.1282089428834783', 'Train Acc: 0.9742833333333333', 'Test Acc: 0.9762', 'Train LL: -0.08238359627654232', 'Test LL: -0.07270715852155786', 'Epoch Time (s): 163.62647828599438')
('Epoch 18', 'Objective: -0.1235141824155332', 'Train Acc: 0.9757833333333333', 'Test Acc: 0.9792', 'Train LL: -0.0779560932495637', 'Test LL: -0.062196250041799406', 'Epoch Time (s): 163.59499359200709')
('Epoch 19', 'Objective: -0.12234155722917822', 'Train Acc: 0.9760166666666666', 'Test Acc: 0.9813', 'Train LL: -0.07740322141777585', 'Test LL: -0.06191905697464216', 'Epoch Time (s): 163.63575366907753')
('Epoch 20', 'Objective: -0.11965000030618211', 'Train Acc: 0.9766833333333333', 'Test Acc: 0.9814', 'Train LL: -0.0751329147579204', 'Test LL: -0.05712183053819988', 'Epoch Time (s): 163.59816180705093')
('Epoch 21', 'Objective: -0.115705062251656', 'Train Acc: 0.9771666666666666', 'Test Acc: 0.9812', 'Train LL: -0.07192396773037253', 'Test LL: -0.06242928360066639', 'Epoch Time (s): 163.655650439905')
('Epoch 22', 'Objective: -0.1149983651082004', 'Train Acc: 0.9774833333333334', 'Test Acc: 0.9726', 'Train LL: -0.07139557512559883', 'Test LL: -0.08142816031160444', 'Epoch Time (s): 163.5810127169825')
('Epoch 23', 'Objective: -0.11298304158063245', 'Train Acc: 0.9780166666666666', 'Test Acc: 0.9811', 'Train LL: -0.0700796888662096', 'Test LL: -0.06218094805247036', 'Epoch Time (s): 163.62458506203257')
('Epoch 24', 'Objective: -0.11040718388917917', 'Train Acc: 0.9789166666666667', 'Test Acc: 0.9838', 'Train LL: -0.06783807165950646', 'Test LL: -0.0538289756440054', 'Epoch Time (s): 163.56898469803855')
('Epoch 25', 'Objective: -0.11033971768467789', 'Train Acc: 0.9788666666666667', 'Test Acc: 0.9833', 'Train LL: -0.06830747147620315', 'Test LL: -0.04991923181757684', 'Epoch Time (s): 163.59162200707942')
('Epoch 26', 'Objective: -0.10946735789943479', 'Train Acc: 0.9785666666666667', 'Test Acc: 0.9794', 'Train LL: -0.06771076962882273', 'Test LL: -0.06043431601326295', 'Epoch Time (s): 163.67466517607681')
('Epoch 27', 'Objective: -0.1085599762925297', 'Train Acc: 0.9791166666666666', 'Test Acc: 0.979', 'Train LL: -0.06705291321798798', 'Test LL: -0.061116642801719856', 'Epoch Time (s): 163.584592979867')
('Epoch 28', 'Objective: -0.10592119115095651', 'Train Acc: 0.9801666666666666', 'Test Acc: 0.9809', 'Train LL: -0.06497546400442007', 'Test LL: -0.059946288494535906', 'Epoch Time (s): 163.6491810809821')
('Epoch 29', 'Objective: -0.10237997519321107', 'Train Acc: 0.9807166666666667', 'Test Acc: 0.9838', 'Train LL: -0.06202335597163718', 'Test LL: -0.049574629752300994', 'Epoch Time (s): 163.64979330892675')
('Epoch 30', 'Objective: -0.10307215787011963', 'Train Acc: 0.9797833333333333', 'Test Acc: 0.9841', 'Train LL: -0.06256601719736243', 'Test LL: -0.04652115570496905', 'Epoch Time (s): 163.5679798061028')
('Epoch 31', 'Objective: -0.09957623393453942', 'Train Acc: 0.9815', 'Test Acc: 0.9808', 'Train LL: -0.05980335737428076', 'Test LL: -0.061091961243220166', 'Epoch Time (s): 163.667511284817')
('Epoch 32', 'Objective: -0.0989149306210276', 'Train Acc: 0.9812333333333333', 'Test Acc: 0.9802', 'Train LL: -0.05936412135392685', 'Test LL: -0.06562790440095127', 'Epoch Time (s): 163.5952227159869')
('Epoch 33', 'Objective: -0.09922546013494624', 'Train Acc: 0.9816166666666667', 'Test Acc: 0.9799', 'Train LL: -0.059849065347609615', 'Test LL: -0.060020168780994095', 'Epoch Time (s): 163.64535094681196')
('Epoch 34', 'Objective: -0.09805384008562397', 'Train Acc: 0.9812', 'Test Acc: 0.9861', 'Train LL: -0.05878995291020125', 'Test LL: -0.04764005989000913', 'Epoch Time (s): 163.5759736117907')
('Epoch 35', 'Objective: -0.09622171702551426', 'Train Acc: 0.9819166666666667', 'Test Acc: 0.9812', 'Train LL: -0.05738919051267324', 'Test LL: -0.05749326093766683', 'Epoch Time (s): 163.6491328959819')
('Epoch 36', 'Objective: -0.09611529480471422', 'Train Acc: 0.9817166666666667', 'Test Acc: 0.9783', 'Train LL: -0.05744824005419823', 'Test LL: -0.062374511978304216', 'Epoch Time (s): 163.63035372295417')
('Epoch 37', 'Objective: -0.09550489298426472', 'Train Acc: 0.98195', 'Test Acc: 0.9844', 'Train LL: -0.05701928386435847', 'Test LL: -0.04814945524205997', 'Epoch Time (s): 163.55705483304337')
('Epoch 38', 'Objective: -0.09538808439683231', 'Train Acc: 0.9820833333333333', 'Test Acc: 0.9887', 'Train LL: -0.05727656180715775', 'Test LL: -0.03511204880058398', 'Epoch Time (s): 163.6743335078936')
('Epoch 39', 'Objective: -0.09158527410957748', 'Train Acc: 0.98275', 'Test Acc: 0.9881', 'Train LL: -0.05379268508800311', 'Test LL: -0.038258092954331024', 'Epoch Time (s): 163.54659477993846')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.07082667226854109', 'Train Acc: 0.98935', 'Test Acc: 0.9914', 'Train LL: -0.03609824201819906', 'Test LL: -0.029420372212020346', 'Epoch Time (s): 163.56034811097197')
('Epoch 41', 'Objective: -0.0641932469847516', 'Train Acc: 0.9902333333333333', 'Test Acc: 0.9897', 'Train LL: -0.03074834755808427', 'Test LL: -0.034031504348979294', 'Epoch Time (s): 163.62716156011447')
('Epoch 42', 'Objective: -0.06216583211847986', 'Train Acc: 0.99075', 'Test Acc: 0.991', 'Train LL: -0.029397555464144177', 'Test LL: -0.029412505069179126', 'Epoch Time (s): 163.5628292229958')
('Epoch 43', 'Objective: -0.061283121937561025', 'Train Acc: 0.9913166666666666', 'Test Acc: 0.9905', 'Train LL: -0.02891104755947961', 'Test LL: -0.029839900700978764', 'Epoch Time (s): 163.55114709516056')
('Epoch 44', 'Objective: -0.059728511084351434', 'Train Acc: 0.9915', 'Test Acc: 0.9912', 'Train LL: -0.027775752834304102', 'Test LL: -0.029917482791975557', 'Epoch Time (s): 163.73134508589283')
('Epoch 45', 'Objective: -0.058945645044479945', 'Train Acc: 0.9914666666666667', 'Test Acc: 0.9912', 'Train LL: -0.027269371513662714', 'Test LL: -0.02759745810479219', 'Epoch Time (s): 163.5815454008989')
('Epoch 46', 'Objective: -0.058448005627357094', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9906', 'Train LL: -0.026974854237807044', 'Test LL: -0.030905341332339187', 'Epoch Time (s): 163.65964888292365')
('Epoch 47', 'Objective: -0.05839090353320201', 'Train Acc: 0.99155', 'Test Acc: 0.9904', 'Train LL: -0.027138606484118283', 'Test LL: -0.030754734562944107', 'Epoch Time (s): 163.5551831361372')
('Epoch 48', 'Objective: -0.05742415413471047', 'Train Acc: 0.9916166666666667', 'Test Acc: 0.9905', 'Train LL: -0.02640318103801803', 'Test LL: -0.03233797963097503', 'Epoch Time (s): 163.62676045601256')
('Epoch 49', 'Objective: -0.05642212785705957', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.9915', 'Train LL: -0.025732046095254524', 'Test LL: -0.030235795457485712', 'Epoch Time (s): 163.56433811411262')
('Epoch 50', 'Objective: -0.056789803888423404', 'Train Acc: 0.9919166666666667', 'Test Acc: 0.9897', 'Train LL: -0.026281782303992356', 'Test LL: -0.03229472809490829', 'Epoch Time (s): 163.64521666592918')
('Epoch 51', 'Objective: -0.05542925102628111', 'Train Acc: 0.99185', 'Test Acc: 0.992', 'Train LL: -0.02511130023159203', 'Test LL: -0.029979867441010624', 'Epoch Time (s): 163.56090304884128')
('Epoch 52', 'Objective: -0.055199494050382464', 'Train Acc: 0.99215', 'Test Acc: 0.9908', 'Train LL: -0.025003589372607757', 'Test LL: -0.02986556149219536', 'Epoch Time (s): 163.66255150805227')
('Epoch 53', 'Objective: -0.055373442791636626', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.9911', 'Train LL: -0.02528647286251477', 'Test LL: -0.03010741868942139', 'Epoch Time (s): 163.6340185860172')
('Epoch 54', 'Objective: -0.054945994981823405', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9909', 'Train LL: -0.025075217870903277', 'Test LL: -0.029482828752517048', 'Epoch Time (s): 163.642030633986')
('Epoch 55', 'Objective: -0.05531349969651237', 'Train Acc: 0.992', 'Test Acc: 0.9909', 'Train LL: -0.025399699355169825', 'Test LL: -0.02905996676508749', 'Epoch Time (s): 163.56907875393517')
('Epoch 56', 'Objective: -0.05436385001140561', 'Train Acc: 0.9924', 'Test Acc: 0.9906', 'Train LL: -0.02475990840984511', 'Test LL: -0.02979029762200998', 'Epoch Time (s): 163.65994914108887')
('Epoch 57', 'Objective: -0.05403265434067046', 'Train Acc: 0.99215', 'Test Acc: 0.9907', 'Train LL: -0.024605964711676264', 'Test LL: -0.0303484212006054', 'Epoch Time (s): 163.56987066217698')
('Epoch 58', 'Objective: -0.05335601801480274', 'Train Acc: 0.99245', 'Test Acc: 0.9897', 'Train LL: -0.024052046150002282', 'Test LL: -0.03268552484582292', 'Epoch Time (s): 163.63330409303308')
('Epoch 59', 'Objective: -0.053655681138167814', 'Train Acc: 0.99235', 'Test Acc: 0.9903', 'Train LL: -0.02442209997463826', 'Test LL: -0.031141510510738567', 'Epoch Time (s): 163.57211576099508')
('Epoch 60', 'Objective: -0.05229952217063608', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9921', 'Train LL: -0.02333988768638504', 'Test LL: -0.027499645776070572', 'Epoch Time (s): 163.6262020089198')
('Epoch 61', 'Objective: -0.053421926964756554', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9903', 'Train LL: -0.024460899010871822', 'Test LL: -0.029354703465265475', 'Epoch Time (s): 163.58481666399166')
('Epoch 62', 'Objective: -0.05178065955599549', 'Train Acc: 0.9926333333333334', 'Test Acc: 0.9901', 'Train LL: -0.02302674598243103', 'Test LL: -0.031500347398229975', 'Epoch Time (s): 163.63682948891073')
('Epoch 63', 'Objective: -0.05214623258479571', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9909', 'Train LL: -0.023429148779930152', 'Test LL: -0.03149945426668413', 'Epoch Time (s): 163.60988567885943')
('Epoch 64', 'Objective: -0.05108744972310925', 'Train Acc: 0.99285', 'Test Acc: 0.9897', 'Train LL: -0.022578002779290257', 'Test LL: -0.03372004306037377', 'Epoch Time (s): 163.57540459209122')
('Epoch 65', 'Objective: -0.05184458198159765', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9894', 'Train LL: -0.02336188566540105', 'Test LL: -0.033974650945928525', 'Epoch Time (s): 163.65114830620587')
('Epoch 66', 'Objective: -0.0518401881259798', 'Train Acc: 0.99225', 'Test Acc: 0.9911', 'Train LL: -0.023489152223433226', 'Test LL: -0.028945992274239354', 'Epoch Time (s): 163.6003602258861')
('Epoch 67', 'Objective: -0.05066533364135044', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9901', 'Train LL: -0.022606341943334732', 'Test LL: -0.031091975526180454', 'Epoch Time (s): 163.64069387991913')
('Epoch 68', 'Objective: -0.05087255420065732', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9895', 'Train LL: -0.022837540562637208', 'Test LL: -0.030703398726501886', 'Epoch Time (s): 163.5772136009764')
('Epoch 69', 'Objective: -0.04979960953240631', 'Train Acc: 0.9932333333333333', 'Test Acc: 0.9915', 'Train LL: -0.021829595288335203', 'Test LL: -0.029369694037335', 'Epoch Time (s): 163.6366788649466')
('Epoch 70', 'Objective: -0.04963747397720256', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9895', 'Train LL: -0.021711105748803364', 'Test LL: -0.03399056030646837', 'Epoch Time (s): 163.57157108513638')
('Epoch 71', 'Objective: -0.05072107881593536', 'Train Acc: 0.9926', 'Test Acc: 0.9902', 'Train LL: -0.02290013715573974', 'Test LL: -0.029209563453124143', 'Epoch Time (s): 163.64173486595973')
('Epoch 72', 'Objective: -0.04925078837123106', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9884', 'Train LL: -0.021584279201306192', 'Test LL: -0.03724352527883443', 'Epoch Time (s): 163.58752847090364')
('Epoch 73', 'Objective: -0.05023287131538066', 'Train Acc: 0.99335', 'Test Acc: 0.9904', 'Train LL: -0.02272914117333453', 'Test LL: -0.030385839055351367', 'Epoch Time (s): 163.60666020284407')
('Epoch 74', 'Objective: -0.05041054928126949', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9913', 'Train LL: -0.02284922554207157', 'Test LL: -0.029479606082878182', 'Epoch Time (s): 163.53776558092795')
('Epoch 75', 'Objective: -0.0498973445622837', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9915', 'Train LL: -0.02250256182425293', 'Test LL: -0.028230862998744208', 'Epoch Time (s): 163.60101305390708')
('Epoch 76', 'Objective: -0.04991420194825401', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9903', 'Train LL: -0.022564922937628802', 'Test LL: -0.030625282709685207', 'Epoch Time (s): 163.629979042802')
('Epoch 77', 'Objective: -0.04911880047517959', 'Train Acc: 0.9930666666666667', 'Test Acc: 0.9884', 'Train LL: -0.021866161088762277', 'Test LL: -0.034750441092354784', 'Epoch Time (s): 163.63659361586906')
('Epoch 78', 'Objective: -0.04909223553922054', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9886', 'Train LL: -0.0218750187048099', 'Test LL: -0.03500119063563374', 'Epoch Time (s): 163.6901007220149')
('Epoch 79', 'Objective: -0.048664368245446614', 'Train Acc: 0.99305', 'Test Acc: 0.9912', 'Train LL: -0.02155622888536486', 'Test LL: -0.03079269363837751', 'Epoch Time (s): 163.6439453479834')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04529219082333587', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.991', 'Train LL: -0.01856003395952098', 'Test LL: -0.029207251245250535', 'Epoch Time (s): 163.64931163797155')
('Epoch 81', 'Objective: -0.04512817953623159', 'Train Acc: 0.99425', 'Test Acc: 0.9918', 'Train LL: -0.018472013252761803', 'Test LL: -0.027562380148790363', 'Epoch Time (s): 163.59811763907783')
('Epoch 82', 'Objective: -0.04541146427011596', 'Train Acc: 0.9941', 'Test Acc: 0.9917', 'Train LL: -0.018781313675137856', 'Test LL: -0.0279750874431664', 'Epoch Time (s): 163.62269930006005')
('Epoch 83', 'Objective: -0.044673812555167836', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9916', 'Train LL: -0.01807062684219834', 'Test LL: -0.027625807928600993', 'Epoch Time (s): 163.67628980008885')
('Epoch 84', 'Objective: -0.044605416531044016', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9921', 'Train LL: -0.018058148896622713', 'Test LL: -0.027794532563363828', 'Epoch Time (s): 163.6733195320703')
('Epoch 85', 'Objective: -0.045108252634380896', 'Train Acc: 0.9942333333333333', 'Test Acc: 0.9916', 'Train LL: -0.018457712225885364', 'Test LL: -0.027669038680643347', 'Epoch Time (s): 163.67013312899508')
('Epoch 86', 'Objective: -0.044147143301071334', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9918', 'Train LL: -0.017610636805570623', 'Test LL: -0.02716412770726214', 'Epoch Time (s): 163.60040212003514')
('Epoch 87', 'Objective: -0.04395828492496354', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9916', 'Train LL: -0.017478621316493772', 'Test LL: -0.0275220248523973', 'Epoch Time (s): 163.66514163208194')
('Epoch 88', 'Objective: -0.04413175688916886', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.9916', 'Train LL: -0.017646463142078107', 'Test LL: -0.027736601689664103', 'Epoch Time (s): 163.64625146402977')
('Epoch 89', 'Objective: -0.04423148919968952', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9915', 'Train LL: -0.01770915742688801', 'Test LL: -0.02744444814906791', 'Epoch Time (s): 163.5955781491939')
('Epoch 90', 'Objective: -0.044190448548894576', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9913', 'Train LL: -0.01759115869806267', 'Test LL: -0.02762696679328323', 'Epoch Time (s): 163.6781911449507')
('Epoch 91', 'Objective: -0.04547049311387822', 'Train Acc: 0.9941', 'Test Acc: 0.9916', 'Train LL: -0.018838381333581667', 'Test LL: -0.027403453657259574', 'Epoch Time (s): 163.5712851791177')
('Epoch 92', 'Objective: -0.04366910497805216', 'Train Acc: 0.99475', 'Test Acc: 0.9911', 'Train LL: -0.01720403130109771', 'Test LL: -0.028730293108853427', 'Epoch Time (s): 163.58192052599043')
('Epoch 93', 'Objective: -0.04454491898729347', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9914', 'Train LL: -0.01804789472272981', 'Test LL: -0.028264764002271806', 'Epoch Time (s): 163.67454776610248')
('Epoch 94', 'Objective: -0.043636177976449406', 'Train Acc: 0.99455', 'Test Acc: 0.9912', 'Train LL: -0.01720774366963283', 'Test LL: -0.029278144851758725', 'Epoch Time (s): 163.6721947088372')
('Epoch 95', 'Objective: -0.044061347054262304', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.9916', 'Train LL: -0.017600211880077946', 'Test LL: -0.02781003268013489', 'Epoch Time (s): 163.56877385196276')
('Epoch 96', 'Objective: -0.0438396917385421', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9911', 'Train LL: -0.017415049032383195', 'Test LL: -0.02847392166808954', 'Epoch Time (s): 163.64067171211354')
('Epoch 97', 'Objective: -0.0436412704267162', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9912', 'Train LL: -0.017191246649281795', 'Test LL: -0.02798792784469988', 'Epoch Time (s): 163.50874282605946')
('Epoch 98', 'Objective: -0.043904297138996816', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.992', 'Train LL: -0.01746289276383777', 'Test LL: -0.027761834355008824', 'Epoch Time (s): 163.5634997440502')
('Epoch 99', 'Objective: -0.04382007749383661', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9913', 'Train LL: -0.01742222078311308', 'Test LL: -0.027976910816842223', 'Epoch Time (s): 163.59200586285442')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04342350582887047
Final Train Accuracy: £0.9945333333333334
Final Train LL: £-0.01703176677678672
Final Test Accuracy: £0.9913
Final Test LL: £-0.02789438773733267
