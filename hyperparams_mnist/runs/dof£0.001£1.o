dataset: MNIST
dtype: float64
dof: 0.001
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2578168293440222', 'Train Acc: 0.5615666666666667', 'Test Acc: 0.8376', 'Train LL: -1.2272288601555958', 'Test LL: -0.49656700781059515', 'Epoch Time (s): 172.45711774611846')
('Epoch 1', 'Objective: -0.4286269543994463', 'Train Acc: 0.8617666666666667', 'Test Acc: 0.9165', 'Train LL: -0.41218890553778637', 'Test LL: -0.25235114034843936', 'Epoch Time (s): 171.34490917809308')
('Epoch 2', 'Objective: -0.23011013417222678', 'Train Acc: 0.9306666666666666', 'Test Acc: 0.9345', 'Train LL: -0.21863413991282774', 'Test LL: -0.19760695446297014', 'Epoch Time (s): 171.40285669406876')
('Epoch 3', 'Objective: -0.1808563407289214', 'Train Acc: 0.9456666666666667', 'Test Acc: 0.9471', 'Train LL: -0.17128581237501037', 'Test LL: -0.15707702099156576', 'Epoch Time (s): 171.3532551759854')
('Epoch 4', 'Objective: -0.15250454982612954', 'Train Acc: 0.9545666666666667', 'Test Acc: 0.9635', 'Train LL: -0.1440982532677975', 'Test LL: -0.11566850728493441', 'Epoch Time (s): 171.41217238875106')
('Epoch 5', 'Objective: -0.12949864637528355', 'Train Acc: 0.9613166666666667', 'Test Acc: 0.9724', 'Train LL: -0.12184265184359529', 'Test LL: -0.09056900801845835', 'Epoch Time (s): 171.3387643089518')
('Epoch 6', 'Objective: -0.11635110905757731', 'Train Acc: 0.9657666666666667', 'Test Acc: 0.9572', 'Train LL: -0.10931473924616293', 'Test LL: -0.13128576449988905', 'Epoch Time (s): 171.3334973086603')
('Epoch 7', 'Objective: -0.10656826072142517', 'Train Acc: 0.969', 'Test Acc: 0.9811', 'Train LL: -0.10002651460327804', 'Test LL: -0.06514189191990649', 'Epoch Time (s): 171.35470443218946')
('Epoch 8', 'Objective: -0.10115321622524302', 'Train Acc: 0.9698833333333333', 'Test Acc: 0.9782', 'Train LL: -0.09483567145513823', 'Test LL: -0.06780121125225162', 'Epoch Time (s): 171.35675424523652')
('Epoch 9', 'Objective: -0.09419436164142701', 'Train Acc: 0.97245', 'Test Acc: 0.9705', 'Train LL: -0.08819823855799741', 'Test LL: -0.08801208134452129', 'Epoch Time (s): 171.4444604278542')
('Epoch 10', 'Objective: -0.08965877387896008', 'Train Acc: 0.9736', 'Test Acc: 0.9836', 'Train LL: -0.0839234156931419', 'Test LL: -0.0514842582946376', 'Epoch Time (s): 171.39111352106556')
('Epoch 11', 'Objective: -0.08320046477070925', 'Train Acc: 0.9755833333333334', 'Test Acc: 0.9812', 'Train LL: -0.07776686677775758', 'Test LL: -0.0631368873759391', 'Epoch Time (s): 171.40457958728075')
('Epoch 12', 'Objective: -0.08074037134625105', 'Train Acc: 0.9754166666666667', 'Test Acc: 0.9838', 'Train LL: -0.07546286810339257', 'Test LL: -0.051263652842113865', 'Epoch Time (s): 171.3577227271162')
('Epoch 13', 'Objective: -0.07731090616049603', 'Train Acc: 0.9775333333333334', 'Test Acc: 0.9785', 'Train LL: -0.07219132479568567', 'Test LL: -0.06648790453267903', 'Epoch Time (s): 171.36180588323623')
('Epoch 14', 'Objective: -0.0749337638427151', 'Train Acc: 0.9779', 'Test Acc: 0.9797', 'Train LL: -0.06999164655944679', 'Test LL: -0.05969033412059155', 'Epoch Time (s): 171.36614853609353')
('Epoch 15', 'Objective: -0.071899505218423', 'Train Acc: 0.97875', 'Test Acc: 0.9823', 'Train LL: -0.06715077151277618', 'Test LL: -0.05309097780299866', 'Epoch Time (s): 171.3685686578974')
('Epoch 16', 'Objective: -0.06740196498424936', 'Train Acc: 0.9799666666666667', 'Test Acc: 0.9685', 'Train LL: -0.06283224584787331', 'Test LL: -0.09390264465827401', 'Epoch Time (s): 171.3232731469907')
('Epoch 17', 'Objective: -0.06579483560713703', 'Train Acc: 0.9801833333333333', 'Test Acc: 0.9812', 'Train LL: -0.06136124426641752', 'Test LL: -0.05948392545502247', 'Epoch Time (s): 171.34159472677857')
('Epoch 18', 'Objective: -0.0657270299125647', 'Train Acc: 0.9808333333333333', 'Test Acc: 0.9806', 'Train LL: -0.061466129899823994', 'Test LL: -0.0626431380658273', 'Epoch Time (s): 171.35637981863692')
('Epoch 19', 'Objective: -0.062094784882763376', 'Train Acc: 0.98175', 'Test Acc: 0.9806', 'Train LL: -0.05793548478025544', 'Test LL: -0.05969183361413757', 'Epoch Time (s): 171.31840042816475')
('Epoch 20', 'Objective: -0.061436102103147996', 'Train Acc: 0.98085', 'Test Acc: 0.9811', 'Train LL: -0.05731194497220383', 'Test LL: -0.05752978942474615', 'Epoch Time (s): 171.38800450507551')
('Epoch 21', 'Objective: -0.06099821894938024', 'Train Acc: 0.9815666666666667', 'Test Acc: 0.9785', 'Train LL: -0.05702493415506641', 'Test LL: -0.06207213361640949', 'Epoch Time (s): 171.37713439809158')
('Epoch 22', 'Objective: -0.05893311662255558', 'Train Acc: 0.9825166666666667', 'Test Acc: 0.9866', 'Train LL: -0.05508816345469655', 'Test LL: -0.042353903321428514', 'Epoch Time (s): 171.35248204693198')
('Epoch 23', 'Objective: -0.05733769828489227', 'Train Acc: 0.9830166666666666', 'Test Acc: 0.9787', 'Train LL: -0.053610841568554696', 'Test LL: -0.06439307144260441', 'Epoch Time (s): 171.3208114337176')
('Epoch 24', 'Objective: -0.05572543756623833', 'Train Acc: 0.98315', 'Test Acc: 0.9878', 'Train LL: -0.052064086280329464', 'Test LL: -0.04039005512166385', 'Epoch Time (s): 171.3385253311135')
('Epoch 25', 'Objective: -0.05501062276963825', 'Train Acc: 0.9833', 'Test Acc: 0.9864', 'Train LL: -0.05147729925863728', 'Test LL: -0.04272231072299313', 'Epoch Time (s): 171.32703022286296')
('Epoch 26', 'Objective: -0.0536583636910742', 'Train Acc: 0.9838666666666667', 'Test Acc: 0.9786', 'Train LL: -0.05017601980970893', 'Test LL: -0.05959955970908354', 'Epoch Time (s): 171.30185028212145')
('Epoch 27', 'Objective: -0.051295643704243964', 'Train Acc: 0.9849333333333333', 'Test Acc: 0.9844', 'Train LL: -0.047847348289201085', 'Test LL: -0.049622481106813755', 'Epoch Time (s): 171.23068142309785')
('Epoch 28', 'Objective: -0.0511702697290325', 'Train Acc: 0.98435', 'Test Acc: 0.9838', 'Train LL: -0.047766755420073935', 'Test LL: -0.05011545212349103', 'Epoch Time (s): 171.28002583794296')
('Epoch 29', 'Objective: -0.0522525412116398', 'Train Acc: 0.9846666666666667', 'Test Acc: 0.9837', 'Train LL: -0.04895472439583074', 'Test LL: -0.046177945088074525', 'Epoch Time (s): 171.2907618600875')
('Epoch 30', 'Objective: -0.048956150118594034', 'Train Acc: 0.9853333333333333', 'Test Acc: 0.9879', 'Train LL: -0.045752561484625996', 'Test LL: -0.036893616420638826', 'Epoch Time (s): 171.32545115659013')
('Epoch 31', 'Objective: -0.05122540082383861', 'Train Acc: 0.9848', 'Test Acc: 0.9882', 'Train LL: -0.04804227510423326', 'Test LL: -0.03518321667836747', 'Epoch Time (s): 171.28031216701493')
('Epoch 32', 'Objective: -0.04882740971875481', 'Train Acc: 0.98545', 'Test Acc: 0.9884', 'Train LL: -0.045717859296035536', 'Test LL: -0.03790311976575087', 'Epoch Time (s): 171.261671716813')
('Epoch 33', 'Objective: -0.04648805013142139', 'Train Acc: 0.9857666666666667', 'Test Acc: 0.9863', 'Train LL: -0.04341314478427302', 'Test LL: -0.04402732955913374', 'Epoch Time (s): 171.2620925111696')
('Epoch 34', 'Objective: -0.047126614433764556', 'Train Acc: 0.9859666666666667', 'Test Acc: 0.9853', 'Train LL: -0.04411766542613242', 'Test LL: -0.05174992892867831', 'Epoch Time (s): 171.24554157210514')
('Epoch 35', 'Objective: -0.046554498857462316', 'Train Acc: 0.9865833333333334', 'Test Acc: 0.9863', 'Train LL: -0.04357777262231496', 'Test LL: -0.040128894128627544', 'Epoch Time (s): 171.2914719316177')
('Epoch 36', 'Objective: -0.04466882274423083', 'Train Acc: 0.9866333333333334', 'Test Acc: 0.9875', 'Train LL: -0.041745201103018534', 'Test LL: -0.03929014456977886', 'Epoch Time (s): 171.23975773900747')
('Epoch 37', 'Objective: -0.04513839905800279', 'Train Acc: 0.9858333333333333', 'Test Acc: 0.9842', 'Train LL: -0.04223089770809358', 'Test LL: -0.04787228002409529', 'Epoch Time (s): 171.30959325982258')
('Epoch 38', 'Objective: -0.045196329104852946', 'Train Acc: 0.9863333333333333', 'Test Acc: 0.9875', 'Train LL: -0.04231931108859915', 'Test LL: -0.04195704017550366', 'Epoch Time (s): 171.32753316732123')
('Epoch 39', 'Objective: -0.04441268806769662', 'Train Acc: 0.9871166666666666', 'Test Acc: 0.9823', 'Train LL: -0.041609441511395895', 'Test LL: -0.05631867392288102', 'Epoch Time (s): 171.27980582835153')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.028854247730413396', 'Train Acc: 0.9917666666666667', 'Test Acc: 0.9925', 'Train LL: -0.026311166127915873', 'Test LL: -0.02484988605181839', 'Epoch Time (s): 171.29457112308592')
('Epoch 41', 'Objective: -0.022999666763691324', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9918', 'Train LL: -0.020587347477745276', 'Test LL: -0.02547511896598076', 'Epoch Time (s): 171.303102159407')
('Epoch 42', 'Objective: -0.021061543097842528', 'Train Acc: 0.9937333333333334', 'Test Acc: 0.9925', 'Train LL: -0.018692392215480504', 'Test LL: -0.025198265877974933', 'Epoch Time (s): 171.3322055558674')
('Epoch 43', 'Objective: -0.02068257640836701', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9928', 'Train LL: -0.018353839797527', 'Test LL: -0.0269842543439559', 'Epoch Time (s): 171.16860759304836')
('Epoch 44', 'Objective: -0.0185487412543741', 'Train Acc: 0.9944', 'Test Acc: 0.9921', 'Train LL: -0.016265578976542218', 'Test LL: -0.026205206957698072', 'Epoch Time (s): 171.2821148200892')
('Epoch 45', 'Objective: -0.01826475833508878', 'Train Acc: 0.9949833333333333', 'Test Acc: 0.9915', 'Train LL: -0.016022205444837977', 'Test LL: -0.0290351585299168', 'Epoch Time (s): 171.17669387487695')
('Epoch 46', 'Objective: -0.018626632970008623', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9922', 'Train LL: -0.01636575604847088', 'Test LL: -0.025395779264175345', 'Epoch Time (s): 171.17642125301063')
('Epoch 47', 'Objective: -0.017591349941621835', 'Train Acc: 0.9950166666666667', 'Test Acc: 0.9921', 'Train LL: -0.015364617340016592', 'Test LL: -0.025230466306791453', 'Epoch Time (s): 171.2061978559941')
('Epoch 48', 'Objective: -0.016796372604770925', 'Train Acc: 0.9954666666666667', 'Test Acc: 0.9915', 'Train LL: -0.014599718468127203', 'Test LL: -0.02723232979935588', 'Epoch Time (s): 171.21798882028088')
('Epoch 49', 'Objective: -0.016061838196736844', 'Train Acc: 0.99545', 'Test Acc: 0.9913', 'Train LL: -0.013882216599504258', 'Test LL: -0.031292206481046206', 'Epoch Time (s): 171.15194114716724')
('Epoch 50', 'Objective: -0.01668384719414414', 'Train Acc: 0.9951833333333333', 'Test Acc: 0.9926', 'Train LL: -0.014482427276881132', 'Test LL: -0.02448020585409274', 'Epoch Time (s): 171.1716357250698')
('Epoch 51', 'Objective: -0.01500690451854885', 'Train Acc: 0.99555', 'Test Acc: 0.991', 'Train LL: -0.01283538214680691', 'Test LL: -0.02870599992487837', 'Epoch Time (s): 171.20841906685382')
('Epoch 52', 'Objective: -0.015590729168807738', 'Train Acc: 0.9959', 'Test Acc: 0.9909', 'Train LL: -0.013399701119537614', 'Test LL: -0.029075938457053037', 'Epoch Time (s): 171.15920552797616')
('Epoch 53', 'Objective: -0.014205834056808874', 'Train Acc: 0.9959666666666667', 'Test Acc: 0.9919', 'Train LL: -0.012049881183478115', 'Test LL: -0.027030982688927372', 'Epoch Time (s): 171.21573589090258')
('Epoch 54', 'Objective: -0.014399346204851421', 'Train Acc: 0.9960166666666667', 'Test Acc: 0.9923', 'Train LL: -0.012206366881638061', 'Test LL: -0.02645245111907359', 'Epoch Time (s): 171.24887363193557')
('Epoch 55', 'Objective: -0.01449179994571914', 'Train Acc: 0.9959833333333333', 'Test Acc: 0.9918', 'Train LL: -0.012324961095492585', 'Test LL: -0.026107472371681137', 'Epoch Time (s): 171.2058063657023')
('Epoch 56', 'Objective: -0.013743822954678292', 'Train Acc: 0.9963166666666666', 'Test Acc: 0.9907', 'Train LL: -0.011634247873574536', 'Test LL: -0.02988531079953044', 'Epoch Time (s): 171.28142319293693')
('Epoch 57', 'Objective: -0.013690042843774102', 'Train Acc: 0.9960666666666667', 'Test Acc: 0.9918', 'Train LL: -0.011560176381262117', 'Test LL: -0.027694110999589645', 'Epoch Time (s): 171.1791297015734')
('Epoch 58', 'Objective: -0.013615940688797285', 'Train Acc: 0.9961666666666666', 'Test Acc: 0.9911', 'Train LL: -0.011492710144595193', 'Test LL: -0.02790423834761151', 'Epoch Time (s): 171.1893518967554')
('Epoch 59', 'Objective: -0.012554089831834592', 'Train Acc: 0.9962833333333333', 'Test Acc: 0.9917', 'Train LL: -0.010441395637038312', 'Test LL: -0.026869493922178866', 'Epoch Time (s): 171.18921763496473')
('Epoch 60', 'Objective: -0.013336361898448314', 'Train Acc: 0.9965', 'Test Acc: 0.9906', 'Train LL: -0.011219386333125227', 'Test LL: -0.029178410793158013', 'Epoch Time (s): 171.20252576982602')
('Epoch 61', 'Objective: -0.012534386276407967', 'Train Acc: 0.99665', 'Test Acc: 0.9906', 'Train LL: -0.010449081762225669', 'Test LL: -0.030603069106700038', 'Epoch Time (s): 171.234536212869')
('Epoch 62', 'Objective: -0.012042991412269654', 'Train Acc: 0.9965', 'Test Acc: 0.9904', 'Train LL: -0.009949123451661452', 'Test LL: -0.031968304324343735', 'Epoch Time (s): 171.12852059304714')
('Epoch 63', 'Objective: -0.01228933176897062', 'Train Acc: 0.9967166666666667', 'Test Acc: 0.9924', 'Train LL: -0.010201442461367867', 'Test LL: -0.02675191974399133', 'Epoch Time (s): 171.1713412962854')
('Epoch 64', 'Objective: -0.011605707253299874', 'Train Acc: 0.9965666666666667', 'Test Acc: 0.9912', 'Train LL: -0.009520173032679512', 'Test LL: -0.026642475177200798', 'Epoch Time (s): 171.18082831986248')
('Epoch 65', 'Objective: -0.01174172897335444', 'Train Acc: 0.9967666666666667', 'Test Acc: 0.9921', 'Train LL: -0.009677423580339323', 'Test LL: -0.028249252004126858', 'Epoch Time (s): 171.1965532102622')
('Epoch 66', 'Objective: -0.011647152723365188', 'Train Acc: 0.9967833333333334', 'Test Acc: 0.9918', 'Train LL: -0.009546230878928832', 'Test LL: -0.029875942211862513', 'Epoch Time (s): 171.2357729850337')
('Epoch 67', 'Objective: -0.011447827196924843', 'Train Acc: 0.9970666666666667', 'Test Acc: 0.9906', 'Train LL: -0.009379048319058876', 'Test LL: -0.032026916924891055', 'Epoch Time (s): 171.17038816493005')
('Epoch 68', 'Objective: -0.01111578425650394', 'Train Acc: 0.9969', 'Test Acc: 0.9921', 'Train LL: -0.009076180459476063', 'Test LL: -0.029030789626932733', 'Epoch Time (s): 171.2049366971478')
('Epoch 69', 'Objective: -0.010091870943316818', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9906', 'Train LL: -0.008060659233910776', 'Test LL: -0.03574351229210797', 'Epoch Time (s): 171.18808385822922')
('Epoch 70', 'Objective: -0.010899307628956975', 'Train Acc: 0.997', 'Test Acc: 0.9914', 'Train LL: -0.008850100662381677', 'Test LL: -0.03110329767852209', 'Epoch Time (s): 171.13847453333437')
('Epoch 71', 'Objective: -0.01062442455339607', 'Train Acc: 0.997', 'Test Acc: 0.9915', 'Train LL: -0.00859157585331232', 'Test LL: -0.03227778894940799', 'Epoch Time (s): 171.2026854851283')
('Epoch 72', 'Objective: -0.010116372836550324', 'Train Acc: 0.9971833333333333', 'Test Acc: 0.9913', 'Train LL: -0.008092563648943873', 'Test LL: -0.03175890150910872', 'Epoch Time (s): 171.17136957822368')
('Epoch 73', 'Objective: -0.010420931759412973', 'Train Acc: 0.99715', 'Test Acc: 0.9905', 'Train LL: -0.008365837650165828', 'Test LL: -0.033672929789599536', 'Epoch Time (s): 171.15735992696136')
('Epoch 74', 'Objective: -0.009802677250649811', 'Train Acc: 0.99745', 'Test Acc: 0.9908', 'Train LL: -0.0077690449009474825', 'Test LL: -0.033691566163687514', 'Epoch Time (s): 171.16792489029467')
('Epoch 75', 'Objective: -0.009620225907644152', 'Train Acc: 0.99755', 'Test Acc: 0.9911', 'Train LL: -0.007596144821738732', 'Test LL: -0.035187874748471515', 'Epoch Time (s): 171.2030141199939')
('Epoch 76', 'Objective: -0.010030013210227114', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9913', 'Train LL: -0.008008405704824983', 'Test LL: -0.03305508949673488', 'Epoch Time (s): 171.18454184569418')
('Epoch 77', 'Objective: -0.009076382466652815', 'Train Acc: 0.9977333333333334', 'Test Acc: 0.9918', 'Train LL: -0.00708623949192574', 'Test LL: -0.03505752333651398', 'Epoch Time (s): 171.16272003296763')
('Epoch 78', 'Objective: -0.00936680857768683', 'Train Acc: 0.9974', 'Test Acc: 0.9915', 'Train LL: -0.00732730341019393', 'Test LL: -0.03223779823248468', 'Epoch Time (s): 171.16935969283804')
('Epoch 79', 'Objective: -0.009477658055871176', 'Train Acc: 0.9973833333333333', 'Test Acc: 0.9908', 'Train LL: -0.007467261881811161', 'Test LL: -0.03574700472830815', 'Epoch Time (s): 171.14470103010535')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.007626832012320557', 'Train Acc: 0.99835', 'Test Acc: 0.9914', 'Train LL: -0.005738314675671568', 'Test LL: -0.03388775049776297', 'Epoch Time (s): 171.10428298916668')
('Epoch 81', 'Objective: -0.007336943115122387', 'Train Acc: 0.99825', 'Test Acc: 0.9918', 'Train LL: -0.0054484297915279945', 'Test LL: -0.03224079960153863', 'Epoch Time (s): 171.14422908099368')
('Epoch 82', 'Objective: -0.006978177156021212', 'Train Acc: 0.9982833333333333', 'Test Acc: 0.9921', 'Train LL: -0.005100166074108902', 'Test LL: -0.03175412839804871', 'Epoch Time (s): 171.1676924698986')
('Epoch 83', 'Objective: -0.0061851687510293745', 'Train Acc: 0.9987', 'Test Acc: 0.9918', 'Train LL: -0.0043565308439075185', 'Test LL: -0.0338625358507349', 'Epoch Time (s): 171.1877710269764')
('Epoch 84', 'Objective: -0.006551883463997468', 'Train Acc: 0.9984166666666666', 'Test Acc: 0.9916', 'Train LL: -0.004683338413074908', 'Test LL: -0.032421595021470476', 'Epoch Time (s): 171.24345052288845')
('Epoch 85', 'Objective: -0.005915868278873975', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9915', 'Train LL: -0.004065953071818914', 'Test LL: -0.033954865290416754', 'Epoch Time (s): 171.20234986627474')
('Epoch 86', 'Objective: -0.006449807694861541', 'Train Acc: 0.99865', 'Test Acc: 0.9915', 'Train LL: -0.004590694749885412', 'Test LL: -0.03389101228126543', 'Epoch Time (s): 171.19102725479752')
('Epoch 87', 'Objective: -0.006189479374746162', 'Train Acc: 0.9986333333333334', 'Test Acc: 0.9917', 'Train LL: -0.004325263566177943', 'Test LL: -0.03500542022423093', 'Epoch Time (s): 171.29381370032206')
('Epoch 88', 'Objective: -0.006098404154917238', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9914', 'Train LL: -0.004236086414540342', 'Test LL: -0.033890266269650186', 'Epoch Time (s): 171.1977602476254')
('Epoch 89', 'Objective: -0.005939235551434988', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.991', 'Train LL: -0.004086041482213461', 'Test LL: -0.036341085464302814', 'Epoch Time (s): 171.1418327577412')
('Epoch 90', 'Objective: -0.00631433752240472', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.9911', 'Train LL: -0.00443895217124742', 'Test LL: -0.035345970181947683', 'Epoch Time (s): 171.18912664009258')
('Epoch 91', 'Objective: -0.0057206569039244745', 'Train Acc: 0.9987333333333334', 'Test Acc: 0.9913', 'Train LL: -0.003861132478570183', 'Test LL: -0.03403810875752803', 'Epoch Time (s): 171.1922213542275')
('Epoch 92', 'Objective: -0.005876726234890461', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9913', 'Train LL: -0.004009812814602172', 'Test LL: -0.03568292252122611', 'Epoch Time (s): 171.17703492194414')
('Epoch 93', 'Objective: -0.005649027977465788', 'Train Acc: 0.9988833333333333', 'Test Acc: 0.9912', 'Train LL: -0.0038025871164582884', 'Test LL: -0.037552885229913076', 'Epoch Time (s): 171.1837237160653')
('Epoch 94', 'Objective: -0.005509642323205382', 'Train Acc: 0.9988166666666667', 'Test Acc: 0.991', 'Train LL: -0.003653762549738179', 'Test LL: -0.03665230910102306', 'Epoch Time (s): 171.21309153968468')
('Epoch 95', 'Objective: -0.005903064833312708', 'Train Acc: 0.9986', 'Test Acc: 0.9913', 'Train LL: -0.004013924234195656', 'Test LL: -0.03631173244130755', 'Epoch Time (s): 171.1989371026866')
('Epoch 96', 'Objective: -0.004984898456932426', 'Train Acc: 0.9990333333333333', 'Test Acc: 0.9907', 'Train LL: -0.003147858082345959', 'Test LL: -0.03852370060006859', 'Epoch Time (s): 171.14432630408555')
('Epoch 97', 'Objective: -0.005253432536903223', 'Train Acc: 0.9989', 'Test Acc: 0.9912', 'Train LL: -0.0033897719759115466', 'Test LL: -0.03785158880090301', 'Epoch Time (s): 171.15972812473774')
('Epoch 98', 'Objective: -0.005704393499951867', 'Train Acc: 0.99885', 'Test Acc: 0.9909', 'Train LL: -0.003824292636683656', 'Test LL: -0.039414782084182226', 'Epoch Time (s): 171.14907313603908')
('Epoch 99', 'Objective: -0.005669714266957597', 'Train Acc: 0.99885', 'Test Acc: 0.991', 'Train LL: -0.003792435827640301', 'Test LL: -0.039112384542199494', 'Epoch Time (s): 171.15760853514075')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.005084140898407435
Final Train Accuracy: £0.9991
Final Train LL: £-0.003242238310923736
Final Test Accuracy: £0.9912
Final Test LL: £-0.03870861435116715
