dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3287502922650427', 'Train Acc: 0.5415666666666666', 'Test Acc: 0.8034', 'Train LL: -1.2763738119932955', 'Test LL: -0.6327716260792429', 'Epoch Time (s): 163.50974338990636')
('Epoch 1', 'Objective: -0.5159384223283918', 'Train Acc: 0.8436166666666667', 'Test Acc: 0.8769', 'Train LL: -0.46241537713418307', 'Test LL: -0.3757101647244341', 'Epoch Time (s): 163.63815687107854')
('Epoch 2', 'Objective: -0.32108574752286695', 'Train Acc: 0.91385', 'Test Acc: 0.9285', 'Train LL: -0.27021298488325496', 'Test LL: -0.22026168043027083', 'Epoch Time (s): 163.66255944687873')
('Epoch 3', 'Objective: -0.24361411746734907', 'Train Acc: 0.9375833333333333', 'Test Acc: 0.933', 'Train LL: -0.19644087073057137', 'Test LL: -0.2183104073771784', 'Epoch Time (s): 163.6735314859543')
('Epoch 4', 'Objective: -0.21003490297176353', 'Train Acc: 0.94795', 'Test Acc: 0.9475', 'Train LL: -0.1653513842270706', 'Test LL: -0.1659491242743028', 'Epoch Time (s): 163.60533317411318')
('Epoch 5', 'Objective: -0.18975902261810865', 'Train Acc: 0.9544', 'Test Acc: 0.9569', 'Train LL: -0.14700937162225988', 'Test LL: -0.1329529849136916', 'Epoch Time (s): 163.67695268196985')
('Epoch 6', 'Objective: -0.1719948673102355', 'Train Acc: 0.9587166666666667', 'Test Acc: 0.9557', 'Train LL: -0.1310809301709268', 'Test LL: -0.14397743914633693', 'Epoch Time (s): 163.67503699008375')
('Epoch 7', 'Objective: -0.16289843194631654', 'Train Acc: 0.9614333333333334', 'Test Acc: 0.975', 'Train LL: -0.123190851496201', 'Test LL: -0.08467869842036826', 'Epoch Time (s): 163.6870578462258')
('Epoch 8', 'Objective: -0.1523285514288464', 'Train Acc: 0.9639166666666666', 'Test Acc: 0.9545', 'Train LL: -0.11340125301308844', 'Test LL: -0.14308725523564603', 'Epoch Time (s): 163.66335317795165')
('Epoch 9', 'Objective: -0.14410609085477294', 'Train Acc: 0.9669833333333333', 'Test Acc: 0.9683', 'Train LL: -0.10581951599650177', 'Test LL: -0.0963039762145076', 'Epoch Time (s): 163.67533304495737')
('Epoch 10', 'Objective: -0.13869940262048167', 'Train Acc: 0.9670666666666666', 'Test Acc: 0.9684', 'Train LL: -0.10118057899656845', 'Test LL: -0.09979272635538086', 'Epoch Time (s): 163.66446611681022')
('Epoch 11', 'Objective: -0.13261861759398363', 'Train Acc: 0.9693', 'Test Acc: 0.9682', 'Train LL: -0.09592310550319251', 'Test LL: -0.09713611055091669', 'Epoch Time (s): 163.65607046498917')
('Epoch 12', 'Objective: -0.1262996071842767', 'Train Acc: 0.9712666666666666', 'Test Acc: 0.9763', 'Train LL: -0.09017639701346199', 'Test LL: -0.0778553849914818', 'Epoch Time (s): 163.67288112896495')
('Epoch 13', 'Objective: -0.12195671318705739', 'Train Acc: 0.97275', 'Test Acc: 0.9737', 'Train LL: -0.08681218226310145', 'Test LL: -0.08241289388285175', 'Epoch Time (s): 163.67455617990345')
('Epoch 14', 'Objective: -0.11846697478673786', 'Train Acc: 0.9734333333333334', 'Test Acc: 0.9723', 'Train LL: -0.08383834927776668', 'Test LL: -0.08871774693399113', 'Epoch Time (s): 163.70990112796426')
('Epoch 15', 'Objective: -0.11266747194491157', 'Train Acc: 0.9749166666666667', 'Test Acc: 0.9777', 'Train LL: -0.07856408764450606', 'Test LL: -0.06592132121158942', 'Epoch Time (s): 163.72239420795813')
('Epoch 16', 'Objective: -0.10953556701634747', 'Train Acc: 0.9754166666666667', 'Test Acc: 0.9775', 'Train LL: -0.07637996269760072', 'Test LL: -0.06585316111528318', 'Epoch Time (s): 163.71789210196584')
('Epoch 17', 'Objective: -0.10718900371804353', 'Train Acc: 0.9761', 'Test Acc: 0.9816', 'Train LL: -0.07441808358700318', 'Test LL: -0.056814108266151166', 'Epoch Time (s): 163.67967344098724')
('Epoch 18', 'Objective: -0.10441836985463636', 'Train Acc: 0.9772666666666666', 'Test Acc: 0.9748', 'Train LL: -0.07215124594316849', 'Test LL: -0.07674478003095347', 'Epoch Time (s): 163.70256834919564')
('Epoch 19', 'Objective: -0.1041624537371643', 'Train Acc: 0.9772', 'Test Acc: 0.9682', 'Train LL: -0.07226162752723661', 'Test LL: -0.09239677986442771', 'Epoch Time (s): 163.6621304869186')
('Epoch 20', 'Objective: -0.10022797149417405', 'Train Acc: 0.9782666666666666', 'Test Acc: 0.9805', 'Train LL: -0.06892776115061115', 'Test LL: -0.05882476530901024', 'Epoch Time (s): 163.68051070091315')
('Epoch 21', 'Objective: -0.09999504193135891', 'Train Acc: 0.9778166666666667', 'Test Acc: 0.9839', 'Train LL: -0.06875187632513943', 'Test LL: -0.05189433855178723', 'Epoch Time (s): 163.68873289390467')
('Epoch 22', 'Objective: -0.09717809956410998', 'Train Acc: 0.9789666666666667', 'Test Acc: 0.9755', 'Train LL: -0.06637069506585849', 'Test LL: -0.07899628761592868', 'Epoch Time (s): 163.6723997630179')
('Epoch 23', 'Objective: -0.09783411871861566', 'Train Acc: 0.9789', 'Test Acc: 0.9785', 'Train LL: -0.06736828365205864', 'Test LL: -0.06346983769976809', 'Epoch Time (s): 163.66817900189199')
('Epoch 24', 'Objective: -0.09469413434044814', 'Train Acc: 0.9799166666666667', 'Test Acc: 0.9815', 'Train LL: -0.0644607618291726', 'Test LL: -0.0551885344739058', 'Epoch Time (s): 163.628120778827')
('Epoch 25', 'Objective: -0.0923085313165891', 'Train Acc: 0.9806333333333334', 'Test Acc: 0.9813', 'Train LL: -0.06265549719850469', 'Test LL: -0.059288245043293886', 'Epoch Time (s): 163.64564542099833')
('Epoch 26', 'Objective: -0.09234345236386986', 'Train Acc: 0.9799833333333333', 'Test Acc: 0.9836', 'Train LL: -0.06301429508129763', 'Test LL: -0.056491633077832', 'Epoch Time (s): 163.68826138903387')
('Epoch 27', 'Objective: -0.09083698562792637', 'Train Acc: 0.9803833333333334', 'Test Acc: 0.9774', 'Train LL: -0.06178467102484826', 'Test LL: -0.0696382787143753', 'Epoch Time (s): 163.6891998280771')
('Epoch 28', 'Objective: -0.09021513170635256', 'Train Acc: 0.9801666666666666', 'Test Acc: 0.9776', 'Train LL: -0.06130112771891073', 'Test LL: -0.06496512148018499', 'Epoch Time (s): 163.7278437470086')
('Epoch 29', 'Objective: -0.08769982763028272', 'Train Acc: 0.9814', 'Test Acc: 0.9823', 'Train LL: -0.058969569842635086', 'Test LL: -0.0546945624141193', 'Epoch Time (s): 163.72427354496904')
('Epoch 30', 'Objective: -0.08932428486148987', 'Train Acc: 0.9806333333333334', 'Test Acc: 0.9839', 'Train LL: -0.06083877944270885', 'Test LL: -0.05795320473181218', 'Epoch Time (s): 163.72452535689808')
('Epoch 31', 'Objective: -0.08631658250880679', 'Train Acc: 0.98165', 'Test Acc: 0.98', 'Train LL: -0.05802294501131408', 'Test LL: -0.06857400392683063', 'Epoch Time (s): 163.67996398499236')
('Epoch 32', 'Objective: -0.08563455104734763', 'Train Acc: 0.9817666666666667', 'Test Acc: 0.9829', 'Train LL: -0.05779782458363913', 'Test LL: -0.05040423198793805', 'Epoch Time (s): 163.67892522807233')
('Epoch 33', 'Objective: -0.08394916880704062', 'Train Acc: 0.9821666666666666', 'Test Acc: 0.9822', 'Train LL: -0.056291863561506755', 'Test LL: -0.05562295353512817', 'Epoch Time (s): 163.7627971789334')
('Epoch 34', 'Objective: -0.08363098006995791', 'Train Acc: 0.9821666666666666', 'Test Acc: 0.9799', 'Train LL: -0.05621214538885957', 'Test LL: -0.057421602189272405', 'Epoch Time (s): 164.28460555709898')
('Epoch 35', 'Objective: -0.08266198416476943', 'Train Acc: 0.9826333333333334', 'Test Acc: 0.9731', 'Train LL: -0.05548594063276708', 'Test LL: -0.08000425854876998', 'Epoch Time (s): 163.71883534500375')
('Epoch 36', 'Objective: -0.08109587103054441', 'Train Acc: 0.9828666666666667', 'Test Acc: 0.9852', 'Train LL: -0.05416996260832515', 'Test LL: -0.046349460967885475', 'Epoch Time (s): 163.68895946000703')
('Epoch 37', 'Objective: -0.08136141326998533', 'Train Acc: 0.98245', 'Test Acc: 0.9791', 'Train LL: -0.05452816671593826', 'Test LL: -0.05968616681856705', 'Epoch Time (s): 163.67562130698934')
('Epoch 38', 'Objective: -0.08037591678747345', 'Train Acc: 0.9827333333333333', 'Test Acc: 0.9882', 'Train LL: -0.05358377443826169', 'Test LL: -0.03570718014482195', 'Epoch Time (s): 163.65817949012853')
('Epoch 39', 'Objective: -0.07779228157199373', 'Train Acc: 0.9833833333333334', 'Test Acc: 0.9799', 'Train LL: -0.05136056003574107', 'Test LL: -0.06532508873447361', 'Epoch Time (s): 163.67994436994195')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.05918311451006748', 'Train Acc: 0.9894', 'Test Acc: 0.9896', 'Train LL: -0.03437720138695606', 'Test LL: -0.03164901091577834', 'Epoch Time (s): 163.69458810891956')
('Epoch 41', 'Objective: -0.05378387465293394', 'Train Acc: 0.9906', 'Test Acc: 0.9899', 'Train LL: -0.029895722248531712', 'Test LL: -0.029558159384175296', 'Epoch Time (s): 163.6242174480576')
('Epoch 42', 'Objective: -0.05169802618535899', 'Train Acc: 0.9909833333333333', 'Test Acc: 0.9893', 'Train LL: -0.02816960684890781', 'Test LL: -0.031830670305949674', 'Epoch Time (s): 163.62468604696915')
('Epoch 43', 'Objective: -0.05029188952757561', 'Train Acc: 0.9911333333333333', 'Test Acc: 0.9899', 'Train LL: -0.026885863680838756', 'Test LL: -0.031640244948106556', 'Epoch Time (s): 163.6610749908723')
('Epoch 44', 'Objective: -0.05019294389765242', 'Train Acc: 0.99105', 'Test Acc: 0.9906', 'Train LL: -0.02697777270726173', 'Test LL: -0.028871775401626037', 'Epoch Time (s): 163.64573539607227')
('Epoch 45', 'Objective: -0.04801038938245793', 'Train Acc: 0.9916333333333334', 'Test Acc: 0.9892', 'Train LL: -0.025074002032677584', 'Test LL: -0.030576885426837497', 'Epoch Time (s): 163.65081736189313')
('Epoch 46', 'Objective: -0.048394838126057056', 'Train Acc: 0.9916', 'Test Acc: 0.9892', 'Train LL: -0.02554210906560034', 'Test LL: -0.0323437063605445', 'Epoch Time (s): 163.65210944600403')
('Epoch 47', 'Objective: -0.04826232821030778', 'Train Acc: 0.99145', 'Test Acc: 0.9899', 'Train LL: -0.025540002305875335', 'Test LL: -0.030447377930775853', 'Epoch Time (s): 163.6969090460334')
('Epoch 48', 'Objective: -0.04768811690555053', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9912', 'Train LL: -0.025137617089668166', 'Test LL: -0.027605807838607315', 'Epoch Time (s): 163.67079838900827')
('Epoch 49', 'Objective: -0.04687764446831838', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9896', 'Train LL: -0.024492887632455503', 'Test LL: -0.032568358471035515', 'Epoch Time (s): 163.67654348886572')
('Epoch 50', 'Objective: -0.046950487481784466', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.9911', 'Train LL: -0.024640043527260763', 'Test LL: -0.027736569428678814', 'Epoch Time (s): 163.6987808549311')
('Epoch 51', 'Objective: -0.04633072908674037', 'Train Acc: 0.992', 'Test Acc: 0.9904', 'Train LL: -0.024097811693518708', 'Test LL: -0.031583837607467365', 'Epoch Time (s): 163.64304501307197')
('Epoch 52', 'Objective: -0.04575057464930249', 'Train Acc: 0.99235', 'Test Acc: 0.9912', 'Train LL: -0.02361908240553977', 'Test LL: -0.027761401970723534', 'Epoch Time (s): 163.6907223269809')
('Epoch 53', 'Objective: -0.04446749231786887', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9918', 'Train LL: -0.022529823256817297', 'Test LL: -0.02630824287376265', 'Epoch Time (s): 163.69514441816136')
('Epoch 54', 'Objective: -0.04596137221699609', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9909', 'Train LL: -0.024049209890675147', 'Test LL: -0.028400602751993687', 'Epoch Time (s): 163.6226927288808')
('Epoch 55', 'Objective: -0.04423507489469956', 'Train Acc: 0.9926', 'Test Acc: 0.9902', 'Train LL: -0.022387995638293613', 'Test LL: -0.030580502594288014', 'Epoch Time (s): 163.62652081111446')
('Epoch 56', 'Objective: -0.044083676080563045', 'Train Acc: 0.9928', 'Test Acc: 0.9913', 'Train LL: -0.02236341210067288', 'Test LL: -0.026410397779887865', 'Epoch Time (s): 163.63882559305057')
('Epoch 57', 'Objective: -0.044543673712862594', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9908', 'Train LL: -0.022856259054869394', 'Test LL: -0.028825693996679558', 'Epoch Time (s): 163.684920553118')
('Epoch 58', 'Objective: -0.0442620389968494', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9908', 'Train LL: -0.022653780644300146', 'Test LL: -0.03135056727778522', 'Epoch Time (s): 163.68405979685485')
('Epoch 59', 'Objective: -0.04407175460977418', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9896', 'Train LL: -0.022572160715999025', 'Test LL: -0.029835100736922606', 'Epoch Time (s): 163.6623954048846')
('Epoch 60', 'Objective: -0.04490736244406374', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9902', 'Train LL: -0.023441194371870703', 'Test LL: -0.03006755498099742', 'Epoch Time (s): 163.67906333087012')
('Epoch 61', 'Objective: -0.04345087904863878', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.991', 'Train LL: -0.022051746146633855', 'Test LL: -0.029806986451588795', 'Epoch Time (s): 163.70086017693393')
('Epoch 62', 'Objective: -0.04355894703381716', 'Train Acc: 0.99265', 'Test Acc: 0.9906', 'Train LL: -0.022209685055498654', 'Test LL: -0.029759698185014543', 'Epoch Time (s): 163.6771874818951')
('Epoch 63', 'Objective: -0.04285000670018427', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9903', 'Train LL: -0.02156244288172959', 'Test LL: -0.03243071636930356', 'Epoch Time (s): 163.6664913110435')
('Epoch 64', 'Objective: -0.04282196764569836', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9908', 'Train LL: -0.021623997430595805', 'Test LL: -0.027622315547080972', 'Epoch Time (s): 163.67377452994697')
('Epoch 65', 'Objective: -0.04341649366955388', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9911', 'Train LL: -0.022268457325133016', 'Test LL: -0.026992464207743178', 'Epoch Time (s): 163.6587586349342')
('Epoch 66', 'Objective: -0.04334056923018992', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9903', 'Train LL: -0.022172730905761842', 'Test LL: -0.030789785257382563', 'Epoch Time (s): 163.67163050407544')
('Epoch 67', 'Objective: -0.04261435558766307', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9911', 'Train LL: -0.0215510398297787', 'Test LL: -0.029238540762616328', 'Epoch Time (s): 163.6939138509333')
('Epoch 68', 'Objective: -0.042592042511581205', 'Train Acc: 0.9926333333333334', 'Test Acc: 0.9914', 'Train LL: -0.02158264810313729', 'Test LL: -0.029163780910115317', 'Epoch Time (s): 163.6819810050074')
('Epoch 69', 'Objective: -0.041779368609940463', 'Train Acc: 0.9932', 'Test Acc: 0.9908', 'Train LL: -0.020841085292277475', 'Test LL: -0.031238897266289898', 'Epoch Time (s): 163.67391401412897')
('Epoch 70', 'Objective: -0.04176920748785866', 'Train Acc: 0.9930333333333333', 'Test Acc: 0.9908', 'Train LL: -0.020813464583000898', 'Test LL: -0.028117047641051038', 'Epoch Time (s): 163.69602413102984')
('Epoch 71', 'Objective: -0.042555811886946404', 'Train Acc: 0.99275', 'Test Acc: 0.9908', 'Train LL: -0.021671074973625457', 'Test LL: -0.03049472100672914', 'Epoch Time (s): 163.660445866175')
('Epoch 72', 'Objective: -0.04098984908255743', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.9908', 'Train LL: -0.020197166919069757', 'Test LL: -0.030492892910419515', 'Epoch Time (s): 163.6642412301153')
('Epoch 73', 'Objective: -0.04111958164598769', 'Train Acc: 0.9933333333333333', 'Test Acc: 0.9904', 'Train LL: -0.020233662104655742', 'Test LL: -0.032127345823754705', 'Epoch Time (s): 163.6518431850709')
('Epoch 74', 'Objective: -0.04127562675408227', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9914', 'Train LL: -0.020437506367586147', 'Test LL: -0.02879828015085441', 'Epoch Time (s): 163.67353382403962')
('Epoch 75', 'Objective: -0.04125671254843834', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9917', 'Train LL: -0.020479305968322137', 'Test LL: -0.028689057544583067', 'Epoch Time (s): 163.67405458097346')
('Epoch 76', 'Objective: -0.04112226178782036', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.9911', 'Train LL: -0.020450593580998582', 'Test LL: -0.029070954877403507', 'Epoch Time (s): 163.67892745579593')
('Epoch 77', 'Objective: -0.04137263098533842', 'Train Acc: 0.99335', 'Test Acc: 0.9897', 'Train LL: -0.02070748466060801', 'Test LL: -0.03216600993511873', 'Epoch Time (s): 163.65920475288294')
('Epoch 78', 'Objective: -0.041136237984578404', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.9907', 'Train LL: -0.020532478945993186', 'Test LL: -0.030029599751247645', 'Epoch Time (s): 163.68330597295426')
('Epoch 79', 'Objective: -0.04096503379764795', 'Train Acc: 0.9934', 'Test Acc: 0.9918', 'Train LL: -0.020397130461771072', 'Test LL: -0.026587586023223815', 'Epoch Time (s): 163.67799045797437')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.03836414210945038', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.9914', 'Train LL: -0.018061637527756223', 'Test LL: -0.028184424813528692', 'Epoch Time (s): 163.67229625489563')
('Epoch 81', 'Objective: -0.03747877252248473', 'Train Acc: 0.9944', 'Test Acc: 0.9913', 'Train LL: -0.017202321994641258', 'Test LL: -0.028772128482981305', 'Epoch Time (s): 163.67457953491248')
('Epoch 82', 'Objective: -0.03761192316045829', 'Train Acc: 0.99465', 'Test Acc: 0.9916', 'Train LL: -0.017296215050024745', 'Test LL: -0.028119355381071198', 'Epoch Time (s): 163.68405891396105')
('Epoch 83', 'Objective: -0.0373173603266157', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9917', 'Train LL: -0.01702152974100985', 'Test LL: -0.028226945726180015', 'Epoch Time (s): 163.65344384498894')
('Epoch 84', 'Objective: -0.0373041154109236', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9911', 'Train LL: -0.016999477175882596', 'Test LL: -0.028507618504881618', 'Epoch Time (s): 163.68490881915204')
('Epoch 85', 'Objective: -0.03732122966450963', 'Train Acc: 0.99445', 'Test Acc: 0.9917', 'Train LL: -0.01702481972638978', 'Test LL: -0.027800114246671052', 'Epoch Time (s): 163.623179881135')
('Epoch 86', 'Objective: -0.03658836315945061', 'Train Acc: 0.9946', 'Test Acc: 0.9912', 'Train LL: -0.016325447423493695', 'Test LL: -0.02906881903053467', 'Epoch Time (s): 163.6231860120315')
('Epoch 87', 'Objective: -0.03719511039603818', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9917', 'Train LL: -0.01689691578667535', 'Test LL: -0.027206177112129033', 'Epoch Time (s): 163.667307642987')
('Epoch 88', 'Objective: -0.037308410767016895', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.992', 'Train LL: -0.016979753883380574', 'Test LL: -0.027807510289042846', 'Epoch Time (s): 163.66199645609595')
('Epoch 89', 'Objective: -0.03722752169011093', 'Train Acc: 0.99485', 'Test Acc: 0.9915', 'Train LL: -0.016923317698028194', 'Test LL: -0.028043153260749187', 'Epoch Time (s): 163.6696958488319')
('Epoch 90', 'Objective: -0.037506073912900464', 'Train Acc: 0.9944', 'Test Acc: 0.9916', 'Train LL: -0.01716808559222267', 'Test LL: -0.027365790014620767', 'Epoch Time (s): 163.66798171494156')
('Epoch 91', 'Objective: -0.03674465090420434', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9917', 'Train LL: -0.016513141586771283', 'Test LL: -0.027759528527060297', 'Epoch Time (s): 163.63708023983054')
('Epoch 92', 'Objective: -0.036168281847428284', 'Train Acc: 0.9948', 'Test Acc: 0.9912', 'Train LL: -0.015973226959766183', 'Test LL: -0.0288999402821866', 'Epoch Time (s): 163.66289271600544')
('Epoch 93', 'Objective: -0.03672629011581531', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9916', 'Train LL: -0.016487559215091686', 'Test LL: -0.02820259862273208', 'Epoch Time (s): 163.5984982131049')
('Epoch 94', 'Objective: -0.0364544275794166', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9916', 'Train LL: -0.01619516163320073', 'Test LL: -0.028712880105647036', 'Epoch Time (s): 163.58950829086825')
('Epoch 95', 'Objective: -0.03624682814953846', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9919', 'Train LL: -0.016011561029623398', 'Test LL: -0.028473683669073352', 'Epoch Time (s): 163.58341007004492')
('Epoch 96', 'Objective: -0.036634347998968496', 'Train Acc: 0.9945', 'Test Acc: 0.9916', 'Train LL: -0.01637787125893907', 'Test LL: -0.02942179900435592', 'Epoch Time (s): 163.62359876697883')
('Epoch 97', 'Objective: -0.036365322646072576', 'Train Acc: 0.9948', 'Test Acc: 0.9921', 'Train LL: -0.016124745140564563', 'Test LL: -0.02927281546799473', 'Epoch Time (s): 163.55568991182372')
('Epoch 98', 'Objective: -0.03686015756612622', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.992', 'Train LL: -0.016602585622402497', 'Test LL: -0.028147927271241133', 'Epoch Time (s): 163.61250353301875')
('Epoch 99', 'Objective: -0.03685678860447835', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.9922', 'Train LL: -0.016564867984348735', 'Test LL: -0.027593565013728345', 'Epoch Time (s): 163.60455205803737')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.035977819199387404
Final Train Accuracy: £0.9949333333333333
Final Train LL: £-0.015808823310176853
Final Test Accuracy: £0.9922
Final Test LL: £-0.027560825271313906
