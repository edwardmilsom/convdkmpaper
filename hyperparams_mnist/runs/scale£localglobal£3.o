dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: local
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.281073742286963', 'Train Acc: 0.5598666666666666', 'Test Acc: 0.7951', 'Train LL: -1.2273131608960748', 'Test LL: -0.619867308118303', 'Epoch Time (s): 163.44733353098854')
('Epoch 1', 'Objective: -0.589239092725391', 'Train Acc: 0.8180333333333333', 'Test Acc: 0.7656', 'Train LL: -0.5351829735264119', 'Test LL: -0.7592224253347419', 'Epoch Time (s): 163.51589226606302')
('Epoch 2', 'Objective: -0.33662785263393824', 'Train Acc: 0.90975', 'Test Acc: 0.919', 'Train LL: -0.28476846079047974', 'Test LL: -0.2380985753447313', 'Epoch Time (s): 163.53742242814042')
('Epoch 3', 'Objective: -0.26011677848780024', 'Train Acc: 0.93315', 'Test Acc: 0.9422', 'Train LL: -0.2126074778509531', 'Test LL: -0.18208294265579844', 'Epoch Time (s): 163.5300119270105')
('Epoch 4', 'Objective: -0.21994885261014263', 'Train Acc: 0.9456166666666667', 'Test Acc: 0.953', 'Train LL: -0.17517889879519566', 'Test LL: -0.14889910176581767', 'Epoch Time (s): 163.64280351810157')
('Epoch 5', 'Objective: -0.19579494417057372', 'Train Acc: 0.9523333333333334', 'Test Acc: 0.9528', 'Train LL: -0.15257070303424472', 'Test LL: -0.150501948134479', 'Epoch Time (s): 163.55586605798453')
('Epoch 6', 'Objective: -0.17759516474991832', 'Train Acc: 0.9575666666666667', 'Test Acc: 0.9654', 'Train LL: -0.1357751459847293', 'Test LL: -0.10898066450712113', 'Epoch Time (s): 163.5226008668542')
('Epoch 7', 'Objective: -0.16758675528090886', 'Train Acc: 0.96065', 'Test Acc: 0.9684', 'Train LL: -0.12708286606409264', 'Test LL: -0.10102092390432493', 'Epoch Time (s): 163.50505679799244')
('Epoch 8', 'Objective: -0.1557223516979589', 'Train Acc: 0.96375', 'Test Acc: 0.9536', 'Train LL: -0.11644678034030673', 'Test LL: -0.1360484294094508', 'Epoch Time (s): 163.5197990539018')
('Epoch 9', 'Objective: -0.14529763926211145', 'Train Acc: 0.9662666666666667', 'Test Acc: 0.9737', 'Train LL: -0.10682975248438006', 'Test LL: -0.08315076216542727', 'Epoch Time (s): 163.5470984010026')
('Epoch 10', 'Objective: -0.13852863855885464', 'Train Acc: 0.9689166666666666', 'Test Acc: 0.9708', 'Train LL: -0.10117310710401198', 'Test LL: -0.09158756410607943', 'Epoch Time (s): 163.5394647801295')
('Epoch 11', 'Objective: -0.13265864834697352', 'Train Acc: 0.9698833333333333', 'Test Acc: 0.9716', 'Train LL: -0.09586944425390218', 'Test LL: -0.08554334165304742', 'Epoch Time (s): 163.48316459404305')
('Epoch 12', 'Objective: -0.1247888262622999', 'Train Acc: 0.9722333333333333', 'Test Acc: 0.9705', 'Train LL: -0.08890537769286477', 'Test LL: -0.09689018817412016', 'Epoch Time (s): 163.4720492460765')
('Epoch 13', 'Objective: -0.12174723493606388', 'Train Acc: 0.9720666666666666', 'Test Acc: 0.9747', 'Train LL: -0.0865486539066044', 'Test LL: -0.08565209549816338', 'Epoch Time (s): 163.47527975100093')
('Epoch 14', 'Objective: -0.1173666820286225', 'Train Acc: 0.9744166666666667', 'Test Acc: 0.9749', 'Train LL: -0.08319421753011517', 'Test LL: -0.08451476829399393', 'Epoch Time (s): 163.5180834669154')
('Epoch 15', 'Objective: -0.11551092668982275', 'Train Acc: 0.9741166666666666', 'Test Acc: 0.976', 'Train LL: -0.08189953772638905', 'Test LL: -0.0764429443666282', 'Epoch Time (s): 163.5443209609948')
('Epoch 16', 'Objective: -0.11106496080154804', 'Train Acc: 0.9756166666666667', 'Test Acc: 0.9744', 'Train LL: -0.07805462357138701', 'Test LL: -0.08055148545447241', 'Epoch Time (s): 163.514984985115')
('Epoch 17', 'Objective: -0.11041883230236765', 'Train Acc: 0.9755666666666667', 'Test Acc: 0.9839', 'Train LL: -0.07791257442570701', 'Test LL: -0.05390822618411726', 'Epoch Time (s): 163.50133590586483')
('Epoch 18', 'Objective: -0.1060219359776432', 'Train Acc: 0.9764', 'Test Acc: 0.9805', 'Train LL: -0.0738065345176526', 'Test LL: -0.061724156160971655', 'Epoch Time (s): 163.48947379691526')
('Epoch 19', 'Objective: -0.10566556348453646', 'Train Acc: 0.9760833333333333', 'Test Acc: 0.9799', 'Train LL: -0.07379452836590156', 'Test LL: -0.06107804989055164', 'Epoch Time (s): 163.55323293292895')
('Epoch 20', 'Objective: -0.10108793336086978', 'Train Acc: 0.9773166666666666', 'Test Acc: 0.9824', 'Train LL: -0.0696840229553812', 'Test LL: -0.05652561511362361', 'Epoch Time (s): 163.51680164900608')
('Epoch 21', 'Objective: -0.09864794880222685', 'Train Acc: 0.9785166666666667', 'Test Acc: 0.9834', 'Train LL: -0.06765845725343886', 'Test LL: -0.0516427950243788', 'Epoch Time (s): 163.5128418051172')
('Epoch 22', 'Objective: -0.09689010253922678', 'Train Acc: 0.9785', 'Test Acc: 0.9852', 'Train LL: -0.06623975635029615', 'Test LL: -0.04664239714492165', 'Epoch Time (s): 163.53114950703457')
('Epoch 23', 'Objective: -0.09516919624447742', 'Train Acc: 0.9795', 'Test Acc: 0.9815', 'Train LL: -0.06494103575023395', 'Test LL: -0.06095332617548721', 'Epoch Time (s): 163.51613152283244')
('Epoch 24', 'Objective: -0.09480212621914966', 'Train Acc: 0.9799', 'Test Acc: 0.9824', 'Train LL: -0.06477041703450975', 'Test LL: -0.05433141494505916', 'Epoch Time (s): 163.48923037713394')
('Epoch 25', 'Objective: -0.09246580382726313', 'Train Acc: 0.97985', 'Test Acc: 0.984', 'Train LL: -0.06276045958583615', 'Test LL: -0.0470545230404305', 'Epoch Time (s): 163.5336157809943')
('Epoch 26', 'Objective: -0.09118930453497928', 'Train Acc: 0.9803666666666667', 'Test Acc: 0.9807', 'Train LL: -0.061682628155225225', 'Test LL: -0.05919851102035419', 'Epoch Time (s): 163.55424170009792')
('Epoch 27', 'Objective: -0.09026026637684946', 'Train Acc: 0.9807333333333333', 'Test Acc: 0.9831', 'Train LL: -0.06112015462255413', 'Test LL: -0.054612782992678126', 'Epoch Time (s): 163.5620671370998')
('Epoch 28', 'Objective: -0.08805882715248023', 'Train Acc: 0.9808833333333333', 'Test Acc: 0.9859', 'Train LL: -0.05890711050976353', 'Test LL: -0.050023715779942586', 'Epoch Time (s): 163.49878140492365')
('Epoch 29', 'Objective: -0.08578253346101955', 'Train Acc: 0.9818166666666667', 'Test Acc: 0.9774', 'Train LL: -0.05704468451261942', 'Test LL: -0.06566710917902781', 'Epoch Time (s): 163.49030296085402')
('Epoch 30', 'Objective: -0.08713340654344962', 'Train Acc: 0.9814333333333334', 'Test Acc: 0.9867', 'Train LL: -0.05849240762270725', 'Test LL: -0.04319560035381328', 'Epoch Time (s): 163.48971945792437')
('Epoch 31', 'Objective: -0.08468998634754335', 'Train Acc: 0.9821166666666666', 'Test Acc: 0.9848', 'Train LL: -0.05638407648247179', 'Test LL: -0.04898488498636144', 'Epoch Time (s): 163.48237911402248')
('Epoch 32', 'Objective: -0.08512982258323781', 'Train Acc: 0.9817166666666667', 'Test Acc: 0.9826', 'Train LL: -0.0570098263247294', 'Test LL: -0.04931290865420072', 'Epoch Time (s): 163.52273386716843')
('Epoch 33', 'Objective: -0.08365592008640084', 'Train Acc: 0.9827166666666667', 'Test Acc: 0.9803', 'Train LL: -0.05572593558989162', 'Test LL: -0.061337323701172966', 'Epoch Time (s): 163.5794667052105')
('Epoch 34', 'Objective: -0.08397165001193155', 'Train Acc: 0.98225', 'Test Acc: 0.9837', 'Train LL: -0.05597041115336359', 'Test LL: -0.052861489805211145', 'Epoch Time (s): 163.55752395791933')
('Epoch 35', 'Objective: -0.08160257937333014', 'Train Acc: 0.9832166666666666', 'Test Acc: 0.9788', 'Train LL: -0.05418674543427545', 'Test LL: -0.06152052875749632', 'Epoch Time (s): 163.5544454769697')
('Epoch 36', 'Objective: -0.08099299177534357', 'Train Acc: 0.9828833333333333', 'Test Acc: 0.9882', 'Train LL: -0.053713272892873525', 'Test LL: -0.038001285951039014', 'Epoch Time (s): 163.54881192091852')
('Epoch 37', 'Objective: -0.08005805571826699', 'Train Acc: 0.9833833333333334', 'Test Acc: 0.9859', 'Train LL: -0.053015250463364014', 'Test LL: -0.044349562313436716', 'Epoch Time (s): 163.53301306511275')
('Epoch 38', 'Objective: -0.0794028194660098', 'Train Acc: 0.9837333333333333', 'Test Acc: 0.9825', 'Train LL: -0.05235740376526881', 'Test LL: -0.05305345554337312', 'Epoch Time (s): 163.50528086489066')
('Epoch 39', 'Objective: -0.07879393934343201', 'Train Acc: 0.9831333333333333', 'Test Acc: 0.9833', 'Train LL: -0.05176029029601089', 'Test LL: -0.04870764659857957', 'Epoch Time (s): 163.473138977075')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.05723178856921154', 'Train Acc: 0.9899', 'Test Acc: 0.9896', 'Train LL: -0.032013754206231405', 'Test LL: -0.031037944565754903', 'Epoch Time (s): 163.48447571205907')
('Epoch 41', 'Objective: -0.05206017368541747', 'Train Acc: 0.9911', 'Test Acc: 0.9891', 'Train LL: -0.02778212932174507', 'Test LL: -0.032281500499961036', 'Epoch Time (s): 163.46991343190894')
('Epoch 42', 'Objective: -0.051525367825568824', 'Train Acc: 0.9909166666666667', 'Test Acc: 0.9904', 'Train LL: -0.02763347840454644', 'Test LL: -0.028255956449584663', 'Epoch Time (s): 163.49548825691454')
('Epoch 43', 'Objective: -0.05001202512483068', 'Train Acc: 0.9912833333333333', 'Test Acc: 0.9903', 'Train LL: -0.026392525759330567', 'Test LL: -0.02798133679099398', 'Epoch Time (s): 163.4827662180178')
('Epoch 44', 'Objective: -0.04918984003365808', 'Train Acc: 0.9916', 'Test Acc: 0.9906', 'Train LL: -0.025823883510774043', 'Test LL: -0.02697652720030445', 'Epoch Time (s): 163.5314223249443')
('Epoch 45', 'Objective: -0.04848581320868769', 'Train Acc: 0.9916', 'Test Acc: 0.9909', 'Train LL: -0.025336754440042946', 'Test LL: -0.02860828008127127', 'Epoch Time (s): 163.5299256250728')
('Epoch 46', 'Objective: -0.04800999342685054', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9916', 'Train LL: -0.02495334277608938', 'Test LL: -0.0264128644607708', 'Epoch Time (s): 163.5353193441406')
('Epoch 47', 'Objective: -0.04701796523699369', 'Train Acc: 0.99195', 'Test Acc: 0.9901', 'Train LL: -0.024234562635812498', 'Test LL: -0.0292741457017818', 'Epoch Time (s): 163.53870314802043')
('Epoch 48', 'Objective: -0.047096090600536926', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9902', 'Train LL: -0.02439524663082828', 'Test LL: -0.028049446334244364', 'Epoch Time (s): 163.53858570405282')
('Epoch 49', 'Objective: -0.0465327112831574', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9902', 'Train LL: -0.024008178692538452', 'Test LL: -0.030969098860382654', 'Epoch Time (s): 163.5445718280971')
('Epoch 50', 'Objective: -0.04667398025216731', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.992', 'Train LL: -0.024297028545099714', 'Test LL: -0.0232963090110026', 'Epoch Time (s): 163.5261690779589')
('Epoch 51', 'Objective: -0.04550941964989588', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9905', 'Train LL: -0.02326295723001336', 'Test LL: -0.027287125914399156', 'Epoch Time (s): 163.5295058118645')
('Epoch 52', 'Objective: -0.0461607777431998', 'Train Acc: 0.99235', 'Test Acc: 0.9912', 'Train LL: -0.023926543523670643', 'Test LL: -0.025834158200616474', 'Epoch Time (s): 163.58809561096132')
('Epoch 53', 'Objective: -0.045863946676874406', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9908', 'Train LL: -0.023806739545481494', 'Test LL: -0.027138991866146166', 'Epoch Time (s): 163.55388683988713')
('Epoch 54', 'Objective: -0.04541961157951847', 'Train Acc: 0.9923166666666666', 'Test Acc: 0.9917', 'Train LL: -0.02345919781607134', 'Test LL: -0.026850202620862483', 'Epoch Time (s): 163.51831000181846')
('Epoch 55', 'Objective: -0.04436133990219451', 'Train Acc: 0.9929', 'Test Acc: 0.99', 'Train LL: -0.022467212314957612', 'Test LL: -0.03153936500435192', 'Epoch Time (s): 163.54041759599932')
('Epoch 56', 'Objective: -0.04426475595323484', 'Train Acc: 0.9928166666666667', 'Test Acc: 0.9898', 'Train LL: -0.022414290443446915', 'Test LL: -0.03186038398407814', 'Epoch Time (s): 163.5213189809583')
('Epoch 57', 'Objective: -0.044950130834456856', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9911', 'Train LL: -0.023140585859342058', 'Test LL: -0.026801722055092455', 'Epoch Time (s): 163.5531201241538')
('Epoch 58', 'Objective: -0.04373010807012267', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9908', 'Train LL: -0.022115721641083625', 'Test LL: -0.025608750652176472', 'Epoch Time (s): 163.53322070115246')
('Epoch 59', 'Objective: -0.04370785063033306', 'Train Acc: 0.99275', 'Test Acc: 0.9913', 'Train LL: -0.022112103993528552', 'Test LL: -0.027001710348116062', 'Epoch Time (s): 163.5418348000385')
('Epoch 60', 'Objective: -0.04408026988754842', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9898', 'Train LL: -0.022538736640330972', 'Test LL: -0.030469938696070356', 'Epoch Time (s): 163.54959281603806')
('Epoch 61', 'Objective: -0.04393742812163439', 'Train Acc: 0.99265', 'Test Acc: 0.9918', 'Train LL: -0.022497770761129868', 'Test LL: -0.025603069540073898', 'Epoch Time (s): 163.534341160208')
('Epoch 62', 'Objective: -0.04401949702274044', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9906', 'Train LL: -0.022659053612619117', 'Test LL: -0.02890006163997633', 'Epoch Time (s): 163.52476002904586')
('Epoch 63', 'Objective: -0.04337190974602775', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9917', 'Train LL: -0.022039950885924985', 'Test LL: -0.025010377645550894', 'Epoch Time (s): 163.50969211920165')
('Epoch 64', 'Objective: -0.04300516683542458', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9915', 'Train LL: -0.021793580727838935', 'Test LL: -0.026454397108323986', 'Epoch Time (s): 163.49691647896543')
('Epoch 65', 'Objective: -0.04293175096060097', 'Train Acc: 0.99295', 'Test Acc: 0.9909', 'Train LL: -0.02172823488037777', 'Test LL: -0.026461116686099267', 'Epoch Time (s): 163.48934847093187')
('Epoch 66', 'Objective: -0.0429796667235342', 'Train Acc: 0.9929', 'Test Acc: 0.9918', 'Train LL: -0.02184009968980594', 'Test LL: -0.024337907558190364', 'Epoch Time (s): 163.51057115197182')
('Epoch 67', 'Objective: -0.04240085299143561', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9912', 'Train LL: -0.02131920045840085', 'Test LL: -0.027477341190751594', 'Epoch Time (s): 163.51348962192424')
('Epoch 68', 'Objective: -0.04191021267175095', 'Train Acc: 0.9935', 'Test Acc: 0.9916', 'Train LL: -0.020937232929520502', 'Test LL: -0.02489983530474864', 'Epoch Time (s): 163.49665293004364')
('Epoch 69', 'Objective: -0.04215527537005005', 'Train Acc: 0.9931833333333333', 'Test Acc: 0.9909', 'Train LL: -0.021195800023778605', 'Test LL: -0.02699820983329108', 'Epoch Time (s): 163.50494909798726')
('Epoch 70', 'Objective: -0.04246006869122202', 'Train Acc: 0.9930666666666667', 'Test Acc: 0.9916', 'Train LL: -0.021539241612456326', 'Test LL: -0.025933641628105637', 'Epoch Time (s): 163.49187322007492')
('Epoch 71', 'Objective: -0.041532457102450925', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.9904', 'Train LL: -0.02073471590233951', 'Test LL: -0.027474074678957232', 'Epoch Time (s): 163.51040270691738')
('Epoch 72', 'Objective: -0.04202752566519305', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9911', 'Train LL: -0.021207977371264213', 'Test LL: -0.026619065191134744', 'Epoch Time (s): 163.4972936939448')
('Epoch 73', 'Objective: -0.04216654847696379', 'Train Acc: 0.9929', 'Test Acc: 0.9897', 'Train LL: -0.021365111589240628', 'Test LL: -0.030448863552451435', 'Epoch Time (s): 163.4882358291652')
('Epoch 74', 'Objective: -0.0415017972715225', 'Train Acc: 0.9933833333333333', 'Test Acc: 0.993', 'Train LL: -0.020792999148421254', 'Test LL: -0.022140130531475576', 'Epoch Time (s): 163.47864532005042')
('Epoch 75', 'Objective: -0.04121833947481034', 'Train Acc: 0.99365', 'Test Acc: 0.9898', 'Train LL: -0.020502414308205295', 'Test LL: -0.03138657364231027', 'Epoch Time (s): 163.48328741290607')
('Epoch 76', 'Objective: -0.04118441208632059', 'Train Acc: 0.9933', 'Test Acc: 0.9925', 'Train LL: -0.020546449424414536', 'Test LL: -0.02392974019764697', 'Epoch Time (s): 163.49674142501317')
('Epoch 77', 'Objective: -0.04136155779619351', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9905', 'Train LL: -0.02076363030915248', 'Test LL: -0.027740743201158012', 'Epoch Time (s): 164.19554019183852')
('Epoch 78', 'Objective: -0.04107675304591125', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.9912', 'Train LL: -0.020455477369070267', 'Test LL: -0.02678085684234428', 'Epoch Time (s): 163.62828701687977')
('Epoch 79', 'Objective: -0.040708024617906256', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9907', 'Train LL: -0.020190514022849153', 'Test LL: -0.029458259969858784', 'Epoch Time (s): 163.66471815202385')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.03872696986066125', 'Train Acc: 0.9937', 'Test Acc: 0.992', 'Train LL: -0.018461521631632397', 'Test LL: -0.026832996285525258', 'Epoch Time (s): 163.5758692920208')
('Epoch 81', 'Objective: -0.03760558874478989', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9918', 'Train LL: -0.017425898472562238', 'Test LL: -0.025490832849040447', 'Epoch Time (s): 163.38575849495828')
('Epoch 82', 'Objective: -0.03753979202665814', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9914', 'Train LL: -0.017351024817401462', 'Test LL: -0.026914760620297812', 'Epoch Time (s): 163.83963102591224')
('Epoch 83', 'Objective: -0.03751809656946798', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9919', 'Train LL: -0.017295862789258182', 'Test LL: -0.026161784633396967', 'Epoch Time (s): 163.58871577004902')
('Epoch 84', 'Objective: -0.037724754197084556', 'Train Acc: 0.99455', 'Test Acc: 0.9918', 'Train LL: -0.017526011212489936', 'Test LL: -0.025777537685956007', 'Epoch Time (s): 163.6020296900533')
('Epoch 85', 'Objective: -0.03664581846020677', 'Train Acc: 0.9949833333333333', 'Test Acc: 0.9915', 'Train LL: -0.01655222719423216', 'Test LL: -0.025506800693353846', 'Epoch Time (s): 163.57931150100194')
('Epoch 86', 'Objective: -0.03709935187713866', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9914', 'Train LL: -0.016938936768333242', 'Test LL: -0.025965386377726656', 'Epoch Time (s): 163.57372187194414')
('Epoch 87', 'Objective: -0.03690185599009699', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.9919', 'Train LL: -0.016744254133957436', 'Test LL: -0.025848580337660347', 'Epoch Time (s): 163.49028380890377')
('Epoch 88', 'Objective: -0.03719630331267855', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9915', 'Train LL: -0.017008429591580353', 'Test LL: -0.026799173224153292', 'Epoch Time (s): 163.53670902899466')
('Epoch 89', 'Objective: -0.03677963580735083', 'Train Acc: 0.9948', 'Test Acc: 0.9915', 'Train LL: -0.016640350599637768', 'Test LL: -0.02616715476634265', 'Epoch Time (s): 163.56357986410148')
('Epoch 90', 'Objective: -0.03714758873169272', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9915', 'Train LL: -0.016961995700558827', 'Test LL: -0.025938072800110207', 'Epoch Time (s): 163.60344052989967')
('Epoch 91', 'Objective: -0.037458903930059566', 'Train Acc: 0.9946166666666667', 'Test Acc: 0.9917', 'Train LL: -0.017264808918559863', 'Test LL: -0.02594197481094874', 'Epoch Time (s): 163.49919735686854')
('Epoch 92', 'Objective: -0.03676842337211013', 'Train Acc: 0.99485', 'Test Acc: 0.991', 'Train LL: -0.016647345263311256', 'Test LL: -0.026637893677626517', 'Epoch Time (s): 163.49192097503692')
('Epoch 93', 'Objective: -0.036633839344549224', 'Train Acc: 0.9950333333333333', 'Test Acc: 0.9916', 'Train LL: -0.01649845526656313', 'Test LL: -0.026646046803280556', 'Epoch Time (s): 163.73997469921596')
('Epoch 94', 'Objective: -0.03704367143847541', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.9916', 'Train LL: -0.016917077601045685', 'Test LL: -0.02554073416617707', 'Epoch Time (s): 163.65210286993533')
('Epoch 95', 'Objective: -0.03708872584354731', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9918', 'Train LL: -0.01694785973479851', 'Test LL: -0.025335888365576622', 'Epoch Time (s): 163.69818490906619')
('Epoch 96', 'Objective: -0.036791509815819176', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9918', 'Train LL: -0.016679138523204753', 'Test LL: -0.025441729889634182', 'Epoch Time (s): 163.61762685887516')
('Epoch 97', 'Objective: -0.036367556440824816', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9917', 'Train LL: -0.016255333194362603', 'Test LL: -0.025829134267823708', 'Epoch Time (s): 163.62424372392707')
('Epoch 98', 'Objective: -0.03700342481154123', 'Train Acc: 0.9946', 'Test Acc: 0.9916', 'Train LL: -0.01684592516914989', 'Test LL: -0.02584495733166566', 'Epoch Time (s): 163.6724245569203')
('Epoch 99', 'Objective: -0.03618414887416314', 'Train Acc: 0.99485', 'Test Acc: 0.992', 'Train LL: -0.01612065972436178', 'Test LL: -0.025168638971603666', 'Epoch Time (s): 163.66500892490149')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03622013181938398
Final Train Accuracy: £0.9947333333333334
Final Train LL: £-0.016068475694832204
Final Test Accuracy: £0.992
Final Test LL: £-0.02511182732878312
