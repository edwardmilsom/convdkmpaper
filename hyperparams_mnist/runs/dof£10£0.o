dataset: MNIST
dtype: float64
dof: 10.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.470879327644406', 'Train Acc: 0.5057', 'Test Acc: 0.7444', 'Train LL: -1.3734896410118245', 'Test LL: -0.7890551052878376', 'Epoch Time (s): 163.49035975686274')
('Epoch 1', 'Objective: -0.7567511861377586', 'Train Acc: 0.7777833333333334', 'Test Acc: 0.8423', 'Train LL: -0.643687725666283', 'Test LL: -0.46019249796353023', 'Epoch Time (s): 163.50864582089707')
('Epoch 2', 'Objective: -0.5310348088655632', 'Train Acc: 0.86185', 'Test Acc: 0.87', 'Train LL: -0.4133913090748437', 'Test LL: -0.4015975704513336', 'Epoch Time (s): 163.4525020159781')
('Epoch 3', 'Objective: -0.40848016176625707', 'Train Acc: 0.9083333333333333', 'Test Acc: 0.9211', 'Train LL: -0.290196915589302', 'Test LL: -0.26020302750988883', 'Epoch Time (s): 163.49821497313678')
('Epoch 4', 'Objective: -0.3557032137162354', 'Train Acc: 0.9245333333333333', 'Test Acc: 0.9292', 'Train LL: -0.2407952596220231', 'Test LL: -0.23082411400027508', 'Epoch Time (s): 163.4235791049432')
('Epoch 5', 'Objective: -0.3195819628491365', 'Train Acc: 0.9356666666666666', 'Test Acc: 0.8936', 'Train LL: -0.20893537146074334', 'Test LL: -0.3110219824695976', 'Epoch Time (s): 163.42925493512303')
('Epoch 6', 'Objective: -0.2925109651671271', 'Train Acc: 0.94275', 'Test Acc: 0.943', 'Train LL: -0.18493532726832965', 'Test LL: -0.18369462524136793', 'Epoch Time (s): 163.42236218508333')
('Epoch 7', 'Objective: -0.27469397049053246', 'Train Acc: 0.94695', 'Test Acc: 0.9338', 'Train LL: -0.17021797217780343', 'Test LL: -0.21375523080218808', 'Epoch Time (s): 163.40217391215265')
('Epoch 8', 'Objective: -0.2547247649086619', 'Train Acc: 0.95285', 'Test Acc: 0.9538', 'Train LL: -0.1543532170654874', 'Test LL: -0.1442895087553833', 'Epoch Time (s): 163.4477703308221')
('Epoch 9', 'Objective: -0.24473884506777538', 'Train Acc: 0.95425', 'Test Acc: 0.9682', 'Train LL: -0.1463531515994067', 'Test LL: -0.101403035453196', 'Epoch Time (s): 163.45373466983438')
('Epoch 10', 'Objective: -0.23767893750481295', 'Train Acc: 0.9568166666666666', 'Test Acc: 0.9574', 'Train LL: -0.14152618849529508', 'Test LL: -0.13370386124583994', 'Epoch Time (s): 163.43502367590554')
('Epoch 11', 'Objective: -0.22684584826033216', 'Train Acc: 0.95915', 'Test Acc: 0.9641', 'Train LL: -0.13352472311316235', 'Test LL: -0.1101939362510278', 'Epoch Time (s): 163.39095378108323')
('Epoch 12', 'Objective: -0.22150914136661773', 'Train Acc: 0.95965', 'Test Acc: 0.9643', 'Train LL: -0.13073808299812184', 'Test LL: -0.11221771971141145', 'Epoch Time (s): 163.45560355391353')
('Epoch 13', 'Objective: -0.21450059571284674', 'Train Acc: 0.9614166666666667', 'Test Acc: 0.9718', 'Train LL: -0.1253425035036087', 'Test LL: -0.09119125107565006', 'Epoch Time (s): 163.44812546507455')
('Epoch 14', 'Objective: -0.21021437717784475', 'Train Acc: 0.9619166666666666', 'Test Acc: 0.965', 'Train LL: -0.122081999569182', 'Test LL: -0.10895403528890031', 'Epoch Time (s): 163.40338075510226')
('Epoch 15', 'Objective: -0.20372955211948499', 'Train Acc: 0.96365', 'Test Acc: 0.9718', 'Train LL: -0.1170450538759785', 'Test LL: -0.0920596781732839', 'Epoch Time (s): 163.4263848599512')
('Epoch 16', 'Objective: -0.19835132893678656', 'Train Acc: 0.9642166666666667', 'Test Acc: 0.9728', 'Train LL: -0.1132264682401035', 'Test LL: -0.08895506772418808', 'Epoch Time (s): 163.50142593495548')
('Epoch 17', 'Objective: -0.19740946632659404', 'Train Acc: 0.9656166666666667', 'Test Acc: 0.9693', 'Train LL: -0.11329783260874317', 'Test LL: -0.09522114037795568', 'Epoch Time (s): 163.43635408813134')
('Epoch 18', 'Objective: -0.19258983623354922', 'Train Acc: 0.9662166666666666', 'Test Acc: 0.97', 'Train LL: -0.10939493655501241', 'Test LL: -0.09684455759658547', 'Epoch Time (s): 163.4443855350837')
('Epoch 19', 'Objective: -0.19256139530768748', 'Train Acc: 0.9657833333333333', 'Test Acc: 0.963', 'Train LL: -0.109499459146776', 'Test LL: -0.1142543050227614', 'Epoch Time (s): 163.46225193701684')
('Epoch 20', 'Objective: -0.18656301885617838', 'Train Acc: 0.9671833333333333', 'Test Acc: 0.9703', 'Train LL: -0.10435695769136301', 'Test LL: -0.0905683888912169', 'Epoch Time (s): 163.4172686659731')
('Epoch 21', 'Objective: -0.18642800927496125', 'Train Acc: 0.9676333333333333', 'Test Acc: 0.9757', 'Train LL: -0.10516519604513563', 'Test LL: -0.08120736030537468', 'Epoch Time (s): 163.41303410707042')
('Epoch 22', 'Objective: -0.1839940520106057', 'Train Acc: 0.9681166666666666', 'Test Acc: 0.9637', 'Train LL: -0.10332738984703922', 'Test LL: -0.11975089204804304', 'Epoch Time (s): 163.4408573678229')
('Epoch 23', 'Objective: -0.18164428655402223', 'Train Acc: 0.9684', 'Test Acc: 0.9647', 'Train LL: -0.10148131448688655', 'Test LL: -0.10905599639847219', 'Epoch Time (s): 163.45005878293887')
('Epoch 24', 'Objective: -0.17775488222713925', 'Train Acc: 0.96855', 'Test Acc: 0.9628', 'Train LL: -0.09843159394755585', 'Test LL: -0.1178650639204668', 'Epoch Time (s): 163.44086790597066')
('Epoch 25', 'Objective: -0.17474275559498242', 'Train Acc: 0.9695166666666667', 'Test Acc: 0.9748', 'Train LL: -0.09601445233557858', 'Test LL: -0.07417017420072933', 'Epoch Time (s): 163.4231987099629')
('Epoch 26', 'Objective: -0.17429814817217493', 'Train Acc: 0.9702333333333333', 'Test Acc: 0.9759', 'Train LL: -0.09626730521910128', 'Test LL: -0.07388277717660255', 'Epoch Time (s): 163.42120354902')
('Epoch 27', 'Objective: -0.17243867994068168', 'Train Acc: 0.9703666666666667', 'Test Acc: 0.9658', 'Train LL: -0.0949913156432502', 'Test LL: -0.10996348087702013', 'Epoch Time (s): 163.41317327995785')
('Epoch 28', 'Objective: -0.16970264052762263', 'Train Acc: 0.9711', 'Test Acc: 0.9678', 'Train LL: -0.0926779738376104', 'Test LL: -0.09383776120132085', 'Epoch Time (s): 163.44012927100994')
('Epoch 29', 'Objective: -0.16837082629108624', 'Train Acc: 0.9715666666666667', 'Test Acc: 0.9739', 'Train LL: -0.09158438437020137', 'Test LL: -0.0793982005083861', 'Epoch Time (s): 163.4542356301099')
('Epoch 30', 'Objective: -0.16973012860289413', 'Train Acc: 0.97065', 'Test Acc: 0.9734', 'Train LL: -0.09309195342002238', 'Test LL: -0.08820185454312447', 'Epoch Time (s): 163.48080583289266')
('Epoch 31', 'Objective: -0.16327231378834872', 'Train Acc: 0.9721666666666666', 'Test Acc: 0.9775', 'Train LL: -0.08747457008681749', 'Test LL: -0.07303424402191136', 'Epoch Time (s): 163.42050718492828')
('Epoch 32', 'Objective: -0.16206167488916282', 'Train Acc: 0.9735', 'Test Acc: 0.9752', 'Train LL: -0.08652184394587918', 'Test LL: -0.0783241679835715', 'Epoch Time (s): 163.42536204704084')
('Epoch 33', 'Objective: -0.16073483689861187', 'Train Acc: 0.9730833333333333', 'Test Acc: 0.9794', 'Train LL: -0.08581428127592482', 'Test LL: -0.06457863863699131', 'Epoch Time (s): 163.44542532088235')
('Epoch 34', 'Objective: -0.1582191264668288', 'Train Acc: 0.9736', 'Test Acc: 0.977', 'Train LL: -0.0844124495787268', 'Test LL: -0.07567305992085181', 'Epoch Time (s): 163.41477786609903')
('Epoch 35', 'Objective: -0.1564914331059389', 'Train Acc: 0.9737666666666667', 'Test Acc: 0.9689', 'Train LL: -0.08336536443303905', 'Test LL: -0.0938328224908214', 'Epoch Time (s): 163.42489067581482')
('Epoch 36', 'Objective: -0.1560110461630259', 'Train Acc: 0.9740666666666666', 'Test Acc: 0.9727', 'Train LL: -0.08255862025327805', 'Test LL: -0.0823130945160916', 'Epoch Time (s): 163.41588129708543')
('Epoch 37', 'Objective: -0.1559531594344745', 'Train Acc: 0.9736', 'Test Acc: 0.9737', 'Train LL: -0.08297203748526988', 'Test LL: -0.08158134147848191', 'Epoch Time (s): 163.42909110104665')
('Epoch 38', 'Objective: -0.15697514792785547', 'Train Acc: 0.9738333333333333', 'Test Acc: 0.9787', 'Train LL: -0.08367898410160823', 'Test LL: -0.06689601983506514', 'Epoch Time (s): 163.44668426387943')
('Epoch 39', 'Objective: -0.15125969178634285', 'Train Acc: 0.9748833333333333', 'Test Acc: 0.9761', 'Train LL: -0.07884206745898398', 'Test LL: -0.07304412503651943', 'Epoch Time (s): 163.4537602579221')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.12306108694073539', 'Train Acc: 0.98305', 'Test Acc: 0.9852', 'Train LL: -0.0548325966737924', 'Test LL: -0.04433692420680076', 'Epoch Time (s): 163.4721160971094')
('Epoch 41', 'Objective: -0.11643499108565034', 'Train Acc: 0.9839166666666667', 'Test Acc: 0.9855', 'Train LL: -0.05136067520756822', 'Test LL: -0.042638802517163746', 'Epoch Time (s): 163.43447417020798')
('Epoch 42', 'Objective: -0.11412458212090845', 'Train Acc: 0.9840833333333333', 'Test Acc: 0.9851', 'Train LL: -0.04995503394265555', 'Test LL: -0.04385703349375845', 'Epoch Time (s): 163.4029395089019')
('Epoch 43', 'Objective: -0.11363571912940677', 'Train Acc: 0.98405', 'Test Acc: 0.9846', 'Train LL: -0.05012594364055564', 'Test LL: -0.044546957690909515', 'Epoch Time (s): 163.4369298638776')
('Epoch 44', 'Objective: -0.11194257456550834', 'Train Acc: 0.9844', 'Test Acc: 0.984', 'Train LL: -0.04899833567404436', 'Test LL: -0.04529994857173341', 'Epoch Time (s): 163.4400820240844')
('Epoch 45', 'Objective: -0.11067793573948638', 'Train Acc: 0.98455', 'Test Acc: 0.9848', 'Train LL: -0.04838462508886623', 'Test LL: -0.04305396845536377', 'Epoch Time (s): 163.47636227705516')
('Epoch 46', 'Objective: -0.11048555982380734', 'Train Acc: 0.9842666666666666', 'Test Acc: 0.9828', 'Train LL: -0.04848936136146869', 'Test LL: -0.04839649365093407', 'Epoch Time (s): 163.44616895308718')
('Epoch 47', 'Objective: -0.11022089590621525', 'Train Acc: 0.985', 'Test Acc: 0.9857', 'Train LL: -0.04847668522571333', 'Test LL: -0.041527259696182185', 'Epoch Time (s): 163.50456633185968')
('Epoch 48', 'Objective: -0.10924481131739452', 'Train Acc: 0.9846333333333334', 'Test Acc: 0.9863', 'Train LL: -0.04791163063783925', 'Test LL: -0.04135296243515944', 'Epoch Time (s): 163.44928671210073')
('Epoch 49', 'Objective: -0.10865468276502988', 'Train Acc: 0.9848', 'Test Acc: 0.9852', 'Train LL: -0.047655728061536624', 'Test LL: -0.045266772350687094', 'Epoch Time (s): 163.45794207998551')
('Epoch 50', 'Objective: -0.10901854822765641', 'Train Acc: 0.9846666666666667', 'Test Acc: 0.9856', 'Train LL: -0.04815303942653448', 'Test LL: -0.043047796829126565', 'Epoch Time (s): 163.44514923612587')
('Epoch 51', 'Objective: -0.10850211690171094', 'Train Acc: 0.9847', 'Test Acc: 0.985', 'Train LL: -0.047808101648335606', 'Test LL: -0.04502701808583532', 'Epoch Time (s): 163.4785557440482')
('Epoch 52', 'Objective: -0.10750802191367308', 'Train Acc: 0.9850833333333333', 'Test Acc: 0.9862', 'Train LL: -0.04709386638610789', 'Test LL: -0.04245320616649819', 'Epoch Time (s): 163.43453615694307')
('Epoch 53', 'Objective: -0.10645752257033667', 'Train Acc: 0.9850333333333333', 'Test Acc: 0.9861', 'Train LL: -0.046302993400197674', 'Test LL: -0.04095702756972615', 'Epoch Time (s): 163.43110706913285')
('Epoch 54', 'Objective: -0.10659429503497776', 'Train Acc: 0.9852333333333333', 'Test Acc: 0.9859', 'Train LL: -0.04671123428408569', 'Test LL: -0.04083624099634053', 'Epoch Time (s): 163.42170449788682')
('Epoch 55', 'Objective: -0.1057905938608636', 'Train Acc: 0.9853333333333333', 'Test Acc: 0.9846', 'Train LL: -0.046053748899441714', 'Test LL: -0.04492815525181394', 'Epoch Time (s): 163.44845119002275')
('Epoch 56', 'Objective: -0.10586702907344132', 'Train Acc: 0.9852', 'Test Acc: 0.9866', 'Train LL: -0.04634876758486014', 'Test LL: -0.04003824950087637', 'Epoch Time (s): 163.4350458891131')
('Epoch 57', 'Objective: -0.10597754515003995', 'Train Acc: 0.9856333333333334', 'Test Acc: 0.9846', 'Train LL: -0.04660024059018304', 'Test LL: -0.04411370558070475', 'Epoch Time (s): 163.40861516003497')
('Epoch 58', 'Objective: -0.10554371015795183', 'Train Acc: 0.9855', 'Test Acc: 0.9869', 'Train LL: -0.0462317363580299', 'Test LL: -0.04031558285738161', 'Epoch Time (s): 163.45001694606617')
('Epoch 59', 'Objective: -0.10493743432038051', 'Train Acc: 0.9853666666666666', 'Test Acc: 0.9853', 'Train LL: -0.046055326461982224', 'Test LL: -0.043900448858099884', 'Epoch Time (s): 163.41403814801015')
('Epoch 60', 'Objective: -0.10555064943504265', 'Train Acc: 0.98505', 'Test Acc: 0.985', 'Train LL: -0.0467041441611545', 'Test LL: -0.04379923442745269', 'Epoch Time (s): 163.4413521871902')
('Epoch 61', 'Objective: -0.10540496996888016', 'Train Acc: 0.9853166666666666', 'Test Acc: 0.9848', 'Train LL: -0.04669278376513794', 'Test LL: -0.043781903823014064', 'Epoch Time (s): 163.45224753208458')
('Epoch 62', 'Objective: -0.10528424837191486', 'Train Acc: 0.9850333333333333', 'Test Acc: 0.9861', 'Train LL: -0.046712148339219814', 'Test LL: -0.04193079246845289', 'Epoch Time (s): 163.46512242779136')
('Epoch 63', 'Objective: -0.10429544063219334', 'Train Acc: 0.9855', 'Test Acc: 0.9856', 'Train LL: -0.04591698963478895', 'Test LL: -0.04590701728910766', 'Epoch Time (s): 163.43649257486686')
('Epoch 64', 'Objective: -0.10406720228262335', 'Train Acc: 0.9850666666666666', 'Test Acc: 0.9857', 'Train LL: -0.04570061961547477', 'Test LL: -0.04160278119197612', 'Epoch Time (s): 163.45238037314266')
('Epoch 65', 'Objective: -0.10496239752021809', 'Train Acc: 0.9852333333333333', 'Test Acc: 0.9857', 'Train LL: -0.04684162093783696', 'Test LL: -0.04256639974489512', 'Epoch Time (s): 163.46569981309585')
('Epoch 66', 'Objective: -0.10421857892114729', 'Train Acc: 0.9854166666666667', 'Test Acc: 0.9838', 'Train LL: -0.04609879255812104', 'Test LL: -0.04743444887698278', 'Epoch Time (s): 163.45225317496806')
('Epoch 67', 'Objective: -0.10413483823411132', 'Train Acc: 0.9853833333333334', 'Test Acc: 0.9856', 'Train LL: -0.046311778037645066', 'Test LL: -0.04139892848132295', 'Epoch Time (s): 163.43315771687776')
('Epoch 68', 'Objective: -0.10363733802997634', 'Train Acc: 0.9856', 'Test Acc: 0.9866', 'Train LL: -0.04587486187320018', 'Test LL: -0.043078122834956004', 'Epoch Time (s): 163.44748862297274')
('Epoch 69', 'Objective: -0.10369612189533793', 'Train Acc: 0.9857333333333334', 'Test Acc: 0.9852', 'Train LL: -0.04598743260696563', 'Test LL: -0.04451177207765209', 'Epoch Time (s): 163.44768235692754')
('Epoch 70', 'Objective: -0.10277086568495053', 'Train Acc: 0.9856333333333334', 'Test Acc: 0.9868', 'Train LL: -0.04511913892232025', 'Test LL: -0.038825683127113694', 'Epoch Time (s): 163.4791966069024')
('Epoch 71', 'Objective: -0.10376189374954269', 'Train Acc: 0.9853166666666666', 'Test Acc: 0.9838', 'Train LL: -0.0463715219385292', 'Test LL: -0.04598251531932682', 'Epoch Time (s): 163.4221605299972')
('Epoch 72', 'Objective: -0.10260418545408169', 'Train Acc: 0.98575', 'Test Acc: 0.9847', 'Train LL: -0.04519173711882048', 'Test LL: -0.04331326067310972', 'Epoch Time (s): 163.54199985810556')
('Epoch 73', 'Objective: -0.10289523857103428', 'Train Acc: 0.98525', 'Test Acc: 0.9873', 'Train LL: -0.04569246896708351', 'Test LL: -0.04041761608099492', 'Epoch Time (s): 163.4628787098918')
('Epoch 74', 'Objective: -0.1023561338027358', 'Train Acc: 0.98585', 'Test Acc: 0.9866', 'Train LL: -0.04529051519663833', 'Test LL: -0.03970340763327171', 'Epoch Time (s): 163.45458071515895')
('Epoch 75', 'Objective: -0.1023705592473207', 'Train Acc: 0.9859333333333333', 'Test Acc: 0.9854', 'Train LL: -0.04541644988477897', 'Test LL: -0.04520745518843639', 'Epoch Time (s): 163.47500276309438')
('Epoch 76', 'Objective: -0.10260576132612903', 'Train Acc: 0.98585', 'Test Acc: 0.9859', 'Train LL: -0.04568022696129408', 'Test LL: -0.0423124448522316', 'Epoch Time (s): 163.59927288093604')
('Epoch 77', 'Objective: -0.10278098105326146', 'Train Acc: 0.9859333333333333', 'Test Acc: 0.9854', 'Train LL: -0.04584765551155231', 'Test LL: -0.046285155950902455', 'Epoch Time (s): 163.42283866507933')
('Epoch 78', 'Objective: -0.102393843709026', 'Train Acc: 0.9853833333333334', 'Test Acc: 0.9861', 'Train LL: -0.04564919374490355', 'Test LL: -0.0410653330340225', 'Epoch Time (s): 163.4829730829224')
('Epoch 79', 'Objective: -0.10199568166532634', 'Train Acc: 0.9855333333333334', 'Test Acc: 0.9859', 'Train LL: -0.045317780247108', 'Test LL: -0.04044497810435496', 'Epoch Time (s): 163.50379013409838')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.0985188036517169', 'Train Acc: 0.9872333333333333', 'Test Acc: 0.9863', 'Train LL: -0.042458051117464535', 'Test LL: -0.041637473981822284', 'Epoch Time (s): 163.45788405300118')
('Epoch 81', 'Objective: -0.09737693866660135', 'Train Acc: 0.9869333333333333', 'Test Acc: 0.9868', 'Train LL: -0.041420100590171975', 'Test LL: -0.04026118839169004', 'Epoch Time (s): 163.45200431882404')
('Epoch 82', 'Objective: -0.09672149349026285', 'Train Acc: 0.9872', 'Test Acc: 0.9865', 'Train LL: -0.040772289482139186', 'Test LL: -0.040899364710505336', 'Epoch Time (s): 163.4796067958232')
('Epoch 83', 'Objective: -0.09672698838831825', 'Train Acc: 0.98695', 'Test Acc: 0.9862', 'Train LL: -0.04080977213273107', 'Test LL: -0.040572857229401765', 'Epoch Time (s): 163.44379745284095')
('Epoch 84', 'Objective: -0.09664168880772533', 'Train Acc: 0.9870333333333333', 'Test Acc: 0.9865', 'Train LL: -0.04082173175722134', 'Test LL: -0.03934587592719146', 'Epoch Time (s): 163.4222287198063')
('Epoch 85', 'Objective: -0.0961410754195032', 'Train Acc: 0.9872833333333333', 'Test Acc: 0.9864', 'Train LL: -0.04029473650937357', 'Test LL: -0.03993152601854261', 'Epoch Time (s): 163.45932419900782')
('Epoch 86', 'Objective: -0.09663673410637631', 'Train Acc: 0.9870666666666666', 'Test Acc: 0.9868', 'Train LL: -0.04076157279838552', 'Test LL: -0.03947068679389094', 'Epoch Time (s): 163.45233919401653')
('Epoch 87', 'Objective: -0.0965247427802262', 'Train Acc: 0.9865666666666667', 'Test Acc: 0.9866', 'Train LL: -0.04065454025415135', 'Test LL: -0.03893989394624004', 'Epoch Time (s): 163.44304262194782')
('Epoch 88', 'Objective: -0.09629335332793475', 'Train Acc: 0.9872333333333333', 'Test Acc: 0.9871', 'Train LL: -0.04050708795902869', 'Test LL: -0.03925264068457872', 'Epoch Time (s): 163.42136072507128')
('Epoch 89', 'Objective: -0.09659234708789688', 'Train Acc: 0.98715', 'Test Acc: 0.9872', 'Train LL: -0.04078469833196618', 'Test LL: -0.039487930707903046', 'Epoch Time (s): 163.39810364390723')
('Epoch 90', 'Objective: -0.09674346568090866', 'Train Acc: 0.9873', 'Test Acc: 0.9872', 'Train LL: -0.04099777105003514', 'Test LL: -0.03893607471504742', 'Epoch Time (s): 163.38416701904498')
('Epoch 91', 'Objective: -0.09600375602110507', 'Train Acc: 0.9869166666666667', 'Test Acc: 0.9871', 'Train LL: -0.04033920404175953', 'Test LL: -0.038988917568834276', 'Epoch Time (s): 163.37214415799826')
('Epoch 92', 'Objective: -0.09632368332356515', 'Train Acc: 0.98725', 'Test Acc: 0.9866', 'Train LL: -0.04062961670205769', 'Test LL: -0.04005614657124975', 'Epoch Time (s): 163.4295342990663')
('Epoch 93', 'Objective: -0.09622649382970265', 'Train Acc: 0.9869333333333333', 'Test Acc: 0.9869', 'Train LL: -0.040554309712659706', 'Test LL: -0.03951670086549562', 'Epoch Time (s): 163.43196227913722')
('Epoch 94', 'Objective: -0.0962588626168142', 'Train Acc: 0.9873833333333333', 'Test Acc: 0.9869', 'Train LL: -0.040560885049700006', 'Test LL: -0.03897424704981713', 'Epoch Time (s): 163.47167355916463')
('Epoch 95', 'Objective: -0.0961925299571216', 'Train Acc: 0.9873666666666666', 'Test Acc: 0.9868', 'Train LL: -0.04051653181558998', 'Test LL: -0.03962145055119759', 'Epoch Time (s): 163.43477562302724')
('Epoch 96', 'Objective: -0.09558209666745507', 'Train Acc: 0.9871', 'Test Acc: 0.9863', 'Train LL: -0.039976423968713516', 'Test LL: -0.03991665254481609', 'Epoch Time (s): 163.44380612415262')
('Epoch 97', 'Objective: -0.09551936624318305', 'Train Acc: 0.9872', 'Test Acc: 0.9866', 'Train LL: -0.039950686334760704', 'Test LL: -0.03951740033907123', 'Epoch Time (s): 163.40382890193723')
('Epoch 98', 'Objective: -0.09630002410073035', 'Train Acc: 0.9867833333333333', 'Test Acc: 0.9869', 'Train LL: -0.040574963585599866', 'Test LL: -0.03952442314252028', 'Epoch Time (s): 163.45190771995112')
('Epoch 99', 'Objective: -0.09644359650572935', 'Train Acc: 0.9868833333333333', 'Test Acc: 0.9871', 'Train LL: -0.04081038201735135', 'Test LL: -0.03841144319240234', 'Epoch Time (s): 163.4299185089767')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.09581753957774271
Final Train Accuracy: £0.98685
Final Train LL: £-0.04021953715207751
Final Test Accuracy: £0.987
Final Test LL: £-0.03834821477281322
