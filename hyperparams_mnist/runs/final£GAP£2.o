dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2845920294466213', 'Train Acc: 0.5584666666666667', 'Test Acc: 0.7294', 'Train LL: -1.2288430927964835', 'Test LL: -0.7594980796028038', 'Epoch Time (s): 163.90173401194625')
('Epoch 1', 'Objective: -0.5521238914856166', 'Train Acc: 0.8315333333333333', 'Test Acc: 0.8442', 'Train LL: -0.5000628084074225', 'Test LL: -0.46927014049265797', 'Epoch Time (s): 163.9747687750496')
('Epoch 2', 'Objective: -0.3270069644567121', 'Train Acc: 0.9114', 'Test Acc: 0.9194', 'Train LL: -0.2765448880201339', 'Test LL: -0.25153570648929086', 'Epoch Time (s): 163.95551351783797')
('Epoch 3', 'Objective: -0.2531961072085804', 'Train Acc: 0.9352833333333334', 'Test Acc: 0.9464', 'Train LL: -0.20713437685946048', 'Test LL: -0.17052276119143406', 'Epoch Time (s): 163.97410299698822')
('Epoch 4', 'Objective: -0.21906839589153462', 'Train Acc: 0.9457333333333333', 'Test Acc: 0.9404', 'Train LL: -0.1754167912894587', 'Test LL: -0.17693673742687466', 'Epoch Time (s): 164.0591496070847')
('Epoch 5', 'Objective: -0.19471335025109704', 'Train Acc: 0.9518333333333333', 'Test Acc: 0.9545', 'Train LL: -0.15278396358958482', 'Test LL: -0.13930792628970368', 'Epoch Time (s): 164.0300687609706')
('Epoch 6', 'Objective: -0.1778202839900995', 'Train Acc: 0.9580666666666666', 'Test Acc: 0.9524', 'Train LL: -0.13708073312830893', 'Test LL: -0.14817857107512772', 'Epoch Time (s): 164.07879367796704')
('Epoch 7', 'Objective: -0.16595495453156456', 'Train Acc: 0.9599166666666666', 'Test Acc: 0.9627', 'Train LL: -0.1258684213283609', 'Test LL: -0.12312483470032444', 'Epoch Time (s): 164.05846343492158')
('Epoch 8', 'Objective: -0.15527955420111936', 'Train Acc: 0.9642333333333334', 'Test Acc: 0.9713', 'Train LL: -0.11586778353276542', 'Test LL: -0.08957626060658376', 'Epoch Time (s): 164.08677842700854')
('Epoch 9', 'Objective: -0.14600975832007737', 'Train Acc: 0.967', 'Test Acc: 0.974', 'Train LL: -0.10766850562947984', 'Test LL: -0.08667042345654229', 'Epoch Time (s): 164.02803310891613')
('Epoch 10', 'Objective: -0.14013740577258904', 'Train Acc: 0.9680666666666666', 'Test Acc: 0.9704', 'Train LL: -0.10230764119687638', 'Test LL: -0.09660278465228637', 'Epoch Time (s): 163.99049593904056')
('Epoch 11', 'Objective: -0.1344780120282133', 'Train Acc: 0.9700166666666666', 'Test Acc: 0.9642', 'Train LL: -0.09726830245318074', 'Test LL: -0.11336684084577724', 'Epoch Time (s): 164.00433147791773')
('Epoch 12', 'Objective: -0.13003129314333162', 'Train Acc: 0.9704', 'Test Acc: 0.9731', 'Train LL: -0.09337508430259785', 'Test LL: -0.08732955808026643', 'Epoch Time (s): 164.0345673491247')
('Epoch 13', 'Objective: -0.1258803994541024', 'Train Acc: 0.9711', 'Test Acc: 0.9743', 'Train LL: -0.08979565471922751', 'Test LL: -0.07661610041390336', 'Epoch Time (s): 164.09504518308677')
('Epoch 14', 'Objective: -0.11936761234387099', 'Train Acc: 0.9736833333333333', 'Test Acc: 0.975', 'Train LL: -0.08417524641774299', 'Test LL: -0.08256133550696793', 'Epoch Time (s): 164.01712208497338')
('Epoch 15', 'Objective: -0.11435773685814508', 'Train Acc: 0.9751333333333333', 'Test Acc: 0.9793', 'Train LL: -0.07960275114507227', 'Test LL: -0.06562856078280954', 'Epoch Time (s): 163.991797470022')
('Epoch 16', 'Objective: -0.11288887067030597', 'Train Acc: 0.9750333333333333', 'Test Acc: 0.979', 'Train LL: -0.07853837293967166', 'Test LL: -0.0685971724167099', 'Epoch Time (s): 164.0360448481515')
('Epoch 17', 'Objective: -0.10999494069074875', 'Train Acc: 0.9754833333333334', 'Test Acc: 0.9862', 'Train LL: -0.07606316803114947', 'Test LL: -0.04636472196523697', 'Epoch Time (s): 164.02201016806066')
('Epoch 18', 'Objective: -0.10840753943890702', 'Train Acc: 0.977', 'Test Acc: 0.9844', 'Train LL: -0.07531213436072764', 'Test LL: -0.051281503226097085', 'Epoch Time (s): 164.1063903949689')
('Epoch 19', 'Objective: -0.10698008937419304', 'Train Acc: 0.9767666666666667', 'Test Acc: 0.975', 'Train LL: -0.07392346033102548', 'Test LL: -0.07389829674522812', 'Epoch Time (s): 164.0149402481038')
('Epoch 20', 'Objective: -0.10414582134159414', 'Train Acc: 0.9776166666666667', 'Test Acc: 0.9784', 'Train LL: -0.07174763084009494', 'Test LL: -0.06687136676897998', 'Epoch Time (s): 164.09056584211066')
('Epoch 21', 'Objective: -0.1024465549166011', 'Train Acc: 0.9778333333333333', 'Test Acc: 0.9766', 'Train LL: -0.07049997137194382', 'Test LL: -0.07290907484676308', 'Epoch Time (s): 164.0349583029747')
('Epoch 22', 'Objective: -0.10008736480327735', 'Train Acc: 0.9787166666666667', 'Test Acc: 0.9794', 'Train LL: -0.06833812829474926', 'Test LL: -0.06560743742753598', 'Epoch Time (s): 164.00885646394454')
('Epoch 23', 'Objective: -0.09692757083018845', 'Train Acc: 0.9795833333333334', 'Test Acc: 0.9793', 'Train LL: -0.06534014400974132', 'Test LL: -0.0664427801654429', 'Epoch Time (s): 164.0630819229409')
('Epoch 24', 'Objective: -0.09619808985156948', 'Train Acc: 0.9795333333333334', 'Test Acc: 0.9784', 'Train LL: -0.06512763793428927', 'Test LL: -0.06477799145586999', 'Epoch Time (s): 163.97463224898092')
('Epoch 25', 'Objective: -0.09337070285250208', 'Train Acc: 0.9799', 'Test Acc: 0.9741', 'Train LL: -0.06275184266611944', 'Test LL: -0.08737968142763111', 'Epoch Time (s): 163.98634254187346')
('Epoch 26', 'Objective: -0.09322063801029852', 'Train Acc: 0.9801833333333333', 'Test Acc: 0.9798', 'Train LL: -0.0627114153297573', 'Test LL: -0.06806161527895759', 'Epoch Time (s): 163.95406645489857')
('Epoch 27', 'Objective: -0.0928697425493437', 'Train Acc: 0.9803', 'Test Acc: 0.9873', 'Train LL: -0.06247641250619909', 'Test LL: -0.037870730241334104', 'Epoch Time (s): 164.0278543611057')
('Epoch 28', 'Objective: -0.09191876502392099', 'Train Acc: 0.9808833333333333', 'Test Acc: 0.9706', 'Train LL: -0.06176425958877246', 'Test LL: -0.08697738640775747', 'Epoch Time (s): 164.0669132929761')
('Epoch 29', 'Objective: -0.09154709288776361', 'Train Acc: 0.98045', 'Test Acc: 0.9844', 'Train LL: -0.06168436301061626', 'Test LL: -0.04800987181745438', 'Epoch Time (s): 164.0720512981061')
('Epoch 30', 'Objective: -0.08819726975414904', 'Train Acc: 0.9815666666666667', 'Test Acc: 0.9784', 'Train LL: -0.058611346287565494', 'Test LL: -0.06424041511501251', 'Epoch Time (s): 164.0727270268835')
('Epoch 31', 'Objective: -0.08703687150450612', 'Train Acc: 0.9816333333333334', 'Test Acc: 0.9855', 'Train LL: -0.05777774399969529', 'Test LL: -0.045033047283080024', 'Epoch Time (s): 164.10764920292422')
('Epoch 32', 'Objective: -0.08548158932017427', 'Train Acc: 0.9824', 'Test Acc: 0.9824', 'Train LL: -0.05636471575921171', 'Test LL: -0.05755747926893879', 'Epoch Time (s): 163.99854249693453')
('Epoch 33', 'Objective: -0.08536080497978693', 'Train Acc: 0.9826', 'Test Acc: 0.982', 'Train LL: -0.0566536586724229', 'Test LL: -0.05782473959387387', 'Epoch Time (s): 164.1099858439993')
('Epoch 34', 'Objective: -0.08308044988709001', 'Train Acc: 0.9829', 'Test Acc: 0.9867', 'Train LL: -0.0543705340513244', 'Test LL: -0.04138713626407224', 'Epoch Time (s): 164.08437289879657')
('Epoch 35', 'Objective: -0.08474249318096058', 'Train Acc: 0.9822833333333333', 'Test Acc: 0.9866', 'Train LL: -0.05623091317369902', 'Test LL: -0.03808382458915527', 'Epoch Time (s): 164.08733552717604')
('Epoch 36', 'Objective: -0.08232142500964285', 'Train Acc: 0.9826333333333334', 'Test Acc: 0.9853', 'Train LL: -0.0538437066263081', 'Test LL: -0.04406184591707925', 'Epoch Time (s): 164.07614553300664')
('Epoch 37', 'Objective: -0.08160179096294953', 'Train Acc: 0.9831', 'Test Acc: 0.9889', 'Train LL: -0.053408330352628944', 'Test LL: -0.03689476520475655', 'Epoch Time (s): 164.09872341807932')
('Epoch 38', 'Objective: -0.07976647580711979', 'Train Acc: 0.9835333333333334', 'Test Acc: 0.9823', 'Train LL: -0.05193649056202582', 'Test LL: -0.055004434101924744', 'Epoch Time (s): 164.044078418985')
('Epoch 39', 'Objective: -0.08036866815047289', 'Train Acc: 0.98295', 'Test Acc: 0.981', 'Train LL: -0.05261469998126882', 'Test LL: -0.06016944859304265', 'Epoch Time (s): 164.02427362184972')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.05976863169623698', 'Train Acc: 0.9890666666666666', 'Test Acc: 0.9904', 'Train LL: -0.03387143599925485', 'Test LL: -0.030565557223391483', 'Epoch Time (s): 163.99385662004352')
('Epoch 41', 'Objective: -0.053704541789374706', 'Train Acc: 0.9906833333333334', 'Test Acc: 0.9899', 'Train LL: -0.028714083712505667', 'Test LL: -0.029503948957109016', 'Epoch Time (s): 164.01272976701148')
('Epoch 42', 'Objective: -0.05214251801682029', 'Train Acc: 0.9912333333333333', 'Test Acc: 0.9901', 'Train LL: -0.027555056352022482', 'Test LL: -0.030299685622584685', 'Epoch Time (s): 164.0114860839676')
('Epoch 43', 'Objective: -0.05105877830245805', 'Train Acc: 0.9910833333333333', 'Test Acc: 0.9902', 'Train LL: -0.026705590488946072', 'Test LL: -0.03057119520710848', 'Epoch Time (s): 164.071243789047')
('Epoch 44', 'Objective: -0.05012024242791627', 'Train Acc: 0.992', 'Test Acc: 0.99', 'Train LL: -0.02610853817688568', 'Test LL: -0.030497524613183963', 'Epoch Time (s): 164.1260736240074')
('Epoch 45', 'Objective: -0.049998471516616586', 'Train Acc: 0.9917666666666667', 'Test Acc: 0.9904', 'Train LL: -0.026101851942814704', 'Test LL: -0.029672469249501558', 'Epoch Time (s): 164.14054788881913')
('Epoch 46', 'Objective: -0.04940560811640167', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9909', 'Train LL: -0.02570371814726196', 'Test LL: -0.027892863158766927', 'Epoch Time (s): 164.06329200183973')
('Epoch 47', 'Objective: -0.04862994723680805', 'Train Acc: 0.99235', 'Test Acc: 0.9905', 'Train LL: -0.025123136878564652', 'Test LL: -0.028520002498216537', 'Epoch Time (s): 164.06736119207926')
('Epoch 48', 'Objective: -0.04834903758497128', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9903', 'Train LL: -0.024863107522741124', 'Test LL: -0.028646559738721874', 'Epoch Time (s): 164.08893358102068')
('Epoch 49', 'Objective: -0.047508030313678486', 'Train Acc: 0.9921', 'Test Acc: 0.9905', 'Train LL: -0.02423782838926236', 'Test LL: -0.0295166069968166', 'Epoch Time (s): 164.10372545011342')
('Epoch 50', 'Objective: -0.04687546160850178', 'Train Acc: 0.99265', 'Test Acc: 0.9911', 'Train LL: -0.023775575798321333', 'Test LL: -0.027229330513200086', 'Epoch Time (s): 164.0752586168237')
('Epoch 51', 'Objective: -0.047266605437287404', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9914', 'Train LL: -0.024234855238093975', 'Test LL: -0.02659093935765439', 'Epoch Time (s): 164.09320433693938')
('Epoch 52', 'Objective: -0.04650426138922065', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9916', 'Train LL: -0.023556283669003596', 'Test LL: -0.026860674868105793', 'Epoch Time (s): 164.0927827868145')
('Epoch 53', 'Objective: -0.04616265916924264', 'Train Acc: 0.9925666666666667', 'Test Acc: 0.9907', 'Train LL: -0.023290716683428296', 'Test LL: -0.029598485695751617', 'Epoch Time (s): 164.09994202386588')
('Epoch 54', 'Objective: -0.04619303460994502', 'Train Acc: 0.99255', 'Test Acc: 0.9895', 'Train LL: -0.02333391387632947', 'Test LL: -0.031658235541253965', 'Epoch Time (s): 164.08924036915414')
('Epoch 55', 'Objective: -0.04522651139295378', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9915', 'Train LL: -0.022467508296215927', 'Test LL: -0.02734819114444515', 'Epoch Time (s): 164.02441667183302')
('Epoch 56', 'Objective: -0.04554427072823322', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.992', 'Train LL: -0.022942948417880013', 'Test LL: -0.02580802198858296', 'Epoch Time (s): 164.06792324897833')
('Epoch 57', 'Objective: -0.04542135560006418', 'Train Acc: 0.99305', 'Test Acc: 0.9903', 'Train LL: -0.022936644969591455', 'Test LL: -0.03148145315422046', 'Epoch Time (s): 164.0202528059017')
('Epoch 58', 'Objective: -0.04430092232393176', 'Train Acc: 0.99285', 'Test Acc: 0.9907', 'Train LL: -0.02194192537271603', 'Test LL: -0.028146298162976', 'Epoch Time (s): 164.0235653349664')
('Epoch 59', 'Objective: -0.04457388554823633', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9921', 'Train LL: -0.022196003563626936', 'Test LL: -0.025131090262696176', 'Epoch Time (s): 163.9867988319602')
('Epoch 60', 'Objective: -0.04437254710691649', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9903', 'Train LL: -0.021993880478376058', 'Test LL: -0.03191050858792686', 'Epoch Time (s): 164.07548673590645')
('Epoch 61', 'Objective: -0.043495653983671674', 'Train Acc: 0.993', 'Test Acc: 0.9901', 'Train LL: -0.021216764689139328', 'Test LL: -0.030786026926117212', 'Epoch Time (s): 164.0625765961595')
('Epoch 62', 'Objective: -0.044329135179245145', 'Train Acc: 0.9928', 'Test Acc: 0.9915', 'Train LL: -0.022067050877023948', 'Test LL: -0.02881600308422734', 'Epoch Time (s): 163.99224048596807')
('Epoch 63', 'Objective: -0.04351807072046669', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9906', 'Train LL: -0.021493646890134173', 'Test LL: -0.02849684153457929', 'Epoch Time (s): 163.95703809685074')
('Epoch 64', 'Objective: -0.04329717149452778', 'Train Acc: 0.99315', 'Test Acc: 0.9892', 'Train LL: -0.021303920997483627', 'Test LL: -0.029843848528268067', 'Epoch Time (s): 164.01624974305741')
('Epoch 65', 'Objective: -0.04397305555974003', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9926', 'Train LL: -0.022010184172158994', 'Test LL: -0.025880464487513098', 'Epoch Time (s): 164.01145753404126')
('Epoch 66', 'Objective: -0.04254636471097895', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9922', 'Train LL: -0.02076610122604328', 'Test LL: -0.025303976604487233', 'Epoch Time (s): 164.08541832398623')
('Epoch 67', 'Objective: -0.04323143443532935', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9894', 'Train LL: -0.02137878518632846', 'Test LL: -0.03173144233772412', 'Epoch Time (s): 164.01948255999014')
('Epoch 68', 'Objective: -0.04322143810544649', 'Train Acc: 0.99305', 'Test Acc: 0.9909', 'Train LL: -0.02152533721107918', 'Test LL: -0.02818679135984119', 'Epoch Time (s): 164.03296759701334')
('Epoch 69', 'Objective: -0.042930084957809735', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.991', 'Train LL: -0.02127130454936445', 'Test LL: -0.026416423072430622', 'Epoch Time (s): 163.99373764102347')
('Epoch 70', 'Objective: -0.04321062435425446', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9918', 'Train LL: -0.021539817864694676', 'Test LL: -0.02577516595038362', 'Epoch Time (s): 164.0873236048501')
('Epoch 71', 'Objective: -0.04221275192079125', 'Train Acc: 0.99345', 'Test Acc: 0.9895', 'Train LL: -0.020696272751081005', 'Test LL: -0.03132087162927207', 'Epoch Time (s): 164.01706481608562')
('Epoch 72', 'Objective: -0.04194144278365138', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9916', 'Train LL: -0.020451218599943477', 'Test LL: -0.02606904324084228', 'Epoch Time (s): 164.08725136797875')
('Epoch 73', 'Objective: -0.04124718461744008', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.9919', 'Train LL: -0.0198137149570378', 'Test LL: -0.026753736940627316', 'Epoch Time (s): 164.07107166806236')
('Epoch 74', 'Objective: -0.04145803631049981', 'Train Acc: 0.9938166666666667', 'Test Acc: 0.9914', 'Train LL: -0.020054538398471374', 'Test LL: -0.028312939457417342', 'Epoch Time (s): 164.09013629611582')
('Epoch 75', 'Objective: -0.04175678261944451', 'Train Acc: 0.9934', 'Test Acc: 0.9902', 'Train LL: -0.020312109405719567', 'Test LL: -0.03170602269959502', 'Epoch Time (s): 164.0946515710093')
('Epoch 76', 'Objective: -0.041082291676999276', 'Train Acc: 0.9936166666666667', 'Test Acc: 0.9901', 'Train LL: -0.019750827121609634', 'Test LL: -0.031375461472586054', 'Epoch Time (s): 164.14966818410903')
('Epoch 77', 'Objective: -0.04164686562268354', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.991', 'Train LL: -0.02032381823095863', 'Test LL: -0.02989150839144722', 'Epoch Time (s): 164.07426306209527')
('Epoch 78', 'Objective: -0.041712080355904534', 'Train Acc: 0.9934333333333333', 'Test Acc: 0.9908', 'Train LL: -0.020447448204976484', 'Test LL: -0.029548726919491862', 'Epoch Time (s): 164.1314985069912')
('Epoch 79', 'Objective: -0.04103354816249456', 'Train Acc: 0.9937166666666667', 'Test Acc: 0.9896', 'Train LL: -0.01982913136248985', 'Test LL: -0.031145300433803185', 'Epoch Time (s): 164.12449380615726')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.038363719902699045', 'Train Acc: 0.99435', 'Test Acc: 0.9919', 'Train LL: -0.017390716499910665', 'Test LL: -0.026365839707427913', 'Epoch Time (s): 164.10302484896965')
('Epoch 81', 'Objective: -0.03829080974463617', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.9915', 'Train LL: -0.017412253947874025', 'Test LL: -0.026028746766048806', 'Epoch Time (s): 164.00326845305972')
('Epoch 82', 'Objective: -0.03815942789950378', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9914', 'Train LL: -0.017294054652826837', 'Test LL: -0.02604186606442329', 'Epoch Time (s): 164.0944307888858')
('Epoch 83', 'Objective: -0.03779397645059073', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9914', 'Train LL: -0.016924631148687523', 'Test LL: -0.025714337084971818', 'Epoch Time (s): 164.05326532083564')
('Epoch 84', 'Objective: -0.03747933286666933', 'Train Acc: 0.9946166666666667', 'Test Acc: 0.9914', 'Train LL: -0.016611637493663768', 'Test LL: -0.025487160273511576', 'Epoch Time (s): 164.12865401199088')
('Epoch 85', 'Objective: -0.03725815354838979', 'Train Acc: 0.995', 'Test Acc: 0.9914', 'Train LL: -0.0164725900260946', 'Test LL: -0.02582536729240321', 'Epoch Time (s): 164.0484828609042')
('Epoch 86', 'Objective: -0.037021828738325796', 'Train Acc: 0.9949833333333333', 'Test Acc: 0.9918', 'Train LL: -0.016237111948761724', 'Test LL: -0.025338358166724653', 'Epoch Time (s): 164.0272165921051')
('Epoch 87', 'Objective: -0.0372891440732165', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9914', 'Train LL: -0.01646109198214618', 'Test LL: -0.02616320860031923', 'Epoch Time (s): 164.01409454201348')
('Epoch 88', 'Objective: -0.03724073409342996', 'Train Acc: 0.99495', 'Test Acc: 0.9916', 'Train LL: -0.0164119492448387', 'Test LL: -0.025662487997495213', 'Epoch Time (s): 164.07564121601172')
('Epoch 89', 'Objective: -0.036850762800745396', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9907', 'Train LL: -0.016020003567949578', 'Test LL: -0.027688911661009865', 'Epoch Time (s): 164.0730575809721')
('Epoch 90', 'Objective: -0.03709262434346918', 'Train Acc: 0.9947', 'Test Acc: 0.9914', 'Train LL: -0.016245630553018694', 'Test LL: -0.025741934583897876', 'Epoch Time (s): 164.00405002594925')
('Epoch 91', 'Objective: -0.03662493328108664', 'Train Acc: 0.9951166666666666', 'Test Acc: 0.9914', 'Train LL: -0.015855765988373825', 'Test LL: -0.026182675453655865', 'Epoch Time (s): 164.00452033802867')
('Epoch 92', 'Objective: -0.037280043532651005', 'Train Acc: 0.9949', 'Test Acc: 0.9914', 'Train LL: -0.01647548007117772', 'Test LL: -0.02589456507255486', 'Epoch Time (s): 164.05933270510286')
('Epoch 93', 'Objective: -0.03659600861811176', 'Train Acc: 0.9950333333333333', 'Test Acc: 0.9916', 'Train LL: -0.015851312065757985', 'Test LL: -0.026030159397073635', 'Epoch Time (s): 164.07048800890334')
('Epoch 94', 'Objective: -0.03696103063258002', 'Train Acc: 0.9949', 'Test Acc: 0.9915', 'Train LL: -0.016182484391851156', 'Test LL: -0.026080097258193876', 'Epoch Time (s): 164.1169506229926')
('Epoch 95', 'Objective: -0.036709040555160166', 'Train Acc: 0.9952166666666666', 'Test Acc: 0.9918', 'Train LL: -0.015930277275782386', 'Test LL: -0.025887639161078', 'Epoch Time (s): 164.1289306038525')
('Epoch 96', 'Objective: -0.03677671821210034', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9914', 'Train LL: -0.015986715325718447', 'Test LL: -0.02640229054594754', 'Epoch Time (s): 163.95008971495554')
('Epoch 97', 'Objective: -0.03670641017685123', 'Train Acc: 0.9947666666666667', 'Test Acc: 0.9913', 'Train LL: -0.015910386233446927', 'Test LL: -0.026132728008905776', 'Epoch Time (s): 163.90063562593423')
('Epoch 98', 'Objective: -0.03639913593836744', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.9913', 'Train LL: -0.015646773906432442', 'Test LL: -0.026200361698689414', 'Epoch Time (s): 164.0138147159014')
('Epoch 99', 'Objective: -0.0365980634072344', 'Train Acc: 0.9951', 'Test Acc: 0.9913', 'Train LL: -0.015833426573128317', 'Test LL: -0.026037103995502776', 'Epoch Time (s): 163.9671751940623')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03647520752398527
Final Train Accuracy: £0.9949333333333333
Final Train LL: £-0.01569222051165149
Final Test Accuracy: £0.9915
Final Test LL: £-0.026090288030238627
