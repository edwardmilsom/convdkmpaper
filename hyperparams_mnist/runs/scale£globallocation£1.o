dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: location
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.443150814046977', 'Train Acc: 0.48101666666666665', 'Test Acc: 0.8088', 'Train LL: -1.3999797960437959', 'Test LL: -0.576560910079005', 'Epoch Time (s): 164.21159578417428')
('Epoch 1', 'Objective: -0.5573842444271625', 'Train Acc: 0.8265166666666667', 'Test Acc: 0.9063', 'Train LL: -0.5109738984012414', 'Test LL: -0.30292486345791725', 'Epoch Time (s): 164.6550097791478')
('Epoch 2', 'Objective: -0.326523364615865', 'Train Acc: 0.9107', 'Test Acc: 0.9479', 'Train LL: -0.2811634426273878', 'Test LL: -0.1649870223022855', 'Epoch Time (s): 164.17429593997076')
('Epoch 3', 'Objective: -0.25924396767171465', 'Train Acc: 0.9318333333333333', 'Test Acc: 0.9392', 'Train LL: -0.21687640860047527', 'Test LL: -0.1911024865295129', 'Epoch Time (s): 164.4480922902003')
('Epoch 4', 'Objective: -0.2277943886485293', 'Train Acc: 0.9433166666666667', 'Test Acc: 0.945', 'Train LL: -0.18762270492525548', 'Test LL: -0.16681083812568373', 'Epoch Time (s): 164.22164565394633')
('Epoch 5', 'Objective: -0.20286962497329622', 'Train Acc: 0.9486', 'Test Acc: 0.9521', 'Train LL: -0.16364645177164627', 'Test LL: -0.14768440313401074', 'Epoch Time (s): 164.39917606394738')
('Epoch 6', 'Objective: -0.18744277438005497', 'Train Acc: 0.9538666666666666', 'Test Acc: 0.9487', 'Train LL: -0.14892837047973795', 'Test LL: -0.15391009576009818', 'Epoch Time (s): 164.34030476794578')
('Epoch 7', 'Objective: -0.16992966755774624', 'Train Acc: 0.9594333333333334', 'Test Acc: 0.9723', 'Train LL: -0.13247565506659903', 'Test LL: -0.09309451687179966', 'Epoch Time (s): 164.2585299720522')
('Epoch 8', 'Objective: -0.16191326256288477', 'Train Acc: 0.96055', 'Test Acc: 0.969', 'Train LL: -0.1252488673010512', 'Test LL: -0.09535462806362593', 'Epoch Time (s): 164.08799866680056')
('Epoch 9', 'Objective: -0.1552109280940729', 'Train Acc: 0.963', 'Test Acc: 0.963', 'Train LL: -0.11897088447125792', 'Test LL: -0.11317255806994396', 'Epoch Time (s): 164.37249338417314')
('Epoch 10', 'Objective: -0.1464724734419347', 'Train Acc: 0.9644', 'Test Acc: 0.9805', 'Train LL: -0.11115404217155679', 'Test LL: -0.05985013915726174', 'Epoch Time (s): 164.1887042489834')
('Epoch 11', 'Objective: -0.13845951312421242', 'Train Acc: 0.9667166666666667', 'Test Acc: 0.9767', 'Train LL: -0.10349146089195077', 'Test LL: -0.07639975162839595', 'Epoch Time (s): 164.34692455106415')
('Epoch 12', 'Objective: -0.13522082973423974', 'Train Acc: 0.9689', 'Test Acc: 0.9739', 'Train LL: -0.10078902876182279', 'Test LL: -0.08293148448886999', 'Epoch Time (s): 164.35282377013937')
('Epoch 13', 'Objective: -0.1311634711791897', 'Train Acc: 0.9703', 'Test Acc: 0.9759', 'Train LL: -0.09717778355607007', 'Test LL: -0.07544203429605041', 'Epoch Time (s): 164.34590014000423')
('Epoch 14', 'Objective: -0.1268816890644728', 'Train Acc: 0.9705333333333334', 'Test Acc: 0.9719', 'Train LL: -0.09294132986488028', 'Test LL: -0.09089943015639601', 'Epoch Time (s): 164.28609871002845')
('Epoch 15', 'Objective: -0.12371192609696506', 'Train Acc: 0.9716', 'Test Acc: 0.9773', 'Train LL: -0.09029132661433317', 'Test LL: -0.07082713269086273', 'Epoch Time (s): 164.33383657992817')
('Epoch 16', 'Objective: -0.11969828507718167', 'Train Acc: 0.9724', 'Test Acc: 0.9774', 'Train LL: -0.08639032389183257', 'Test LL: -0.06917967719407205', 'Epoch Time (s): 164.34173939516768')
('Epoch 17', 'Objective: -0.11713975210570483', 'Train Acc: 0.9728833333333333', 'Test Acc: 0.9748', 'Train LL: -0.08409460473330388', 'Test LL: -0.08571842745634782', 'Epoch Time (s): 164.36406412511133')
('Epoch 18', 'Objective: -0.116376481377547', 'Train Acc: 0.9733666666666667', 'Test Acc: 0.9786', 'Train LL: -0.08362441786219652', 'Test LL: -0.0634945320248359', 'Epoch Time (s): 164.3484527701512')
('Epoch 19', 'Objective: -0.11101530044253632', 'Train Acc: 0.9756', 'Test Acc: 0.977', 'Train LL: -0.07857562704040302', 'Test LL: -0.07057727706976702', 'Epoch Time (s): 164.38230173592456')
('Epoch 20', 'Objective: -0.10951008498595473', 'Train Acc: 0.9754833333333334', 'Test Acc: 0.975', 'Train LL: -0.07754279386317754', 'Test LL: -0.07858191314547155', 'Epoch Time (s): 164.37792049883865')
('Epoch 21', 'Objective: -0.10938094834443296', 'Train Acc: 0.9759', 'Test Acc: 0.9761', 'Train LL: -0.07780914555679795', 'Test LL: -0.07075517666203598', 'Epoch Time (s): 164.33821096993051')
('Epoch 22', 'Objective: -0.1068992856022306', 'Train Acc: 0.9764', 'Test Acc: 0.9843', 'Train LL: -0.07548353235926447', 'Test LL: -0.05110671134876071', 'Epoch Time (s): 164.3236032158602')
('Epoch 23', 'Objective: -0.10308598243308827', 'Train Acc: 0.9771', 'Test Acc: 0.9733', 'Train LL: -0.07184967060110936', 'Test LL: -0.08108550189817594', 'Epoch Time (s): 164.29703044192865')
('Epoch 24', 'Objective: -0.10278658044824739', 'Train Acc: 0.97695', 'Test Acc: 0.9779', 'Train LL: -0.07172875333282358', 'Test LL: -0.0655845298626858', 'Epoch Time (s): 164.3770820091013')
('Epoch 25', 'Objective: -0.10237087892592969', 'Train Acc: 0.9775833333333334', 'Test Acc: 0.983', 'Train LL: -0.0714364209063093', 'Test LL: -0.050253577273607894', 'Epoch Time (s): 164.31104269996285')
('Epoch 26', 'Objective: -0.09972428178665188', 'Train Acc: 0.9783166666666666', 'Test Acc: 0.9816', 'Train LL: -0.06913757817860636', 'Test LL: -0.05713921792383846', 'Epoch Time (s): 164.28801686502993')
('Epoch 27', 'Objective: -0.09704523920911201', 'Train Acc: 0.9787833333333333', 'Test Acc: 0.9778', 'Train LL: -0.06653634022404517', 'Test LL: -0.06208549469437039', 'Epoch Time (s): 164.3923010849394')
('Epoch 28', 'Objective: -0.09666388402348453', 'Train Acc: 0.9785666666666667', 'Test Acc: 0.9784', 'Train LL: -0.06636054571827067', 'Test LL: -0.06383811609626129', 'Epoch Time (s): 164.34279729798436')
('Epoch 29', 'Objective: -0.09594333021232167', 'Train Acc: 0.97905', 'Test Acc: 0.9744', 'Train LL: -0.06564326846865948', 'Test LL: -0.07558951113713425', 'Epoch Time (s): 164.3037562048994')
('Epoch 30', 'Objective: -0.09373864601946713', 'Train Acc: 0.9797833333333333', 'Test Acc: 0.9836', 'Train LL: -0.06382564530299165', 'Test LL: -0.05047552075691563', 'Epoch Time (s): 164.38493137806654')
('Epoch 31', 'Objective: -0.09291741678559819', 'Train Acc: 0.9802', 'Test Acc: 0.986', 'Train LL: -0.06326360051809822', 'Test LL: -0.04786111576232082', 'Epoch Time (s): 164.51746780914254')
('Epoch 32', 'Objective: -0.09210230977677997', 'Train Acc: 0.9796333333333334', 'Test Acc: 0.9829', 'Train LL: -0.0625927528851737', 'Test LL: -0.05316442030997842', 'Epoch Time (s): 164.2666271009948')
('Epoch 33', 'Objective: -0.0914704392109942', 'Train Acc: 0.9803', 'Test Acc: 0.9833', 'Train LL: -0.06209611340127935', 'Test LL: -0.050681697068913824', 'Epoch Time (s): 164.89785818802193')
('Epoch 34', 'Objective: -0.08970687370652324', 'Train Acc: 0.98065', 'Test Acc: 0.9772', 'Train LL: -0.06058205000089257', 'Test LL: -0.06609525798725856', 'Epoch Time (s): 164.86729148193263')
('Epoch 35', 'Objective: -0.08902576296066586', 'Train Acc: 0.98135', 'Test Acc: 0.9876', 'Train LL: -0.06006511394668503', 'Test LL: -0.03983712019050009', 'Epoch Time (s): 164.88654193212278')
('Epoch 36', 'Objective: -0.08760880575070144', 'Train Acc: 0.9808666666666667', 'Test Acc: 0.9814', 'Train LL: -0.05856088070655998', 'Test LL: -0.0552331190147208', 'Epoch Time (s): 164.8394606441725')
('Epoch 37', 'Objective: -0.08785956188900992', 'Train Acc: 0.98075', 'Test Acc: 0.979', 'Train LL: -0.05883051148904959', 'Test LL: -0.06445947471930161', 'Epoch Time (s): 164.28054941399023')
('Epoch 38', 'Objective: -0.08530254157868243', 'Train Acc: 0.9822333333333333', 'Test Acc: 0.9852', 'Train LL: -0.05654967727615514', 'Test LL: -0.04283922994123923', 'Epoch Time (s): 164.15702287806198')
('Epoch 39', 'Objective: -0.0858311795709055', 'Train Acc: 0.9828666666666667', 'Test Acc: 0.9847', 'Train LL: -0.05710246081696995', 'Test LL: -0.04406983229572133', 'Epoch Time (s): 164.18915853905492')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06401450356723452', 'Train Acc: 0.9881833333333333', 'Test Acc: 0.9897', 'Train LL: -0.037111552119954004', 'Test LL: -0.03111537387021488', 'Epoch Time (s): 164.1861407919787')
('Epoch 41', 'Objective: -0.05834533907491034', 'Train Acc: 0.98985', 'Test Acc: 0.9897', 'Train LL: -0.03242145516951291', 'Test LL: -0.031282662633994346', 'Epoch Time (s): 164.23538787593134')
('Epoch 42', 'Objective: -0.056413595378116486', 'Train Acc: 0.9902', 'Test Acc: 0.9898', 'Train LL: -0.030989187490598608', 'Test LL: -0.030350497117574298', 'Epoch Time (s): 164.23654104792513')
('Epoch 43', 'Objective: -0.05484121340961655', 'Train Acc: 0.9908833333333333', 'Test Acc: 0.9891', 'Train LL: -0.029799415841647647', 'Test LL: -0.032103586491651515', 'Epoch Time (s): 164.25536125083454')
('Epoch 44', 'Objective: -0.05310553881751109', 'Train Acc: 0.9911166666666666', 'Test Acc: 0.9897', 'Train LL: -0.028296034365322034', 'Test LL: -0.03045912925592845', 'Epoch Time (s): 164.28606248483993')
('Epoch 45', 'Objective: -0.05291141365813222', 'Train Acc: 0.9908', 'Test Acc: 0.988', 'Train LL: -0.028251585057040333', 'Test LL: -0.03339759444172165', 'Epoch Time (s): 164.24986062105745')
('Epoch 46', 'Objective: -0.05307196006638144', 'Train Acc: 0.9910166666666667', 'Test Acc: 0.9887', 'Train LL: -0.028517383571338616', 'Test LL: -0.03190516835383099', 'Epoch Time (s): 164.2297316440381')
('Epoch 47', 'Objective: -0.051685972457324536', 'Train Acc: 0.9917166666666667', 'Test Acc: 0.9883', 'Train LL: -0.0272389036669815', 'Test LL: -0.03336396056491998', 'Epoch Time (s): 164.235295885941')
('Epoch 48', 'Objective: -0.051587235006695036', 'Train Acc: 0.9912666666666666', 'Test Acc: 0.9893', 'Train LL: -0.02736713493201082', 'Test LL: -0.030487796207563214', 'Epoch Time (s): 164.28679161611944')
('Epoch 49', 'Objective: -0.051427372020132645', 'Train Acc: 0.9914333333333334', 'Test Acc: 0.99', 'Train LL: -0.02731863667325379', 'Test LL: -0.03250874639736875', 'Epoch Time (s): 164.24283276498318')
('Epoch 50', 'Objective: -0.05116229063510708', 'Train Acc: 0.9913666666666666', 'Test Acc: 0.9904', 'Train LL: -0.02704371074233119', 'Test LL: -0.027949262337297404', 'Epoch Time (s): 164.293769601034')
('Epoch 51', 'Objective: -0.05006699406713198', 'Train Acc: 0.99155', 'Test Acc: 0.989', 'Train LL: -0.026146910574197674', 'Test LL: -0.03039519067367475', 'Epoch Time (s): 164.22185173304752')
('Epoch 52', 'Objective: -0.04998999504400053', 'Train Acc: 0.99165', 'Test Acc: 0.9882', 'Train LL: -0.026158971277766802', 'Test LL: -0.034506559010400895', 'Epoch Time (s): 164.24649275210686')
('Epoch 53', 'Objective: -0.049987072505921146', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9895', 'Train LL: -0.02614506924591231', 'Test LL: -0.029973184638707902', 'Epoch Time (s): 164.28330067708157')
('Epoch 54', 'Objective: -0.0494627214293487', 'Train Acc: 0.99165', 'Test Acc: 0.9897', 'Train LL: -0.025799185195217757', 'Test LL: -0.028702085762832785', 'Epoch Time (s): 164.2135224340018')
('Epoch 55', 'Objective: -0.04923956653797106', 'Train Acc: 0.9918', 'Test Acc: 0.9895', 'Train LL: -0.025643922138907402', 'Test LL: -0.02993636213301703', 'Epoch Time (s): 164.20354440808296')
('Epoch 56', 'Objective: -0.048813574508919946', 'Train Acc: 0.9919', 'Test Acc: 0.988', 'Train LL: -0.025293576928304806', 'Test LL: -0.03308589051271208', 'Epoch Time (s): 164.23231245111674')
('Epoch 57', 'Objective: -0.04963590919096145', 'Train Acc: 0.9915166666666667', 'Test Acc: 0.9899', 'Train LL: -0.026171801636719057', 'Test LL: -0.030454739952756302', 'Epoch Time (s): 164.2063601030968')
('Epoch 58', 'Objective: -0.04852874826646572', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.9895', 'Train LL: -0.025126045809225592', 'Test LL: -0.03200212798903207', 'Epoch Time (s): 164.18549316190183')
('Epoch 59', 'Objective: -0.04823302115827327', 'Train Acc: 0.9919', 'Test Acc: 0.9888', 'Train LL: -0.02493828804420514', 'Test LL: -0.032421853609514176', 'Epoch Time (s): 164.33494540699758')
('Epoch 60', 'Objective: -0.04892956655017623', 'Train Acc: 0.99215', 'Test Acc: 0.9892', 'Train LL: -0.025759758585696735', 'Test LL: -0.031701897117277306', 'Epoch Time (s): 164.35682410909794')
('Epoch 61', 'Objective: -0.0476389583380852', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.9886', 'Train LL: -0.024465481403717328', 'Test LL: -0.0332397335431128', 'Epoch Time (s): 164.39117917604744')
('Epoch 62', 'Objective: -0.04729456151172352', 'Train Acc: 0.9920666666666667', 'Test Acc: 0.9876', 'Train LL: -0.024093783135881532', 'Test LL: -0.03560929821013856', 'Epoch Time (s): 164.3930219959002')
('Epoch 63', 'Objective: -0.04775814323185005', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9886', 'Train LL: -0.02456857819276335', 'Test LL: -0.03140676077365074', 'Epoch Time (s): 164.36755510699004')
('Epoch 64', 'Objective: -0.04662814309994851', 'Train Acc: 0.99245', 'Test Acc: 0.989', 'Train LL: -0.023644606554528717', 'Test LL: -0.031538234895116424', 'Epoch Time (s): 164.4234659471549')
('Epoch 65', 'Objective: -0.047588432514795116', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.9897', 'Train LL: -0.024628633142571243', 'Test LL: -0.02900267601728554', 'Epoch Time (s): 164.42145344708115')
('Epoch 66', 'Objective: -0.04676425824965', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9888', 'Train LL: -0.023739163129430425', 'Test LL: -0.03311748368819753', 'Epoch Time (s): 164.46174579812214')
('Epoch 67', 'Objective: -0.04651330990211131', 'Train Acc: 0.99245', 'Test Acc: 0.9896', 'Train LL: -0.02366041727548773', 'Test LL: -0.030741747547596128', 'Epoch Time (s): 164.37678462802432')
('Epoch 68', 'Objective: -0.04741357133260889', 'Train Acc: 0.9921833333333333', 'Test Acc: 0.9896', 'Train LL: -0.02454991294380791', 'Test LL: -0.03086103641675861', 'Epoch Time (s): 164.38228360703215')
('Epoch 69', 'Objective: -0.04606097357473682', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.988', 'Train LL: -0.023250934772191933', 'Test LL: -0.03279069848503094', 'Epoch Time (s): 164.29290882498026')
('Epoch 70', 'Objective: -0.046331433710685044', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9904', 'Train LL: -0.023615226803671945', 'Test LL: -0.027436008357481723', 'Epoch Time (s): 164.2057416238822')
('Epoch 71', 'Objective: -0.04629184387867338', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9894', 'Train LL: -0.023539609856572778', 'Test LL: -0.030126224085144128', 'Epoch Time (s): 164.23559450590983')
('Epoch 72', 'Objective: -0.04592615049527426', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9884', 'Train LL: -0.023269390511589147', 'Test LL: -0.032822467942161294', 'Epoch Time (s): 164.2083254889585')
('Epoch 73', 'Objective: -0.045829950383550484', 'Train Acc: 0.99255', 'Test Acc: 0.9889', 'Train LL: -0.023139731528665015', 'Test LL: -0.031606641512384986', 'Epoch Time (s): 164.4158858919982')
('Epoch 74', 'Objective: -0.04615835191913319', 'Train Acc: 0.99225', 'Test Acc: 0.9894', 'Train LL: -0.023469454861758395', 'Test LL: -0.030381079414199222', 'Epoch Time (s): 164.26129981293343')
('Epoch 75', 'Objective: -0.044744771067733426', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9888', 'Train LL: -0.022262212918220295', 'Test LL: -0.03172791818812218', 'Epoch Time (s): 164.47115429793485')
('Epoch 76', 'Objective: -0.04581574597024462', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9891', 'Train LL: -0.02325306076107393', 'Test LL: -0.03189946772472584', 'Epoch Time (s): 164.45823544310406')
('Epoch 77', 'Objective: -0.04543808329174415', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9898', 'Train LL: -0.02289118639620311', 'Test LL: -0.031384807840965', 'Epoch Time (s): 164.43945843004622')
('Epoch 78', 'Objective: -0.04593526824574157', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.9902', 'Train LL: -0.023471477301835686', 'Test LL: -0.029655853372330915', 'Epoch Time (s): 164.48002880509011')
('Epoch 79', 'Objective: -0.04471070877306901', 'Train Acc: 0.99305', 'Test Acc: 0.9898', 'Train LL: -0.022326226731674583', 'Test LL: -0.031004210739308712', 'Epoch Time (s): 164.4510968059767')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04245640387766733', 'Train Acc: 0.99365', 'Test Acc: 0.9901', 'Train LL: -0.02027667396741928', 'Test LL: -0.029805859280731976', 'Epoch Time (s): 164.46785584790632')
('Epoch 81', 'Objective: -0.041995780726119133', 'Train Acc: 0.9936166666666667', 'Test Acc: 0.991', 'Train LL: -0.019866590649138517', 'Test LL: -0.027877917915653985', 'Epoch Time (s): 164.44257474178448')
('Epoch 82', 'Objective: -0.04185719573519265', 'Train Acc: 0.9938', 'Test Acc: 0.9909', 'Train LL: -0.019741900722328752', 'Test LL: -0.027755403101414073', 'Epoch Time (s): 164.44553800392896')
('Epoch 83', 'Objective: -0.04157995408086285', 'Train Acc: 0.9939666666666667', 'Test Acc: 0.9905', 'Train LL: -0.019559699572488706', 'Test LL: -0.028879002279169914', 'Epoch Time (s): 164.4357857562136')
('Epoch 84', 'Objective: -0.04194329968311533', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.9906', 'Train LL: -0.019850335194449828', 'Test LL: -0.028969772643520377', 'Epoch Time (s): 164.31841357494704')
('Epoch 85', 'Objective: -0.04158099198037455', 'Train Acc: 0.99365', 'Test Acc: 0.9897', 'Train LL: -0.019516454763893912', 'Test LL: -0.029721964726929728', 'Epoch Time (s): 164.23695958196186')
('Epoch 86', 'Objective: -0.041423458553426724', 'Train Acc: 0.9937666666666667', 'Test Acc: 0.9903', 'Train LL: -0.01935591166794626', 'Test LL: -0.02892044957677059', 'Epoch Time (s): 164.25549403904006')
('Epoch 87', 'Objective: -0.04159520233517727', 'Train Acc: 0.99375', 'Test Acc: 0.9902', 'Train LL: -0.019544419369622146', 'Test LL: -0.028748563284915367', 'Epoch Time (s): 164.1628323099576')
('Epoch 88', 'Objective: -0.040607641203928714', 'Train Acc: 0.9939166666666667', 'Test Acc: 0.9905', 'Train LL: -0.018653801710853877', 'Test LL: -0.028297441169033367', 'Epoch Time (s): 164.12053207703866')
('Epoch 89', 'Objective: -0.04090116150787399', 'Train Acc: 0.99415', 'Test Acc: 0.9895', 'Train LL: -0.0188848593034771', 'Test LL: -0.030302456357286657', 'Epoch Time (s): 164.2326801470481')
('Epoch 90', 'Objective: -0.04092101605042227', 'Train Acc: 0.99405', 'Test Acc: 0.9902', 'Train LL: -0.018914957164856548', 'Test LL: -0.029253892138620792', 'Epoch Time (s): 164.13901355094276')
('Epoch 91', 'Objective: -0.041160306385232784', 'Train Acc: 0.99395', 'Test Acc: 0.9903', 'Train LL: -0.01911140921722309', 'Test LL: -0.028995971764139903', 'Epoch Time (s): 164.10734804091044')
('Epoch 92', 'Objective: -0.04098099793473817', 'Train Acc: 0.994', 'Test Acc: 0.9903', 'Train LL: -0.0189686384099543', 'Test LL: -0.028502480908157223', 'Epoch Time (s): 164.03377436008304')
('Epoch 93', 'Objective: -0.04160488979265669', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.99', 'Train LL: -0.019556891354522956', 'Test LL: -0.030024278067368737', 'Epoch Time (s): 164.0089914749842')
('Epoch 94', 'Objective: -0.041272494727038235', 'Train Acc: 0.99385', 'Test Acc: 0.9898', 'Train LL: -0.019234260124314506', 'Test LL: -0.02960316206056715', 'Epoch Time (s): 163.9987852529157')
('Epoch 95', 'Objective: -0.040974122329787', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9906', 'Train LL: -0.019006708557030835', 'Test LL: -0.028949291106970993', 'Epoch Time (s): 164.04411066812463')
('Epoch 96', 'Objective: -0.04014848558517058', 'Train Acc: 0.99415', 'Test Acc: 0.9901', 'Train LL: -0.01821654634448755', 'Test LL: -0.028819583106842298', 'Epoch Time (s): 164.1684316659812')
('Epoch 97', 'Objective: -0.04107280185200879', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9904', 'Train LL: -0.019035235517907024', 'Test LL: -0.028675921814428743', 'Epoch Time (s): 164.0942258471623')
('Epoch 98', 'Objective: -0.03979369420484445', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.99', 'Train LL: -0.017912002652426765', 'Test LL: -0.030360275075156675', 'Epoch Time (s): 164.09421136509627')
('Epoch 99', 'Objective: -0.040961820858536925', 'Train Acc: 0.99425', 'Test Acc: 0.9903', 'Train LL: -0.01895369243095397', 'Test LL: -0.029345636167913466', 'Epoch Time (s): 164.25511028897017')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04027988671985244
Final Train Accuracy: £0.9944
Final Train LL: £-0.018338572043164945
Final Test Accuracy: £0.9902
Final Test LL: £-0.029494953987292103
