dataset: MNIST
dtype: float64
dof: 100.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.7953847843178894', 'Train Acc: 0.40298333333333336', 'Test Acc: 0.6356', 'Train LL: -1.635752771017097', 'Test LL: -1.0989878238315849', 'Epoch Time (s): 172.36796615319327')
('Epoch 1', 'Objective: -1.1450304946201184', 'Train Acc: 0.6756', 'Test Acc: 0.672', 'Train LL: -0.9382680545461306', 'Test LL: -0.9471654800505747', 'Epoch Time (s): 171.32336912304163')
('Epoch 2', 'Objective: -0.8414689844005946', 'Train Acc: 0.7809833333333334', 'Test Acc: 0.8002', 'Train LL: -0.6410083541940697', 'Test LL: -0.6110605911992275', 'Epoch Time (s): 171.32316517923027')
('Epoch 3', 'Objective: -0.7322903082585714', 'Train Acc: 0.8265833333333333', 'Test Acc: 0.8336', 'Train LL: -0.5288434987804678', 'Test LL: -0.5084512874517156', 'Epoch Time (s): 171.3396504279226')
('Epoch 4', 'Objective: -0.6627293855281642', 'Train Acc: 0.8517333333333333', 'Test Acc: 0.8461', 'Train LL: -0.45852413393882635', 'Test LL: -0.4594471800018737', 'Epoch Time (s): 171.32485160883516')
('Epoch 5', 'Objective: -0.6135845472216168', 'Train Acc: 0.8662333333333333', 'Test Acc: 0.8614', 'Train LL: -0.413095204214074', 'Test LL: -0.4325287165412154', 'Epoch Time (s): 171.29328498104587')
('Epoch 6', 'Objective: -0.5747977455055095', 'Train Acc: 0.8820333333333333', 'Test Acc: 0.8743', 'Train LL: -0.3758592746496766', 'Test LL: -0.39290035817219887', 'Epoch Time (s): 171.27166670700535')
('Epoch 7', 'Objective: -0.5456114888736533', 'Train Acc: 0.8881166666666667', 'Test Acc: 0.8993', 'Train LL: -0.34738982508361077', 'Test LL: -0.31972300509923973', 'Epoch Time (s): 171.3165714563802')
('Epoch 8', 'Objective: -0.5154367828103615', 'Train Acc: 0.9003333333333333', 'Test Acc: 0.8914', 'Train LL: -0.31890853819165094', 'Test LL: -0.34050710183872335', 'Epoch Time (s): 171.30284227943048')
('Epoch 9', 'Objective: -0.5023872062800611', 'Train Acc: 0.9028166666666667', 'Test Acc: 0.9126', 'Train LL: -0.3080143891520637', 'Test LL: -0.2707115312727844', 'Epoch Time (s): 171.287662695162')
('Epoch 10', 'Objective: -0.47927802094617794', 'Train Acc: 0.9103333333333333', 'Test Acc: 0.912', 'Train LL: -0.2890677550335701', 'Test LL: -0.2826605836987005', 'Epoch Time (s): 171.29980883700773')
('Epoch 11', 'Objective: -0.4608238644383098', 'Train Acc: 0.9148166666666666', 'Test Acc: 0.9137', 'Train LL: -0.27521316408477886', 'Test LL: -0.27217880143105033', 'Epoch Time (s): 171.2969890376553')
('Epoch 12', 'Objective: -0.444412682357371', 'Train Acc: 0.9181', 'Test Acc: 0.927', 'Train LL: -0.26323459234817626', 'Test LL: -0.23621663170849047', 'Epoch Time (s): 171.3512094737962')
('Epoch 13', 'Objective: -0.43696148863189666', 'Train Acc: 0.9209', 'Test Acc: 0.9231', 'Train LL: -0.25682904304236737', 'Test LL: -0.25616819138259306', 'Epoch Time (s): 171.31016719527543')
('Epoch 14', 'Objective: -0.42547795978179004', 'Train Acc: 0.9242166666666667', 'Test Acc: 0.9363', 'Train LL: -0.24759601110431673', 'Test LL: -0.21304427237508167', 'Epoch Time (s): 171.33296861499548')
('Epoch 15', 'Objective: -0.4168685495750042', 'Train Acc: 0.9278333333333333', 'Test Acc: 0.9307', 'Train LL: -0.2388495521941484', 'Test LL: -0.23206276053842612', 'Epoch Time (s): 171.28759916173294')
('Epoch 16', 'Objective: -0.40688088316667265', 'Train Acc: 0.9296666666666666', 'Test Acc: 0.93', 'Train LL: -0.22852227230565755', 'Test LL: -0.22915995198416866', 'Epoch Time (s): 171.33942128391936')
('Epoch 17', 'Objective: -0.4014625234683551', 'Train Acc: 0.9311', 'Test Acc: 0.9448', 'Train LL: -0.22446779559188818', 'Test LL: -0.18502412536431087', 'Epoch Time (s): 171.33469750685617')
('Epoch 18', 'Objective: -0.39795764114908816', 'Train Acc: 0.9325', 'Test Acc: 0.9152', 'Train LL: -0.22091475676206548', 'Test LL: -0.26305938128846285', 'Epoch Time (s): 171.35734577989206')
('Epoch 19', 'Objective: -0.3907754908632171', 'Train Acc: 0.9356166666666667', 'Test Acc: 0.9416', 'Train LL: -0.21361903023595055', 'Test LL: -0.18729580764931522', 'Epoch Time (s): 171.28063915111125')
('Epoch 20', 'Objective: -0.38465293279025614', 'Train Acc: 0.9372333333333334', 'Test Acc: 0.9383', 'Train LL: -0.2083169053324994', 'Test LL: -0.19618679890057455', 'Epoch Time (s): 171.29876942140982')
('Epoch 21', 'Objective: -0.3803285111489385', 'Train Acc: 0.9371', 'Test Acc: 0.9492', 'Train LL: -0.20446555061630553', 'Test LL: -0.16554946441826915', 'Epoch Time (s): 171.28568254085258')
('Epoch 22', 'Objective: -0.37859926792994464', 'Train Acc: 0.9386666666666666', 'Test Acc: 0.9342', 'Train LL: -0.2028065501080783', 'Test LL: -0.20684748451072496', 'Epoch Time (s): 171.308195900172')
('Epoch 23', 'Objective: -0.37439614085746403', 'Train Acc: 0.94', 'Test Acc: 0.9467', 'Train LL: -0.1980581887886156', 'Test LL: -0.17581456590917854', 'Epoch Time (s): 171.3501759339124')
('Epoch 24', 'Objective: -0.37139209839020393', 'Train Acc: 0.9408166666666666', 'Test Acc: 0.9361', 'Train LL: -0.19572730415436987', 'Test LL: -0.20604734140321', 'Epoch Time (s): 171.31987568177283')
('Epoch 25', 'Objective: -0.3682988696914617', 'Train Acc: 0.9423166666666667', 'Test Acc: 0.9509', 'Train LL: -0.19361370323571617', 'Test LL: -0.1586982184943945', 'Epoch Time (s): 171.28551695588976')
('Epoch 26', 'Objective: -0.3612973557540972', 'Train Acc: 0.9431666666666667', 'Test Acc: 0.948', 'Train LL: -0.18736351246273625', 'Test LL: -0.16928123049822041', 'Epoch Time (s): 171.27725482499227')
('Epoch 27', 'Objective: -0.3612060287119469', 'Train Acc: 0.9435666666666667', 'Test Acc: 0.9498', 'Train LL: -0.1870788821961269', 'Test LL: -0.1635131680033876', 'Epoch Time (s): 171.32376562384889')
('Epoch 28', 'Objective: -0.35879771045924197', 'Train Acc: 0.9437833333333333', 'Test Acc: 0.9516', 'Train LL: -0.18436123943750668', 'Test LL: -0.1533814791636264', 'Epoch Time (s): 171.34747444977984')
('Epoch 29', 'Objective: -0.35517700282524084', 'Train Acc: 0.9452166666666667', 'Test Acc: 0.9441', 'Train LL: -0.18085529063310143', 'Test LL: -0.18403342681084328', 'Epoch Time (s): 171.3386758370325')
('Epoch 30', 'Objective: -0.3518491721159153', 'Train Acc: 0.9455166666666667', 'Test Acc: 0.9566', 'Train LL: -0.17822009514557097', 'Test LL: -0.14051259661188534', 'Epoch Time (s): 171.31074352096766')
('Epoch 31', 'Objective: -0.3493324387689894', 'Train Acc: 0.9473166666666667', 'Test Acc: 0.9441', 'Train LL: -0.17572740945745063', 'Test LL: -0.17505317574059404', 'Epoch Time (s): 171.3212881819345')
('Epoch 32', 'Objective: -0.34889900215736797', 'Train Acc: 0.9480833333333333', 'Test Acc: 0.9561', 'Train LL: -0.1751769743538033', 'Test LL: -0.14304833846675719', 'Epoch Time (s): 171.318279475905')
('Epoch 33', 'Objective: -0.3485397650222325', 'Train Acc: 0.9470166666666666', 'Test Acc: 0.9563', 'Train LL: -0.17468208305006938', 'Test LL: -0.14451016880930956', 'Epoch Time (s): 171.33725173026323')
('Epoch 34', 'Objective: -0.3428754168902442', 'Train Acc: 0.9486166666666667', 'Test Acc: 0.9546', 'Train LL: -0.17074344826570098', 'Test LL: -0.15062471895358528', 'Epoch Time (s): 171.34165859222412')
('Epoch 35', 'Objective: -0.3430113114680745', 'Train Acc: 0.9478666666666666', 'Test Acc: 0.9558', 'Train LL: -0.1700475019456516', 'Test LL: -0.1427382693141545', 'Epoch Time (s): 171.3120334991254')
('Epoch 36', 'Objective: -0.34121599875365805', 'Train Acc: 0.9507166666666667', 'Test Acc: 0.9494', 'Train LL: -0.16722369171510837', 'Test LL: -0.15533505614077145', 'Epoch Time (s): 171.30442864401266')
('Epoch 37', 'Objective: -0.33968777818472873', 'Train Acc: 0.9493666666666667', 'Test Acc: 0.9595', 'Train LL: -0.1676923055048652', 'Test LL: -0.14159286721243444', 'Epoch Time (s): 171.34320639586076')
('Epoch 38', 'Objective: -0.3405366433917056', 'Train Acc: 0.9496833333333333', 'Test Acc: 0.9607', 'Train LL: -0.16837728343737418', 'Test LL: -0.13409984827559054', 'Epoch Time (s): 171.31240257294849')
('Epoch 39', 'Objective: -0.336025773483743', 'Train Acc: 0.9506333333333333', 'Test Acc: 0.9482', 'Train LL: -0.16416031595938815', 'Test LL: -0.16711486521644833', 'Epoch Time (s): 171.28774619521573')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.29348645489005076', 'Train Acc: 0.9597333333333333', 'Test Acc: 0.9654', 'Train LL: -0.13548063903721771', 'Test LL: -0.11580289297875461', 'Epoch Time (s): 171.33419755799696')
('Epoch 41', 'Objective: -0.2840165861154422', 'Train Acc: 0.9622166666666667', 'Test Acc: 0.9625', 'Train LL: -0.12912368557938034', 'Test LL: -0.11969334471344346', 'Epoch Time (s): 171.3139557489194')
('Epoch 42', 'Objective: -0.2836098614189944', 'Train Acc: 0.9624166666666667', 'Test Acc: 0.9641', 'Train LL: -0.1290078014688735', 'Test LL: -0.11488776130005969', 'Epoch Time (s): 171.31232383102179')
('Epoch 43', 'Objective: -0.28094595730726607', 'Train Acc: 0.9625166666666667', 'Test Acc: 0.9662', 'Train LL: -0.1262343895147282', 'Test LL: -0.111507987111091', 'Epoch Time (s): 171.22123090783134')
('Epoch 44', 'Objective: -0.28052113525616357', 'Train Acc: 0.9634166666666667', 'Test Acc: 0.9664', 'Train LL: -0.1253930430346647', 'Test LL: -0.10991255268056395', 'Epoch Time (s): 171.3279284844175')
('Epoch 45', 'Objective: -0.2815319827460281', 'Train Acc: 0.9627833333333333', 'Test Acc: 0.9657', 'Train LL: -0.1267575329134285', 'Test LL: -0.11062691959429535', 'Epoch Time (s): 171.28380694566295')
('Epoch 46', 'Objective: -0.2790907284828736', 'Train Acc: 0.9634', 'Test Acc: 0.9651', 'Train LL: -0.12414922749005011', 'Test LL: -0.11095649473563107', 'Epoch Time (s): 171.30877127079293')
('Epoch 47', 'Objective: -0.27999945471906135', 'Train Acc: 0.9629333333333333', 'Test Acc: 0.9656', 'Train LL: -0.12550677535839952', 'Test LL: -0.1079268568052812', 'Epoch Time (s): 171.32781827822328')
('Epoch 48', 'Objective: -0.27892580659882615', 'Train Acc: 0.9631666666666666', 'Test Acc: 0.9634', 'Train LL: -0.1240459615954165', 'Test LL: -0.1165341149060588', 'Epoch Time (s): 171.31550199585035')
('Epoch 49', 'Objective: -0.2785497005362342', 'Train Acc: 0.9634166666666667', 'Test Acc: 0.964', 'Train LL: -0.12360982695721347', 'Test LL: -0.10795093866978554', 'Epoch Time (s): 171.34404092282057')
('Epoch 50', 'Objective: -0.2775326355950604', 'Train Acc: 0.9634', 'Test Acc: 0.9674', 'Train LL: -0.1226302916507315', 'Test LL: -0.10411220286130882', 'Epoch Time (s): 171.2561457203701')
('Epoch 51', 'Objective: -0.27708421822769963', 'Train Acc: 0.9642666666666667', 'Test Acc: 0.966', 'Train LL: -0.12207957833911165', 'Test LL: -0.10804698298947037', 'Epoch Time (s): 171.33417001692578')
('Epoch 52', 'Objective: -0.27775088880584764', 'Train Acc: 0.9636666666666667', 'Test Acc: 0.9664', 'Train LL: -0.12262094577060986', 'Test LL: -0.10443417147864612', 'Epoch Time (s): 171.30811417568475')
('Epoch 53', 'Objective: -0.27687777479932213', 'Train Acc: 0.9633', 'Test Acc: 0.9659', 'Train LL: -0.12207916077917641', 'Test LL: -0.10637014612026882', 'Epoch Time (s): 171.27248257678002')
('Epoch 54', 'Objective: -0.2757816681853139', 'Train Acc: 0.9642166666666667', 'Test Acc: 0.967', 'Train LL: -0.1213307348554397', 'Test LL: -0.10415790105473648', 'Epoch Time (s): 171.354723429773')
('Epoch 55', 'Objective: -0.27413873601602456', 'Train Acc: 0.9645833333333333', 'Test Acc: 0.9659', 'Train LL: -0.11957377244232598', 'Test LL: -0.10851572387210942', 'Epoch Time (s): 171.33774699876085')
('Epoch 56', 'Objective: -0.2758140394886498', 'Train Acc: 0.9644166666666667', 'Test Acc: 0.9655', 'Train LL: -0.1215876093136508', 'Test LL: -0.1090613375788424', 'Epoch Time (s): 171.25307776080444')
('Epoch 57', 'Objective: -0.2747885179854539', 'Train Acc: 0.9642666666666667', 'Test Acc: 0.9671', 'Train LL: -0.12040063123162388', 'Test LL: -0.10774556367184147', 'Epoch Time (s): 171.26257949881256')
('Epoch 58', 'Objective: -0.2758000705169829', 'Train Acc: 0.96435', 'Test Acc: 0.9652', 'Train LL: -0.12149190381509116', 'Test LL: -0.10520515805658881', 'Epoch Time (s): 171.25583562767133')
('Epoch 59', 'Objective: -0.27493504937771496', 'Train Acc: 0.96435', 'Test Acc: 0.966', 'Train LL: -0.12058566239024344', 'Test LL: -0.10503400833865346', 'Epoch Time (s): 171.2560065886937')
('Epoch 60', 'Objective: -0.2741770396871745', 'Train Acc: 0.9648666666666667', 'Test Acc: 0.9654', 'Train LL: -0.12049039536498081', 'Test LL: -0.10960720914553622', 'Epoch Time (s): 171.22741334093735')
('Epoch 61', 'Objective: -0.27281862127411094', 'Train Acc: 0.9649333333333333', 'Test Acc: 0.966', 'Train LL: -0.11894673107742598', 'Test LL: -0.10709979727988293', 'Epoch Time (s): 171.27957248780876')
('Epoch 62', 'Objective: -0.2732230562062678', 'Train Acc: 0.9648', 'Test Acc: 0.9655', 'Train LL: -0.11896872275743832', 'Test LL: -0.10567777620823124', 'Epoch Time (s): 171.29831451782957')
('Epoch 63', 'Objective: -0.2735274740433229', 'Train Acc: 0.9653333333333334', 'Test Acc: 0.966', 'Train LL: -0.11997122128177513', 'Test LL: -0.10385658011426395', 'Epoch Time (s): 171.2605116320774')
('Epoch 64', 'Objective: -0.27180147393966064', 'Train Acc: 0.9657166666666667', 'Test Acc: 0.9656', 'Train LL: -0.11820127443645898', 'Test LL: -0.10385822594595047', 'Epoch Time (s): 171.28657995397225')
('Epoch 65', 'Objective: -0.274886806664781', 'Train Acc: 0.9644333333333334', 'Test Acc: 0.9665', 'Train LL: -0.12115339089525835', 'Test LL: -0.10425451539027106', 'Epoch Time (s): 171.25953342299908')
('Epoch 66', 'Objective: -0.27362119571799304', 'Train Acc: 0.9639333333333333', 'Test Acc: 0.9657', 'Train LL: -0.11965611735230997', 'Test LL: -0.10513327223307296', 'Epoch Time (s): 171.22188275773078')
('Epoch 67', 'Objective: -0.27342969380115845', 'Train Acc: 0.9647333333333333', 'Test Acc: 0.966', 'Train LL: -0.11973769228406325', 'Test LL: -0.10537397052005731', 'Epoch Time (s): 171.23270839778706')
('Epoch 68', 'Objective: -0.2720393802538205', 'Train Acc: 0.9653166666666667', 'Test Acc: 0.9645', 'Train LL: -0.11845898830174817', 'Test LL: -0.10782613771028586', 'Epoch Time (s): 171.25258800713345')
('Epoch 69', 'Objective: -0.27276867723306697', 'Train Acc: 0.96515', 'Test Acc: 0.9652', 'Train LL: -0.11913865010349849', 'Test LL: -0.10821773201697812', 'Epoch Time (s): 171.24234211212024')
('Epoch 70', 'Objective: -0.2726075578751541', 'Train Acc: 0.9647166666666667', 'Test Acc: 0.9666', 'Train LL: -0.11893133570600203', 'Test LL: -0.10274125342187049', 'Epoch Time (s): 171.24711780110374')
('Epoch 71', 'Objective: -0.2715972835175968', 'Train Acc: 0.96575', 'Test Acc: 0.967', 'Train LL: -0.11814396712360856', 'Test LL: -0.10083907869382835', 'Epoch Time (s): 171.24856837792322')
('Epoch 72', 'Objective: -0.2716877621555944', 'Train Acc: 0.9652666666666667', 'Test Acc: 0.9667', 'Train LL: -0.11837458925801957', 'Test LL: -0.10241681765094493', 'Epoch Time (s): 171.25612859986722')
('Epoch 73', 'Objective: -0.2712124285465169', 'Train Acc: 0.9655833333333333', 'Test Acc: 0.9668', 'Train LL: -0.11806204348220149', 'Test LL: -0.10134401371069555', 'Epoch Time (s): 171.2368480260484')
('Epoch 74', 'Objective: -0.27227701979211927', 'Train Acc: 0.96505', 'Test Acc: 0.9677', 'Train LL: -0.11900080228360158', 'Test LL: -0.1008615018533444', 'Epoch Time (s): 171.1770067177713')
('Epoch 75', 'Objective: -0.2727230596985018', 'Train Acc: 0.965', 'Test Acc: 0.9672', 'Train LL: -0.11908224843037768', 'Test LL: -0.10363669527990264', 'Epoch Time (s): 171.1687718932517')
('Epoch 76', 'Objective: -0.2708369183747157', 'Train Acc: 0.9650333333333333', 'Test Acc: 0.9668', 'Train LL: -0.11776495251804323', 'Test LL: -0.10387722992652441', 'Epoch Time (s): 171.19458365393803')
('Epoch 77', 'Objective: -0.2716496787866362', 'Train Acc: 0.9655166666666667', 'Test Acc: 0.9665', 'Train LL: -0.11812447898949346', 'Test LL: -0.10282527418541129', 'Epoch Time (s): 171.20329128205776')
('Epoch 78', 'Objective: -0.27130379744638555', 'Train Acc: 0.9651833333333333', 'Test Acc: 0.9671', 'Train LL: -0.11788091258545047', 'Test LL: -0.10306662897947312', 'Epoch Time (s): 171.13756684493273')
('Epoch 79', 'Objective: -0.2707994000747556', 'Train Acc: 0.96575', 'Test Acc: 0.9673', 'Train LL: -0.11757355311678981', 'Test LL: -0.0998649042895362', 'Epoch Time (s): 171.1160830310546')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.2664351303290599', 'Train Acc: 0.9668333333333333', 'Test Acc: 0.9683', 'Train LL: -0.11439260999542201', 'Test LL: -0.09785033484933732', 'Epoch Time (s): 171.12398021528497')
('Epoch 81', 'Objective: -0.26417539414222746', 'Train Acc: 0.9669833333333333', 'Test Acc: 0.9681', 'Train LL: -0.11256934087288921', 'Test LL: -0.09815534171483384', 'Epoch Time (s): 171.17006291309372')
('Epoch 82', 'Objective: -0.2641786694936591', 'Train Acc: 0.9672166666666666', 'Test Acc: 0.9678', 'Train LL: -0.11255762214716146', 'Test LL: -0.09819401156801308', 'Epoch Time (s): 171.15053882217035')
('Epoch 83', 'Objective: -0.26378580617285896', 'Train Acc: 0.9668833333333333', 'Test Acc: 0.9685', 'Train LL: -0.11217894157565034', 'Test LL: -0.0990792419181855', 'Epoch Time (s): 171.27463955199346')
('Epoch 84', 'Objective: -0.26240663510823226', 'Train Acc: 0.9676333333333333', 'Test Acc: 0.9671', 'Train LL: -0.1113305338132624', 'Test LL: -0.09965756008225647', 'Epoch Time (s): 171.1168288756162')
('Epoch 85', 'Objective: -0.263424536354473', 'Train Acc: 0.9670666666666666', 'Test Acc: 0.9678', 'Train LL: -0.1120872961022631', 'Test LL: -0.09813225584505887', 'Epoch Time (s): 171.14584120176733')
('Epoch 86', 'Objective: -0.26349833667359784', 'Train Acc: 0.9673166666666667', 'Test Acc: 0.9683', 'Train LL: -0.11229270660610667', 'Test LL: -0.09929182188793682', 'Epoch Time (s): 171.1231588050723')
('Epoch 87', 'Objective: -0.2614299248547977', 'Train Acc: 0.9675', 'Test Acc: 0.9677', 'Train LL: -0.11038907450492695', 'Test LL: -0.09849320659467323', 'Epoch Time (s): 171.14147475687787')
('Epoch 88', 'Objective: -0.2618281299465518', 'Train Acc: 0.9673', 'Test Acc: 0.9684', 'Train LL: -0.11052893702576133', 'Test LL: -0.09765197315342385', 'Epoch Time (s): 171.1329202959314')
('Epoch 89', 'Objective: -0.2618153970787458', 'Train Acc: 0.9671833333333333', 'Test Acc: 0.968', 'Train LL: -0.11048106582096874', 'Test LL: -0.09800039687551731', 'Epoch Time (s): 171.12862463993952')
('Epoch 90', 'Objective: -0.2634665224281987', 'Train Acc: 0.9666666666666667', 'Test Acc: 0.9683', 'Train LL: -0.1119345152193502', 'Test LL: -0.09786937059348973', 'Epoch Time (s): 171.09777201525867')
('Epoch 91', 'Objective: -0.26306890632870455', 'Train Acc: 0.9671833333333333', 'Test Acc: 0.9675', 'Train LL: -0.11151095513535872', 'Test LL: -0.09918126124030141', 'Epoch Time (s): 171.11986561585218')
('Epoch 92', 'Objective: -0.2630751439937046', 'Train Acc: 0.96805', 'Test Acc: 0.9679', 'Train LL: -0.11155850740103582', 'Test LL: -0.09784127280294529', 'Epoch Time (s): 171.13232281198725')
('Epoch 93', 'Objective: -0.2615415437842432', 'Train Acc: 0.96805', 'Test Acc: 0.9675', 'Train LL: -0.11046777913215106', 'Test LL: -0.09845704166178677', 'Epoch Time (s): 171.11863186676055')
('Epoch 94', 'Objective: -0.26264474762021717', 'Train Acc: 0.9677', 'Test Acc: 0.9676', 'Train LL: -0.11130121109085783', 'Test LL: -0.09783424388328193', 'Epoch Time (s): 171.13143282895908')
('Epoch 95', 'Objective: -0.26352586048372767', 'Train Acc: 0.9672666666666667', 'Test Acc: 0.9679', 'Train LL: -0.11234972189155916', 'Test LL: -0.09853211821748051', 'Epoch Time (s): 171.12998494692147')
('Epoch 96', 'Objective: -0.262839719882488', 'Train Acc: 0.9673833333333334', 'Test Acc: 0.9676', 'Train LL: -0.11130222177484934', 'Test LL: -0.0975222238951872', 'Epoch Time (s): 171.12774865422398')
('Epoch 97', 'Objective: -0.2636956061818867', 'Train Acc: 0.96675', 'Test Acc: 0.9679', 'Train LL: -0.11228088431102122', 'Test LL: -0.0977714228914929', 'Epoch Time (s): 171.08441920392215')
('Epoch 98', 'Objective: -0.26305510275671307', 'Train Acc: 0.9678166666666667', 'Test Acc: 0.9674', 'Train LL: -0.11159003394356214', 'Test LL: -0.09770598531841299', 'Epoch Time (s): 171.08527077687904')
('Epoch 99', 'Objective: -0.262401899852359', 'Train Acc: 0.9678666666666667', 'Test Acc: 0.9678', 'Train LL: -0.11080509666950573', 'Test LL: -0.0988957509286416', 'Epoch Time (s): 171.13386660907418')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.26262945907185425
Final Train Accuracy: £0.9678833333333333
Final Train LL: £-0.11121464118862008
Final Test Accuracy: £0.9678
Final Test LL: £-0.09884046319450618
