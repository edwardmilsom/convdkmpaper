dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: none
bn_tnorm: none
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.518488335699007', 'Train Acc: 0.4588333333333333', 'Test Acc: 0.7549', 'Train LL: -1.4786419183082458', 'Test LL: -0.7494449698813733', 'Epoch Time (s): 168.98076248029247')
('Epoch 1', 'Objective: -0.6356740364464429', 'Train Acc: 0.8025333333333333', 'Test Acc: 0.8389', 'Train LL: -0.5822705217660908', 'Test LL: -0.4653460239633332', 'Epoch Time (s): 167.86904212506488')
('Epoch 2', 'Objective: -0.40657181402336434', 'Train Acc: 0.88785', 'Test Acc: 0.922', 'Train LL: -0.35268170626068845', 'Test LL: -0.2511429233613917', 'Epoch Time (s): 167.93032721802592')
('Epoch 3', 'Objective: -0.29863234652574255', 'Train Acc: 0.92265', 'Test Acc: 0.9359', 'Train LL: -0.24797348615275447', 'Test LL: -0.20055631207714897', 'Epoch Time (s): 167.9769691922702')
('Epoch 4', 'Objective: -0.2517316855633601', 'Train Acc: 0.93685', 'Test Acc: 0.9404', 'Train LL: -0.2030077929488424', 'Test LL: -0.19235775550447765', 'Epoch Time (s): 167.8331805509515')
('Epoch 5', 'Objective: -0.22309950787927985', 'Train Acc: 0.9456666666666667', 'Test Acc: 0.9516', 'Train LL: -0.17614635353704294', 'Test LL: -0.1665614811892914', 'Epoch Time (s): 167.8396778437309')
('Epoch 6', 'Objective: -0.20216936199664726', 'Train Acc: 0.9516166666666667', 'Test Acc: 0.9632', 'Train LL: -0.15694566704325813', 'Test LL: -0.11719445211178092', 'Epoch Time (s): 167.979798770044')
('Epoch 7', 'Objective: -0.18575584473724932', 'Train Acc: 0.9562333333333334', 'Test Acc: 0.9614', 'Train LL: -0.14225566359377145', 'Test LL: -0.11764691777179105', 'Epoch Time (s): 168.06807023799047')
('Epoch 8', 'Objective: -0.16819257339008428', 'Train Acc: 0.9610833333333333', 'Test Acc: 0.9693', 'Train LL: -0.12622906350338972', 'Test LL: -0.10762964393976611', 'Epoch Time (s): 167.8626557267271')
('Epoch 9', 'Objective: -0.157529031195697', 'Train Acc: 0.9633333333333334', 'Test Acc: 0.9543', 'Train LL: -0.11695776488910413', 'Test LL: -0.14329436685935917', 'Epoch Time (s): 167.84489867836237')
('Epoch 10', 'Objective: -0.14944307441270258', 'Train Acc: 0.9662166666666666', 'Test Acc: 0.9656', 'Train LL: -0.10975190878986638', 'Test LL: -0.10843552158225132', 'Epoch Time (s): 167.9703342556022')
('Epoch 11', 'Objective: -0.13920987519616815', 'Train Acc: 0.96855', 'Test Acc: 0.9678', 'Train LL: -0.10042462091410255', 'Test LL: -0.09373949149760702', 'Epoch Time (s): 168.0248728049919')
('Epoch 12', 'Objective: -0.13456958192586302', 'Train Acc: 0.9695666666666667', 'Test Acc: 0.9739', 'Train LL: -0.096500176900466', 'Test LL: -0.08597254343601902', 'Epoch Time (s): 167.86987461708486')
('Epoch 13', 'Objective: -0.1290858325597904', 'Train Acc: 0.9710833333333333', 'Test Acc: 0.971', 'Train LL: -0.09175826500690969', 'Test LL: -0.09092768201785055', 'Epoch Time (s): 167.8422129508108')
('Epoch 14', 'Objective: -0.12514446394394432', 'Train Acc: 0.97295', 'Test Acc: 0.9694', 'Train LL: -0.08887697566176757', 'Test LL: -0.10397463902028788', 'Epoch Time (s): 168.1146459178999')
('Epoch 15', 'Objective: -0.11821304184275751', 'Train Acc: 0.9739833333333333', 'Test Acc: 0.9775', 'Train LL: -0.08265840004014485', 'Test LL: -0.07430997254552427', 'Epoch Time (s): 167.84711333783343')
('Epoch 16', 'Objective: -0.11726545193633917', 'Train Acc: 0.9748', 'Test Acc: 0.9783', 'Train LL: -0.08241733244603155', 'Test LL: -0.06776104818102922', 'Epoch Time (s): 167.95460369624197')
('Epoch 17', 'Objective: -0.11199881453332593', 'Train Acc: 0.9758333333333333', 'Test Acc: 0.9794', 'Train LL: -0.07784108799860169', 'Test LL: -0.06337107753214595', 'Epoch Time (s): 167.84150423808023')
('Epoch 18', 'Objective: -0.11037444109949615', 'Train Acc: 0.9764333333333334', 'Test Acc: 0.9794', 'Train LL: -0.07696224302120142', 'Test LL: -0.06451397502178367', 'Epoch Time (s): 168.0017014280893')
('Epoch 19', 'Objective: -0.10577961808344181', 'Train Acc: 0.9772166666666666', 'Test Acc: 0.9817', 'Train LL: -0.0729618095745813', 'Test LL: -0.05633736279238616', 'Epoch Time (s): 167.82582691218704')
('Epoch 20', 'Objective: -0.10373914145032694', 'Train Acc: 0.9780166666666666', 'Test Acc: 0.9812', 'Train LL: -0.07125216576396814', 'Test LL: -0.06247707430642389', 'Epoch Time (s): 167.92978212982416')
('Epoch 21', 'Objective: -0.1030368834059127', 'Train Acc: 0.9778833333333333', 'Test Acc: 0.9799', 'Train LL: -0.07104207576149596', 'Test LL: -0.059579031087275414', 'Epoch Time (s): 167.84614371182397')
('Epoch 22', 'Objective: -0.1000769927007631', 'Train Acc: 0.9783666666666667', 'Test Acc: 0.975', 'Train LL: -0.06856763792366795', 'Test LL: -0.0815036063381371', 'Epoch Time (s): 167.9558247961104')
('Epoch 23', 'Objective: -0.09756317099612338', 'Train Acc: 0.9793166666666666', 'Test Acc: 0.9793', 'Train LL: -0.06661845216605351', 'Test LL: -0.06560329027888974', 'Epoch Time (s): 167.8565347958356')
('Epoch 24', 'Objective: -0.09519195306118446', 'Train Acc: 0.9798', 'Test Acc: 0.984', 'Train LL: -0.06449971395893897', 'Test LL: -0.04875920184586326', 'Epoch Time (s): 167.99959371518344')
('Epoch 25', 'Objective: -0.09367226495390511', 'Train Acc: 0.9804', 'Test Acc: 0.977', 'Train LL: -0.06344158420353861', 'Test LL: -0.07638845069508585', 'Epoch Time (s): 167.84957540081814')
('Epoch 26', 'Objective: -0.09299967196110756', 'Train Acc: 0.97975', 'Test Acc: 0.9781', 'Train LL: -0.06290218201117057', 'Test LL: -0.07195211098571525', 'Epoch Time (s): 167.9028598498553')
('Epoch 27', 'Objective: -0.09289757127944999', 'Train Acc: 0.9801', 'Test Acc: 0.9856', 'Train LL: -0.06305833505680611', 'Test LL: -0.0450175785010219', 'Epoch Time (s): 167.83752206899226')
('Epoch 28', 'Objective: -0.09038186299738116', 'Train Acc: 0.981', 'Test Acc: 0.9773', 'Train LL: -0.06108877566410521', 'Test LL: -0.06689178028210123', 'Epoch Time (s): 167.93524646013975')
('Epoch 29', 'Objective: -0.08998704443460065', 'Train Acc: 0.98135', 'Test Acc: 0.9809', 'Train LL: -0.06067830846164287', 'Test LL: -0.06320403394351568', 'Epoch Time (s): 167.84691939409822')
('Epoch 30', 'Objective: -0.08710152823921577', 'Train Acc: 0.98185', 'Test Acc: 0.9835', 'Train LL: -0.058240596268684566', 'Test LL: -0.05114002996055607', 'Epoch Time (s): 167.8516746130772')
('Epoch 31', 'Objective: -0.0865144706603835', 'Train Acc: 0.9817833333333333', 'Test Acc: 0.9855', 'Train LL: -0.057717497823473005', 'Test LL: -0.0442197360980592', 'Epoch Time (s): 167.94759821798652')
('Epoch 32', 'Objective: -0.08531781617045159', 'Train Acc: 0.9826833333333334', 'Test Acc: 0.9791', 'Train LL: -0.05663081331541527', 'Test LL: -0.06411858183545945', 'Epoch Time (s): 168.01188185811043')
('Epoch 33', 'Objective: -0.0839771968632542', 'Train Acc: 0.9826833333333334', 'Test Acc: 0.9773', 'Train LL: -0.0558586335725135', 'Test LL: -0.06135818463784478', 'Epoch Time (s): 167.8630063533783')
('Epoch 34', 'Objective: -0.08351646282665931', 'Train Acc: 0.9827', 'Test Acc: 0.9834', 'Train LL: -0.05526788762646221', 'Test LL: -0.05239282392102592', 'Epoch Time (s): 167.83864218275994')
('Epoch 35', 'Objective: -0.08312389537195365', 'Train Acc: 0.9828666666666667', 'Test Acc: 0.9819', 'Train LL: -0.05520289755130595', 'Test LL: -0.04985462710908755', 'Epoch Time (s): 167.97811228688806')
('Epoch 36', 'Objective: -0.08164399457004959', 'Train Acc: 0.9828333333333333', 'Test Acc: 0.9876', 'Train LL: -0.05376082780122224', 'Test LL: -0.04088652185453853', 'Epoch Time (s): 167.98582315072417')
('Epoch 37', 'Objective: -0.08099591943768347', 'Train Acc: 0.9834166666666667', 'Test Acc: 0.9849', 'Train LL: -0.05314558969962796', 'Test LL: -0.04554067789508467', 'Epoch Time (s): 167.8237211969681')
('Epoch 38', 'Objective: -0.07993906756471397', 'Train Acc: 0.9832', 'Test Acc: 0.9865', 'Train LL: -0.05260426982837208', 'Test LL: -0.0435250938569566', 'Epoch Time (s): 167.83634691080078')
('Epoch 39', 'Objective: -0.07872717412656105', 'Train Acc: 0.9837333333333333', 'Test Acc: 0.9794', 'Train LL: -0.05149151728280809', 'Test LL: -0.0705285298018055', 'Epoch Time (s): 167.9610716556199')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.05977403896605507', 'Train Acc: 0.9891', 'Test Acc: 0.9905', 'Train LL: -0.033719820289263715', 'Test LL: -0.03110229719040962', 'Epoch Time (s): 168.00674554379657')
('Epoch 41', 'Objective: -0.05281023519607828', 'Train Acc: 0.99085', 'Test Acc: 0.9906', 'Train LL: -0.027916993415563713', 'Test LL: -0.029517987357170233', 'Epoch Time (s): 167.83977027609944')
('Epoch 42', 'Objective: -0.05163508984957598', 'Train Acc: 0.9912833333333333', 'Test Acc: 0.9899', 'Train LL: -0.027186753384752196', 'Test LL: -0.031644232326898995', 'Epoch Time (s): 167.88239260576665')
('Epoch 43', 'Objective: -0.0499924911697726', 'Train Acc: 0.9915', 'Test Acc: 0.9909', 'Train LL: -0.025799316412231415', 'Test LL: -0.028046045758807453', 'Epoch Time (s): 167.98084747092798')
('Epoch 44', 'Objective: -0.05011078176921722', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.99', 'Train LL: -0.02606774806114338', 'Test LL: -0.030174228556815876', 'Epoch Time (s): 167.92159732291475')
('Epoch 45', 'Objective: -0.049180371119850165', 'Train Acc: 0.992', 'Test Acc: 0.9903', 'Train LL: -0.025433388836985926', 'Test LL: -0.02901840690239037', 'Epoch Time (s): 167.93722374830395')
('Epoch 46', 'Objective: -0.0484119356606905', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.9905', 'Train LL: -0.02479134408724915', 'Test LL: -0.028277999965461594', 'Epoch Time (s): 167.84314990835264')
('Epoch 47', 'Objective: -0.04733122607612231', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9904', 'Train LL: -0.02394416007920052', 'Test LL: -0.029190059044158716', 'Epoch Time (s): 167.95566397113726')
('Epoch 48', 'Objective: -0.04685373787469598', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9907', 'Train LL: -0.023473225422196972', 'Test LL: -0.02799623684302783', 'Epoch Time (s): 167.86615695198998')
('Epoch 49', 'Objective: -0.04649348084637993', 'Train Acc: 0.9923', 'Test Acc: 0.9904', 'Train LL: -0.023333201547918115', 'Test LL: -0.029019461531693342', 'Epoch Time (s): 167.91520246118307')
('Epoch 50', 'Objective: -0.045829012754382496', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9901', 'Train LL: -0.0227773455469547', 'Test LL: -0.029199264566568718', 'Epoch Time (s): 167.8264435697347')
('Epoch 51', 'Objective: -0.046305829793533995', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9901', 'Train LL: -0.023278338172354515', 'Test LL: -0.03045183239681196', 'Epoch Time (s): 167.98803706793115')
('Epoch 52', 'Objective: -0.04563541862561578', 'Train Acc: 0.9928', 'Test Acc: 0.9908', 'Train LL: -0.02280165242224815', 'Test LL: -0.02806162292753798', 'Epoch Time (s): 167.87652126699686')
('Epoch 53', 'Objective: -0.04585234821734004', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.9904', 'Train LL: -0.022981616322827594', 'Test LL: -0.02987608736745541', 'Epoch Time (s): 167.94251643680036')
('Epoch 54', 'Objective: -0.04572734356585553', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9899', 'Train LL: -0.022934596314309146', 'Test LL: -0.02910522553290839', 'Epoch Time (s): 167.85024537704885')
('Epoch 55', 'Objective: -0.04504680092156129', 'Train Acc: 0.9928166666666667', 'Test Acc: 0.9905', 'Train LL: -0.022363779949231954', 'Test LL: -0.029254254176477024', 'Epoch Time (s): 167.90206921799108')
('Epoch 56', 'Objective: -0.044865622153448276', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9909', 'Train LL: -0.022372797534211203', 'Test LL: -0.02919438011035432', 'Epoch Time (s): 167.87913169991225')
('Epoch 57', 'Objective: -0.04489051194734102', 'Train Acc: 0.9929', 'Test Acc: 0.9902', 'Train LL: -0.02244972727320643', 'Test LL: -0.02912595862438153', 'Epoch Time (s): 167.92283058632165')
('Epoch 58', 'Objective: -0.04370149366131463', 'Train Acc: 0.99315', 'Test Acc: 0.9904', 'Train LL: -0.021367784455869263', 'Test LL: -0.029282444627219018', 'Epoch Time (s): 167.8427610998042')
('Epoch 59', 'Objective: -0.04431543266264131', 'Train Acc: 0.99265', 'Test Acc: 0.991', 'Train LL: -0.021949145180430462', 'Test LL: -0.028490173678502213', 'Epoch Time (s): 168.018376363907')
('Epoch 60', 'Objective: -0.04397982314892861', 'Train Acc: 0.99265', 'Test Acc: 0.99', 'Train LL: -0.021657361080042764', 'Test LL: -0.03283468271070423', 'Epoch Time (s): 167.9698904226534')
('Epoch 61', 'Objective: -0.043417209006763574', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.9897', 'Train LL: -0.02125681329277474', 'Test LL: -0.03335380849807249', 'Epoch Time (s): 167.89853005018085')
('Epoch 62', 'Objective: -0.04343515786382313', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9901', 'Train LL: -0.021275838061445913', 'Test LL: -0.0320575512873255', 'Epoch Time (s): 167.90111793624237')
('Epoch 63', 'Objective: -0.043447392689228904', 'Train Acc: 0.99325', 'Test Acc: 0.9896', 'Train LL: -0.021421412941258638', 'Test LL: -0.029410286443285725', 'Epoch Time (s): 167.9513437608257')
('Epoch 64', 'Objective: -0.04324930511241967', 'Train Acc: 0.9932833333333333', 'Test Acc: 0.9899', 'Train LL: -0.02130831544402791', 'Test LL: -0.030003853973591413', 'Epoch Time (s): 167.90836555883288')
('Epoch 65', 'Objective: -0.04388281840081303', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9913', 'Train LL: -0.02197555252220753', 'Test LL: -0.02924241675581962', 'Epoch Time (s): 167.90787955513224')
('Epoch 66', 'Objective: -0.04229757661673503', 'Train Acc: 0.9933833333333333', 'Test Acc: 0.9915', 'Train LL: -0.020495137670559396', 'Test LL: -0.027522468726424377', 'Epoch Time (s): 167.97648022091016')
('Epoch 67', 'Objective: -0.04305892519142754', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9892', 'Train LL: -0.021197797341648394', 'Test LL: -0.03329313581976175', 'Epoch Time (s): 167.90653658518568')
('Epoch 68', 'Objective: -0.04245309228214127', 'Train Acc: 0.9934666666666667', 'Test Acc: 0.9907', 'Train LL: -0.020755894542865187', 'Test LL: -0.027808047452851002', 'Epoch Time (s): 167.90907878335565')
('Epoch 69', 'Objective: -0.04282311863580968', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9902', 'Train LL: -0.02109265557582241', 'Test LL: -0.028645177321583868', 'Epoch Time (s): 167.95523352501914')
('Epoch 70', 'Objective: -0.04256422134575097', 'Train Acc: 0.9932', 'Test Acc: 0.9918', 'Train LL: -0.02091378969108741', 'Test LL: -0.025953495320859565', 'Epoch Time (s): 167.9545120592229')
('Epoch 71', 'Objective: -0.04221518621343965', 'Train Acc: 0.9933333333333333', 'Test Acc: 0.9897', 'Train LL: -0.02060060935572038', 'Test LL: -0.031111523089581306', 'Epoch Time (s): 167.9042873661965')
('Epoch 72', 'Objective: -0.0421876235397153', 'Train Acc: 0.99305', 'Test Acc: 0.991', 'Train LL: -0.020618683588785856', 'Test LL: -0.029545173268317022', 'Epoch Time (s): 167.87875462137163')
('Epoch 73', 'Objective: -0.041381749426252515', 'Train Acc: 0.9935333333333334', 'Test Acc: 0.992', 'Train LL: -0.01981032420448446', 'Test LL: -0.02792800635952413', 'Epoch Time (s): 167.9163543470204')
('Epoch 74', 'Objective: -0.04136152083138142', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.99', 'Train LL: -0.01989296935095716', 'Test LL: -0.03169733120754195', 'Epoch Time (s): 167.8730342136696')
('Epoch 75', 'Objective: -0.041898592355247344', 'Train Acc: 0.9930666666666667', 'Test Acc: 0.9899', 'Train LL: -0.020427521858265154', 'Test LL: -0.032138934597943515', 'Epoch Time (s): 167.88120940234512')
('Epoch 76', 'Objective: -0.04163771249054536', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9895', 'Train LL: -0.020270392609502186', 'Test LL: -0.03247731791536999', 'Epoch Time (s): 167.86765517294407')
('Epoch 77', 'Objective: -0.04145585938667508', 'Train Acc: 0.99335', 'Test Acc: 0.9903', 'Train LL: -0.02009625033821445', 'Test LL: -0.030433125485070867', 'Epoch Time (s): 167.74129049200565')
('Epoch 78', 'Objective: -0.04138782756724526', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.9902', 'Train LL: -0.020015453715209682', 'Test LL: -0.02939748671192909', 'Epoch Time (s): 167.746022536885')
('Epoch 79', 'Objective: -0.04068556744314671', 'Train Acc: 0.9936666666666667', 'Test Acc: 0.9905', 'Train LL: -0.019474069837035184', 'Test LL: -0.03359592994251099', 'Epoch Time (s): 167.71443071123213')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.038178556641086776', 'Train Acc: 0.99455', 'Test Acc: 0.9904', 'Train LL: -0.016948101267627188', 'Test LL: -0.030668352812532686', 'Epoch Time (s): 167.71749712573364')
('Epoch 81', 'Objective: -0.037962813901439726', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9906', 'Train LL: -0.016939698234121302', 'Test LL: -0.030105427262757792', 'Epoch Time (s): 167.71565976226702')
('Epoch 82', 'Objective: -0.037120243378141224', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9909', 'Train LL: -0.016143555332737414', 'Test LL: -0.02993748272627704', 'Epoch Time (s): 167.73463189601898')
('Epoch 83', 'Objective: -0.037708498233979475', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9911', 'Train LL: -0.01669963049830265', 'Test LL: -0.029784655875447485', 'Epoch Time (s): 167.67938304925337')
('Epoch 84', 'Objective: -0.037139204278609304', 'Train Acc: 0.9950166666666667', 'Test Acc: 0.9915', 'Train LL: -0.016091882952599685', 'Test LL: -0.02911005223672903', 'Epoch Time (s): 167.70108161773533')
('Epoch 85', 'Objective: -0.037329972031412535', 'Train Acc: 0.9947', 'Test Acc: 0.9912', 'Train LL: -0.016371295991951012', 'Test LL: -0.02987733695056691', 'Epoch Time (s): 167.7414471968077')
('Epoch 86', 'Objective: -0.03712618878085874', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9915', 'Train LL: -0.016095260865678643', 'Test LL: -0.029470123479478975', 'Epoch Time (s): 167.69387994613498')
('Epoch 87', 'Objective: -0.03733075433537726', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9911', 'Train LL: -0.016342195060213914', 'Test LL: -0.029863941967447166', 'Epoch Time (s): 167.6959575456567')
('Epoch 88', 'Objective: -0.03700046473838762', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9912', 'Train LL: -0.016053602595839583', 'Test LL: -0.029064717258053013', 'Epoch Time (s): 167.71594227897003')
('Epoch 89', 'Objective: -0.03707481880630015', 'Train Acc: 0.9948', 'Test Acc: 0.9909', 'Train LL: -0.016056194866473895', 'Test LL: -0.03014352663847003', 'Epoch Time (s): 167.7186624170281')
('Epoch 90', 'Objective: -0.03710940126945447', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.9911', 'Train LL: -0.01609927890357917', 'Test LL: -0.029679810843827058', 'Epoch Time (s): 167.7215460347943')
('Epoch 91', 'Objective: -0.03708828462901374', 'Train Acc: 0.99465', 'Test Acc: 0.9913', 'Train LL: -0.01608959138469165', 'Test LL: -0.029472311174965647', 'Epoch Time (s): 167.70207729097456')
('Epoch 92', 'Objective: -0.03738387935933349', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9913', 'Train LL: -0.016424534587562534', 'Test LL: -0.02986712962272649', 'Epoch Time (s): 167.75676318025216')
('Epoch 93', 'Objective: -0.036885653500495386', 'Train Acc: 0.9950666666666667', 'Test Acc: 0.9913', 'Train LL: -0.015967457396442817', 'Test LL: -0.029836286414117195', 'Epoch Time (s): 167.73950588610023')
('Epoch 94', 'Objective: -0.03693526510726649', 'Train Acc: 0.9952', 'Test Acc: 0.991', 'Train LL: -0.015922445473295896', 'Test LL: -0.02974605718264043', 'Epoch Time (s): 167.71955730766058')
('Epoch 95', 'Objective: -0.03686260434059556', 'Train Acc: 0.99475', 'Test Acc: 0.9905', 'Train LL: -0.015878053466347318', 'Test LL: -0.02943338141053152', 'Epoch Time (s): 167.78626936813816')
('Epoch 96', 'Objective: -0.03713083607718253', 'Train Acc: 0.9951333333333333', 'Test Acc: 0.9908', 'Train LL: -0.016203648354486417', 'Test LL: -0.029298496085284786', 'Epoch Time (s): 167.68698537303135')
('Epoch 97', 'Objective: -0.03718862032650003', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.9907', 'Train LL: -0.016229065140263062', 'Test LL: -0.029878281460493417', 'Epoch Time (s): 167.76357882190496')
('Epoch 98', 'Objective: -0.03678353329282238', 'Train Acc: 0.99485', 'Test Acc: 0.9908', 'Train LL: -0.015871132191620476', 'Test LL: -0.029909235609900678', 'Epoch Time (s): 167.75348727824166')
('Epoch 99', 'Objective: -0.036980019532627965', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9908', 'Train LL: -0.01602838964302548', 'Test LL: -0.028909014270645635', 'Epoch Time (s): 167.7427485571243')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03669829363437963
Final Train Accuracy: £0.9948666666666667
Final Train LL: £-0.015736294584131526
Final Test Accuracy: £0.9909
Final Test LL: £-0.028969758955476085
