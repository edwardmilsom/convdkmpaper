dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 3
bn_indnorm: local
bn_tnorm: local
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.5498718459083036', 'Train Acc: 0.4406', 'Test Acc: 0.7252', 'Train LL: -1.5000524080089752', 'Test LL: -0.8109163643876972', 'Epoch Time (s): 165.23335455707274')
('Epoch 1', 'Objective: -0.6990779681009003', 'Train Acc: 0.78095', 'Test Acc: 0.726', 'Train LL: -0.6356255152873588', 'Test LL: -0.8955121464603617', 'Epoch Time (s): 165.30215392797254')
('Epoch 2', 'Objective: -0.4539947667509452', 'Train Acc: 0.87005', 'Test Acc: 0.8835', 'Train LL: -0.39266256372496366', 'Test LL: -0.3292412162303537', 'Epoch Time (s): 165.25763982301578')
('Epoch 3', 'Objective: -0.31386454510909384', 'Train Acc: 0.9200166666666667', 'Test Acc: 0.9196', 'Train LL: -0.25511228675177433', 'Test LL: -0.24404418075334794', 'Epoch Time (s): 165.30795219610445')
('Epoch 4', 'Objective: -0.2638768685843827', 'Train Acc: 0.9340666666666667', 'Test Acc: 0.931', 'Train LL: -0.20920988949853697', 'Test LL: -0.20705171677005405', 'Epoch Time (s): 165.27933486783877')
('Epoch 5', 'Objective: -0.23069350101256653', 'Train Acc: 0.9449', 'Test Acc: 0.9419', 'Train LL: -0.17935968707257743', 'Test LL: -0.18622896936473404', 'Epoch Time (s): 165.270156071987')
('Epoch 6', 'Objective: -0.21032040873282343', 'Train Acc: 0.9490333333333333', 'Test Acc: 0.9428', 'Train LL: -0.16131145588539023', 'Test LL: -0.18114419651288413', 'Epoch Time (s): 165.1858578498941')
('Epoch 7', 'Objective: -0.19326000554085615', 'Train Acc: 0.9549166666666666', 'Test Acc: 0.9648', 'Train LL: -0.14623632681707568', 'Test LL: -0.105169506570468', 'Epoch Time (s): 165.23814318794757')
('Epoch 8', 'Objective: -0.17830243780999466', 'Train Acc: 0.9589666666666666', 'Test Acc: 0.9569', 'Train LL: -0.1328576209964892', 'Test LL: -0.13165578008590959', 'Epoch Time (s): 165.24426705995575')
('Epoch 9', 'Objective: -0.17248800100277079', 'Train Acc: 0.9602166666666667', 'Test Acc: 0.9741', 'Train LL: -0.12811691061311198', 'Test LL: -0.07928936095048338', 'Epoch Time (s): 165.16845149500296')
('Epoch 10', 'Objective: -0.16131704354800408', 'Train Acc: 0.9633166666666667', 'Test Acc: 0.9714', 'Train LL: -0.11795405935358795', 'Test LL: -0.08824719572691635', 'Epoch Time (s): 165.2606519619003')
('Epoch 11', 'Objective: -0.15498311703139753', 'Train Acc: 0.9645833333333333', 'Test Acc: 0.97', 'Train LL: -0.1125451316140379', 'Test LL: -0.09042350069328348', 'Epoch Time (s): 165.22052454506047')
('Epoch 12', 'Objective: -0.14857071316901954', 'Train Acc: 0.9668166666666667', 'Test Acc: 0.9688', 'Train LL: -0.10709801786447158', 'Test LL: -0.09734355983695937', 'Epoch Time (s): 165.27018737397157')
('Epoch 13', 'Objective: -0.14316482596975066', 'Train Acc: 0.9680166666666666', 'Test Acc: 0.9794', 'Train LL: -0.10259811477799391', 'Test LL: -0.06519565240278904', 'Epoch Time (s): 165.31809492502362')
('Epoch 14', 'Objective: -0.13864712620623268', 'Train Acc: 0.9698333333333333', 'Test Acc: 0.9814', 'Train LL: -0.09912718452698252', 'Test LL: -0.05987147475390226', 'Epoch Time (s): 165.31162144010887')
('Epoch 15', 'Objective: -0.1345228682712441', 'Train Acc: 0.9697666666666667', 'Test Acc: 0.9792', 'Train LL: -0.0957851187100373', 'Test LL: -0.06109655182796434', 'Epoch Time (s): 165.2422106640879')
('Epoch 16', 'Objective: -0.12987847042153963', 'Train Acc: 0.9712333333333333', 'Test Acc: 0.9675', 'Train LL: -0.09155987429885222', 'Test LL: -0.10679109857082794', 'Epoch Time (s): 165.3219333118759')
('Epoch 17', 'Objective: -0.12736761280799075', 'Train Acc: 0.9720666666666666', 'Test Acc: 0.9805', 'Train LL: -0.08958543076281851', 'Test LL: -0.06509255058970449', 'Epoch Time (s): 165.28012517513707')
('Epoch 18', 'Objective: -0.1249105075706034', 'Train Acc: 0.97245', 'Test Acc: 0.9768', 'Train LL: -0.08749939624842067', 'Test LL: -0.07413404392132965', 'Epoch Time (s): 165.17973928316496')
('Epoch 19', 'Objective: -0.12193039742556044', 'Train Acc: 0.9734166666666667', 'Test Acc: 0.9692', 'Train LL: -0.08502108086142042', 'Test LL: -0.09714124142540075', 'Epoch Time (s): 165.23571881907992')
('Epoch 20', 'Objective: -0.11669889190384053', 'Train Acc: 0.9744666666666667', 'Test Acc: 0.9793', 'Train LL: -0.08026318370219042', 'Test LL: -0.06584033425765208', 'Epoch Time (s): 165.2536152601242')
('Epoch 21', 'Objective: -0.11433120737919707', 'Train Acc: 0.9752666666666666', 'Test Acc: 0.9825', 'Train LL: -0.07845738929748156', 'Test LL: -0.05246853254584454', 'Epoch Time (s): 165.2153722711373')
('Epoch 22', 'Objective: -0.11477180319128917', 'Train Acc: 0.9757', 'Test Acc: 0.9765', 'Train LL: -0.07909627639183603', 'Test LL: -0.0695997252861868', 'Epoch Time (s): 165.24939379887655')
('Epoch 23', 'Objective: -0.11182743000214727', 'Train Acc: 0.9758666666666667', 'Test Acc: 0.9787', 'Train LL: -0.07666257646485333', 'Test LL: -0.06388928904299482', 'Epoch Time (s): 165.27793727302924')
('Epoch 24', 'Objective: -0.10575419513045436', 'Train Acc: 0.9782833333333333', 'Test Acc: 0.9791', 'Train LL: -0.071143797092285', 'Test LL: -0.059555787634849595', 'Epoch Time (s): 165.32883012108505')
('Epoch 25', 'Objective: -0.10601433088163924', 'Train Acc: 0.9774166666666667', 'Test Acc: 0.9763', 'Train LL: -0.07146746751605411', 'Test LL: -0.07422529868913007', 'Epoch Time (s): 165.29505976103246')
('Epoch 26', 'Objective: -0.10352660692391662', 'Train Acc: 0.9781833333333333', 'Test Acc: 0.9809', 'Train LL: -0.06931517655963547', 'Test LL: -0.05926251056298224', 'Epoch Time (s): 165.2511259780731')
('Epoch 27', 'Objective: -0.10369504244874249', 'Train Acc: 0.9783166666666666', 'Test Acc: 0.9736', 'Train LL: -0.06968858635059694', 'Test LL: -0.07498859799682749', 'Epoch Time (s): 165.22726310184225')
('Epoch 28', 'Objective: -0.10115990152132787', 'Train Acc: 0.9785', 'Test Acc: 0.9802', 'Train LL: -0.06723566150922326', 'Test LL: -0.06167196035286378', 'Epoch Time (s): 165.37895609787665')
('Epoch 29', 'Objective: -0.0982325469893604', 'Train Acc: 0.97915', 'Test Acc: 0.9763', 'Train LL: -0.06481610679669117', 'Test LL: -0.0747357404877946', 'Epoch Time (s): 165.31284026103094')
('Epoch 30', 'Objective: -0.09784623105028373', 'Train Acc: 0.9799666666666667', 'Test Acc: 0.9873', 'Train LL: -0.06490837705268386', 'Test LL: -0.039200398307226804', 'Epoch Time (s): 165.28790109511465')
('Epoch 31', 'Objective: -0.09562290449540105', 'Train Acc: 0.9802833333333333', 'Test Acc: 0.9825', 'Train LL: -0.06259029031803584', 'Test LL: -0.05353743163143027', 'Epoch Time (s): 165.29093554988503')
('Epoch 32', 'Objective: -0.09603544266483385', 'Train Acc: 0.9798166666666667', 'Test Acc: 0.983', 'Train LL: -0.06340834445365924', 'Test LL: -0.052755982655881745', 'Epoch Time (s): 165.26585657405667')
('Epoch 33', 'Objective: -0.09580193741076713', 'Train Acc: 0.97975', 'Test Acc: 0.9808', 'Train LL: -0.06348349653790779', 'Test LL: -0.057522389387125825', 'Epoch Time (s): 165.22906832606532')
('Epoch 34', 'Objective: -0.0946038543078411', 'Train Acc: 0.98015', 'Test Acc: 0.9821', 'Train LL: -0.06255938062013791', 'Test LL: -0.055301115380599355', 'Epoch Time (s): 165.16059675789438')
('Epoch 35', 'Objective: -0.09224494613530951', 'Train Acc: 0.98035', 'Test Acc: 0.9802', 'Train LL: -0.06017721957389494', 'Test LL: -0.05852612351246818', 'Epoch Time (s): 165.25254561309703')
('Epoch 36', 'Objective: -0.0918257377435675', 'Train Acc: 0.9807166666666667', 'Test Acc: 0.984', 'Train LL: -0.060036772976835226', 'Test LL: -0.04942911997811183', 'Epoch Time (s): 165.30661092000082')
('Epoch 37', 'Objective: -0.09090976243501729', 'Train Acc: 0.9813166666666666', 'Test Acc: 0.9836', 'Train LL: -0.059182767554148176', 'Test LL: -0.05312232956301909', 'Epoch Time (s): 165.33504190808162')
('Epoch 38', 'Objective: -0.09004148010619609', 'Train Acc: 0.98095', 'Test Acc: 0.977', 'Train LL: -0.058846601935108066', 'Test LL: -0.07525516659686182', 'Epoch Time (s): 165.35363293392584')
('Epoch 39', 'Objective: -0.08802949023688217', 'Train Acc: 0.9813833333333334', 'Test Acc: 0.9824', 'Train LL: -0.05696260490561323', 'Test LL: -0.05782809714540481', 'Epoch Time (s): 165.29516347195022')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06614881941114076', 'Train Acc: 0.9883166666666666', 'Test Acc: 0.9892', 'Train LL: -0.03709615079633164', 'Test LL: -0.031650450519806736', 'Epoch Time (s): 165.3252485410776')
('Epoch 41', 'Objective: -0.060139703355090265', 'Train Acc: 0.9896333333333334', 'Test Acc: 0.989', 'Train LL: -0.032108891521155064', 'Test LL: -0.03257211740004947', 'Epoch Time (s): 165.18984247813933')
('Epoch 42', 'Objective: -0.05861065133265398', 'Train Acc: 0.9902', 'Test Acc: 0.9893', 'Train LL: -0.031099521858070363', 'Test LL: -0.03259217304664802', 'Epoch Time (s): 165.29964827303775')
('Epoch 43', 'Objective: -0.056589498335750305', 'Train Acc: 0.99065', 'Test Acc: 0.9888', 'Train LL: -0.029429643545970323', 'Test LL: -0.03255511832961608', 'Epoch Time (s): 165.24974088813178')
('Epoch 44', 'Objective: -0.05640996323807593', 'Train Acc: 0.99035', 'Test Acc: 0.9906', 'Train LL: -0.0295059588722616', 'Test LL: -0.027597171090224266', 'Epoch Time (s): 165.20847556786612')
('Epoch 45', 'Objective: -0.05530650875471679', 'Train Acc: 0.9907833333333333', 'Test Acc: 0.9895', 'Train LL: -0.028628677461767886', 'Test LL: -0.0322716313333568', 'Epoch Time (s): 165.31799505697563')
('Epoch 46', 'Objective: -0.05421374237452448', 'Train Acc: 0.9912833333333333', 'Test Acc: 0.9893', 'Train LL: -0.02778378239933894', 'Test LL: -0.031076135464596918', 'Epoch Time (s): 165.19971691002138')
('Epoch 47', 'Objective: -0.05383728139989755', 'Train Acc: 0.9913333333333333', 'Test Acc: 0.9897', 'Train LL: -0.027528582965211625', 'Test LL: -0.0306455139748506', 'Epoch Time (s): 165.24433084693737')
('Epoch 48', 'Objective: -0.05317817092590962', 'Train Acc: 0.9913166666666666', 'Test Acc: 0.9898', 'Train LL: -0.027115839591740316', 'Test LL: -0.031324779378172025', 'Epoch Time (s): 165.39663298195228')
('Epoch 49', 'Objective: -0.05271110899403593', 'Train Acc: 0.99145', 'Test Acc: 0.9887', 'Train LL: -0.026734312562440434', 'Test LL: -0.034457458650580836', 'Epoch Time (s): 165.21711043291725')
('Epoch 50', 'Objective: -0.05281375806685607', 'Train Acc: 0.9915166666666667', 'Test Acc: 0.9911', 'Train LL: -0.027071497124202933', 'Test LL: -0.027393355431334806', 'Epoch Time (s): 165.29452872788534')
('Epoch 51', 'Objective: -0.0518118357114283', 'Train Acc: 0.99155', 'Test Acc: 0.9904', 'Train LL: -0.026226481837737507', 'Test LL: -0.028990755827619254', 'Epoch Time (s): 165.2414665890392')
('Epoch 52', 'Objective: -0.05174625635767647', 'Train Acc: 0.9916', 'Test Acc: 0.9901', 'Train LL: -0.02611294240590311', 'Test LL: -0.028343326684251154', 'Epoch Time (s): 165.2513526759576')
('Epoch 53', 'Objective: -0.0517810741712602', 'Train Acc: 0.9913833333333333', 'Test Acc: 0.9905', 'Train LL: -0.026375723262472357', 'Test LL: -0.030579349975202917', 'Epoch Time (s): 165.2988288239576')
('Epoch 54', 'Objective: -0.05098173137603829', 'Train Acc: 0.9919166666666667', 'Test Acc: 0.9901', 'Train LL: -0.025585988272113128', 'Test LL: -0.029764880495013097', 'Epoch Time (s): 165.33168998686597')
('Epoch 55', 'Objective: -0.050545262253691346', 'Train Acc: 0.9918333333333333', 'Test Acc: 0.9895', 'Train LL: -0.025366012688118094', 'Test LL: -0.03279194659796659', 'Epoch Time (s): 165.2563829079736')
('Epoch 56', 'Objective: -0.05104328351901725', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9886', 'Train LL: -0.025826806802118372', 'Test LL: -0.03455537373721931', 'Epoch Time (s): 165.24229108006693')
('Epoch 57', 'Objective: -0.05082438310679231', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9897', 'Train LL: -0.025727961321047446', 'Test LL: -0.03080598000544615', 'Epoch Time (s): 165.28206806397066')
('Epoch 58', 'Objective: -0.0497040713793487', 'Train Acc: 0.9922333333333333', 'Test Acc: 0.9901', 'Train LL: -0.024842013770933553', 'Test LL: -0.030562495010098275', 'Epoch Time (s): 165.26061360700987')
('Epoch 59', 'Objective: -0.05016613383997352', 'Train Acc: 0.9918333333333333', 'Test Acc: 0.99', 'Train LL: -0.02528506621226021', 'Test LL: -0.029935923427489984', 'Epoch Time (s): 165.14899756317027')
('Epoch 60', 'Objective: -0.04948794220839739', 'Train Acc: 0.99195', 'Test Acc: 0.9896', 'Train LL: -0.02461034047958247', 'Test LL: -0.03225158411949377', 'Epoch Time (s): 165.24821888003498')
('Epoch 61', 'Objective: -0.04979003119999478', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.9911', 'Train LL: -0.024976558659045668', 'Test LL: -0.02823097059918157', 'Epoch Time (s): 165.3515977410134')
('Epoch 62', 'Objective: -0.0486992447888331', 'Train Acc: 0.99205', 'Test Acc: 0.9881', 'Train LL: -0.02399929860797416', 'Test LL: -0.03394400398720616', 'Epoch Time (s): 165.36033192509785')
('Epoch 63', 'Objective: -0.048494501139585276', 'Train Acc: 0.9922', 'Test Acc: 0.9912', 'Train LL: -0.02388522479663188', 'Test LL: -0.027449729189832503', 'Epoch Time (s): 165.2310298641678')
('Epoch 64', 'Objective: -0.04893009209967927', 'Train Acc: 0.9923', 'Test Acc: 0.9902', 'Train LL: -0.02439382553299224', 'Test LL: -0.03161281187413058', 'Epoch Time (s): 165.24706482002512')
('Epoch 65', 'Objective: -0.04914122540887448', 'Train Acc: 0.9920666666666667', 'Test Acc: 0.9891', 'Train LL: -0.024556058881460497', 'Test LL: -0.031504367826089806', 'Epoch Time (s): 165.21139053208753')
('Epoch 66', 'Objective: -0.0490425067194425', 'Train Acc: 0.9921', 'Test Acc: 0.9907', 'Train LL: -0.024485253897988227', 'Test LL: -0.028673896084271393', 'Epoch Time (s): 165.36334523698315')
('Epoch 67', 'Objective: -0.048322118401496', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9901', 'Train LL: -0.02390278845834684', 'Test LL: -0.03113137069090571', 'Epoch Time (s): 165.22668650792912')
('Epoch 68', 'Objective: -0.048057967732065554', 'Train Acc: 0.99205', 'Test Acc: 0.9901', 'Train LL: -0.02374762847365891', 'Test LL: -0.030197992170706227', 'Epoch Time (s): 165.28228659601882')
('Epoch 69', 'Objective: -0.04849706896641098', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9905', 'Train LL: -0.02416751994122557', 'Test LL: -0.029806206076399645', 'Epoch Time (s): 165.3356595749501')
('Epoch 70', 'Objective: -0.048711776221920404', 'Train Acc: 0.9922166666666666', 'Test Acc: 0.9902', 'Train LL: -0.024569705731538806', 'Test LL: -0.028708719766317427', 'Epoch Time (s): 165.2658271251712')
('Epoch 71', 'Objective: -0.04763163377305803', 'Train Acc: 0.9921833333333333', 'Test Acc: 0.9899', 'Train LL: -0.023489324556075903', 'Test LL: -0.031257676980162116', 'Epoch Time (s): 165.34493004903197')
('Epoch 72', 'Objective: -0.047089932791771254', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9892', 'Train LL: -0.022928649986993208', 'Test LL: -0.031744056382130646', 'Epoch Time (s): 165.4351417608559')
('Epoch 73', 'Objective: -0.04829001370880941', 'Train Acc: 0.9924', 'Test Acc: 0.9889', 'Train LL: -0.02412268725328825', 'Test LL: -0.03365693263625626', 'Epoch Time (s): 165.34436865500174')
('Epoch 74', 'Objective: -0.04788187738481371', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.9915', 'Train LL: -0.023773651868505725', 'Test LL: -0.027187044834511953', 'Epoch Time (s): 165.32129812496714')
('Epoch 75', 'Objective: -0.047134469906449365', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9894', 'Train LL: -0.023125738529532917', 'Test LL: -0.03276793773455188', 'Epoch Time (s): 165.35639457893558')
('Epoch 76', 'Objective: -0.04730913349169647', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9904', 'Train LL: -0.02340103594147962', 'Test LL: -0.028663481421097002', 'Epoch Time (s): 165.30219870386645')
('Epoch 77', 'Objective: -0.04715256081690682', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9895', 'Train LL: -0.0231983613815953', 'Test LL: -0.03300410247650981', 'Epoch Time (s): 165.30456436006352')
('Epoch 78', 'Objective: -0.046982156794513244', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9894', 'Train LL: -0.023038181668216952', 'Test LL: -0.031432948510038236', 'Epoch Time (s): 165.26518103620037')
('Epoch 79', 'Objective: -0.04657699641119456', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9891', 'Train LL: -0.02267979824139814', 'Test LL: -0.03290480298351318', 'Epoch Time (s): 165.2947632081341')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04500780668272472', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9898', 'Train LL: -0.02148152241917317', 'Test LL: -0.028694289069090655', 'Epoch Time (s): 165.40390970394947')
('Epoch 81', 'Objective: -0.04389597525934857', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9899', 'Train LL: -0.020409550439609993', 'Test LL: -0.028931903274101296', 'Epoch Time (s): 165.32852323306724')
('Epoch 82', 'Objective: -0.042962582441443097', 'Train Acc: 0.99375', 'Test Acc: 0.9895', 'Train LL: -0.019546317864692665', 'Test LL: -0.030010151216612813', 'Epoch Time (s): 165.35876352293417')
('Epoch 83', 'Objective: -0.043188926345595235', 'Train Acc: 0.99345', 'Test Acc: 0.9901', 'Train LL: -0.019748593342416104', 'Test LL: -0.02988341817503375', 'Epoch Time (s): 165.35568703501485')
('Epoch 84', 'Objective: -0.04284912073249364', 'Train Acc: 0.9936333333333334', 'Test Acc: 0.9899', 'Train LL: -0.019428229336448232', 'Test LL: -0.02912537219313542', 'Epoch Time (s): 165.33168440288864')
('Epoch 85', 'Objective: -0.0426697984777602', 'Train Acc: 0.99355', 'Test Acc: 0.99', 'Train LL: -0.019296801923123514', 'Test LL: -0.028788612058867284', 'Epoch Time (s): 165.3255433961749')
('Epoch 86', 'Objective: -0.04244573859399736', 'Train Acc: 0.9937', 'Test Acc: 0.99', 'Train LL: -0.019106927818310974', 'Test LL: -0.029827231780489724', 'Epoch Time (s): 165.30862964782864')
('Epoch 87', 'Objective: -0.042632602727760115', 'Train Acc: 0.9938', 'Test Acc: 0.9903', 'Train LL: -0.01924503203066353', 'Test LL: -0.028887465010129676', 'Epoch Time (s): 165.2850014618598')
('Epoch 88', 'Objective: -0.04278244290250095', 'Train Acc: 0.9938833333333333', 'Test Acc: 0.9905', 'Train LL: -0.01937633811098648', 'Test LL: -0.029289975181192175', 'Epoch Time (s): 165.27565786312334')
('Epoch 89', 'Objective: -0.04257749770876205', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9898', 'Train LL: -0.019202184721763573', 'Test LL: -0.029482927637557582', 'Epoch Time (s): 165.2664338508621')
('Epoch 90', 'Objective: -0.04228977795033356', 'Train Acc: 0.9938833333333333', 'Test Acc: 0.9902', 'Train LL: -0.018910439929294573', 'Test LL: -0.02873423190087498', 'Epoch Time (s): 165.18351991893724')
('Epoch 91', 'Objective: -0.04216102466252919', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9903', 'Train LL: -0.018828238044570567', 'Test LL: -0.028346594656568812', 'Epoch Time (s): 165.3156102790963')
('Epoch 92', 'Objective: -0.04247221389130893', 'Train Acc: 0.99395', 'Test Acc: 0.9905', 'Train LL: -0.01910090881671123', 'Test LL: -0.02923823751371243', 'Epoch Time (s): 165.28085126681253')
('Epoch 93', 'Objective: -0.0419480282640691', 'Train Acc: 0.9938333333333333', 'Test Acc: 0.9904', 'Train LL: -0.018590993331859103', 'Test LL: -0.028461202463072856', 'Epoch Time (s): 165.29659706610255')
('Epoch 94', 'Objective: -0.04320646336155164', 'Train Acc: 0.99355', 'Test Acc: 0.9902', 'Train LL: -0.019776738398402483', 'Test LL: -0.028566914139873653', 'Epoch Time (s): 165.29048101999797')
('Epoch 95', 'Objective: -0.04210345569168855', 'Train Acc: 0.9935333333333334', 'Test Acc: 0.9903', 'Train LL: -0.01874431009416093', 'Test LL: -0.028320411528918357', 'Epoch Time (s): 165.35573430894874')
('Epoch 96', 'Objective: -0.04214786255874955', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.9907', 'Train LL: -0.018857663237564624', 'Test LL: -0.02755510886281787', 'Epoch Time (s): 165.1894249219913')
('Epoch 97', 'Objective: -0.04204610208615929', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.9899', 'Train LL: -0.018696971459696815', 'Test LL: -0.02947527571193122', 'Epoch Time (s): 165.24020667397417')
('Epoch 98', 'Objective: -0.04217961606157341', 'Train Acc: 0.9939666666666667', 'Test Acc: 0.9904', 'Train LL: -0.018780166754176465', 'Test LL: -0.0287017375806739', 'Epoch Time (s): 165.10770823899657')
('Epoch 99', 'Objective: -0.042084246639463245', 'Train Acc: 0.9937', 'Test Acc: 0.9906', 'Train LL: -0.018698158674394283', 'Test LL: -0.02805703127529134', 'Epoch Time (s): 165.14606166887097')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04147980207139196
Final Train Accuracy: £0.9938166666666667
Final Train LL: £-0.01818144258531532
Final Test Accuracy: £0.9906
Final Test LL: £-0.02806662024333595
