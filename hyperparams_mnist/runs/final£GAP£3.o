dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3289265432468924', 'Train Acc: 0.5461', 'Test Acc: 0.7921', 'Train LL: -1.2741247600220669', 'Test LL: -0.6498329418439678', 'Epoch Time (s): 162.7351376740262')
('Epoch 1', 'Objective: -0.5764772660610948', 'Train Acc: 0.8221', 'Test Acc: 0.8145', 'Train LL: -0.5215412034383451', 'Test LL: -0.5597157759309477', 'Epoch Time (s): 162.91966799111106')
('Epoch 2', 'Objective: -0.3446874825776395', 'Train Acc: 0.90615', 'Test Acc: 0.9224', 'Train LL: -0.29367395729659973', 'Test LL: -0.23978230230145478', 'Epoch Time (s): 162.8387008330319')
('Epoch 3', 'Objective: -0.2546577768826573', 'Train Acc: 0.9350333333333334', 'Test Acc: 0.9591', 'Train LL: -0.20668457227437176', 'Test LL: -0.1336603720230957', 'Epoch Time (s): 162.93770632892847')
('Epoch 4', 'Objective: -0.21797230457299174', 'Train Acc: 0.9468333333333333', 'Test Acc: 0.9331', 'Train LL: -0.17298872768565351', 'Test LL: -0.2017683092725429', 'Epoch Time (s): 162.93154690391384')
('Epoch 5', 'Objective: -0.19607025324009497', 'Train Acc: 0.9528833333333333', 'Test Acc: 0.9404', 'Train LL: -0.15269685629274565', 'Test LL: -0.18965587639332357', 'Epoch Time (s): 162.95101540815085')
('Epoch 6', 'Objective: -0.18196651274553588', 'Train Acc: 0.9566166666666667', 'Test Acc: 0.9544', 'Train LL: -0.13992141920308282', 'Test LL: -0.13423933333333904', 'Epoch Time (s): 162.89934041094966')
('Epoch 7', 'Objective: -0.16975078899619817', 'Train Acc: 0.95925', 'Test Acc: 0.9683', 'Train LL: -0.1288484541582739', 'Test LL: -0.10457500090948058', 'Epoch Time (s): 162.95515075000003')
('Epoch 8', 'Objective: -0.16094482726797543', 'Train Acc: 0.96185', 'Test Acc: 0.9601', 'Train LL: -0.12090526397142295', 'Test LL: -0.12143712290211252', 'Epoch Time (s): 162.93498356593773')
('Epoch 9', 'Objective: -0.15091257613968512', 'Train Acc: 0.9644166666666667', 'Test Acc: 0.966', 'Train LL: -0.1118794546705503', 'Test LL: -0.09887082047954', 'Epoch Time (s): 162.88916942710057')
('Epoch 10', 'Objective: -0.1452035731302062', 'Train Acc: 0.9665666666666667', 'Test Acc: 0.9536', 'Train LL: -0.106868273139664', 'Test LL: -0.14302817375810445', 'Epoch Time (s): 162.94944999786094')
('Epoch 11', 'Objective: -0.14008347516988728', 'Train Acc: 0.96745', 'Test Acc: 0.9697', 'Train LL: -0.10201025370157633', 'Test LL: -0.098447207494459', 'Epoch Time (s): 162.92380617698655')
('Epoch 12', 'Objective: -0.1318421131090046', 'Train Acc: 0.97', 'Test Acc: 0.9705', 'Train LL: -0.09487951562385828', 'Test LL: -0.09275289134055058', 'Epoch Time (s): 162.90818346012384')
('Epoch 13', 'Objective: -0.12899380888260026', 'Train Acc: 0.9703666666666667', 'Test Acc: 0.9774', 'Train LL: -0.09261426368639655', 'Test LL: -0.07492633762163292', 'Epoch Time (s): 162.9039182951674')
('Epoch 14', 'Objective: -0.1228631987214363', 'Train Acc: 0.9722333333333333', 'Test Acc: 0.9781', 'Train LL: -0.08717392496878333', 'Test LL: -0.07131225072763664', 'Epoch Time (s): 162.93523213802837')
('Epoch 15', 'Objective: -0.11833812405871474', 'Train Acc: 0.9734333333333334', 'Test Acc: 0.9708', 'Train LL: -0.08330849007427926', 'Test LL: -0.0867667589449849', 'Epoch Time (s): 162.9040902061388')
('Epoch 16', 'Objective: -0.11680849980003997', 'Train Acc: 0.9742833333333333', 'Test Acc: 0.9799', 'Train LL: -0.08221026026448608', 'Test LL: -0.07060672706005344', 'Epoch Time (s): 162.8812530869618')
('Epoch 17', 'Objective: -0.11395545620946228', 'Train Acc: 0.9748166666666667', 'Test Acc: 0.9724', 'Train LL: -0.08009426932178024', 'Test LL: -0.08726824766722044', 'Epoch Time (s): 162.88140846812166')
('Epoch 18', 'Objective: -0.10868190618592485', 'Train Acc: 0.9764833333333334', 'Test Acc: 0.9797', 'Train LL: -0.07512249718843227', 'Test LL: -0.06057195510969714', 'Epoch Time (s): 162.88402934093028')
('Epoch 19', 'Objective: -0.1110524245346253', 'Train Acc: 0.9754666666666667', 'Test Acc: 0.9782', 'Train LL: -0.07780140070770336', 'Test LL: -0.06660050015053098', 'Epoch Time (s): 162.9151939409785')
('Epoch 20', 'Objective: -0.10610195952242352', 'Train Acc: 0.9763', 'Test Acc: 0.9662', 'Train LL: -0.07345117094406362', 'Test LL: -0.10894426306217914', 'Epoch Time (s): 162.9085475159809')
('Epoch 21', 'Objective: -0.10409236067532786', 'Train Acc: 0.9774666666666667', 'Test Acc: 0.9803', 'Train LL: -0.07167807176423342', 'Test LL: -0.062315309492456755', 'Epoch Time (s): 162.87134145502932')
('Epoch 22', 'Objective: -0.10084192154696325', 'Train Acc: 0.9777', 'Test Acc: 0.9809', 'Train LL: -0.06869965220537481', 'Test LL: -0.05669760838055432', 'Epoch Time (s): 162.84875482693315')
('Epoch 23', 'Objective: -0.10052384837289238', 'Train Acc: 0.9784333333333334', 'Test Acc: 0.9788', 'Train LL: -0.0687277280952302', 'Test LL: -0.06322813721991147', 'Epoch Time (s): 162.90898354398087')
('Epoch 24', 'Objective: -0.0990910378814216', 'Train Acc: 0.9790666666666666', 'Test Acc: 0.9801', 'Train LL: -0.06739863334285522', 'Test LL: -0.061470335971598504', 'Epoch Time (s): 162.90948934084736')
('Epoch 25', 'Objective: -0.09796220897412364', 'Train Acc: 0.9784333333333334', 'Test Acc: 0.9828', 'Train LL: -0.06666115275223604', 'Test LL: -0.05369210417686823', 'Epoch Time (s): 162.8937905849889')
('Epoch 26', 'Objective: -0.09331559329695091', 'Train Acc: 0.98035', 'Test Acc: 0.9816', 'Train LL: -0.06225435541778628', 'Test LL: -0.05757948579586809', 'Epoch Time (s): 162.9162849241402')
('Epoch 27', 'Objective: -0.09483814587542853', 'Train Acc: 0.9799666666666667', 'Test Acc: 0.9855', 'Train LL: -0.0640564671685421', 'Test LL: -0.04581439765645945', 'Epoch Time (s): 162.87213476886973')
('Epoch 28', 'Objective: -0.09179857328252866', 'Train Acc: 0.9803833333333334', 'Test Acc: 0.9761', 'Train LL: -0.06137351095629798', 'Test LL: -0.07352687793826156', 'Epoch Time (s): 162.95760384807363')
('Epoch 29', 'Objective: -0.09002858437622792', 'Train Acc: 0.98095', 'Test Acc: 0.9806', 'Train LL: -0.0598220330148569', 'Test LL: -0.058996714015364715', 'Epoch Time (s): 162.89685367699713')
('Epoch 30', 'Objective: -0.08921161622064713', 'Train Acc: 0.9815166666666667', 'Test Acc: 0.9885', 'Train LL: -0.059298905724076846', 'Test LL: -0.03905489577070528', 'Epoch Time (s): 162.9424088029191')
('Epoch 31', 'Objective: -0.08826219396027672', 'Train Acc: 0.98155', 'Test Acc: 0.9844', 'Train LL: -0.05870006734725985', 'Test LL: -0.05385344793541982', 'Epoch Time (s): 162.9602803150192')
('Epoch 32', 'Objective: -0.08736890143909148', 'Train Acc: 0.9816666666666667', 'Test Acc: 0.98', 'Train LL: -0.05808314125755175', 'Test LL: -0.059761635399589466', 'Epoch Time (s): 162.95646975119598')
('Epoch 33', 'Objective: -0.08570672374619', 'Train Acc: 0.9813666666666667', 'Test Acc: 0.9841', 'Train LL: -0.05667762356289509', 'Test LL: -0.050008547940776464', 'Epoch Time (s): 162.9533138370607')
('Epoch 34', 'Objective: -0.08570813879583378', 'Train Acc: 0.9825', 'Test Acc: 0.9849', 'Train LL: -0.05690583712203539', 'Test LL: -0.04492094029449912', 'Epoch Time (s): 162.971847421024')
('Epoch 35', 'Objective: -0.08542264946049676', 'Train Acc: 0.9822166666666666', 'Test Acc: 0.9828', 'Train LL: -0.05674205040161661', 'Test LL: -0.05487997528631388', 'Epoch Time (s): 162.9567097229883')
('Epoch 36', 'Objective: -0.08351814405337081', 'Train Acc: 0.9823', 'Test Acc: 0.9849', 'Train LL: -0.05532995395273993', 'Test LL: -0.05221827556594075', 'Epoch Time (s): 162.93753082980402')
('Epoch 37', 'Objective: -0.08275854362916571', 'Train Acc: 0.9824166666666667', 'Test Acc: 0.9842', 'Train LL: -0.05471326763342779', 'Test LL: -0.049120873755495675', 'Epoch Time (s): 162.95286394306459')
('Epoch 38', 'Objective: -0.0814857960443929', 'Train Acc: 0.9826166666666667', 'Test Acc: 0.9858', 'Train LL: -0.053564897488349486', 'Test LL: -0.047018224368958896', 'Epoch Time (s): 162.89520479296334')
('Epoch 39', 'Objective: -0.08070392687574426', 'Train Acc: 0.9836666666666667', 'Test Acc: 0.9842', 'Train LL: -0.052814676135231935', 'Test LL: -0.04934807038440097', 'Epoch Time (s): 162.88814041297883')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.058845011928450805', 'Train Acc: 0.9892833333333333', 'Test Acc: 0.9896', 'Train LL: -0.03297392029546991', 'Test LL: -0.030691488169315825', 'Epoch Time (s): 162.9892195109278')
('Epoch 41', 'Objective: -0.05361357871056513', 'Train Acc: 0.9910666666666667', 'Test Acc: 0.9896', 'Train LL: -0.028667594149347192', 'Test LL: -0.03044455409100217', 'Epoch Time (s): 162.89215842611156')
('Epoch 42', 'Objective: -0.05328977215413527', 'Train Acc: 0.99095', 'Test Acc: 0.9911', 'Train LL: -0.02881657874006854', 'Test LL: -0.026902911778374245', 'Epoch Time (s): 162.93310453998856')
('Epoch 43', 'Objective: -0.050600515848947154', 'Train Acc: 0.9911333333333333', 'Test Acc: 0.9897', 'Train LL: -0.026374840887893127', 'Test LL: -0.028475445004304697', 'Epoch Time (s): 162.93909024097957')
('Epoch 44', 'Objective: -0.050689109117128595', 'Train Acc: 0.9912333333333333', 'Test Acc: 0.9912', 'Train LL: -0.026768685267895297', 'Test LL: -0.02770455905318478', 'Epoch Time (s): 162.94298774306662')
('Epoch 45', 'Objective: -0.04939528885818897', 'Train Acc: 0.9918833333333333', 'Test Acc: 0.9896', 'Train LL: -0.025737436119019057', 'Test LL: -0.028441138971787325', 'Epoch Time (s): 162.88240636093542')
('Epoch 46', 'Objective: -0.04892175682966647', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9909', 'Train LL: -0.025352546891085005', 'Test LL: -0.027415487815722405', 'Epoch Time (s): 162.92850889102556')
('Epoch 47', 'Objective: -0.047773373055987466', 'Train Acc: 0.9920666666666667', 'Test Acc: 0.9905', 'Train LL: -0.024394133589538142', 'Test LL: -0.0287824941613444', 'Epoch Time (s): 162.943914441159')
('Epoch 48', 'Objective: -0.04822955759872718', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9912', 'Train LL: -0.025011033367883503', 'Test LL: -0.026756073693380508', 'Epoch Time (s): 162.93345385114662')
('Epoch 49', 'Objective: -0.04747821550369378', 'Train Acc: 0.9920833333333333', 'Test Acc: 0.9905', 'Train LL: -0.024464834328613835', 'Test LL: -0.02941924535773863', 'Epoch Time (s): 162.9677601151634')
('Epoch 50', 'Objective: -0.04694552936357171', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.992', 'Train LL: -0.024037182390220478', 'Test LL: -0.02431098579126368', 'Epoch Time (s): 162.9414698400069')
('Epoch 51', 'Objective: -0.04633017886376756', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9912', 'Train LL: -0.023568643511496873', 'Test LL: -0.026037240493968824', 'Epoch Time (s): 162.9151517630089')
('Epoch 52', 'Objective: -0.046720785352709494', 'Train Acc: 0.9923', 'Test Acc: 0.9911', 'Train LL: -0.024004345743260335', 'Test LL: -0.026713725678445394', 'Epoch Time (s): 162.9005545580294')
('Epoch 53', 'Objective: -0.04683475835974009', 'Train Acc: 0.9922', 'Test Acc: 0.9913', 'Train LL: -0.02426898944239086', 'Test LL: -0.025340426212124827', 'Epoch Time (s): 162.89561258396134')
('Epoch 54', 'Objective: -0.046014939931387264', 'Train Acc: 0.9924', 'Test Acc: 0.9913', 'Train LL: -0.023522276475928826', 'Test LL: -0.027650252765074497', 'Epoch Time (s): 162.90180983184837')
('Epoch 55', 'Objective: -0.04570607882085211', 'Train Acc: 0.99215', 'Test Acc: 0.9908', 'Train LL: -0.023324013431388048', 'Test LL: -0.030287346147488983', 'Epoch Time (s): 162.99723443877883')
('Epoch 56', 'Objective: -0.04559586814401803', 'Train Acc: 0.9925', 'Test Acc: 0.9896', 'Train LL: -0.02324262120936203', 'Test LL: -0.03182728377140873', 'Epoch Time (s): 162.91719447891228')
('Epoch 57', 'Objective: -0.045754122607793137', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.992', 'Train LL: -0.023501692376012413', 'Test LL: -0.02598202726963693', 'Epoch Time (s): 162.9365505850874')
('Epoch 58', 'Objective: -0.04436483315237018', 'Train Acc: 0.9928', 'Test Acc: 0.992', 'Train LL: -0.022308459815345464', 'Test LL: -0.023220736128523295', 'Epoch Time (s): 162.86836561211385')
('Epoch 59', 'Objective: -0.04458606591383552', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9915', 'Train LL: -0.02252835244481841', 'Test LL: -0.025828294339921523', 'Epoch Time (s): 162.87473792792298')
('Epoch 60', 'Objective: -0.04466003877660457', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.9893', 'Train LL: -0.022698273702363977', 'Test LL: -0.03086438939663256', 'Epoch Time (s): 162.90085966698825')
('Epoch 61', 'Objective: -0.04444536149637574', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9916', 'Train LL: -0.022561012975188848', 'Test LL: -0.02523062160025632', 'Epoch Time (s): 162.91316941403784')
('Epoch 62', 'Objective: -0.044450643681944214', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.9906', 'Train LL: -0.022697013797622578', 'Test LL: -0.029009972721260983', 'Epoch Time (s): 162.90825376007706')
('Epoch 63', 'Objective: -0.043859992595455', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9917', 'Train LL: -0.02208259402246506', 'Test LL: -0.024078007519579756', 'Epoch Time (s): 162.8759519411251')
('Epoch 64', 'Objective: -0.0432451927787871', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9914', 'Train LL: -0.021647433225085937', 'Test LL: -0.02608581236058639', 'Epoch Time (s): 162.8492828849703')
('Epoch 65', 'Objective: -0.043438535486144486', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9907', 'Train LL: -0.021750083895566204', 'Test LL: -0.0269077106033537', 'Epoch Time (s): 162.84174336097203')
('Epoch 66', 'Objective: -0.04382514548115285', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9917', 'Train LL: -0.022213684497986632', 'Test LL: -0.024354311214573942', 'Epoch Time (s): 162.89394450187683')
('Epoch 67', 'Objective: -0.04306571531262128', 'Train Acc: 0.9928166666666667', 'Test Acc: 0.9902', 'Train LL: -0.021528568242082578', 'Test LL: -0.028473524483175323', 'Epoch Time (s): 162.8631939040497')
('Epoch 68', 'Objective: -0.04268431682739805', 'Train Acc: 0.99305', 'Test Acc: 0.992', 'Train LL: -0.021305827720297377', 'Test LL: -0.02573730002431346', 'Epoch Time (s): 162.83556314487942')
('Epoch 69', 'Objective: -0.04284104149275041', 'Train Acc: 0.99315', 'Test Acc: 0.9918', 'Train LL: -0.021467489697402', 'Test LL: -0.0246819990312805', 'Epoch Time (s): 162.84804208995774')
('Epoch 70', 'Objective: -0.043374672014112756', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9914', 'Train LL: -0.022084699701512438', 'Test LL: -0.02535518508555026', 'Epoch Time (s): 162.80485423700884')
('Epoch 71', 'Objective: -0.042864391514960125', 'Train Acc: 0.993', 'Test Acc: 0.991', 'Train LL: -0.021682673365472204', 'Test LL: -0.026560611300216544', 'Epoch Time (s): 162.80039851390757')
('Epoch 72', 'Objective: -0.04261326226806179', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9907', 'Train LL: -0.02142985001637088', 'Test LL: -0.027962441932975594', 'Epoch Time (s): 162.8331286930479')
('Epoch 73', 'Objective: -0.04326382640581912', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9897', 'Train LL: -0.02211069721301123', 'Test LL: -0.03106695284603069', 'Epoch Time (s): 162.89904040796682')
('Epoch 74', 'Objective: -0.04223088370252021', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9917', 'Train LL: -0.02121509509683921', 'Test LL: -0.023513413715375055', 'Epoch Time (s): 162.88605388184078')
('Epoch 75', 'Objective: -0.04194496423850493', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.99', 'Train LL: -0.020894171737278977', 'Test LL: -0.030175534442168913', 'Epoch Time (s): 162.8667251279112')
('Epoch 76', 'Objective: -0.04197552724150612', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9922', 'Train LL: -0.021020848703274784', 'Test LL: -0.02331607679988162', 'Epoch Time (s): 162.89164789998904')
('Epoch 77', 'Objective: -0.041650193239103524', 'Train Acc: 0.9934333333333333', 'Test Acc: 0.991', 'Train LL: -0.020712826580680653', 'Test LL: -0.027194225856422997', 'Epoch Time (s): 162.8788449279964')
('Epoch 78', 'Objective: -0.04123421880735407', 'Train Acc: 0.9937333333333334', 'Test Acc: 0.9921', 'Train LL: -0.02027262786093918', 'Test LL: -0.02407943795448084', 'Epoch Time (s): 162.8735376179684')
('Epoch 79', 'Objective: -0.041185038651968466', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9903', 'Train LL: -0.020262134024156945', 'Test LL: -0.030337134147569868', 'Epoch Time (s): 162.87703173910268')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.03949080905623004', 'Train Acc: 0.9939166666666667', 'Test Acc: 0.9921', 'Train LL: -0.018799561458547456', 'Test LL: -0.02566453714570554', 'Epoch Time (s): 162.82631430006586')
('Epoch 81', 'Objective: -0.03810504026081213', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9923', 'Train LL: -0.01752498157053644', 'Test LL: -0.024420726784249915', 'Epoch Time (s): 162.85440393514')
('Epoch 82', 'Objective: -0.038048025747778824', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.9917', 'Train LL: -0.017445788436584224', 'Test LL: -0.025923846170680675', 'Epoch Time (s): 162.88096919190139')
('Epoch 83', 'Objective: -0.03762562013021309', 'Train Acc: 0.9947333333333334', 'Test Acc: 0.9921', 'Train LL: -0.01707194377020195', 'Test LL: -0.024923591551096264', 'Epoch Time (s): 162.90080588893034')
('Epoch 84', 'Objective: -0.038649569052443794', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9922', 'Train LL: -0.018020603531823835', 'Test LL: -0.025141879918119905', 'Epoch Time (s): 162.92118359077722')
('Epoch 85', 'Objective: -0.037547090620691004', 'Train Acc: 0.99475', 'Test Acc: 0.9921', 'Train LL: -0.017052136626923477', 'Test LL: -0.025029516022006253', 'Epoch Time (s): 162.90259042498656')
('Epoch 86', 'Objective: -0.037716438633225366', 'Train Acc: 0.99485', 'Test Acc: 0.9919', 'Train LL: -0.017189735085872793', 'Test LL: -0.025127085427252924', 'Epoch Time (s): 162.87275471305475')
('Epoch 87', 'Objective: -0.03706573379715127', 'Train Acc: 0.995', 'Test Acc: 0.9923', 'Train LL: -0.016547218287391988', 'Test LL: -0.024873932427876378', 'Epoch Time (s): 162.88394072605297')
('Epoch 88', 'Objective: -0.037494812000245764', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.9919', 'Train LL: -0.016937951100870315', 'Test LL: -0.02573198300627222', 'Epoch Time (s): 162.91196531406604')
('Epoch 89', 'Objective: -0.03727735410584279', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9917', 'Train LL: -0.016732857028979104', 'Test LL: -0.025338709050565823', 'Epoch Time (s): 162.87636835384183')
('Epoch 90', 'Objective: -0.03821560835243236', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9921', 'Train LL: -0.01760601949191202', 'Test LL: -0.025316361668809635', 'Epoch Time (s): 162.90849841502495')
('Epoch 91', 'Objective: -0.03781854030487014', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9917', 'Train LL: -0.017234403987101646', 'Test LL: -0.02573750124319376', 'Epoch Time (s): 162.8941710968502')
('Epoch 92', 'Objective: -0.03738858601771745', 'Train Acc: 0.9948', 'Test Acc: 0.9921', 'Train LL: -0.016865427215941683', 'Test LL: -0.02587507772080154', 'Epoch Time (s): 162.93848033901304')
('Epoch 93', 'Objective: -0.03692997676501362', 'Train Acc: 0.9950333333333333', 'Test Acc: 0.9918', 'Train LL: -0.016407785960628328', 'Test LL: -0.025975367998651484', 'Epoch Time (s): 162.84220242197625')
('Epoch 94', 'Objective: -0.03798061922035729', 'Train Acc: 0.9944166666666666', 'Test Acc: 0.9919', 'Train LL: -0.017419790032339462', 'Test LL: -0.025453907379235433', 'Epoch Time (s): 162.91129185282625')
('Epoch 95', 'Objective: -0.0372680903037433', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.9921', 'Train LL: -0.01678953337277839', 'Test LL: -0.02486464665526247', 'Epoch Time (s): 162.84713265113533')
('Epoch 96', 'Objective: -0.03741913359544576', 'Train Acc: 0.99495', 'Test Acc: 0.9923', 'Train LL: -0.01692813908116765', 'Test LL: -0.025014409042794863', 'Epoch Time (s): 162.90250146505423')
('Epoch 97', 'Objective: -0.036782140413635686', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.9918', 'Train LL: -0.01627980936479977', 'Test LL: -0.025719882534994964', 'Epoch Time (s): 162.85174306412227')
('Epoch 98', 'Objective: -0.037291462911004644', 'Train Acc: 0.9945', 'Test Acc: 0.9919', 'Train LL: -0.016769799704083686', 'Test LL: -0.025130196726067096', 'Epoch Time (s): 162.9058059589006')
('Epoch 99', 'Objective: -0.037213476145096326', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.992', 'Train LL: -0.016707498668236793', 'Test LL: -0.024701775289567542', 'Epoch Time (s): 162.8501941380091')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.036579265863368134
Final Train Accuracy: £0.9949166666666667
Final Train LL: £-0.01608162264875039
Final Test Accuracy: £0.9924
Final Test LL: £-0.024655043812709714
