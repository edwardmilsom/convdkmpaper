dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: none
bn_tscale: none
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.333052139214761', 'Train Acc: 0.5411', 'Test Acc: 0.7699', 'Train LL: -1.2806824032588657', 'Test LL: -0.7141882749813488', 'Epoch Time (s): 161.57637855410576')
('Epoch 1', 'Objective: -0.5733998322328716', 'Train Acc: 0.8244666666666667', 'Test Acc: 0.8887', 'Train LL: -0.5207964579249723', 'Test LL: -0.3466276848598077', 'Epoch Time (s): 161.61332361097448')
('Epoch 2', 'Objective: -0.33895449041376297', 'Train Acc: 0.9099', 'Test Acc: 0.8975', 'Train LL: -0.2863819308066549', 'Test LL: -0.3040869304499993', 'Epoch Time (s): 161.47726607113145')
('Epoch 3', 'Objective: -0.2576526961483918', 'Train Acc: 0.9346', 'Test Acc: 0.9477', 'Train LL: -0.20921952395059545', 'Test LL: -0.16852790685079758', 'Epoch Time (s): 161.4878263210412')
('Epoch 4', 'Objective: -0.2164611444027045', 'Train Acc: 0.9465', 'Test Acc: 0.9459', 'Train LL: -0.17055117911920253', 'Test LL: -0.17736616355027368', 'Epoch Time (s): 161.5060402888339')
('Epoch 5', 'Objective: -0.19312516694556858', 'Train Acc: 0.9538666666666666', 'Test Acc: 0.9598', 'Train LL: -0.14914253919497045', 'Test LL: -0.12221242682308026', 'Epoch Time (s): 161.52267604204826')
('Epoch 6', 'Objective: -0.17327197999861207', 'Train Acc: 0.9586833333333333', 'Test Acc: 0.9535', 'Train LL: -0.13110930703420764', 'Test LL: -0.14665196660322394', 'Epoch Time (s): 161.50058290199377')
('Epoch 7', 'Objective: -0.1668551002594627', 'Train Acc: 0.9606666666666667', 'Test Acc: 0.9741', 'Train LL: -0.1253651771610207', 'Test LL: -0.08233713472237703', 'Epoch Time (s): 161.49802296212874')
('Epoch 8', 'Objective: -0.15431900302682477', 'Train Acc: 0.9645833333333333', 'Test Acc: 0.9702', 'Train LL: -0.11388387429243896', 'Test LL: -0.08609486059933016', 'Epoch Time (s): 161.49184755398892')
('Epoch 9', 'Objective: -0.1465070758518534', 'Train Acc: 0.9658833333333333', 'Test Acc: 0.97', 'Train LL: -0.1067731961374907', 'Test LL: -0.09225337718192818', 'Epoch Time (s): 161.8126475000754')
('Epoch 10', 'Objective: -0.13790612395630736', 'Train Acc: 0.9678666666666667', 'Test Acc: 0.9712', 'Train LL: -0.09901195555578395', 'Test LL: -0.0888587383168448', 'Epoch Time (s): 161.8400153820403')
('Epoch 11', 'Objective: -0.13468954237082684', 'Train Acc: 0.9694166666666667', 'Test Acc: 0.9733', 'Train LL: -0.09626880396782975', 'Test LL: -0.08609930506717278', 'Epoch Time (s): 161.6719082170166')
('Epoch 12', 'Objective: -0.12739166133393046', 'Train Acc: 0.9720833333333333', 'Test Acc: 0.9727', 'Train LL: -0.08960600327215947', 'Test LL: -0.09030182048212258', 'Epoch Time (s): 161.6780619600322')
('Epoch 13', 'Objective: -0.12200176500973244', 'Train Acc: 0.97295', 'Test Acc: 0.9765', 'Train LL: -0.08522672086378164', 'Test LL: -0.07439149177102845', 'Epoch Time (s): 161.67802942800336')
('Epoch 14', 'Objective: -0.11958953942109218', 'Train Acc: 0.9736833333333333', 'Test Acc: 0.9759', 'Train LL: -0.08309297959006653', 'Test LL: -0.07383695178628963', 'Epoch Time (s): 161.65386617509648')
('Epoch 15', 'Objective: -0.11357817066091995', 'Train Acc: 0.9752833333333333', 'Test Acc: 0.9719', 'Train LL: -0.07780427418125564', 'Test LL: -0.08907968170122481', 'Epoch Time (s): 161.64782360591926')
('Epoch 16', 'Objective: -0.11178206368290643', 'Train Acc: 0.9754666666666667', 'Test Acc: 0.9766', 'Train LL: -0.07641525438047722', 'Test LL: -0.07033652826996724', 'Epoch Time (s): 161.6775372060947')
('Epoch 17', 'Objective: -0.1111767803250582', 'Train Acc: 0.9759166666666667', 'Test Acc: 0.9825', 'Train LL: -0.07621411348831214', 'Test LL: -0.055413589263783355', 'Epoch Time (s): 161.6848217868246')
('Epoch 18', 'Objective: -0.10598996370182896', 'Train Acc: 0.9776333333333334', 'Test Acc: 0.9787', 'Train LL: -0.07181208835706893', 'Test LL: -0.06441931312731398', 'Epoch Time (s): 161.6876002890058')
('Epoch 19', 'Objective: -0.10799622527190209', 'Train Acc: 0.9760833333333333', 'Test Acc: 0.975', 'Train LL: -0.07374688194800959', 'Test LL: -0.07834884795673965', 'Epoch Time (s): 161.7622046309989')
('Epoch 20', 'Objective: -0.10300378296421081', 'Train Acc: 0.9781333333333333', 'Test Acc: 0.9724', 'Train LL: -0.06917273267997243', 'Test LL: -0.08745611176488131', 'Epoch Time (s): 161.70444703404792')
('Epoch 21', 'Objective: -0.10138959071585771', 'Train Acc: 0.9782', 'Test Acc: 0.9828', 'Train LL: -0.06778512832014501', 'Test LL: -0.05441522827702354', 'Epoch Time (s): 161.70729161705822')
('Epoch 22', 'Objective: -0.0992579565596595', 'Train Acc: 0.9791666666666666', 'Test Acc: 0.9804', 'Train LL: -0.0661729782924488', 'Test LL: -0.06801784975290946', 'Epoch Time (s): 161.69741776492447')
('Epoch 23', 'Objective: -0.0978532929941605', 'Train Acc: 0.9789833333333333', 'Test Acc: 0.9802', 'Train LL: -0.06486374208678516', 'Test LL: -0.05907545055599259', 'Epoch Time (s): 161.71306785102934')
('Epoch 24', 'Objective: -0.09659120775900505', 'Train Acc: 0.9797666666666667', 'Test Acc: 0.982', 'Train LL: -0.06391958838486834', 'Test LL: -0.05958541911552937', 'Epoch Time (s): 161.67132131382823')
('Epoch 25', 'Objective: -0.09411320508458908', 'Train Acc: 0.9809', 'Test Acc: 0.9799', 'Train LL: -0.061907511345185885', 'Test LL: -0.06053096099373797', 'Epoch Time (s): 161.70056990114972')
('Epoch 26', 'Objective: -0.09442975924422724', 'Train Acc: 0.9806', 'Test Acc: 0.9828', 'Train LL: -0.062459074725644784', 'Test LL: -0.054135449511302815', 'Epoch Time (s): 161.7436680831015')
('Epoch 27', 'Objective: -0.09201219965276658', 'Train Acc: 0.9806666666666667', 'Test Acc: 0.9829', 'Train LL: -0.06029842100618737', 'Test LL: -0.052018333597889696', 'Epoch Time (s): 161.69989715889096')
('Epoch 28', 'Objective: -0.09243442103182822', 'Train Acc: 0.9805833333333334', 'Test Acc: 0.9793', 'Train LL: -0.06093698101043168', 'Test LL: -0.05994691842613356', 'Epoch Time (s): 161.67388450005092')
('Epoch 29', 'Objective: -0.09101661805752229', 'Train Acc: 0.9812833333333333', 'Test Acc: 0.9795', 'Train LL: -0.059626871921499104', 'Test LL: -0.06717958493553586', 'Epoch Time (s): 161.70630432106555')
('Epoch 30', 'Objective: -0.09112660440726142', 'Train Acc: 0.9811', 'Test Acc: 0.9827', 'Train LL: -0.059901034188698674', 'Test LL: -0.05524690634765451', 'Epoch Time (s): 161.7770964601077')
('Epoch 31', 'Objective: -0.08804950814824816', 'Train Acc: 0.9816333333333334', 'Test Acc: 0.9806', 'Train LL: -0.05702806122447434', 'Test LL: -0.056720838207827924', 'Epoch Time (s): 161.67541651194915')
('Epoch 32', 'Objective: -0.08766642489881507', 'Train Acc: 0.9822666666666666', 'Test Acc: 0.9819', 'Train LL: -0.057000187672993696', 'Test LL: -0.05972105050117955', 'Epoch Time (s): 161.70513984793797')
('Epoch 33', 'Objective: -0.08706920175179929', 'Train Acc: 0.9821', 'Test Acc: 0.9863', 'Train LL: -0.056498986655398424', 'Test LL: -0.042108248527760656', 'Epoch Time (s): 161.670518389903')
('Epoch 34', 'Objective: -0.08588579499196913', 'Train Acc: 0.9819833333333333', 'Test Acc: 0.983', 'Train LL: -0.05546005461620751', 'Test LL: -0.05577782516166368', 'Epoch Time (s): 161.68474981701002')
('Epoch 35', 'Objective: -0.08517606244163843', 'Train Acc: 0.9824', 'Test Acc: 0.9788', 'Train LL: -0.054951148626765374', 'Test LL: -0.06683393178087862', 'Epoch Time (s): 161.6560208729934')
('Epoch 36', 'Objective: -0.08433543606836647', 'Train Acc: 0.9827666666666667', 'Test Acc: 0.9843', 'Train LL: -0.054381333927805114', 'Test LL: -0.04833394731638402', 'Epoch Time (s): 161.68723627808504')
('Epoch 37', 'Objective: -0.08401908663680632', 'Train Acc: 0.98235', 'Test Acc: 0.9797', 'Train LL: -0.05401957272526766', 'Test LL: -0.06037928749296297', 'Epoch Time (s): 161.68652990390547')
('Epoch 38', 'Objective: -0.08255562000303028', 'Train Acc: 0.9833166666666666', 'Test Acc: 0.9865', 'Train LL: -0.05246771239427095', 'Test LL: -0.04177068750517055', 'Epoch Time (s): 161.71153652807698')
('Epoch 39', 'Objective: -0.0811138316517108', 'Train Acc: 0.98375', 'Test Acc: 0.9845', 'Train LL: -0.05165487237785635', 'Test LL: -0.048940277978968064', 'Epoch Time (s): 161.63966907607391')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06165238244591295', 'Train Acc: 0.9894666666666667', 'Test Acc: 0.9892', 'Train LL: -0.03385676043716798', 'Test LL: -0.03341521067291112', 'Epoch Time (s): 161.69035470392555')
('Epoch 41', 'Objective: -0.05643052668721123', 'Train Acc: 0.9906666666666667', 'Test Acc: 0.9903', 'Train LL: -0.029687763615226435', 'Test LL: -0.03234406531945686', 'Epoch Time (s): 161.6810246258974')
('Epoch 42', 'Objective: -0.05504770275896066', 'Train Acc: 0.9906666666666667', 'Test Acc: 0.9893', 'Train LL: -0.028725137489719964', 'Test LL: -0.03347670386425538', 'Epoch Time (s): 161.71146814804524')
('Epoch 43', 'Objective: -0.053478563159049364', 'Train Acc: 0.9912166666666666', 'Test Acc: 0.9895', 'Train LL: -0.027363010469088084', 'Test LL: -0.03354752203530258', 'Epoch Time (s): 161.6776979630813')
('Epoch 44', 'Objective: -0.05319190294242178', 'Train Acc: 0.9913', 'Test Acc: 0.9905', 'Train LL: -0.02726228005635506', 'Test LL: -0.03071171222876901', 'Epoch Time (s): 161.73441273299977')
('Epoch 45', 'Objective: -0.0515021809435501', 'Train Acc: 0.99195', 'Test Acc: 0.9906', 'Train LL: -0.025883301787069976', 'Test LL: -0.03161690118725733', 'Epoch Time (s): 161.68811542796902')
('Epoch 46', 'Objective: -0.05164123122117371', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9896', 'Train LL: -0.026121097630380646', 'Test LL: -0.03523436009246751', 'Epoch Time (s): 161.70016290899366')
('Epoch 47', 'Objective: -0.05185945062680614', 'Train Acc: 0.9916333333333334', 'Test Acc: 0.9897', 'Train LL: -0.026405361472661478', 'Test LL: -0.03419017368811507', 'Epoch Time (s): 161.72414605901577')
('Epoch 48', 'Objective: -0.05103387604783777', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9908', 'Train LL: -0.025784009020250482', 'Test LL: -0.030440279195364985', 'Epoch Time (s): 161.69066048203968')
('Epoch 49', 'Objective: -0.050599184438133285', 'Train Acc: 0.9920833333333333', 'Test Acc: 0.9897', 'Train LL: -0.025478584467394223', 'Test LL: -0.03345256266090223', 'Epoch Time (s): 161.6932103119325')
('Epoch 50', 'Objective: -0.050469360026209095', 'Train Acc: 0.99205', 'Test Acc: 0.9908', 'Train LL: -0.025454731317868136', 'Test LL: -0.028372440497073628', 'Epoch Time (s): 161.66744036390446')
('Epoch 51', 'Objective: -0.04978410816825671', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9898', 'Train LL: -0.02482566511645588', 'Test LL: -0.03385870659052185', 'Epoch Time (s): 161.70148168806918')
('Epoch 52', 'Objective: -0.04990378322577567', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9906', 'Train LL: -0.024988971970928038', 'Test LL: -0.030718942765196884', 'Epoch Time (s): 161.66377444192767')
('Epoch 53', 'Objective: -0.04872947905599578', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9909', 'Train LL: -0.02405622374383961', 'Test LL: -0.029214469079573625', 'Epoch Time (s): 161.6569449689705')
('Epoch 54', 'Objective: -0.04911704185099035', 'Train Acc: 0.99225', 'Test Acc: 0.991', 'Train LL: -0.02447719907444146', 'Test LL: -0.030230356427487424', 'Epoch Time (s): 161.65559826605022')
('Epoch 55', 'Objective: -0.047846468272956307', 'Train Acc: 0.9925', 'Test Acc: 0.9904', 'Train LL: -0.02327183000675237', 'Test LL: -0.031018185187288345', 'Epoch Time (s): 161.6707562978845')
('Epoch 56', 'Objective: -0.04825795968085963', 'Train Acc: 0.9924', 'Test Acc: 0.9913', 'Train LL: -0.02372402954209296', 'Test LL: -0.02870976703853023', 'Epoch Time (s): 161.68108129501343')
('Epoch 57', 'Objective: -0.04809055970739326', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9894', 'Train LL: -0.023695873131307638', 'Test LL: -0.03331031117052734', 'Epoch Time (s): 161.6643415929284')
('Epoch 58', 'Objective: -0.04799815072323451', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.99', 'Train LL: -0.023620217208098575', 'Test LL: -0.031131634315492793', 'Epoch Time (s): 161.66532652894966')
('Epoch 59', 'Objective: -0.04814954051029535', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.99', 'Train LL: -0.02387048768751656', 'Test LL: -0.032601123810338584', 'Epoch Time (s): 161.67698036693037')
('Epoch 60', 'Objective: -0.04796001764882475', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9899', 'Train LL: -0.02377862519894262', 'Test LL: -0.03178583582848545', 'Epoch Time (s): 161.66762198600918')
('Epoch 61', 'Objective: -0.0475884810032033', 'Train Acc: 0.9925666666666667', 'Test Acc: 0.99', 'Train LL: -0.023398696950708398', 'Test LL: -0.032156131844092536', 'Epoch Time (s): 161.6586429080926')
('Epoch 62', 'Objective: -0.047054030390325505', 'Train Acc: 0.9927', 'Test Acc: 0.9899', 'Train LL: -0.022937499185212002', 'Test LL: -0.033048980604990674', 'Epoch Time (s): 161.65393403894268')
('Epoch 63', 'Objective: -0.04675516009639698', 'Train Acc: 0.9926', 'Test Acc: 0.9904', 'Train LL: -0.022715903928194347', 'Test LL: -0.032458212371078', 'Epoch Time (s): 161.68332719616592')
('Epoch 64', 'Objective: -0.04667422360198095', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9911', 'Train LL: -0.022678695940427936', 'Test LL: -0.028649296769587464', 'Epoch Time (s): 161.64929468999617')
('Epoch 65', 'Objective: -0.047245112089020554', 'Train Acc: 0.99265', 'Test Acc: 0.9909', 'Train LL: -0.023298198573253416', 'Test LL: -0.028381072328876458', 'Epoch Time (s): 161.6867545028217')
('Epoch 66', 'Objective: -0.047218256405873786', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9893', 'Train LL: -0.023292150958517718', 'Test LL: -0.03297949837561665', 'Epoch Time (s): 161.65898368693888')
('Epoch 67', 'Objective: -0.046736188855041445', 'Train Acc: 0.9928166666666667', 'Test Acc: 0.9901', 'Train LL: -0.022896991079728264', 'Test LL: -0.031710360409601596', 'Epoch Time (s): 161.67750831018202')
('Epoch 68', 'Objective: -0.04687625931592406', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9906', 'Train LL: -0.023012212922280503', 'Test LL: -0.029941766943835466', 'Epoch Time (s): 161.63842546194792')
('Epoch 69', 'Objective: -0.04597873063959702', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9887', 'Train LL: -0.022207601271499795', 'Test LL: -0.03302268536109132', 'Epoch Time (s): 161.64799468102865')
('Epoch 70', 'Objective: -0.04593692219854314', 'Train Acc: 0.9933833333333333', 'Test Acc: 0.9905', 'Train LL: -0.022226438986710905', 'Test LL: -0.03020735236235169', 'Epoch Time (s): 161.63699499121867')
('Epoch 71', 'Objective: -0.04643255907502806', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9895', 'Train LL: -0.022755515485095624', 'Test LL: -0.032135301149729345', 'Epoch Time (s): 161.65749011188745')
('Epoch 72', 'Objective: -0.0451547844051776', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9887', 'Train LL: -0.021583158907175853', 'Test LL: -0.03655240237916374', 'Epoch Time (s): 161.68574920785613')
('Epoch 73', 'Objective: -0.04541331722003667', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9893', 'Train LL: -0.021732552852187993', 'Test LL: -0.03492801526973027', 'Epoch Time (s): 161.68334430386312')
('Epoch 74', 'Objective: -0.045116700695423596', 'Train Acc: 0.9933', 'Test Acc: 0.9898', 'Train LL: -0.021568912166630816', 'Test LL: -0.03338662575869934', 'Epoch Time (s): 161.67547703604214')
('Epoch 75', 'Objective: -0.04545486148153795', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9894', 'Train LL: -0.021889334981838673', 'Test LL: -0.03133095751807277', 'Epoch Time (s): 161.69610224105418')
('Epoch 76', 'Objective: -0.04553002691840767', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9902', 'Train LL: -0.02204006534885515', 'Test LL: -0.03119344075097089', 'Epoch Time (s): 161.67733023990877')
('Epoch 77', 'Objective: -0.045185364559309146', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9884', 'Train LL: -0.021737492533435914', 'Test LL: -0.035363062927278796', 'Epoch Time (s): 161.68473390000872')
('Epoch 78', 'Objective: -0.0452523918137265', 'Train Acc: 0.9931833333333333', 'Test Acc: 0.9907', 'Train LL: -0.021843702759258902', 'Test LL: -0.03092332662986131', 'Epoch Time (s): 161.66561713605188')
('Epoch 79', 'Objective: -0.04512037657500049', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9907', 'Train LL: -0.021760117516930588', 'Test LL: -0.02826618317366847', 'Epoch Time (s): 161.64803949813358')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.042645959617945824', 'Train Acc: 0.9938166666666667', 'Test Acc: 0.9902', 'Train LL: -0.01951485115453342', 'Test LL: -0.02922562706974183', 'Epoch Time (s): 161.69115709001198')
('Epoch 81', 'Objective: -0.04161069013706379', 'Train Acc: 0.9942', 'Test Acc: 0.9899', 'Train LL: -0.018550866850762834', 'Test LL: -0.029981395537481546', 'Epoch Time (s): 161.709570719162')
('Epoch 82', 'Objective: -0.04167360952924866', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9902', 'Train LL: -0.01859856543185698', 'Test LL: -0.029495666475799077', 'Epoch Time (s): 161.64389066002332')
('Epoch 83', 'Objective: -0.041642192487786764', 'Train Acc: 0.99425', 'Test Acc: 0.99', 'Train LL: -0.018549247647065756', 'Test LL: -0.030031056262174', 'Epoch Time (s): 161.67945041391067')
('Epoch 84', 'Objective: -0.04128290425511906', 'Train Acc: 0.9942', 'Test Acc: 0.9899', 'Train LL: -0.01821494446613325', 'Test LL: -0.03011034509092666', 'Epoch Time (s): 161.78927425900474')
('Epoch 85', 'Objective: -0.041514979783410684', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.9901', 'Train LL: -0.018432967799596568', 'Test LL: -0.029614606863580365', 'Epoch Time (s): 161.73403738508932')
('Epoch 86', 'Objective: -0.04124245721030304', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9901', 'Train LL: -0.018170002962052192', 'Test LL: -0.030158363783880794', 'Epoch Time (s): 161.67779062013142')
('Epoch 87', 'Objective: -0.04143177131414904', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.9899', 'Train LL: -0.018378408425759163', 'Test LL: -0.029244613951199483', 'Epoch Time (s): 161.74687834689394')
('Epoch 88', 'Objective: -0.041148398762959254', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.9902', 'Train LL: -0.018121630915499235', 'Test LL: -0.029408142302476556', 'Epoch Time (s): 161.685905642109')
('Epoch 89', 'Objective: -0.04164844452344966', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9897', 'Train LL: -0.01858624113374871', 'Test LL: -0.029617257577396906', 'Epoch Time (s): 161.69360565696843')
('Epoch 90', 'Objective: -0.0416622419890815', 'Train Acc: 0.99445', 'Test Acc: 0.9901', 'Train LL: -0.01860607389970595', 'Test LL: -0.029107167476220934', 'Epoch Time (s): 161.69049322698265')
('Epoch 91', 'Objective: -0.04168969365464632', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.9901', 'Train LL: -0.018637378971612523', 'Test LL: -0.029362068571893992', 'Epoch Time (s): 161.72099566599354')
('Epoch 92', 'Objective: -0.04076709414073473', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9897', 'Train LL: -0.017799023495011383', 'Test LL: -0.03059403990574863', 'Epoch Time (s): 161.72472304315306')
('Epoch 93', 'Objective: -0.040956424596424616', 'Train Acc: 0.9944', 'Test Acc: 0.9899', 'Train LL: -0.017963677922391407', 'Test LL: -0.0300740767296679', 'Epoch Time (s): 161.70526446402073')
('Epoch 94', 'Objective: -0.04081027446079035', 'Train Acc: 0.9945', 'Test Acc: 0.9899', 'Train LL: -0.017815484822763746', 'Test LL: -0.029845028748615113', 'Epoch Time (s): 161.72505775094032')
('Epoch 95', 'Objective: -0.04063083239702342', 'Train Acc: 0.9946166666666667', 'Test Acc: 0.99', 'Train LL: -0.01765277315983716', 'Test LL: -0.029393206048604726', 'Epoch Time (s): 161.73552026506513')
('Epoch 96', 'Objective: -0.040912074441820434', 'Train Acc: 0.99445', 'Test Acc: 0.9898', 'Train LL: -0.017920604842503497', 'Test LL: -0.030791005001204165', 'Epoch Time (s): 161.79913963004947')
('Epoch 97', 'Objective: -0.04055860401363692', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9901', 'Train LL: -0.01758517867460749', 'Test LL: -0.029869957347607147', 'Epoch Time (s): 161.6663395301439')
('Epoch 98', 'Objective: -0.041508387952063554', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.99', 'Train LL: -0.01848233383358786', 'Test LL: -0.028962360024966004', 'Epoch Time (s): 161.80207373085432')
('Epoch 99', 'Objective: -0.04106883636416236', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9904', 'Train LL: -0.01810037497570388', 'Test LL: -0.028887631164168193', 'Epoch Time (s): 161.6878270728048')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.040229071401650905
Final Train Accuracy: £0.9948333333333333
Final Train LL: £-0.017317223517135764
Final Test Accuracy: £0.9902
Final Test LL: £-0.0288317602470959
