dataset: MNIST
dtype: float64
dof: 0.001
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2515875303512018', 'Train Acc: 0.56415', 'Test Acc: 0.8016', 'Train LL: -1.217404419719516', 'Test LL: -0.581974889552795', 'Epoch Time (s): 171.6586835309863')
('Epoch 1', 'Objective: -0.46309161066053245', 'Train Acc: 0.84985', 'Test Acc: 0.8814', 'Train LL: -0.44575165677300793', 'Test LL: -0.37152180117075384', 'Epoch Time (s): 170.56866802182049')
('Epoch 2', 'Objective: -0.24584508473633168', 'Train Acc: 0.9270166666666667', 'Test Acc: 0.9516', 'Train LL: -0.2333796363224396', 'Test LL: -0.16537867329716535', 'Epoch Time (s): 170.51309710228816')
('Epoch 3', 'Objective: -0.17682388409861954', 'Train Acc: 0.9475', 'Test Acc: 0.9543', 'Train LL: -0.16680450037147743', 'Test LL: -0.14140531180872082', 'Epoch Time (s): 170.5381208183244')
('Epoch 4', 'Objective: -0.15101269072876564', 'Train Acc: 0.9551', 'Test Acc: 0.9567', 'Train LL: -0.1419797179802016', 'Test LL: -0.1388212431024575', 'Epoch Time (s): 170.5802710042335')
('Epoch 5', 'Objective: -0.13369245170691726', 'Train Acc: 0.9605666666666667', 'Test Acc: 0.9572', 'Train LL: -0.12541452736573558', 'Test LL: -0.13323010397738702', 'Epoch Time (s): 170.53913920605555')
('Epoch 6', 'Objective: -0.11975340499146889', 'Train Acc: 0.96475', 'Test Acc: 0.9724', 'Train LL: -0.11193311667569153', 'Test LL: -0.08558879481490332', 'Epoch Time (s): 170.55406918097287')
('Epoch 7', 'Objective: -0.10641294587885564', 'Train Acc: 0.9688', 'Test Acc: 0.9727', 'Train LL: -0.09912167991491118', 'Test LL: -0.08356352616367974', 'Epoch Time (s): 170.52295054495335')
('Epoch 8', 'Objective: -0.09978587231974691', 'Train Acc: 0.9702333333333333', 'Test Acc: 0.967', 'Train LL: -0.0928587048218672', 'Test LL: -0.09864587304202435', 'Epoch Time (s): 170.5438323454')
('Epoch 9', 'Objective: -0.09206471741128325', 'Train Acc: 0.9728666666666667', 'Test Acc: 0.9668', 'Train LL: -0.0853392032885972', 'Test LL: -0.10106935094856488', 'Epoch Time (s): 170.52632173802704')
('Epoch 10', 'Objective: -0.08895612774394478', 'Train Acc: 0.9738833333333333', 'Test Acc: 0.9735', 'Train LL: -0.08242791350497213', 'Test LL: -0.08440224809112663', 'Epoch Time (s): 170.53793937712908')
('Epoch 11', 'Objective: -0.08499177083818397', 'Train Acc: 0.9748166666666667', 'Test Acc: 0.9745', 'Train LL: -0.07878293354262104', 'Test LL: -0.07760248202447788', 'Epoch Time (s): 170.60322067001835')
('Epoch 12', 'Objective: -0.08071867536488533', 'Train Acc: 0.9761333333333333', 'Test Acc: 0.9762', 'Train LL: -0.07467248302135683', 'Test LL: -0.07474253064243917', 'Epoch Time (s): 170.5347634870559')
('Epoch 13', 'Objective: -0.07765881088201605', 'Train Acc: 0.9772666666666666', 'Test Acc: 0.9767', 'Train LL: -0.07183097684881894', 'Test LL: -0.06794233055560799', 'Epoch Time (s): 170.54979053372517')
('Epoch 14', 'Objective: -0.07349977020474426', 'Train Acc: 0.9787', 'Test Acc: 0.9799', 'Train LL: -0.06787629821097767', 'Test LL: -0.06388553550811144', 'Epoch Time (s): 170.5481968326494')
('Epoch 15', 'Objective: -0.07216758024577188', 'Train Acc: 0.9788', 'Test Acc: 0.9795', 'Train LL: -0.06666587446571079', 'Test LL: -0.0593375533295845', 'Epoch Time (s): 170.51337042683735')
('Epoch 16', 'Objective: -0.07056641534828244', 'Train Acc: 0.9791', 'Test Acc: 0.9809', 'Train LL: -0.06515648318908934', 'Test LL: -0.06280903128923986', 'Epoch Time (s): 170.52089455071837')
('Epoch 17', 'Objective: -0.06941151249279638', 'Train Acc: 0.9792833333333333', 'Test Acc: 0.9862', 'Train LL: -0.06410073661342403', 'Test LL: -0.04543137485453032', 'Epoch Time (s): 170.55571079812944')
('Epoch 18', 'Objective: -0.06551335752102391', 'Train Acc: 0.9803833333333334', 'Test Acc: 0.98', 'Train LL: -0.0603972799162351', 'Test LL: -0.0628988128541793', 'Epoch Time (s): 170.5804333202541')
('Epoch 19', 'Objective: -0.06505717590808771', 'Train Acc: 0.9806166666666667', 'Test Acc: 0.9795', 'Train LL: -0.06007184441442788', 'Test LL: -0.06098611837566051', 'Epoch Time (s): 170.50926837604493')
('Epoch 20', 'Objective: -0.06341494846879825', 'Train Acc: 0.9812', 'Test Acc: 0.9818', 'Train LL: -0.05843860542476784', 'Test LL: -0.0590344487158871', 'Epoch Time (s): 170.64212889922783')
('Epoch 21', 'Objective: -0.05979291758270447', 'Train Acc: 0.9817666666666667', 'Test Acc: 0.9863', 'Train LL: -0.054970554985605', 'Test LL: -0.04191477116863638', 'Epoch Time (s): 170.57593222893775')
('Epoch 22', 'Objective: -0.05823676834388606', 'Train Acc: 0.9833333333333333', 'Test Acc: 0.9844', 'Train LL: -0.05358841496692796', 'Test LL: -0.04734428938258367', 'Epoch Time (s): 170.57605786481872')
('Epoch 23', 'Objective: -0.05966593266002892', 'Train Acc: 0.9827666666666667', 'Test Acc: 0.9799', 'Train LL: -0.055103274283298136', 'Test LL: -0.05992078506128569', 'Epoch Time (s): 170.59220434818417')
('Epoch 24', 'Objective: -0.057961194209320305', 'Train Acc: 0.9828666666666667', 'Test Acc: 0.9829', 'Train LL: -0.053395098095569436', 'Test LL: -0.05135757842158248', 'Epoch Time (s): 170.57655803579837')
('Epoch 25', 'Objective: -0.056403886615334804', 'Train Acc: 0.9827166666666667', 'Test Acc: 0.9855', 'Train LL: -0.05192067505750265', 'Test LL: -0.04193879449538003', 'Epoch Time (s): 170.5395456510596')
('Epoch 26', 'Objective: -0.05462832135770915', 'Train Acc: 0.9837833333333333', 'Test Acc: 0.9866', 'Train LL: -0.05023623461106661', 'Test LL: -0.03824956388597432', 'Epoch Time (s): 170.57615190185606')
('Epoch 27', 'Objective: -0.05539065806932637', 'Train Acc: 0.9837333333333333', 'Test Acc: 0.9857', 'Train LL: -0.051127112672386614', 'Test LL: -0.04591687706178754', 'Epoch Time (s): 170.5706372456625')
('Epoch 28', 'Objective: -0.05239586977521662', 'Train Acc: 0.98405', 'Test Acc: 0.9813', 'Train LL: -0.048112616403648854', 'Test LL: -0.05833759707912357', 'Epoch Time (s): 170.59205368394032')
('Epoch 29', 'Objective: -0.0519014366996993', 'Train Acc: 0.9848166666666667', 'Test Acc: 0.9809', 'Train LL: -0.04768959026496518', 'Test LL: -0.05909396806140362', 'Epoch Time (s): 170.571744015906')
('Epoch 30', 'Objective: -0.05099368094645938', 'Train Acc: 0.9849833333333333', 'Test Acc: 0.9873', 'Train LL: -0.04688955316191744', 'Test LL: -0.03522284720797841', 'Epoch Time (s): 170.5629518791102')
('Epoch 31', 'Objective: -0.05059373555548043', 'Train Acc: 0.9851666666666666', 'Test Acc: 0.9868', 'Train LL: -0.0465043093918354', 'Test LL: -0.040431113239722684', 'Epoch Time (s): 170.5843773521483')
('Epoch 32', 'Objective: -0.05055539802509267', 'Train Acc: 0.9847666666666667', 'Test Acc: 0.987', 'Train LL: -0.04651071118576991', 'Test LL: -0.03974530072698135', 'Epoch Time (s): 170.5588021269068')
('Epoch 33', 'Objective: -0.0492611529773632', 'Train Acc: 0.9855666666666667', 'Test Acc: 0.9857', 'Train LL: -0.045312027237462166', 'Test LL: -0.042915758504551475', 'Epoch Time (s): 170.53619089303538')
('Epoch 34', 'Objective: -0.04986710689069469', 'Train Acc: 0.9855833333333334', 'Test Acc: 0.9874', 'Train LL: -0.04593435306243385', 'Test LL: -0.04217087647152043', 'Epoch Time (s): 170.58134126476943')
('Epoch 35', 'Objective: -0.047729765359429036', 'Train Acc: 0.9852833333333333', 'Test Acc: 0.9847', 'Train LL: -0.04385088319227063', 'Test LL: -0.046280159528229614', 'Epoch Time (s): 170.57003579381853')
('Epoch 36', 'Objective: -0.047879169563245956', 'Train Acc: 0.9855', 'Test Acc: 0.9883', 'Train LL: -0.04407078946129596', 'Test LL: -0.03613572008184508', 'Epoch Time (s): 170.5944981458597')
('Epoch 37', 'Objective: -0.04597323262823615', 'Train Acc: 0.98605', 'Test Acc: 0.989', 'Train LL: -0.04217544293140733', 'Test LL: -0.037644828883382365', 'Epoch Time (s): 170.54307145718485')
('Epoch 38', 'Objective: -0.04571870750570517', 'Train Acc: 0.98655', 'Test Acc: 0.9881', 'Train LL: -0.042016121701778736', 'Test LL: -0.03825360007586058', 'Epoch Time (s): 170.5433405940421')
('Epoch 39', 'Objective: -0.04478030431467003', 'Train Acc: 0.98695', 'Test Acc: 0.9861', 'Train LL: -0.04111569647544368', 'Test LL: -0.044024651993689344', 'Epoch Time (s): 170.58704986609519')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.028508694479732387', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9908', 'Train LL: -0.02534543869829867', 'Test LL: -0.027440173665766412', 'Epoch Time (s): 170.58090388402343')
('Epoch 41', 'Objective: -0.02323058215889339', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9913', 'Train LL: -0.02021461698346757', 'Test LL: -0.027779583098237623', 'Epoch Time (s): 170.55786445504054')
('Epoch 42', 'Objective: -0.02235977756303455', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.9918', 'Train LL: -0.019439837521651522', 'Test LL: -0.02384883806308933', 'Epoch Time (s): 170.58722289232537')
('Epoch 43', 'Objective: -0.02060736805616995', 'Train Acc: 0.9944', 'Test Acc: 0.9925', 'Train LL: -0.01776072854772903', 'Test LL: -0.02303380849234568', 'Epoch Time (s): 170.61658405605704')
('Epoch 44', 'Objective: -0.020389390457496995', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9927', 'Train LL: -0.017584242074665076', 'Test LL: -0.022085209278461585', 'Epoch Time (s): 170.61055063689128')
('Epoch 45', 'Objective: -0.020095599389050457', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9922', 'Train LL: -0.017337869695090508', 'Test LL: -0.024282305298454654', 'Epoch Time (s): 170.59986533178017')
('Epoch 46', 'Objective: -0.01834892672242115', 'Train Acc: 0.9949', 'Test Acc: 0.9927', 'Train LL: -0.015647683551348004', 'Test LL: -0.023388650856525462', 'Epoch Time (s): 170.62665967876092')
('Epoch 47', 'Objective: -0.017383431847351076', 'Train Acc: 0.9951', 'Test Acc: 0.9919', 'Train LL: -0.01473888811880158', 'Test LL: -0.02771852496882292', 'Epoch Time (s): 170.59201631695032')
('Epoch 48', 'Objective: -0.018078731984610918', 'Train Acc: 0.9950333333333333', 'Test Acc: 0.9913', 'Train LL: -0.015420713566049115', 'Test LL: -0.025811827894335806', 'Epoch Time (s): 170.60138762323186')
('Epoch 49', 'Objective: -0.017136823544428456', 'Train Acc: 0.9953166666666666', 'Test Acc: 0.9912', 'Train LL: -0.014534786656881696', 'Test LL: -0.027494837414266095', 'Epoch Time (s): 170.57872594799846')
('Epoch 50', 'Objective: -0.01639217469247356', 'Train Acc: 0.9955', 'Test Acc: 0.993', 'Train LL: -0.013825400267661636', 'Test LL: -0.022275585808631943', 'Epoch Time (s): 170.52031162986532')
('Epoch 51', 'Objective: -0.01578848036471137', 'Train Acc: 0.9957833333333334', 'Test Acc: 0.9918', 'Train LL: -0.013251690014939168', 'Test LL: -0.02539313943206946', 'Epoch Time (s): 170.6157875121571')
('Epoch 52', 'Objective: -0.01637127923256194', 'Train Acc: 0.9957833333333334', 'Test Acc: 0.9933', 'Train LL: -0.013811970561895256', 'Test LL: -0.022136163734192853', 'Epoch Time (s): 170.5904136262834')
('Epoch 53', 'Objective: -0.015463751784444084', 'Train Acc: 0.9958333333333333', 'Test Acc: 0.9921', 'Train LL: -0.01294572118614779', 'Test LL: -0.02529416485198698', 'Epoch Time (s): 170.57188980607316')
('Epoch 54', 'Objective: -0.014665566255421222', 'Train Acc: 0.9958', 'Test Acc: 0.9926', 'Train LL: -0.012151810058754181', 'Test LL: -0.02421362130348468', 'Epoch Time (s): 170.61584562063217')
('Epoch 55', 'Objective: -0.014525369158706954', 'Train Acc: 0.9959833333333333', 'Test Acc: 0.991', 'Train LL: -0.012022637758482673', 'Test LL: -0.027615590158502408', 'Epoch Time (s): 170.56988830910996')
('Epoch 56', 'Objective: -0.014517060066664903', 'Train Acc: 0.9961666666666666', 'Test Acc: 0.9901', 'Train LL: -0.012014029276293098', 'Test LL: -0.03312408604770518', 'Epoch Time (s): 170.5864213728346')
('Epoch 57', 'Objective: -0.014993801700474301', 'Train Acc: 0.9958833333333333', 'Test Acc: 0.9919', 'Train LL: -0.012489313707982405', 'Test LL: -0.02679816858848496', 'Epoch Time (s): 170.54131603706628')
('Epoch 58', 'Objective: -0.013087731063082725', 'Train Acc: 0.9963666666666666', 'Test Acc: 0.9917', 'Train LL: -0.010663870714098703', 'Test LL: -0.024970342593362147', 'Epoch Time (s): 170.58044069074094')
('Epoch 59', 'Objective: -0.01395704454649337', 'Train Acc: 0.9962166666666666', 'Test Acc: 0.9919', 'Train LL: -0.01149671186759381', 'Test LL: -0.025965442953718616', 'Epoch Time (s): 170.5946460030973')
('Epoch 60', 'Objective: -0.01317326807961701', 'Train Acc: 0.9964', 'Test Acc: 0.9905', 'Train LL: -0.010740199636198518', 'Test LL: -0.027015876642437753', 'Epoch Time (s): 170.5189994238317')
('Epoch 61', 'Objective: -0.012963532212708505', 'Train Acc: 0.9962333333333333', 'Test Acc: 0.9916', 'Train LL: -0.010525835660481337', 'Test LL: -0.025333145079606698', 'Epoch Time (s): 170.49423174373806')
('Epoch 62', 'Objective: -0.013151253342333476', 'Train Acc: 0.9964833333333334', 'Test Acc: 0.992', 'Train LL: -0.010732150258441634', 'Test LL: -0.02582347565050454', 'Epoch Time (s): 170.50587390875444')
('Epoch 63', 'Objective: -0.012805343792504836', 'Train Acc: 0.9964666666666666', 'Test Acc: 0.993', 'Train LL: -0.010407139713412766', 'Test LL: -0.022522180603424834', 'Epoch Time (s): 170.49319306202233')
('Epoch 64', 'Objective: -0.012472172928056045', 'Train Acc: 0.9967833333333334', 'Test Acc: 0.9918', 'Train LL: -0.010085617752522058', 'Test LL: -0.027328903380303523', 'Epoch Time (s): 170.49350009905174')
('Epoch 65', 'Objective: -0.012028936488336433', 'Train Acc: 0.99655', 'Test Acc: 0.9921', 'Train LL: -0.009654026745250637', 'Test LL: -0.02348188622819336', 'Epoch Time (s): 170.47703578975052')
('Epoch 66', 'Objective: -0.012386558420331024', 'Train Acc: 0.9966333333333334', 'Test Acc: 0.9928', 'Train LL: -0.009999634149099351', 'Test LL: -0.02402619375165493', 'Epoch Time (s): 170.52355472603813')
('Epoch 67', 'Objective: -0.011693928162882925', 'Train Acc: 0.9967833333333334', 'Test Acc: 0.9914', 'Train LL: -0.009338630102939742', 'Test LL: -0.028580217269803438', 'Epoch Time (s): 170.51219083881006')
('Epoch 68', 'Objective: -0.011650560583178619', 'Train Acc: 0.9967', 'Test Acc: 0.9929', 'Train LL: -0.009307424593203198', 'Test LL: -0.0255267465688664', 'Epoch Time (s): 170.47057137498632')
('Epoch 69', 'Objective: -0.01169999773080066', 'Train Acc: 0.9967333333333334', 'Test Acc: 0.991', 'Train LL: -0.009335540311055298', 'Test LL: -0.028810550533923816', 'Epoch Time (s): 170.45793825667351')
('Epoch 70', 'Objective: -0.011780647415378945', 'Train Acc: 0.9968', 'Test Acc: 0.9923', 'Train LL: -0.009452181665379688', 'Test LL: -0.026362997910805562', 'Epoch Time (s): 170.4828460579738')
('Epoch 71', 'Objective: -0.011634528634913406', 'Train Acc: 0.9968333333333333', 'Test Acc: 0.9906', 'Train LL: -0.009338786268503306', 'Test LL: -0.03014776456016243', 'Epoch Time (s): 170.49479346629232')
('Epoch 72', 'Objective: -0.011172167841652427', 'Train Acc: 0.9969833333333333', 'Test Acc: 0.9912', 'Train LL: -0.008890519949589254', 'Test LL: -0.026109064636671384', 'Epoch Time (s): 170.4908143398352')
('Epoch 73', 'Objective: -0.010807245658938938', 'Train Acc: 0.9971', 'Test Acc: 0.9909', 'Train LL: -0.008528458835878697', 'Test LL: -0.030316278920094693', 'Epoch Time (s): 170.51089039817452')
('Epoch 74', 'Objective: -0.011120198883572466', 'Train Acc: 0.997', 'Test Acc: 0.9919', 'Train LL: -0.008814266347285774', 'Test LL: -0.02799335370930642', 'Epoch Time (s): 170.48905324889347')
('Epoch 75', 'Objective: -0.010572021382439284', 'Train Acc: 0.9972833333333333', 'Test Acc: 0.9904', 'Train LL: -0.008279146323647625', 'Test LL: -0.030726063567202016', 'Epoch Time (s): 170.47248206986114')
('Epoch 76', 'Objective: -0.01077370191300858', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9921', 'Train LL: -0.00851445529332403', 'Test LL: -0.02664568229637637', 'Epoch Time (s): 170.54349889513105')
('Epoch 77', 'Objective: -0.01049295625559879', 'Train Acc: 0.9972333333333333', 'Test Acc: 0.9916', 'Train LL: -0.008244967648192316', 'Test LL: -0.02858422086789135', 'Epoch Time (s): 170.49478994309902')
('Epoch 78', 'Objective: -0.009592485885778818', 'Train Acc: 0.9974', 'Test Acc: 0.9913', 'Train LL: -0.0073682995648623574', 'Test LL: -0.029882844330266993', 'Epoch Time (s): 170.51225244207308')
('Epoch 79', 'Objective: -0.010114398678858886', 'Train Acc: 0.9972666666666666', 'Test Acc: 0.991', 'Train LL: -0.007878545530311361', 'Test LL: -0.03194454677745657', 'Epoch Time (s): 170.50450482824817')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.00821787534308618', 'Train Acc: 0.9979333333333333', 'Test Acc: 0.9924', 'Train LL: -0.006103914093921018', 'Test LL: -0.028831721683871818', 'Epoch Time (s): 170.47827177494764')
('Epoch 81', 'Objective: -0.007686172072174754', 'Train Acc: 0.9982833333333333', 'Test Acc: 0.9925', 'Train LL: -0.0055913526302552915', 'Test LL: -0.028111571792378987', 'Epoch Time (s): 170.47324119880795')
('Epoch 82', 'Objective: -0.007133253862184792', 'Train Acc: 0.9984', 'Test Acc: 0.9922', 'Train LL: -0.005067660473287198', 'Test LL: -0.02930684398963209', 'Epoch Time (s): 170.49741990910843')
('Epoch 83', 'Objective: -0.00691158905392118', 'Train Acc: 0.9984666666666666', 'Test Acc: 0.9921', 'Train LL: -0.004849796400466162', 'Test LL: -0.029460350014123962', 'Epoch Time (s): 170.46926972595975')
('Epoch 84', 'Objective: -0.006804955432053938', 'Train Acc: 0.9985', 'Test Acc: 0.9922', 'Train LL: -0.004733422758618423', 'Test LL: -0.03113370177947388', 'Epoch Time (s): 170.50985993631184')
('Epoch 85', 'Objective: -0.006637756220334731', 'Train Acc: 0.9985166666666667', 'Test Acc: 0.9927', 'Train LL: -0.0045606394217193764', 'Test LL: -0.02932861319074824', 'Epoch Time (s): 170.49363812291995')
('Epoch 86', 'Objective: -0.006639903053056297', 'Train Acc: 0.99855', 'Test Acc: 0.9922', 'Train LL: -0.004553169981247502', 'Test LL: -0.031075071912218935', 'Epoch Time (s): 170.50733822584152')
('Epoch 87', 'Objective: -0.006248828959594055', 'Train Acc: 0.9987166666666667', 'Test Acc: 0.9922', 'Train LL: -0.004186876689148807', 'Test LL: -0.03153284111559971', 'Epoch Time (s): 170.48377330973744')
('Epoch 88', 'Objective: -0.006360650435529696', 'Train Acc: 0.9985833333333334', 'Test Acc: 0.9923', 'Train LL: -0.004285296227477291', 'Test LL: -0.03195434665964011', 'Epoch Time (s): 170.5187623812817')
('Epoch 89', 'Objective: -0.006195672767208246', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9921', 'Train LL: -0.004129820994708774', 'Test LL: -0.032835508681721325', 'Epoch Time (s): 170.49166702805087')
('Epoch 90', 'Objective: -0.006289081171929191', 'Train Acc: 0.99855', 'Test Acc: 0.9919', 'Train LL: -0.004194386583119018', 'Test LL: -0.03277580343603071', 'Epoch Time (s): 170.45544057479128')
('Epoch 91', 'Objective: -0.006006037398740449', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.992', 'Train LL: -0.003919010596933876', 'Test LL: -0.0325433350421376', 'Epoch Time (s): 170.4761245669797')
('Epoch 92', 'Objective: -0.006273208253733025', 'Train Acc: 0.9986166666666667', 'Test Acc: 0.9919', 'Train LL: -0.004170563124561367', 'Test LL: -0.03257684890387364', 'Epoch Time (s): 170.4647867847234')
('Epoch 93', 'Objective: -0.006011310490353123', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9918', 'Train LL: -0.003927022974063526', 'Test LL: -0.03343636418001303', 'Epoch Time (s): 170.51205456722528')
('Epoch 94', 'Objective: -0.006460197399021673', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.992', 'Train LL: -0.004340844447351832', 'Test LL: -0.03316303049379776', 'Epoch Time (s): 170.48045162996277')
('Epoch 95', 'Objective: -0.006064319474511375', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9921', 'Train LL: -0.003965112420247804', 'Test LL: -0.032907761557171525', 'Epoch Time (s): 170.49400183791295')
('Epoch 96', 'Objective: -0.006326842532715825', 'Train Acc: 0.9985333333333334', 'Test Acc: 0.9919', 'Train LL: -0.004198232501364336', 'Test LL: -0.03298854566617032', 'Epoch Time (s): 170.47222224622965')
('Epoch 97', 'Objective: -0.005829900197602046', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9912', 'Train LL: -0.003746632470389725', 'Test LL: -0.0359808370995921', 'Epoch Time (s): 170.45296428585425')
('Epoch 98', 'Objective: -0.006260490285498924', 'Train Acc: 0.9986333333333334', 'Test Acc: 0.9914', 'Train LL: -0.004141126121667694', 'Test LL: -0.03504095256778364', 'Epoch Time (s): 170.4972782758996')
('Epoch 99', 'Objective: -0.005785660447494931', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.9918', 'Train LL: -0.003702509033350384', 'Test LL: -0.034019669245417605', 'Epoch Time (s): 170.47057546116412')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.005327090066652323
Final Train Accuracy: £0.99895
Final Train LL: £-0.0032749672386755834
Final Test Accuracy: £0.9917
Final Test LL: £-0.03386614110775959
