dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 1
bn_indnorm: none
bn_tnorm: none
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.6733662596713892', 'Train Acc: 0.39413333333333334', 'Test Acc: 0.7135', 'Train LL: -1.6379628244227862', 'Test LL: -0.9013674029727775', 'Epoch Time (s): 161.29385441704653')
('Epoch 1', 'Objective: -0.6643049522236228', 'Train Acc: 0.79395', 'Test Acc: 0.8571', 'Train LL: -0.6119907872873592', 'Test LL: -0.42085640403920377', 'Epoch Time (s): 161.36575357592665')
('Epoch 2', 'Objective: -0.40844974496080905', 'Train Acc: 0.8859833333333333', 'Test Acc: 0.9173', 'Train LL: -0.3584547625118651', 'Test LL: -0.2644057933806413', 'Epoch Time (s): 161.3270656550303')
('Epoch 3', 'Objective: -0.31837213139765086', 'Train Acc: 0.9145666666666666', 'Test Acc: 0.9189', 'Train LL: -0.26995988419434447', 'Test LL: -0.24699038305476978', 'Epoch Time (s): 161.33346228697337')
('Epoch 4', 'Objective: -0.2696811291189175', 'Train Acc: 0.9302', 'Test Acc: 0.9441', 'Train LL: -0.22353434171067077', 'Test LL: -0.16657796363401559', 'Epoch Time (s): 161.34333070600405')
('Epoch 5', 'Objective: -0.23090900988194407', 'Train Acc: 0.9422166666666667', 'Test Acc: 0.9377', 'Train LL: -0.18666689823672536', 'Test LL: -0.1949234480244897', 'Epoch Time (s): 161.36518843099475')
('Epoch 6', 'Objective: -0.20876615450841804', 'Train Acc: 0.9482166666666667', 'Test Acc: 0.9532', 'Train LL: -0.166033462717315', 'Test LL: -0.1440762504229133', 'Epoch Time (s): 161.34316013683565')
('Epoch 7', 'Objective: -0.1850609436209049', 'Train Acc: 0.9546', 'Test Acc: 0.9698', 'Train LL: -0.14424654812200854', 'Test LL: -0.1008289080101458', 'Epoch Time (s): 161.36198724992573')
('Epoch 8', 'Objective: -0.16637353876673103', 'Train Acc: 0.9608166666666667', 'Test Acc: 0.9701', 'Train LL: -0.12689770474220752', 'Test LL: -0.09633373396291174', 'Epoch Time (s): 161.31499689188786')
('Epoch 9', 'Objective: -0.15436941262024947', 'Train Acc: 0.9638666666666666', 'Test Acc: 0.9711', 'Train LL: -0.11607208944595844', 'Test LL: -0.09052405779066534', 'Epoch Time (s): 161.3522346650716')
('Epoch 10', 'Objective: -0.14636423480305938', 'Train Acc: 0.9656833333333333', 'Test Acc: 0.9781', 'Train LL: -0.10949270235633472', 'Test LL: -0.06441198174251751', 'Epoch Time (s): 161.35169955110177')
('Epoch 11', 'Objective: -0.13817994695994765', 'Train Acc: 0.9679166666666666', 'Test Acc: 0.9671', 'Train LL: -0.10196357066437634', 'Test LL: -0.10071938523924644', 'Epoch Time (s): 161.3363812728785')
('Epoch 12', 'Objective: -0.13152292894889103', 'Train Acc: 0.9694833333333334', 'Test Acc: 0.975', 'Train LL: -0.0961387258002032', 'Test LL: -0.07364540255247072', 'Epoch Time (s): 161.35333260102198')
('Epoch 13', 'Objective: -0.12890310367565114', 'Train Acc: 0.97115', 'Test Acc: 0.9689', 'Train LL: -0.0937526807653278', 'Test LL: -0.09564548327407862', 'Epoch Time (s): 161.3540899308864')
('Epoch 14', 'Objective: -0.12342333295793637', 'Train Acc: 0.9716666666666667', 'Test Acc: 0.9743', 'Train LL: -0.08879707988252884', 'Test LL: -0.08236384171909189', 'Epoch Time (s): 161.3500624659937')
('Epoch 15', 'Objective: -0.12115437473649258', 'Train Acc: 0.973', 'Test Acc: 0.9793', 'Train LL: -0.08656566719733785', 'Test LL: -0.05990453092637937', 'Epoch Time (s): 161.35196341807023')
('Epoch 16', 'Objective: -0.11365099377673198', 'Train Acc: 0.9749', 'Test Acc: 0.9725', 'Train LL: -0.08006262969284852', 'Test LL: -0.08690002610542061', 'Epoch Time (s): 161.31402444303967')
('Epoch 17', 'Objective: -0.11239112453794832', 'Train Acc: 0.9750166666666666', 'Test Acc: 0.9827', 'Train LL: -0.07880393196348698', 'Test LL: -0.054460331770358826', 'Epoch Time (s): 161.35447001317516')
('Epoch 18', 'Objective: -0.11158297049160894', 'Train Acc: 0.9751833333333333', 'Test Acc: 0.9821', 'Train LL: -0.07826664561933873', 'Test LL: -0.056218521093790545', 'Epoch Time (s): 161.3468954511918')
('Epoch 19', 'Objective: -0.1069992584473748', 'Train Acc: 0.9764333333333334', 'Test Acc: 0.9794', 'Train LL: -0.07393608119285257', 'Test LL: -0.06012648565845539', 'Epoch Time (s): 161.35797596396878')
('Epoch 20', 'Objective: -0.10588565363051794', 'Train Acc: 0.9767333333333333', 'Test Acc: 0.9785', 'Train LL: -0.07310686989007445', 'Test LL: -0.06441953833337573', 'Epoch Time (s): 161.34603083785623')
('Epoch 21', 'Objective: -0.10259029957176538', 'Train Acc: 0.97855', 'Test Acc: 0.9759', 'Train LL: -0.07025613400671253', 'Test LL: -0.06836347009168309', 'Epoch Time (s): 161.4387702399399')
('Epoch 22', 'Objective: -0.09932282767841666', 'Train Acc: 0.9797666666666667', 'Test Acc: 0.984', 'Train LL: -0.06717650576214566', 'Test LL: -0.051987646664162716', 'Epoch Time (s): 162.1751350548584')
('Epoch 23', 'Objective: -0.10015687408669934', 'Train Acc: 0.9780333333333333', 'Test Acc: 0.9809', 'Train LL: -0.0683704645855615', 'Test LL: -0.058019178096708125', 'Epoch Time (s): 161.630594820017')
('Epoch 24', 'Objective: -0.09744260238973601', 'Train Acc: 0.9795', 'Test Acc: 0.9831', 'Train LL: -0.06603790991039192', 'Test LL: -0.05140190362589979', 'Epoch Time (s): 161.66236214200035')
('Epoch 25', 'Objective: -0.09603790037287852', 'Train Acc: 0.9793666666666667', 'Test Acc: 0.9833', 'Train LL: -0.06481457304022678', 'Test LL: -0.05170087072946762', 'Epoch Time (s): 161.63635902106762')
('Epoch 26', 'Objective: -0.09649952166903115', 'Train Acc: 0.9792333333333333', 'Test Acc: 0.9815', 'Train LL: -0.06557823562201279', 'Test LL: -0.05770503111200988', 'Epoch Time (s): 161.63863920909353')
('Epoch 27', 'Objective: -0.09337270058275689', 'Train Acc: 0.98085', 'Test Acc: 0.9852', 'Train LL: -0.06251501807395217', 'Test LL: -0.0469053860960673', 'Epoch Time (s): 161.5965122738853')
('Epoch 28', 'Objective: -0.0901801025835102', 'Train Acc: 0.981', 'Test Acc: 0.9775', 'Train LL: -0.0594690351156681', 'Test LL: -0.06284065717593314', 'Epoch Time (s): 161.62897505285218')
('Epoch 29', 'Objective: -0.09061492429457821', 'Train Acc: 0.9808166666666667', 'Test Acc: 0.9731', 'Train LL: -0.060232341932512534', 'Test LL: -0.08087212495855423', 'Epoch Time (s): 161.65396372205578')
('Epoch 30', 'Objective: -0.08779637511773182', 'Train Acc: 0.9815833333333334', 'Test Acc: 0.9869', 'Train LL: -0.057700117817361375', 'Test LL: -0.04627182094373519', 'Epoch Time (s): 161.64052976109087')
('Epoch 31', 'Objective: -0.08988821750812996', 'Train Acc: 0.9815333333333334', 'Test Acc: 0.9849', 'Train LL: -0.05982205811516348', 'Test LL: -0.048452939184025524', 'Epoch Time (s): 161.6448383689858')
('Epoch 32', 'Objective: -0.0857912109246748', 'Train Acc: 0.9824166666666667', 'Test Acc: 0.9828', 'Train LL: -0.05617722664814116', 'Test LL: -0.05693004995107028', 'Epoch Time (s): 161.66660541691817')
('Epoch 33', 'Objective: -0.0850550908646188', 'Train Acc: 0.9820333333333333', 'Test Acc: 0.9857', 'Train LL: -0.05564660265048889', 'Test LL: -0.05021032403318592', 'Epoch Time (s): 161.66563364909962')
('Epoch 34', 'Objective: -0.0857654871775567', 'Train Acc: 0.98255', 'Test Acc: 0.9766', 'Train LL: -0.056604576615551135', 'Test LL: -0.06782278868051514', 'Epoch Time (s): 161.64143586484715')
('Epoch 35', 'Objective: -0.08457141946281571', 'Train Acc: 0.9819833333333333', 'Test Acc: 0.9849', 'Train LL: -0.05533584229812549', 'Test LL: -0.04552263733836324', 'Epoch Time (s): 161.64756178902462')
('Epoch 36', 'Objective: -0.08297141988018268', 'Train Acc: 0.9830333333333333', 'Test Acc: 0.9862', 'Train LL: -0.05397005479687358', 'Test LL: -0.048236912251598346', 'Epoch Time (s): 161.67753296508454')
('Epoch 37', 'Objective: -0.08340251115850897', 'Train Acc: 0.9825833333333334', 'Test Acc: 0.9819', 'Train LL: -0.05452705158014043', 'Test LL: -0.05793598850003197', 'Epoch Time (s): 161.65328909177333')
('Epoch 38', 'Objective: -0.08167151572067481', 'Train Acc: 0.9835333333333334', 'Test Acc: 0.9875', 'Train LL: -0.052897393170691004', 'Test LL: -0.03885992234780962', 'Epoch Time (s): 161.6413447880186')
('Epoch 39', 'Objective: -0.08217007553513053', 'Train Acc: 0.9831', 'Test Acc: 0.9843', 'Train LL: -0.05351040140818259', 'Test LL: -0.04908094518139447', 'Epoch Time (s): 161.64007866801694')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06196891564123393', 'Train Acc: 0.98885', 'Test Acc: 0.9914', 'Train LL: -0.03504829843882652', 'Test LL: -0.029222953262785466', 'Epoch Time (s): 161.62495325296186')
('Epoch 41', 'Objective: -0.05644230796050025', 'Train Acc: 0.9901333333333333', 'Test Acc: 0.9903', 'Train LL: -0.030207243617715727', 'Test LL: -0.030933282095251827', 'Epoch Time (s): 161.65350101911463')
('Epoch 42', 'Objective: -0.05473213021729476', 'Train Acc: 0.9909833333333333', 'Test Acc: 0.9905', 'Train LL: -0.029031090880436882', 'Test LL: -0.03135845476715883', 'Epoch Time (s): 161.63885190011933')
('Epoch 43', 'Objective: -0.05271030106276831', 'Train Acc: 0.99125', 'Test Acc: 0.9895', 'Train LL: -0.02721444728158854', 'Test LL: -0.03282478944165451', 'Epoch Time (s): 161.64568952890113')
('Epoch 44', 'Objective: -0.05130346979148714', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9909', 'Train LL: -0.02606841227028247', 'Test LL: -0.03036153515653619', 'Epoch Time (s): 161.64960699295625')
('Epoch 45', 'Objective: -0.05075022218378536', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9881', 'Train LL: -0.025673962531267906', 'Test LL: -0.03498301194555173', 'Epoch Time (s): 161.61995153897442')
('Epoch 46', 'Objective: -0.05148383046420237', 'Train Acc: 0.9916166666666667', 'Test Acc: 0.9898', 'Train LL: -0.026541827119597763', 'Test LL: -0.03104175414633309', 'Epoch Time (s): 161.65445717680268')
('Epoch 47', 'Objective: -0.04988626028305944', 'Train Acc: 0.9919166666666667', 'Test Acc: 0.9893', 'Train LL: -0.025083140977125263', 'Test LL: -0.03127119622325132', 'Epoch Time (s): 161.6471376779955')
('Epoch 48', 'Objective: -0.049142461905656326', 'Train Acc: 0.99215', 'Test Acc: 0.9893', 'Train LL: -0.024505935254706783', 'Test LL: -0.03291373299952959', 'Epoch Time (s): 161.57860328094102')
('Epoch 49', 'Objective: -0.048960344677206794', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9894', 'Train LL: -0.024355964642302146', 'Test LL: -0.03375881112867197', 'Epoch Time (s): 161.66561513300985')
('Epoch 50', 'Objective: -0.048700061607572454', 'Train Acc: 0.9921833333333333', 'Test Acc: 0.9908', 'Train LL: -0.024201335721329743', 'Test LL: -0.029289599886990685', 'Epoch Time (s): 161.6629095498938')
('Epoch 51', 'Objective: -0.04806551688683902', 'Train Acc: 0.9922333333333333', 'Test Acc: 0.9901', 'Train LL: -0.023677288950564007', 'Test LL: -0.029514680319411804', 'Epoch Time (s): 161.58937651198357')
('Epoch 52', 'Objective: -0.047811547814388365', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.9888', 'Train LL: -0.023524589742855963', 'Test LL: -0.034211569570390774', 'Epoch Time (s): 161.60241115908138')
('Epoch 53', 'Objective: -0.04773936239828722', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9899', 'Train LL: -0.023543143694728846', 'Test LL: -0.03131810112822475', 'Epoch Time (s): 161.62917072488926')
('Epoch 54', 'Objective: -0.0470741969423074', 'Train Acc: 0.99285', 'Test Acc: 0.9897', 'Train LL: -0.02301998144739599', 'Test LL: -0.031282825215450866', 'Epoch Time (s): 161.5695451661013')
('Epoch 55', 'Objective: -0.047051543986009484', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9901', 'Train LL: -0.023020083542089127', 'Test LL: -0.031213231998557297', 'Epoch Time (s): 161.61293180612847')
('Epoch 56', 'Objective: -0.04663212230424835', 'Train Acc: 0.99275', 'Test Acc: 0.9889', 'Train LL: -0.022663430979736204', 'Test LL: -0.031832010349448936', 'Epoch Time (s): 161.59290970908478')
('Epoch 57', 'Objective: -0.04679717482871413', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9908', 'Train LL: -0.02303311278153512', 'Test LL: -0.031252896926077155', 'Epoch Time (s): 161.63941034395248')
('Epoch 58', 'Objective: -0.04605930220065395', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9898', 'Train LL: -0.022150134577089958', 'Test LL: -0.03268037900413278', 'Epoch Time (s): 161.64748330321163')
('Epoch 59', 'Objective: -0.04614917772180635', 'Train Acc: 0.9926', 'Test Acc: 0.9903', 'Train LL: -0.02234595835100089', 'Test LL: -0.031236626533813774', 'Epoch Time (s): 161.66781240398996')
('Epoch 60', 'Objective: -0.046349078023633965', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9902', 'Train LL: -0.02268729619458132', 'Test LL: -0.032363979084077094', 'Epoch Time (s): 161.6874011598993')
('Epoch 61', 'Objective: -0.04521503325977525', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9894', 'Train LL: -0.02158210795367855', 'Test LL: -0.03275526636651362', 'Epoch Time (s): 161.6353583538439')
('Epoch 62', 'Objective: -0.045547151887271084', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9903', 'Train LL: -0.02197280204599086', 'Test LL: -0.03140708786135718', 'Epoch Time (s): 161.67212779307738')
('Epoch 63', 'Objective: -0.04556097328074505', 'Train Acc: 0.9929', 'Test Acc: 0.9905', 'Train LL: -0.022032874172122737', 'Test LL: -0.03064967574770779', 'Epoch Time (s): 161.65534505899996')
('Epoch 64', 'Objective: -0.04547139280625539', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9911', 'Train LL: -0.022052081793197374', 'Test LL: -0.02777270324130925', 'Epoch Time (s): 161.66284116799943')
('Epoch 65', 'Objective: -0.045076813860831115', 'Train Acc: 0.9931833333333333', 'Test Acc: 0.9901', 'Train LL: -0.021715149286750984', 'Test LL: -0.029536088558666115', 'Epoch Time (s): 161.66019315388985')
('Epoch 66', 'Objective: -0.04505716464234006', 'Train Acc: 0.9928166666666667', 'Test Acc: 0.9892', 'Train LL: -0.021752106609899607', 'Test LL: -0.031676592376596445', 'Epoch Time (s): 161.65028843889013')
('Epoch 67', 'Objective: -0.04439099581868636', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9894', 'Train LL: -0.021059525995965157', 'Test LL: -0.03126459428206165', 'Epoch Time (s): 161.62319424608722')
('Epoch 68', 'Objective: -0.04453891104444134', 'Train Acc: 0.9933333333333333', 'Test Acc: 0.9904', 'Train LL: -0.021343286914760094', 'Test LL: -0.030572135928764895', 'Epoch Time (s): 161.62766470690258')
('Epoch 69', 'Objective: -0.044771793423842327', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9895', 'Train LL: -0.02147956760075897', 'Test LL: -0.03043817045584448', 'Epoch Time (s): 161.67308867815882')
('Epoch 70', 'Objective: -0.044429767740099636', 'Train Acc: 0.9929', 'Test Acc: 0.9897', 'Train LL: -0.021243305098171995', 'Test LL: -0.03033422391027876', 'Epoch Time (s): 161.66653088992462')
('Epoch 71', 'Objective: -0.04470762452534599', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.991', 'Train LL: -0.021604170513425613', 'Test LL: -0.03027363171674034', 'Epoch Time (s): 161.63325645797886')
('Epoch 72', 'Objective: -0.043852309484189174', 'Train Acc: 0.9935833333333334', 'Test Acc: 0.9905', 'Train LL: -0.020848843830544993', 'Test LL: -0.030257603533681926', 'Epoch Time (s): 161.67634162912145')
('Epoch 73', 'Objective: -0.04445405037965637', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9883', 'Train LL: -0.021365376593544955', 'Test LL: -0.03113498493657433', 'Epoch Time (s): 161.6571074158419')
('Epoch 74', 'Objective: -0.044065946948713575', 'Train Acc: 0.9931', 'Test Acc: 0.9915', 'Train LL: -0.021125490411740087', 'Test LL: -0.028672868154142463', 'Epoch Time (s): 161.63847437384538')
('Epoch 75', 'Objective: -0.0429826881848487', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9903', 'Train LL: -0.020043582385748642', 'Test LL: -0.030960001902026288', 'Epoch Time (s): 161.63571679312736')
('Epoch 76', 'Objective: -0.04391696078892403', 'Train Acc: 0.993', 'Test Acc: 0.9897', 'Train LL: -0.020997699663803965', 'Test LL: -0.03147733741519933', 'Epoch Time (s): 161.65706589608453')
('Epoch 77', 'Objective: -0.04287956298272865', 'Train Acc: 0.99375', 'Test Acc: 0.991', 'Train LL: -0.02001406847530004', 'Test LL: -0.02907624612858816', 'Epoch Time (s): 161.60750209586695')
('Epoch 78', 'Objective: -0.04389811024753991', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9899', 'Train LL: -0.02111520283353339', 'Test LL: -0.032224783418360235', 'Epoch Time (s): 161.60730848810636')
('Epoch 79', 'Objective: -0.04275712905544079', 'Train Acc: 0.99325', 'Test Acc: 0.9909', 'Train LL: -0.019980183937364872', 'Test LL: -0.02994299405452952', 'Epoch Time (s): 161.67068760911934')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04094199758255559', 'Train Acc: 0.9942', 'Test Acc: 0.9908', 'Train LL: -0.0182880417943146', 'Test LL: -0.029258349424957458', 'Epoch Time (s): 161.67294707498513')
('Epoch 81', 'Objective: -0.04051425821577534', 'Train Acc: 0.99425', 'Test Acc: 0.9913', 'Train LL: -0.017890414150716415', 'Test LL: -0.028251615815879615', 'Epoch Time (s): 161.61852681892924')
('Epoch 82', 'Objective: -0.04021106527784069', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.9911', 'Train LL: -0.017591630895357476', 'Test LL: -0.028027071062381167', 'Epoch Time (s): 161.63079526089132')
('Epoch 83', 'Objective: -0.04023205214173445', 'Train Acc: 0.99425', 'Test Acc: 0.991', 'Train LL: -0.017681688406566066', 'Test LL: -0.029314141099609024', 'Epoch Time (s): 161.65702172811143')
('Epoch 84', 'Objective: -0.03968554994131905', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9906', 'Train LL: -0.017107488543832594', 'Test LL: -0.029300892479258732', 'Epoch Time (s): 161.6449504289776')
('Epoch 85', 'Objective: -0.039657974450446803', 'Train Acc: 0.9947166666666667', 'Test Acc: 0.9908', 'Train LL: -0.01708887352767558', 'Test LL: -0.02903363251505917', 'Epoch Time (s): 161.67745523015037')
('Epoch 86', 'Objective: -0.03965766923567639', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9905', 'Train LL: -0.017046677262675874', 'Test LL: -0.028692053460381804', 'Epoch Time (s): 161.68023746600375')
('Epoch 87', 'Objective: -0.03950954709537101', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9906', 'Train LL: -0.01693338598821926', 'Test LL: -0.02838989877948231', 'Epoch Time (s): 161.67310350504704')
('Epoch 88', 'Objective: -0.038917713566950285', 'Train Acc: 0.99475', 'Test Acc: 0.9909', 'Train LL: -0.016473324658590888', 'Test LL: -0.02860727544103018', 'Epoch Time (s): 161.64236360182986')
('Epoch 89', 'Objective: -0.03967127051921763', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9904', 'Train LL: -0.01709152110856625', 'Test LL: -0.029694957349267106', 'Epoch Time (s): 161.66839636606164')
('Epoch 90', 'Objective: -0.039354087270315974', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.9907', 'Train LL: -0.01683349566209255', 'Test LL: -0.029106573153796278', 'Epoch Time (s): 161.65198515891097')
('Epoch 91', 'Objective: -0.03925878222355233', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9912', 'Train LL: -0.016710738619629482', 'Test LL: -0.028346312804054155', 'Epoch Time (s): 161.60251272306778')
('Epoch 92', 'Objective: -0.03962995894095655', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9908', 'Train LL: -0.017115245128322788', 'Test LL: -0.028591500037835147', 'Epoch Time (s): 161.6295579560101')
('Epoch 93', 'Objective: -0.04002379047564781', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9909', 'Train LL: -0.01745591681276659', 'Test LL: -0.029022391840123656', 'Epoch Time (s): 161.64252698095515')
('Epoch 94', 'Objective: -0.03865347540523069', 'Train Acc: 0.99465', 'Test Acc: 0.991', 'Train LL: -0.016229497740205906', 'Test LL: -0.02878598736268753', 'Epoch Time (s): 161.65898228506558')
('Epoch 95', 'Objective: -0.03904564060600039', 'Train Acc: 0.9944833333333334', 'Test Acc: 0.9909', 'Train LL: -0.016501263603196703', 'Test LL: -0.02878665191585227', 'Epoch Time (s): 161.6585655240342')
('Epoch 96', 'Objective: -0.038610167520819194', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9908', 'Train LL: -0.016159084240026093', 'Test LL: -0.02916937815748168', 'Epoch Time (s): 161.63344820798375')
('Epoch 97', 'Objective: -0.03843540915099087', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9908', 'Train LL: -0.01590211981247835', 'Test LL: -0.02902481022296458', 'Epoch Time (s): 161.65215667895973')
('Epoch 98', 'Objective: -0.03851611513797333', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9908', 'Train LL: -0.01602813692359005', 'Test LL: -0.029457420671385705', 'Epoch Time (s): 161.66505767498165')
('Epoch 99', 'Objective: -0.0387135329939695', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.991', 'Train LL: -0.016223755551492063', 'Test LL: -0.029024839990193466', 'Epoch Time (s): 161.65574266621843')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.038588697944901273
Final Train Accuracy: £0.9946833333333334
Final Train LL: £-0.01618626111301089
Final Test Accuracy: £0.9911
Final Test LL: £-0.02896447930954903
