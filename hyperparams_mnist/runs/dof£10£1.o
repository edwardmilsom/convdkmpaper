dataset: MNIST
dtype: float64
dof: 10.0
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.4641819136001024', 'Train Acc: 0.50475', 'Test Acc: 0.7184', 'Train LL: -1.3679170488956096', 'Test LL: -0.8195556109674208', 'Epoch Time (s): 164.50481872586533')
('Epoch 1', 'Objective: -0.849747018156401', 'Train Acc: 0.7469166666666667', 'Test Acc: 0.8149', 'Train LL: -0.7402415748643688', 'Test LL: -0.5411602353404779', 'Epoch Time (s): 164.592159233056')
('Epoch 2', 'Objective: -0.5523375773973088', 'Train Acc: 0.85305', 'Test Acc: 0.8753', 'Train LL: -0.4406432905415568', 'Test LL: -0.36885582430290925', 'Epoch Time (s): 164.62237017485313')
('Epoch 3', 'Objective: -0.44319361023343185', 'Train Acc: 0.8945', 'Test Acc: 0.9245', 'Train LL: -0.33177765885850885', 'Test LL: -0.2485717212747928', 'Epoch Time (s): 164.60843567107804')
('Epoch 4', 'Objective: -0.37106267562137674', 'Train Acc: 0.9180833333333334', 'Test Acc: 0.9256', 'Train LL: -0.2617121220076299', 'Test LL: -0.23926655588409904', 'Epoch Time (s): 164.56558736599982')
('Epoch 5', 'Objective: -0.32485720108308735', 'Train Acc: 0.9316166666666666', 'Test Acc: 0.9453', 'Train LL: -0.21937987161436248', 'Test LL: -0.1776381949847542', 'Epoch Time (s): 164.54819351015612')
('Epoch 6', 'Objective: -0.3026099895899815', 'Train Acc: 0.93705', 'Test Acc: 0.9369', 'Train LL: -0.20063750509534783', 'Test LL: -0.1986923815795455', 'Epoch Time (s): 164.4699441702105')
('Epoch 7', 'Objective: -0.27910022703645215', 'Train Acc: 0.9437', 'Test Acc: 0.9623', 'Train LL: -0.18102129974043632', 'Test LL: -0.1276285908060616', 'Epoch Time (s): 164.443465908058')
('Epoch 8', 'Objective: -0.26297577557083096', 'Train Acc: 0.9479833333333333', 'Test Acc: 0.9612', 'Train LL: -0.1670605704616137', 'Test LL: -0.1240358160206642', 'Epoch Time (s): 164.47610304993577')
('Epoch 9', 'Objective: -0.2496047230965594', 'Train Acc: 0.9523666666666667', 'Test Acc: 0.9566', 'Train LL: -0.15626006673569495', 'Test LL: -0.13676600103027411', 'Epoch Time (s): 164.58110146899708')
('Epoch 10', 'Objective: -0.24095950807294156', 'Train Acc: 0.9540166666666666', 'Test Acc: 0.969', 'Train LL: -0.15021098769421382', 'Test LL: -0.0986391658467417', 'Epoch Time (s): 164.48498531710356')
('Epoch 11', 'Objective: -0.23125560022677014', 'Train Acc: 0.95625', 'Test Acc: 0.9535', 'Train LL: -0.14181737297234429', 'Test LL: -0.15253048051284726', 'Epoch Time (s): 164.6249499300029')
('Epoch 12', 'Objective: -0.22490210765351587', 'Train Acc: 0.95745', 'Test Acc: 0.9631', 'Train LL: -0.13712056317577415', 'Test LL: -0.11659191590912624', 'Epoch Time (s): 164.14127410994843')
('Epoch 13', 'Objective: -0.2216350771581757', 'Train Acc: 0.9584166666666667', 'Test Acc: 0.9544', 'Train LL: -0.1351070382307105', 'Test LL: -0.13585112873426217', 'Epoch Time (s): 164.41308514610864')
('Epoch 14', 'Objective: -0.21527181316304778', 'Train Acc: 0.9599833333333333', 'Test Acc: 0.9571', 'Train LL: -0.1299180507231772', 'Test LL: -0.12933588347947306', 'Epoch Time (s): 164.43796866503544')
('Epoch 15', 'Objective: -0.20992079211087963', 'Train Acc: 0.9617333333333333', 'Test Acc: 0.9622', 'Train LL: -0.12482450793516134', 'Test LL: -0.11281773408663194', 'Epoch Time (s): 164.5715216100216')
('Epoch 16', 'Objective: -0.2040263408718101', 'Train Acc: 0.9630833333333333', 'Test Acc: 0.9584', 'Train LL: -0.12099480451336643', 'Test LL: -0.12863595296779956', 'Epoch Time (s): 164.47692330204882')
('Epoch 17', 'Objective: -0.2047440913089228', 'Train Acc: 0.9627666666666667', 'Test Acc: 0.9652', 'Train LL: -0.12208460366030618', 'Test LL: -0.11302407112294409', 'Epoch Time (s): 164.5091244499199')
('Epoch 18', 'Objective: -0.20252769670168888', 'Train Acc: 0.9628333333333333', 'Test Acc: 0.9714', 'Train LL: -0.12039267567863238', 'Test LL: -0.0954476198590101', 'Epoch Time (s): 164.5322107388638')
('Epoch 19', 'Objective: -0.19516588814998756', 'Train Acc: 0.9648333333333333', 'Test Acc: 0.9679', 'Train LL: -0.11384014782110917', 'Test LL: -0.09465042473974865', 'Epoch Time (s): 164.4841534360312')
('Epoch 20', 'Objective: -0.19170753223503292', 'Train Acc: 0.9651333333333333', 'Test Acc: 0.9739', 'Train LL: -0.11086308831700116', 'Test LL: -0.08631898953515935', 'Epoch Time (s): 164.49720009509474')
('Epoch 21', 'Objective: -0.18832966858768013', 'Train Acc: 0.9664', 'Test Acc: 0.9679', 'Train LL: -0.10840494403320226', 'Test LL: -0.1020556429011706', 'Epoch Time (s): 164.4967506728135')
('Epoch 22', 'Objective: -0.18815031780971103', 'Train Acc: 0.96625', 'Test Acc: 0.98', 'Train LL: -0.10844323516038992', 'Test LL: -0.06833926812891247', 'Epoch Time (s): 164.51195289404131')
('Epoch 23', 'Objective: -0.18421325551508835', 'Train Acc: 0.9665166666666667', 'Test Acc: 0.9734', 'Train LL: -0.10532381348400077', 'Test LL: -0.0837821967258379', 'Epoch Time (s): 164.53456622897647')
('Epoch 24', 'Objective: -0.18018100386443903', 'Train Acc: 0.9684166666666667', 'Test Acc: 0.9738', 'Train LL: -0.10153660596235373', 'Test LL: -0.08075478796963605', 'Epoch Time (s): 164.46350712887943')
('Epoch 25', 'Objective: -0.1758039515134146', 'Train Acc: 0.96925', 'Test Acc: 0.9723', 'Train LL: -0.09778032208483999', 'Test LL: -0.08504899492608475', 'Epoch Time (s): 164.4773737860378')
('Epoch 26', 'Objective: -0.1769249381121766', 'Train Acc: 0.9690166666666666', 'Test Acc: 0.9706', 'Train LL: -0.09905499288305346', 'Test LL: -0.09198165984314649', 'Epoch Time (s): 164.44537618686445')
('Epoch 27', 'Objective: -0.17102101830797145', 'Train Acc: 0.9714166666666667', 'Test Acc: 0.9729', 'Train LL: -0.09384979572817825', 'Test LL: -0.08008164865642241', 'Epoch Time (s): 164.42635300080292')
('Epoch 28', 'Objective: -0.16894630442633418', 'Train Acc: 0.9707833333333333', 'Test Acc: 0.973', 'Train LL: -0.092687208006355', 'Test LL: -0.08256175239178631', 'Epoch Time (s): 164.48609003797174')
('Epoch 29', 'Objective: -0.17042654336957622', 'Train Acc: 0.9711', 'Test Acc: 0.9679', 'Train LL: -0.09449914844889848', 'Test LL: -0.09913947431068083', 'Epoch Time (s): 164.49779037595727')
('Epoch 30', 'Objective: -0.16338118929684237', 'Train Acc: 0.9725', 'Test Acc: 0.9792', 'Train LL: -0.08829282882609668', 'Test LL: -0.06384300464121523', 'Epoch Time (s): 164.54628670797683')
('Epoch 31', 'Objective: -0.1627085766272343', 'Train Acc: 0.9723', 'Test Acc: 0.9811', 'Train LL: -0.08804377389003862', 'Test LL: -0.059117202498741514', 'Epoch Time (s): 164.55909456685185')
('Epoch 32', 'Objective: -0.1597745014298576', 'Train Acc: 0.97335', 'Test Acc: 0.9755', 'Train LL: -0.08593655888669592', 'Test LL: -0.07912509159442115', 'Epoch Time (s): 164.44436665601097')
('Epoch 33', 'Objective: -0.15795326917902125', 'Train Acc: 0.9726333333333333', 'Test Acc: 0.9764', 'Train LL: -0.0844684661784608', 'Test LL: -0.07560385695796953', 'Epoch Time (s): 164.45246702991426')
('Epoch 34', 'Objective: -0.15631386406260092', 'Train Acc: 0.9740333333333333', 'Test Acc: 0.9633', 'Train LL: -0.08418735323792159', 'Test LL: -0.1127483776133927', 'Epoch Time (s): 164.40988949406892')
('Epoch 35', 'Objective: -0.15453524647095318', 'Train Acc: 0.9741333333333333', 'Test Acc: 0.9809', 'Train LL: -0.08273167651789701', 'Test LL: -0.05995163043148085', 'Epoch Time (s): 164.45277427718975')
('Epoch 36', 'Objective: -0.15248832631888018', 'Train Acc: 0.9745333333333334', 'Test Acc: 0.974', 'Train LL: -0.08144691480553369', 'Test LL: -0.07670372576954088', 'Epoch Time (s): 164.39454265288077')
('Epoch 37', 'Objective: -0.15271449776835294', 'Train Acc: 0.9740666666666666', 'Test Acc: 0.9672', 'Train LL: -0.08182865392047957', 'Test LL: -0.09803100622242529', 'Epoch Time (s): 164.43167095794342')
('Epoch 38', 'Objective: -0.15043851319868703', 'Train Acc: 0.9756166666666667', 'Test Acc: 0.9756', 'Train LL: -0.08047204535846939', 'Test LL: -0.07878717394717445', 'Epoch Time (s): 164.44880229304545')
('Epoch 39', 'Objective: -0.14945777611571892', 'Train Acc: 0.9751833333333333', 'Test Acc: 0.9788', 'Train LL: -0.07977261389568811', 'Test LL: -0.06674634989825554', 'Epoch Time (s): 164.44243480684236')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.11996458321580107', 'Train Acc: 0.9825', 'Test Acc: 0.9853', 'Train LL: -0.05511195668009254', 'Test LL: -0.04343267394065407', 'Epoch Time (s): 164.43057567882352')
('Epoch 41', 'Objective: -0.11293300062534524', 'Train Acc: 0.98385', 'Test Acc: 0.9852', 'Train LL: -0.050724316206893584', 'Test LL: -0.0445793733318871', 'Epoch Time (s): 164.40164154511876')
('Epoch 42', 'Objective: -0.11044958277839312', 'Train Acc: 0.9845333333333334', 'Test Acc: 0.9847', 'Train LL: -0.049280258845415675', 'Test LL: -0.04456855242810083', 'Epoch Time (s): 164.38933211006224')
('Epoch 43', 'Objective: -0.10876666795697244', 'Train Acc: 0.9846166666666667', 'Test Acc: 0.9842', 'Train LL: -0.04854600129083079', 'Test LL: -0.04850841949925997', 'Epoch Time (s): 164.46698997309431')
('Epoch 44', 'Objective: -0.10649995476465238', 'Train Acc: 0.9847666666666667', 'Test Acc: 0.9851', 'Train LL: -0.04689242108908667', 'Test LL: -0.04620751061564032', 'Epoch Time (s): 164.5271143349819')
('Epoch 45', 'Objective: -0.10611496385947732', 'Train Acc: 0.9850666666666666', 'Test Acc: 0.9829', 'Train LL: -0.04702786715883857', 'Test LL: -0.04887703966074511', 'Epoch Time (s): 164.49625274189748')
('Epoch 46', 'Objective: -0.10733560878639192', 'Train Acc: 0.9847166666666667', 'Test Acc: 0.9843', 'Train LL: -0.04869253351919237', 'Test LL: -0.04626867890380707', 'Epoch Time (s): 164.42685757996514')
('Epoch 47', 'Objective: -0.10516366364426799', 'Train Acc: 0.9853333333333333', 'Test Acc: 0.9853', 'Train LL: -0.04690514973880626', 'Test LL: -0.04486495747306197', 'Epoch Time (s): 164.59952836693265')
('Epoch 48', 'Objective: -0.1044161763273591', 'Train Acc: 0.9851666666666666', 'Test Acc: 0.9859', 'Train LL: -0.046617574567615096', 'Test LL: -0.04562974902538204', 'Epoch Time (s): 164.59209368005395')
('Epoch 49', 'Objective: -0.10343049632756565', 'Train Acc: 0.9851333333333333', 'Test Acc: 0.9849', 'Train LL: -0.045992496681230635', 'Test LL: -0.04672554189622409', 'Epoch Time (s): 164.52862121001817')
('Epoch 50', 'Objective: -0.1039673405710568', 'Train Acc: 0.9849333333333333', 'Test Acc: 0.9858', 'Train LL: -0.04675159751471212', 'Test LL: -0.04371130018464974', 'Epoch Time (s): 164.54579242086038')
('Epoch 51', 'Objective: -0.10311554030568551', 'Train Acc: 0.9849166666666667', 'Test Acc: 0.9851', 'Train LL: -0.04631795698848393', 'Test LL: -0.042818654240045786', 'Epoch Time (s): 164.43653517984785')
('Epoch 52', 'Objective: -0.10218191238984396', 'Train Acc: 0.9852833333333333', 'Test Acc: 0.984', 'Train LL: -0.04562665645822291', 'Test LL: -0.04680010782408573', 'Epoch Time (s): 164.374765093904')
('Epoch 53', 'Objective: -0.10355685368563743', 'Train Acc: 0.98515', 'Test Acc: 0.9852', 'Train LL: -0.04707801208981683', 'Test LL: -0.04510432333232913', 'Epoch Time (s): 164.71140174288303')
('Epoch 54', 'Objective: -0.10223800479797349', 'Train Acc: 0.9854', 'Test Acc: 0.9844', 'Train LL: -0.046181267996262626', 'Test LL: -0.04576246540751961', 'Epoch Time (s): 164.4744282211177')
('Epoch 55', 'Objective: -0.10156264010788317', 'Train Acc: 0.9856833333333334', 'Test Acc: 0.9848', 'Train LL: -0.045701953094694624', 'Test LL: -0.04570496176454891', 'Epoch Time (s): 164.6033629719168')
('Epoch 56', 'Objective: -0.10170792101647132', 'Train Acc: 0.9854', 'Test Acc: 0.9841', 'Train LL: -0.04600464817466738', 'Test LL: -0.04699460495008863', 'Epoch Time (s): 164.46730716782622')
('Epoch 57', 'Objective: -0.10162786135132666', 'Train Acc: 0.98535', 'Test Acc: 0.9861', 'Train LL: -0.04644571518619042', 'Test LL: -0.04361246061398671', 'Epoch Time (s): 164.4535715279635')
('Epoch 58', 'Objective: -0.1015842536736905', 'Train Acc: 0.9855833333333334', 'Test Acc: 0.9865', 'Train LL: -0.04631269423368769', 'Test LL: -0.04021020391861627', 'Epoch Time (s): 165.13711357302964')
('Epoch 59', 'Objective: -0.10137494732053694', 'Train Acc: 0.9851833333333333', 'Test Acc: 0.985', 'Train LL: -0.04624910926230125', 'Test LL: -0.0467968965501448', 'Epoch Time (s): 165.19062369083986')
('Epoch 60', 'Objective: -0.10019253517778039', 'Train Acc: 0.9855333333333334', 'Test Acc: 0.9846', 'Train LL: -0.04550861815430673', 'Test LL: -0.0463104471583845', 'Epoch Time (s): 165.25198900909163')
('Epoch 61', 'Objective: -0.10075746519214682', 'Train Acc: 0.9848666666666667', 'Test Acc: 0.9857', 'Train LL: -0.04601192885785355', 'Test LL: -0.04534478016297918', 'Epoch Time (s): 165.30042109289207')
('Epoch 62', 'Objective: -0.1010703184026404', 'Train Acc: 0.9846833333333334', 'Test Acc: 0.9851', 'Train LL: -0.04648861957449015', 'Test LL: -0.045118954401372376', 'Epoch Time (s): 165.13375951489434')
('Epoch 63', 'Objective: -0.10006034822265703', 'Train Acc: 0.9854333333333334', 'Test Acc: 0.9856', 'Train LL: -0.045598907035030466', 'Test LL: -0.04511376794766932', 'Epoch Time (s): 164.69597186590545')
('Epoch 64', 'Objective: -0.09965102889570575', 'Train Acc: 0.9855333333333334', 'Test Acc: 0.9856', 'Train LL: -0.04538567275894648', 'Test LL: -0.04490814346987172', 'Epoch Time (s): 164.56658041803166')
('Epoch 65', 'Objective: -0.09975814542920955', 'Train Acc: 0.98555', 'Test Acc: 0.9859', 'Train LL: -0.04573592153797348', 'Test LL: -0.04380405451946986', 'Epoch Time (s): 164.62780505698174')
('Epoch 66', 'Objective: -0.09926044731045935', 'Train Acc: 0.9856333333333334', 'Test Acc: 0.9845', 'Train LL: -0.045328333849456524', 'Test LL: -0.04701109658420907', 'Epoch Time (s): 164.60651932284236')
('Epoch 67', 'Objective: -0.09852542454154456', 'Train Acc: 0.9856833333333334', 'Test Acc: 0.9851', 'Train LL: -0.04468098571279909', 'Test LL: -0.045546954746994474', 'Epoch Time (s): 164.51649873098359')
('Epoch 68', 'Objective: -0.09836545279613283', 'Train Acc: 0.9857833333333333', 'Test Acc: 0.9861', 'Train LL: -0.04464899854115988', 'Test LL: -0.04438367027917708', 'Epoch Time (s): 164.53185450006276')
('Epoch 69', 'Objective: -0.09943951623224086', 'Train Acc: 0.9851166666666666', 'Test Acc: 0.9847', 'Train LL: -0.04582660924663445', 'Test LL: -0.04770919152438517', 'Epoch Time (s): 164.47210250399075')
('Epoch 70', 'Objective: -0.09762685283737244', 'Train Acc: 0.9855166666666667', 'Test Acc: 0.9864', 'Train LL: -0.04425083653159575', 'Test LL: -0.04044773997675659', 'Epoch Time (s): 164.48207831615582')
('Epoch 71', 'Objective: -0.0985454641263188', 'Train Acc: 0.9855', 'Test Acc: 0.9864', 'Train LL: -0.04510088645650911', 'Test LL: -0.04361729470593058', 'Epoch Time (s): 164.68985785217956')
('Epoch 72', 'Objective: -0.0982132274831861', 'Train Acc: 0.9857', 'Test Acc: 0.9848', 'Train LL: -0.04509343054558196', 'Test LL: -0.04704975039299369', 'Epoch Time (s): 164.57379957893863')
('Epoch 73', 'Objective: -0.09836166825261927', 'Train Acc: 0.9855666666666667', 'Test Acc: 0.9849', 'Train LL: -0.04512233171545957', 'Test LL: -0.04467637586109871', 'Epoch Time (s): 164.431717219064')
('Epoch 74', 'Objective: -0.09713143427303711', 'Train Acc: 0.9854666666666667', 'Test Acc: 0.9861', 'Train LL: -0.04429710905542183', 'Test LL: -0.043017717486364425', 'Epoch Time (s): 164.57292136200704')
('Epoch 75', 'Objective: -0.09649410394035186', 'Train Acc: 0.9859166666666667', 'Test Acc: 0.9863', 'Train LL: -0.04362513280235421', 'Test LL: -0.04281059434040873', 'Epoch Time (s): 164.64951355895028')
('Epoch 76', 'Objective: -0.09832924319227776', 'Train Acc: 0.9855', 'Test Acc: 0.9854', 'Train LL: -0.04553996101211276', 'Test LL: -0.04468373656429232', 'Epoch Time (s): 164.67245275410824')
('Epoch 77', 'Objective: -0.09734730181659712', 'Train Acc: 0.9857', 'Test Acc: 0.9864', 'Train LL: -0.04464547697684334', 'Test LL: -0.043704208382575584', 'Epoch Time (s): 164.6362396699842')
('Epoch 78', 'Objective: -0.09650092757328284', 'Train Acc: 0.9860833333333333', 'Test Acc: 0.9873', 'Train LL: -0.043920718456077916', 'Test LL: -0.04101021760323738', 'Epoch Time (s): 164.61071622092277')
('Epoch 79', 'Objective: -0.09782491802400847', 'Train Acc: 0.9852166666666666', 'Test Acc: 0.9872', 'Train LL: -0.04532614264369092', 'Test LL: -0.042607375107234786', 'Epoch Time (s): 164.5549058378674')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.09298032170089574', 'Train Acc: 0.9869666666666667', 'Test Acc: 0.9865', 'Train LL: -0.04115175541077459', 'Test LL: -0.04242349214069341', 'Epoch Time (s): 164.5627293488942')
('Epoch 81', 'Objective: -0.09246286235122461', 'Train Acc: 0.9873166666666666', 'Test Acc: 0.9865', 'Train LL: -0.04070390722899527', 'Test LL: -0.04093573429348479', 'Epoch Time (s): 164.51013555401005')
('Epoch 82', 'Objective: -0.09239345638400241', 'Train Acc: 0.9869333333333333', 'Test Acc: 0.9874', 'Train LL: -0.040555145895477214', 'Test LL: -0.04089856087833192', 'Epoch Time (s): 164.49013841198757')
('Epoch 83', 'Objective: -0.09183239106382342', 'Train Acc: 0.98735', 'Test Acc: 0.9867', 'Train LL: -0.0401191081065638', 'Test LL: -0.041862137184798344', 'Epoch Time (s): 164.46258156606928')
('Epoch 84', 'Objective: -0.09244171569517477', 'Train Acc: 0.98735', 'Test Acc: 0.9864', 'Train LL: -0.04072407731143138', 'Test LL: -0.04175592367873151', 'Epoch Time (s): 164.4819567729719')
('Epoch 85', 'Objective: -0.09097480866504437', 'Train Acc: 0.9877666666666667', 'Test Acc: 0.9866', 'Train LL: -0.03935231768558845', 'Test LL: -0.04103353172179558', 'Epoch Time (s): 164.4637694079429')
('Epoch 86', 'Objective: -0.09149072088938426', 'Train Acc: 0.9874333333333334', 'Test Acc: 0.987', 'Train LL: -0.03988622130723087', 'Test LL: -0.04078757644246416', 'Epoch Time (s): 164.43177723209374')
('Epoch 87', 'Objective: -0.09157738986208872', 'Train Acc: 0.9874833333333334', 'Test Acc: 0.9868', 'Train LL: -0.039961286792342315', 'Test LL: -0.04119970200092259', 'Epoch Time (s): 164.5215326200705')
('Epoch 88', 'Objective: -0.09119405274241715', 'Train Acc: 0.9874333333333334', 'Test Acc: 0.9872', 'Train LL: -0.03959632212996632', 'Test LL: -0.040669456400488226', 'Epoch Time (s): 164.55603226390667')
('Epoch 89', 'Objective: -0.09136216926087007', 'Train Acc: 0.9874333333333334', 'Test Acc: 0.9867', 'Train LL: -0.039797340452072436', 'Test LL: -0.04166313517849063', 'Epoch Time (s): 164.6907863668166')
('Epoch 90', 'Objective: -0.09078698476598072', 'Train Acc: 0.9877333333333334', 'Test Acc: 0.9867', 'Train LL: -0.0392458933200855', 'Test LL: -0.041042176174697804', 'Epoch Time (s): 164.48261709604412')
('Epoch 91', 'Objective: -0.09110262070627376', 'Train Acc: 0.9867333333333334', 'Test Acc: 0.9872', 'Train LL: -0.039479514683169105', 'Test LL: -0.03969799783058586', 'Epoch Time (s): 164.56091619795188')
('Epoch 92', 'Objective: -0.0914512290738449', 'Train Acc: 0.9874666666666667', 'Test Acc: 0.9867', 'Train LL: -0.0399443273321072', 'Test LL: -0.0408294420799204', 'Epoch Time (s): 164.49097643094137')
('Epoch 93', 'Objective: -0.09172322661665268', 'Train Acc: 0.9872333333333333', 'Test Acc: 0.9871', 'Train LL: -0.04016833495496514', 'Test LL: -0.04074998342940745', 'Epoch Time (s): 164.35144117986783')
('Epoch 94', 'Objective: -0.0908727155885212', 'Train Acc: 0.9871333333333333', 'Test Acc: 0.9865', 'Train LL: -0.039386529992206924', 'Test LL: -0.04139139585598574', 'Epoch Time (s): 164.14389037317596')
('Epoch 95', 'Objective: -0.0911007893320302', 'Train Acc: 0.9873666666666666', 'Test Acc: 0.9866', 'Train LL: -0.039601356520459895', 'Test LL: -0.04043038848832833', 'Epoch Time (s): 164.638260376174')
('Epoch 96', 'Objective: -0.09136233704527386', 'Train Acc: 0.9869333333333333', 'Test Acc: 0.9863', 'Train LL: -0.03986887449075466', 'Test LL: -0.04075890730229958', 'Epoch Time (s): 164.53388090291992')
('Epoch 97', 'Objective: -0.0911299497417757', 'Train Acc: 0.98735', 'Test Acc: 0.9872', 'Train LL: -0.03962635140173361', 'Test LL: -0.04065380963500784', 'Epoch Time (s): 164.4929456389509')
('Epoch 98', 'Objective: -0.08959861115481203', 'Train Acc: 0.9876666666666667', 'Test Acc: 0.9868', 'Train LL: -0.038242735052413615', 'Test LL: -0.040822230418460455', 'Epoch Time (s): 164.58757115202025')
('Epoch 99', 'Objective: -0.09082436277845883', 'Train Acc: 0.9874333333333334', 'Test Acc: 0.9867', 'Train LL: -0.03935918557247035', 'Test LL: -0.0409997694002549', 'Epoch Time (s): 164.63293857197277')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.09024603286454437
Final Train Accuracy: £0.9878166666666667
Final Train LL: £-0.03880097637581574
Final Test Accuracy: £0.9868
Final Test LL: £-0.04113983250117774
