dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: none
bn_tscale: none
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3305729156865542', 'Train Acc: 0.5392166666666667', 'Test Acc: 0.7609', 'Train LL: -1.2720884439667381', 'Test LL: -0.6983215681647681', 'Epoch Time (s): 162.41158160497434')
('Epoch 1', 'Objective: -0.5443854368109382', 'Train Acc: 0.8351666666666666', 'Test Acc: 0.868', 'Train LL: -0.49289868329700465', 'Test LL: -0.3827936187241154', 'Epoch Time (s): 162.46835646987893')
('Epoch 2', 'Objective: -0.3482751877279986', 'Train Acc: 0.9072166666666667', 'Test Acc: 0.9082', 'Train LL: -0.29844172100304067', 'Test LL: -0.28146615584267026', 'Epoch Time (s): 162.20858145598322')
('Epoch 3', 'Objective: -0.2645295126561836', 'Train Acc: 0.9324166666666667', 'Test Acc: 0.944', 'Train LL: -0.21671041859549914', 'Test LL: -0.17677231231456975', 'Epoch Time (s): 161.92811943008564')
('Epoch 4', 'Objective: -0.22800171753805226', 'Train Acc: 0.9426', 'Test Acc: 0.9395', 'Train LL: -0.18164704356711203', 'Test LL: -0.18878390529330394', 'Epoch Time (s): 161.9505279029254')
('Epoch 5', 'Objective: -0.20051226045832063', 'Train Acc: 0.9517', 'Test Acc: 0.9561', 'Train LL: -0.1556696954962809', 'Test LL: -0.1409719809052734', 'Epoch Time (s): 161.96093423198909')
('Epoch 6', 'Objective: -0.18515086810221526', 'Train Acc: 0.9562', 'Test Acc: 0.9652', 'Train LL: -0.14144848879551722', 'Test LL: -0.11323541844717902', 'Epoch Time (s): 161.93532857811078')
('Epoch 7', 'Objective: -0.17031079151644063', 'Train Acc: 0.9613166666666667', 'Test Acc: 0.9695', 'Train LL: -0.12712855023572509', 'Test LL: -0.09677274269953112', 'Epoch Time (s): 161.93966423906386')
('Epoch 8', 'Objective: -0.15750494890063738', 'Train Acc: 0.9635', 'Test Acc: 0.974', 'Train LL: -0.11505318510484028', 'Test LL: -0.08152356567783668', 'Epoch Time (s): 161.92185988114215')
('Epoch 9', 'Objective: -0.1503828884436645', 'Train Acc: 0.9662333333333334', 'Test Acc: 0.9658', 'Train LL: -0.10890121618806546', 'Test LL: -0.10521362084836369', 'Epoch Time (s): 161.98920284793712')
('Epoch 10', 'Objective: -0.1432134962645356', 'Train Acc: 0.9681333333333333', 'Test Acc: 0.9706', 'Train LL: -0.10245875609322357', 'Test LL: -0.0894168931585387', 'Epoch Time (s): 161.93278809916228')
('Epoch 11', 'Objective: -0.13625559968210868', 'Train Acc: 0.9701', 'Test Acc: 0.9636', 'Train LL: -0.09643079312733373', 'Test LL: -0.10654409432847381', 'Epoch Time (s): 161.93613650393672')
('Epoch 12', 'Objective: -0.13179720367874007', 'Train Acc: 0.9712666666666666', 'Test Acc: 0.9778', 'Train LL: -0.09273962043509607', 'Test LL: -0.06888516311212547', 'Epoch Time (s): 161.91687709791586')
('Epoch 13', 'Objective: -0.12678737702913864', 'Train Acc: 0.9724333333333334', 'Test Acc: 0.9717', 'Train LL: -0.08806386507238374', 'Test LL: -0.09084848706604727', 'Epoch Time (s): 161.9107257768046')
('Epoch 14', 'Objective: -0.12250759491941772', 'Train Acc: 0.9740833333333333', 'Test Acc: 0.9775', 'Train LL: -0.08448746242963746', 'Test LL: -0.07242372133441415', 'Epoch Time (s): 161.9028850281611')
('Epoch 15', 'Objective: -0.12020768675854199', 'Train Acc: 0.9738166666666667', 'Test Acc: 0.972', 'Train LL: -0.08255636341488971', 'Test LL: -0.08383819491663327', 'Epoch Time (s): 161.9014001940377')
('Epoch 16', 'Objective: -0.11716768752232282', 'Train Acc: 0.9748', 'Test Acc: 0.9788', 'Train LL: -0.08006323608392489', 'Test LL: -0.06442901822324075', 'Epoch Time (s): 161.9649645499885')
('Epoch 17', 'Objective: -0.11530698361003017', 'Train Acc: 0.9753333333333334', 'Test Acc: 0.983', 'Train LL: -0.078288672348952', 'Test LL: -0.050476495584559467', 'Epoch Time (s): 161.9029357249383')
('Epoch 18', 'Objective: -0.11154360336323256', 'Train Acc: 0.9759', 'Test Acc: 0.981', 'Train LL: -0.07524740877873773', 'Test LL: -0.06109709359390954', 'Epoch Time (s): 161.95276278513484')
('Epoch 19', 'Objective: -0.11043487575421813', 'Train Acc: 0.9770833333333333', 'Test Acc: 0.9821', 'Train LL: -0.0744941121474241', 'Test LL: -0.054884437048524366', 'Epoch Time (s): 161.95239061606117')
('Epoch 20', 'Objective: -0.10670318493911021', 'Train Acc: 0.9776166666666667', 'Test Acc: 0.9766', 'Train LL: -0.071086484669294', 'Test LL: -0.06924331532247832', 'Epoch Time (s): 161.93439262686297')
('Epoch 21', 'Objective: -0.104527189793819', 'Train Acc: 0.97775', 'Test Acc: 0.9806', 'Train LL: -0.06930825601199565', 'Test LL: -0.059245657735942904', 'Epoch Time (s): 161.97181443986483')
('Epoch 22', 'Objective: -0.10389922487156976', 'Train Acc: 0.9782333333333333', 'Test Acc: 0.9724', 'Train LL: -0.06901810443175721', 'Test LL: -0.08194099155685669', 'Epoch Time (s): 161.98371932609007')
('Epoch 23', 'Objective: -0.1002831594364472', 'Train Acc: 0.9790666666666666', 'Test Acc: 0.9707', 'Train LL: -0.06570537394588512', 'Test LL: -0.09001668510907834', 'Epoch Time (s): 161.92910744599067')
('Epoch 24', 'Objective: -0.10010707262191844', 'Train Acc: 0.97855', 'Test Acc: 0.9809', 'Train LL: -0.06583418620969995', 'Test LL: -0.05738487829496764', 'Epoch Time (s): 161.89962120191194')
('Epoch 25', 'Objective: -0.09732605287210304', 'Train Acc: 0.9799833333333333', 'Test Acc: 0.9779', 'Train LL: -0.06358132160229664', 'Test LL: -0.06772584860395457', 'Epoch Time (s): 161.97029524180107')
('Epoch 26', 'Objective: -0.09520173598126125', 'Train Acc: 0.9809833333333333', 'Test Acc: 0.9802', 'Train LL: -0.06165797899186489', 'Test LL: -0.06244550579600602', 'Epoch Time (s): 161.93264582706615')
('Epoch 27', 'Objective: -0.09618789932670983', 'Train Acc: 0.98', 'Test Acc: 0.9856', 'Train LL: -0.06291881065455072', 'Test LL: -0.049830143410801254', 'Epoch Time (s): 161.9328176479321')
('Epoch 28', 'Objective: -0.09389831020365161', 'Train Acc: 0.98085', 'Test Acc: 0.9665', 'Train LL: -0.060907896391521464', 'Test LL: -0.09627418903138711', 'Epoch Time (s): 161.94846259104088')
('Epoch 29', 'Objective: -0.09227543274971264', 'Train Acc: 0.9811166666666666', 'Test Acc: 0.9817', 'Train LL: -0.05935611438024691', 'Test LL: -0.05218630843978848', 'Epoch Time (s): 161.91263289004564')
('Epoch 30', 'Objective: -0.09203401799787214', 'Train Acc: 0.9816', 'Test Acc: 0.9837', 'Train LL: -0.05933202202537665', 'Test LL: -0.04837109823587172', 'Epoch Time (s): 161.91080933087505')
('Epoch 31', 'Objective: -0.08980356321396452', 'Train Acc: 0.9818', 'Test Acc: 0.9833', 'Train LL: -0.05730522194344983', 'Test LL: -0.05518853230233161', 'Epoch Time (s): 161.91533594788052')
('Epoch 32', 'Objective: -0.08897722004062351', 'Train Acc: 0.98245', 'Test Acc: 0.9854', 'Train LL: -0.05693429513078565', 'Test LL: -0.04194964790264376', 'Epoch Time (s): 161.91181076783687')
('Epoch 33', 'Objective: -0.08868840501162804', 'Train Acc: 0.9821333333333333', 'Test Acc: 0.9773', 'Train LL: -0.05668403769066529', 'Test LL: -0.06787822599542184', 'Epoch Time (s): 161.87952233594842')
('Epoch 34', 'Objective: -0.0872419742315403', 'Train Acc: 0.98205', 'Test Acc: 0.982', 'Train LL: -0.0554804265217667', 'Test LL: -0.05170751041840663', 'Epoch Time (s): 161.95133762806654')
('Epoch 35', 'Objective: -0.0871038354414696', 'Train Acc: 0.9825166666666667', 'Test Acc: 0.9859', 'Train LL: -0.055525090323917725', 'Test LL: -0.04079156157357858', 'Epoch Time (s): 161.9358526498545')
('Epoch 36', 'Objective: -0.08675777608186162', 'Train Acc: 0.9824833333333334', 'Test Acc: 0.9856', 'Train LL: -0.05512646471835601', 'Test LL: -0.044509054402841815', 'Epoch Time (s): 161.9096866780892')
('Epoch 37', 'Objective: -0.08537057230350895', 'Train Acc: 0.9833666666666666', 'Test Acc: 0.9847', 'Train LL: -0.05423650993944316', 'Test LL: -0.04535279256546094', 'Epoch Time (s): 161.92787835304625')
('Epoch 38', 'Objective: -0.08290037823913124', 'Train Acc: 0.9836166666666667', 'Test Acc: 0.9828', 'Train LL: -0.05204010307893901', 'Test LL: -0.05104672869550898', 'Epoch Time (s): 161.94564754795283')
('Epoch 39', 'Objective: -0.08334605213440814', 'Train Acc: 0.9834166666666667', 'Test Acc: 0.977', 'Train LL: -0.05263337350384997', 'Test LL: -0.06444509845937903', 'Epoch Time (s): 161.91620232001878')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.0634864243801329', 'Train Acc: 0.9886833333333334', 'Test Acc: 0.9895', 'Train LL: -0.03434140277076961', 'Test LL: -0.03109092755431756', 'Epoch Time (s): 161.95882174302824')
('Epoch 41', 'Objective: -0.05753589347891653', 'Train Acc: 0.9908', 'Test Acc: 0.9909', 'Train LL: -0.029684163971137018', 'Test LL: -0.027951199211130894', 'Epoch Time (s): 161.91741864010692')
('Epoch 42', 'Objective: -0.05590006005116646', 'Train Acc: 0.9905666666666667', 'Test Acc: 0.9892', 'Train LL: -0.028613364472520865', 'Test LL: -0.030818716827727292', 'Epoch Time (s): 161.9463734580204')
('Epoch 43', 'Objective: -0.05482239305664726', 'Train Acc: 0.9908833333333333', 'Test Acc: 0.9904', 'Train LL: -0.02785004671084167', 'Test LL: -0.028574385555007575', 'Epoch Time (s): 161.91861896286719')
('Epoch 44', 'Objective: -0.05423293651951864', 'Train Acc: 0.99095', 'Test Acc: 0.989', 'Train LL: -0.027493445827866086', 'Test LL: -0.030943642919740496', 'Epoch Time (s): 161.9527468921151')
('Epoch 45', 'Objective: -0.053688966854808555', 'Train Acc: 0.9915166666666667', 'Test Acc: 0.9903', 'Train LL: -0.027148235732837353', 'Test LL: -0.02853470303952396', 'Epoch Time (s): 161.93100091908127')
('Epoch 46', 'Objective: -0.05240927312378862', 'Train Acc: 0.99145', 'Test Acc: 0.9892', 'Train LL: -0.02611749206817788', 'Test LL: -0.030721169393613804', 'Epoch Time (s): 161.97207357920706')
('Epoch 47', 'Objective: -0.05231649827879442', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9891', 'Train LL: -0.026168221110450245', 'Test LL: -0.03058746907283862', 'Epoch Time (s): 161.98039603000507')
('Epoch 48', 'Objective: -0.05209098506126352', 'Train Acc: 0.9916166666666667', 'Test Acc: 0.9907', 'Train LL: -0.026060256971152003', 'Test LL: -0.02714487354934746', 'Epoch Time (s): 162.11189806903712')
('Epoch 49', 'Objective: -0.05115505546851732', 'Train Acc: 0.9917666666666667', 'Test Acc: 0.9907', 'Train LL: -0.025313132757402806', 'Test LL: -0.029364612192962915', 'Epoch Time (s): 162.167254650034')
('Epoch 50', 'Objective: -0.05075781124520499', 'Train Acc: 0.9917666666666667', 'Test Acc: 0.9915', 'Train LL: -0.02500002786463941', 'Test LL: -0.028740278689941112', 'Epoch Time (s): 162.086811196059')
('Epoch 51', 'Objective: -0.05042259421313775', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.9905', 'Train LL: -0.024804213074649615', 'Test LL: -0.03008336580231355', 'Epoch Time (s): 162.18528829980642')
('Epoch 52', 'Objective: -0.05020898031517397', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.991', 'Train LL: -0.024676766578208553', 'Test LL: -0.027067273008169582', 'Epoch Time (s): 162.11993264500052')
('Epoch 53', 'Objective: -0.050268026698731406', 'Train Acc: 0.9919166666666667', 'Test Acc: 0.9907', 'Train LL: -0.024773171041171237', 'Test LL: -0.0268416352418929', 'Epoch Time (s): 162.16219853586517')
('Epoch 54', 'Objective: -0.05011279500631445', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.9904', 'Train LL: -0.024762120539591675', 'Test LL: -0.029536219323233564', 'Epoch Time (s): 162.14691706001759')
('Epoch 55', 'Objective: -0.04932764982308125', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9914', 'Train LL: -0.02401166599345157', 'Test LL: -0.02587215684987493', 'Epoch Time (s): 162.12724587297998')
('Epoch 56', 'Objective: -0.049340858186693266', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9916', 'Train LL: -0.02412994980411116', 'Test LL: -0.024998045627584748', 'Epoch Time (s): 162.12923813494854')
('Epoch 57', 'Objective: -0.04919208202108521', 'Train Acc: 0.99205', 'Test Acc: 0.9911', 'Train LL: -0.02411919685108785', 'Test LL: -0.027081695198198866', 'Epoch Time (s): 162.13708449411206')
('Epoch 58', 'Objective: -0.04815535300302471', 'Train Acc: 0.9925666666666667', 'Test Acc: 0.9905', 'Train LL: -0.023202847691102587', 'Test LL: -0.027898003094149602', 'Epoch Time (s): 162.15537700708956')
('Epoch 59', 'Objective: -0.048444355469558706', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9921', 'Train LL: -0.023511949342319875', 'Test LL: -0.02390460468281389', 'Epoch Time (s): 162.17010568804108')
('Epoch 60', 'Objective: -0.04915267939066859', 'Train Acc: 0.9922', 'Test Acc: 0.9906', 'Train LL: -0.024158480678736806', 'Test LL: -0.028537545054965013', 'Epoch Time (s): 162.18584324093536')
('Epoch 61', 'Objective: -0.0480435071907112', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9904', 'Train LL: -0.02314563670681877', 'Test LL: -0.029594415252265242', 'Epoch Time (s): 162.12750968616456')
('Epoch 62', 'Objective: -0.04804700430837734', 'Train Acc: 0.99235', 'Test Acc: 0.9906', 'Train LL: -0.023227287469580096', 'Test LL: -0.028806998342807498', 'Epoch Time (s): 162.14696458587423')
('Epoch 63', 'Objective: -0.04768833720651415', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9906', 'Train LL: -0.02304032086519575', 'Test LL: -0.02793688333940134', 'Epoch Time (s): 162.0846920441836')
('Epoch 64', 'Objective: -0.04767393627259134', 'Train Acc: 0.99255', 'Test Acc: 0.9907', 'Train LL: -0.023047690104537093', 'Test LL: -0.028202576530026488', 'Epoch Time (s): 162.08997055981308')
('Epoch 65', 'Objective: -0.047581419076476256', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9924', 'Train LL: -0.022996984561416158', 'Test LL: -0.02453163403900888', 'Epoch Time (s): 162.12871363805607')
('Epoch 66', 'Objective: -0.046452345228480046', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9917', 'Train LL: -0.022007568846716112', 'Test LL: -0.02443663435723267', 'Epoch Time (s): 162.19811846292578')
('Epoch 67', 'Objective: -0.0469621163237765', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9881', 'Train LL: -0.022467525417108822', 'Test LL: -0.0340655094893685', 'Epoch Time (s): 162.18629493610933')
('Epoch 68', 'Objective: -0.04693901839472047', 'Train Acc: 0.9927', 'Test Acc: 0.9909', 'Train LL: -0.022568874383300516', 'Test LL: -0.02822388545042823', 'Epoch Time (s): 162.07661374215968')
('Epoch 69', 'Objective: -0.04710008066338447', 'Train Acc: 0.99265', 'Test Acc: 0.9907', 'Train LL: -0.022719743528277186', 'Test LL: -0.027562148811373702', 'Epoch Time (s): 162.13746569305658')
('Epoch 70', 'Objective: -0.046818756821813697', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9913', 'Train LL: -0.0224851699058414', 'Test LL: -0.027465841271304133', 'Epoch Time (s): 162.08906125999056')
('Epoch 71', 'Objective: -0.04611394187768504', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9904', 'Train LL: -0.02189940022132151', 'Test LL: -0.02970915195946691', 'Epoch Time (s): 162.18318247701973')
('Epoch 72', 'Objective: -0.046515095158415586', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9903', 'Train LL: -0.022319985216582426', 'Test LL: -0.02893667094781986', 'Epoch Time (s): 162.2062357100658')
('Epoch 73', 'Objective: -0.04584287499713262', 'Train Acc: 0.9933833333333333', 'Test Acc: 0.9911', 'Train LL: -0.021692927682529034', 'Test LL: -0.026664812637002853', 'Epoch Time (s): 162.26386358309537')
('Epoch 74', 'Objective: -0.04573386023419814', 'Train Acc: 0.99295', 'Test Acc: 0.9909', 'Train LL: -0.021611777834194434', 'Test LL: -0.028394479995133257', 'Epoch Time (s): 162.23262099479325')
('Epoch 75', 'Objective: -0.046331594578938436', 'Train Acc: 0.9929', 'Test Acc: 0.9904', 'Train LL: -0.022197836817018434', 'Test LL: -0.0295960461763847', 'Epoch Time (s): 162.27295879204758')
('Epoch 76', 'Objective: -0.04530584838267201', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9897', 'Train LL: -0.021260017217329764', 'Test LL: -0.03042762441853322', 'Epoch Time (s): 162.2812903309241')
('Epoch 77', 'Objective: -0.045251383829059195', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9899', 'Train LL: -0.021217236854153748', 'Test LL: -0.03033120112220788', 'Epoch Time (s): 162.21291016601026')
('Epoch 78', 'Objective: -0.04582394930150086', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9904', 'Train LL: -0.021797279259355415', 'Test LL: -0.029204687597719516', 'Epoch Time (s): 162.15475362795405')
('Epoch 79', 'Objective: -0.0456195899770059', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9907', 'Train LL: -0.021719467642299574', 'Test LL: -0.031201610768846342', 'Epoch Time (s): 162.26838098000735')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.042869473086332696', 'Train Acc: 0.9938333333333333', 'Test Acc: 0.9916', 'Train LL: -0.019206206291494617', 'Test LL: -0.02722703649778984', 'Epoch Time (s): 162.28861278807744')
('Epoch 81', 'Objective: -0.042847012483171965', 'Train Acc: 0.9938833333333333', 'Test Acc: 0.9917', 'Train LL: -0.019188302208869676', 'Test LL: -0.02624024317812524', 'Epoch Time (s): 162.19169890577905')
('Epoch 82', 'Objective: -0.0419104744666487', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9915', 'Train LL: -0.01833115582580532', 'Test LL: -0.02623692401022193', 'Epoch Time (s): 162.25491748005152')
('Epoch 83', 'Objective: -0.041713135471796454', 'Train Acc: 0.99405', 'Test Acc: 0.9916', 'Train LL: -0.018126811253010824', 'Test LL: -0.02579823209169847', 'Epoch Time (s): 162.3356435149908')
('Epoch 84', 'Objective: -0.041510652751759684', 'Train Acc: 0.9942', 'Test Acc: 0.9918', 'Train LL: -0.017933909400402674', 'Test LL: -0.02501321922049678', 'Epoch Time (s): 162.23744643596')
('Epoch 85', 'Objective: -0.04191927410385355', 'Train Acc: 0.9945', 'Test Acc: 0.9913', 'Train LL: -0.018320776838348478', 'Test LL: -0.026025425491832926', 'Epoch Time (s): 162.3428850369528')
('Epoch 86', 'Objective: -0.04133968420658375', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9915', 'Train LL: -0.017769544756837802', 'Test LL: -0.025643415200921792', 'Epoch Time (s): 162.2242826160509')
('Epoch 87', 'Objective: -0.04169092769666264', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9913', 'Train LL: -0.018112658364006884', 'Test LL: -0.025725018498408844', 'Epoch Time (s): 162.18465010891668')
('Epoch 88', 'Objective: -0.04174793393324192', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.9914', 'Train LL: -0.01818155904494323', 'Test LL: -0.025709537170872033', 'Epoch Time (s): 162.25809700298123')
('Epoch 89', 'Objective: -0.04148380257602255', 'Train Acc: 0.9943', 'Test Acc: 0.9907', 'Train LL: -0.017913475442287316', 'Test LL: -0.0274146074818219', 'Epoch Time (s): 162.1871610789094')
('Epoch 90', 'Objective: -0.041631636869634274', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9914', 'Train LL: -0.018037014094973196', 'Test LL: -0.02598350145894578', 'Epoch Time (s): 162.20219131396152')
('Epoch 91', 'Objective: -0.04115918249266583', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9913', 'Train LL: -0.017588095788018815', 'Test LL: -0.02662323467556213', 'Epoch Time (s): 162.24839026597328')
('Epoch 92', 'Objective: -0.04157978409209535', 'Train Acc: 0.9944', 'Test Acc: 0.9911', 'Train LL: -0.018031339903616567', 'Test LL: -0.02565121348400578', 'Epoch Time (s): 162.27046226896346')
('Epoch 93', 'Objective: -0.04075390774868188', 'Train Acc: 0.99475', 'Test Acc: 0.9913', 'Train LL: -0.017257067168811736', 'Test LL: -0.025741043903408076', 'Epoch Time (s): 162.25159222097136')
('Epoch 94', 'Objective: -0.041535366218667436', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9911', 'Train LL: -0.01798165063120151', 'Test LL: -0.02601496827239174', 'Epoch Time (s): 162.16675874497741')
('Epoch 95', 'Objective: -0.041040703587467225', 'Train Acc: 0.9945', 'Test Acc: 0.9912', 'Train LL: -0.017522203256579185', 'Test LL: -0.025420494056769816', 'Epoch Time (s): 162.18547194893472')
('Epoch 96', 'Objective: -0.0412755546011206', 'Train Acc: 0.99425', 'Test Acc: 0.9909', 'Train LL: -0.01774042771067084', 'Test LL: -0.026092178512669147', 'Epoch Time (s): 162.26366276992485')
('Epoch 97', 'Objective: -0.041043788912044375', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9913', 'Train LL: -0.017539858997084', 'Test LL: -0.025735697918552763', 'Epoch Time (s): 162.22055027191527')
('Epoch 98', 'Objective: -0.04055627634609233', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9915', 'Train LL: -0.017082809926955458', 'Test LL: -0.02595567325830827', 'Epoch Time (s): 162.1487783929333')
('Epoch 99', 'Objective: -0.040861257147923935', 'Train Acc: 0.9947666666666667', 'Test Acc: 0.9921', 'Train LL: -0.017386390711078694', 'Test LL: -0.02533448516994025', 'Epoch Time (s): 162.20549330092035')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.040513622832589205
Final Train Accuracy: £0.9946166666666667
Final Train LL: £-0.01704084669509993
Final Test Accuracy: £0.9919
Final Test LL: £-0.025258862739354897
