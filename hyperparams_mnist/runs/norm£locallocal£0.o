dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: local
bn_tnorm: local
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.55732933799117', 'Train Acc: 0.43853333333333333', 'Test Acc: 0.6632', 'Train LL: -1.5105689797635935', 'Test LL: -0.993764356427564', 'Epoch Time (s): 165.72628995915875')
('Epoch 1', 'Objective: -0.6866197939542149', 'Train Acc: 0.7873833333333333', 'Test Acc: 0.8342', 'Train LL: -0.6240488018831842', 'Test LL: -0.453008394842178', 'Epoch Time (s): 165.53349021892063')
('Epoch 2', 'Objective: -0.41043178419434473', 'Train Acc: 0.8860666666666667', 'Test Acc: 0.9212', 'Train LL: -0.35101902683780234', 'Test LL: -0.24941118731287962', 'Epoch Time (s): 165.62670614104718')
('Epoch 3', 'Objective: -0.3076549164974075', 'Train Acc: 0.92055', 'Test Acc: 0.9222', 'Train LL: -0.25154967739579454', 'Test LL: -0.23681270620251238', 'Epoch Time (s): 165.58021352114156')
('Epoch 4', 'Objective: -0.2622699172688852', 'Train Acc: 0.9346166666666667', 'Test Acc: 0.9472', 'Train LL: -0.2091104661490331', 'Test LL: -0.16187167198328406', 'Epoch Time (s): 165.64682819298469')
('Epoch 5', 'Objective: -0.2328199457632193', 'Train Acc: 0.9426', 'Test Acc: 0.9632', 'Train LL: -0.18220565950226666', 'Test LL: -0.12231923880373674', 'Epoch Time (s): 165.6139508630149')
('Epoch 6', 'Objective: -0.21082897824866545', 'Train Acc: 0.9499333333333333', 'Test Acc: 0.9562', 'Train LL: -0.16232162946197648', 'Test LL: -0.13472224549114095', 'Epoch Time (s): 165.6420366470702')
('Epoch 7', 'Objective: -0.19295134750883486', 'Train Acc: 0.9542333333333334', 'Test Acc: 0.9592', 'Train LL: -0.14612663228288586', 'Test LL: -0.12783877141638295', 'Epoch Time (s): 165.607842593221')
('Epoch 8', 'Objective: -0.18234546407747226', 'Train Acc: 0.9569333333333333', 'Test Acc: 0.9684', 'Train LL: -0.13716749309695261', 'Test LL: -0.10417081746911946', 'Epoch Time (s): 165.69156128005125')
('Epoch 9', 'Objective: -0.17012129190284395', 'Train Acc: 0.9598833333333333', 'Test Acc: 0.9732', 'Train LL: -0.12575505353660854', 'Test LL: -0.08380341353444383', 'Epoch Time (s): 165.6073304831516')
('Epoch 10', 'Objective: -0.16143391996871945', 'Train Acc: 0.9620166666666666', 'Test Acc: 0.9332', 'Train LL: -0.11773788580912208', 'Test LL: -0.19943854532870559', 'Epoch Time (s): 165.61885710200295')
('Epoch 11', 'Objective: -0.15177284469158556', 'Train Acc: 0.9657', 'Test Acc: 0.9637', 'Train LL: -0.10909871871532557', 'Test LL: -0.11628869318368956', 'Epoch Time (s): 165.4833095620852')
('Epoch 12', 'Objective: -0.14781435024009626', 'Train Acc: 0.9669666666666666', 'Test Acc: 0.9794', 'Train LL: -0.1058841624721965', 'Test LL: -0.0740972485590467', 'Epoch Time (s): 165.5910429819487')
('Epoch 13', 'Objective: -0.14322455707499884', 'Train Acc: 0.96825', 'Test Acc: 0.9781', 'Train LL: -0.10236568898258665', 'Test LL: -0.06515738607175224', 'Epoch Time (s): 165.46688024583273')
('Epoch 14', 'Objective: -0.13728245093933478', 'Train Acc: 0.9698333333333333', 'Test Acc: 0.9745', 'Train LL: -0.09660036847603269', 'Test LL: -0.08067776254818494', 'Epoch Time (s): 165.21470712102018')
('Epoch 15', 'Objective: -0.12952412551831208', 'Train Acc: 0.97155', 'Test Acc: 0.9784', 'Train LL: -0.09002084843423483', 'Test LL: -0.06762999581959186', 'Epoch Time (s): 165.87703265389428')
('Epoch 16', 'Objective: -0.12692013413799014', 'Train Acc: 0.9725', 'Test Acc: 0.9723', 'Train LL: -0.08806664565556982', 'Test LL: -0.08555421244017335', 'Epoch Time (s): 165.93070531683043')
('Epoch 17', 'Objective: -0.12661576751151452', 'Train Acc: 0.9731166666666666', 'Test Acc: 0.9745', 'Train LL: -0.08827067791516878', 'Test LL: -0.08017391999489723', 'Epoch Time (s): 165.8452216561418')
('Epoch 18', 'Objective: -0.11955586154125884', 'Train Acc: 0.97405', 'Test Acc: 0.9673', 'Train LL: -0.08226314240464666', 'Test LL: -0.1004737421666633', 'Epoch Time (s): 165.8439970340114')
('Epoch 19', 'Objective: -0.12038524420797325', 'Train Acc: 0.97435', 'Test Acc: 0.973', 'Train LL: -0.08303724794992798', 'Test LL: -0.08654660253959186', 'Epoch Time (s): 165.79313606396317')
('Epoch 20', 'Objective: -0.1163408559749129', 'Train Acc: 0.9751666666666666', 'Test Acc: 0.9791', 'Train LL: -0.07958022631472227', 'Test LL: -0.0645489008464778', 'Epoch Time (s): 165.82755155302584')
('Epoch 21', 'Objective: -0.11316685813185694', 'Train Acc: 0.97605', 'Test Acc: 0.9756', 'Train LL: -0.0767848930607324', 'Test LL: -0.0746284809920226', 'Epoch Time (s): 165.81023218412884')
('Epoch 22', 'Objective: -0.11071098380189467', 'Train Acc: 0.9767833333333333', 'Test Acc: 0.9797', 'Train LL: -0.07480538466377687', 'Test LL: -0.06437609354156858', 'Epoch Time (s): 165.84491522493772')
('Epoch 23', 'Objective: -0.11022228848382742', 'Train Acc: 0.97685', 'Test Acc: 0.9809', 'Train LL: -0.07447941392875236', 'Test LL: -0.05675717004543951', 'Epoch Time (s): 165.6729924569372')
('Epoch 24', 'Objective: -0.10624019027061168', 'Train Acc: 0.9783166666666666', 'Test Acc: 0.9801', 'Train LL: -0.07115451430431582', 'Test LL: -0.05694941830068517', 'Epoch Time (s): 165.40964188589714')
('Epoch 25', 'Objective: -0.10595851752737272', 'Train Acc: 0.97815', 'Test Acc: 0.9752', 'Train LL: -0.07100994233748768', 'Test LL: -0.0721372186809656', 'Epoch Time (s): 165.5042138081044')
('Epoch 26', 'Objective: -0.10404161870038925', 'Train Acc: 0.9778666666666667', 'Test Acc: 0.9789', 'Train LL: -0.06952690276225126', 'Test LL: -0.06428074510149201', 'Epoch Time (s): 165.5798614071682')
('Epoch 27', 'Objective: -0.10199150809033362', 'Train Acc: 0.97825', 'Test Acc: 0.9864', 'Train LL: -0.06767546592596933', 'Test LL: -0.04254030319816324', 'Epoch Time (s): 165.71321446006186')
('Epoch 28', 'Objective: -0.10014277095495491', 'Train Acc: 0.97945', 'Test Acc: 0.973', 'Train LL: -0.06615251343448535', 'Test LL: -0.07774856371962599', 'Epoch Time (s): 165.57734353700653')
('Epoch 29', 'Objective: -0.09933168054399787', 'Train Acc: 0.9795', 'Test Acc: 0.9811', 'Train LL: -0.06561224230968792', 'Test LL: -0.05971946606891155', 'Epoch Time (s): 165.51976846787147')
('Epoch 30', 'Objective: -0.09895330492477619', 'Train Acc: 0.9786166666666667', 'Test Acc: 0.9788', 'Train LL: -0.06543976430038807', 'Test LL: -0.06585384082164909', 'Epoch Time (s): 165.4827068480663')
('Epoch 31', 'Objective: -0.0968450481018577', 'Train Acc: 0.97965', 'Test Acc: 0.9764', 'Train LL: -0.06373313413513743', 'Test LL: -0.07253937329549952', 'Epoch Time (s): 165.6178796798922')
('Epoch 32', 'Objective: -0.09531250621545012', 'Train Acc: 0.9799666666666667', 'Test Acc: 0.9832', 'Train LL: -0.06240696944772039', 'Test LL: -0.04937694048051822', 'Epoch Time (s): 165.5882442020811')
('Epoch 33', 'Objective: -0.09390728673183041', 'Train Acc: 0.9804666666666667', 'Test Acc: 0.9778', 'Train LL: -0.06112424067733008', 'Test LL: -0.06734125747661523', 'Epoch Time (s): 165.63801407604478')
('Epoch 34', 'Objective: -0.0940244947793425', 'Train Acc: 0.9807333333333333', 'Test Acc: 0.9825', 'Train LL: -0.06143496102470085', 'Test LL: -0.056213571223773566', 'Epoch Time (s): 165.6300221439451')
('Epoch 35', 'Objective: -0.09208348449085653', 'Train Acc: 0.9811166666666666', 'Test Acc: 0.9785', 'Train LL: -0.05984487470883215', 'Test LL: -0.06438636883353172', 'Epoch Time (s): 165.65362404007465')
('Epoch 36', 'Objective: -0.08959933563420602', 'Train Acc: 0.982', 'Test Acc: 0.985', 'Train LL: -0.05775060049495093', 'Test LL: -0.04574121910859479', 'Epoch Time (s): 165.65282010193914')
('Epoch 37', 'Objective: -0.09214451357929226', 'Train Acc: 0.9805166666666667', 'Test Acc: 0.9813', 'Train LL: -0.06013825272604298', 'Test LL: -0.05694976993129672', 'Epoch Time (s): 165.61246589198709')
('Epoch 38', 'Objective: -0.09012897526219975', 'Train Acc: 0.9813166666666666', 'Test Acc: 0.9897', 'Train LL: -0.05832670899242039', 'Test LL: -0.035093825199344265', 'Epoch Time (s): 165.5704725640826')
('Epoch 39', 'Objective: -0.08792737725733565', 'Train Acc: 0.9820833333333333', 'Test Acc: 0.9831', 'Train LL: -0.05652574914704919', 'Test LL: -0.05366937913396257', 'Epoch Time (s): 165.64541705697775')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.0669340559101626', 'Train Acc: 0.9882666666666666', 'Test Acc: 0.9907', 'Train LL: -0.03755196627783691', 'Test LL: -0.029154482753773737', 'Epoch Time (s): 165.63749375287443')
('Epoch 41', 'Objective: -0.05939766282537184', 'Train Acc: 0.9900333333333333', 'Test Acc: 0.9911', 'Train LL: -0.03138518221549431', 'Test LL: -0.02725691222155332', 'Epoch Time (s): 165.6606628790032')
('Epoch 42', 'Objective: -0.058132510134218274', 'Train Acc: 0.9907333333333334', 'Test Acc: 0.9893', 'Train LL: -0.03061715067771079', 'Test LL: -0.030765050500795792', 'Epoch Time (s): 165.6136222369969')
('Epoch 43', 'Objective: -0.05679668370655592', 'Train Acc: 0.9907666666666667', 'Test Acc: 0.9896', 'Train LL: -0.029572975992249374', 'Test LL: -0.02960235471619664', 'Epoch Time (s): 165.60163936205208')
('Epoch 44', 'Objective: -0.05636110870221733', 'Train Acc: 0.99065', 'Test Acc: 0.9906', 'Train LL: -0.029361065487946075', 'Test LL: -0.028495834281712807', 'Epoch Time (s): 165.57799356197938')
('Epoch 45', 'Objective: -0.05556609614297704', 'Train Acc: 0.9909166666666667', 'Test Acc: 0.9901', 'Train LL: -0.02890177290528846', 'Test LL: -0.02765199209769753', 'Epoch Time (s): 165.6706749969162')
('Epoch 46', 'Objective: -0.054113049223681736', 'Train Acc: 0.99105', 'Test Acc: 0.9893', 'Train LL: -0.027729071743030263', 'Test LL: -0.03405454394139337', 'Epoch Time (s): 165.5956710318569')
('Epoch 47', 'Objective: -0.054471283366217586', 'Train Acc: 0.9911166666666666', 'Test Acc: 0.9913', 'Train LL: -0.028176435043362435', 'Test LL: -0.028020116650561328', 'Epoch Time (s): 165.50243949494325')
('Epoch 48', 'Objective: -0.05364091654044804', 'Train Acc: 0.9908166666666667', 'Test Acc: 0.991', 'Train LL: -0.027592483407974468', 'Test LL: -0.02994845840803478', 'Epoch Time (s): 165.51713753817603')
('Epoch 49', 'Objective: -0.05335126235897502', 'Train Acc: 0.9909166666666667', 'Test Acc: 0.9894', 'Train LL: -0.027396238104843193', 'Test LL: -0.03098089977069509', 'Epoch Time (s): 165.49428076390177')
('Epoch 50', 'Objective: -0.05362601496402656', 'Train Acc: 0.99125', 'Test Acc: 0.9923', 'Train LL: -0.027879019408779133', 'Test LL: -0.02575398852151415', 'Epoch Time (s): 165.51163259986788')
('Epoch 51', 'Objective: -0.05266355648163297', 'Train Acc: 0.9915', 'Test Acc: 0.9896', 'Train LL: -0.026976781243544315', 'Test LL: -0.03087025082584693', 'Epoch Time (s): 165.47700140299276')
('Epoch 52', 'Objective: -0.05124525318054397', 'Train Acc: 0.99155', 'Test Acc: 0.9905', 'Train LL: -0.025850039168939694', 'Test LL: -0.027730623286461316', 'Epoch Time (s): 165.49614373687655')
('Epoch 53', 'Objective: -0.051557512319610886', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9919', 'Train LL: -0.02624052560731897', 'Test LL: -0.025036485371536674', 'Epoch Time (s): 165.57820846582763')
('Epoch 54', 'Objective: -0.05111129873056622', 'Train Acc: 0.9919166666666667', 'Test Acc: 0.9909', 'Train LL: -0.025885751393798364', 'Test LL: -0.02579763356616375', 'Epoch Time (s): 165.51417933194898')
('Epoch 55', 'Objective: -0.050463591690021105', 'Train Acc: 0.9922333333333333', 'Test Acc: 0.9907', 'Train LL: -0.02538674861399345', 'Test LL: -0.030231236307785365', 'Epoch Time (s): 165.51597886602394')
('Epoch 56', 'Objective: -0.050014615019519086', 'Train Acc: 0.99175', 'Test Acc: 0.9907', 'Train LL: -0.02495497104794881', 'Test LL: -0.026780314952327428', 'Epoch Time (s): 165.5067259380594')
('Epoch 57', 'Objective: -0.05061964694573042', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.9909', 'Train LL: -0.025635582124949277', 'Test LL: -0.02759088640581295', 'Epoch Time (s): 165.52416082611308')
('Epoch 58', 'Objective: -0.05027378543872855', 'Train Acc: 0.9919', 'Test Acc: 0.9919', 'Train LL: -0.025354047061340573', 'Test LL: -0.02512030430566336', 'Epoch Time (s): 165.53295905003324')
('Epoch 59', 'Objective: -0.04983156612402454', 'Train Acc: 0.9918833333333333', 'Test Acc: 0.99', 'Train LL: -0.024984351519025443', 'Test LL: -0.03044382629241803', 'Epoch Time (s): 165.64327902486548')
('Epoch 60', 'Objective: -0.049784934220260105', 'Train Acc: 0.9919166666666667', 'Test Acc: 0.9903', 'Train LL: -0.02502243080183882', 'Test LL: -0.02901543417792447', 'Epoch Time (s): 165.5872694940772')
('Epoch 61', 'Objective: -0.04925530261487156', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9897', 'Train LL: -0.024633281471572264', 'Test LL: -0.031760460644667025', 'Epoch Time (s): 165.61331549310125')
('Epoch 62', 'Objective: -0.049403652379753006', 'Train Acc: 0.9917666666666667', 'Test Acc: 0.9913', 'Train LL: -0.02484965987766505', 'Test LL: -0.02796775886892479', 'Epoch Time (s): 165.66736669605598')
('Epoch 63', 'Objective: -0.048807001019091134', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9907', 'Train LL: -0.024308491312446178', 'Test LL: -0.02877912961116638', 'Epoch Time (s): 165.6230355859734')
('Epoch 64', 'Objective: -0.04825582365941988', 'Train Acc: 0.9919', 'Test Acc: 0.9914', 'Train LL: -0.023937631478036434', 'Test LL: -0.027158503439430364', 'Epoch Time (s): 165.56678263517097')
('Epoch 65', 'Objective: -0.04863965178320596', 'Train Acc: 0.99195', 'Test Acc: 0.9918', 'Train LL: -0.024311948747513752', 'Test LL: -0.02602786544017638', 'Epoch Time (s): 165.63867213018239')
('Epoch 66', 'Objective: -0.048651640832713734', 'Train Acc: 0.992', 'Test Acc: 0.991', 'Train LL: -0.024371846350221146', 'Test LL: -0.02693002432349022', 'Epoch Time (s): 165.46719240979291')
('Epoch 67', 'Objective: -0.04824301286358338', 'Train Acc: 0.9921833333333333', 'Test Acc: 0.9915', 'Train LL: -0.02407487677186327', 'Test LL: -0.02768039255796878', 'Epoch Time (s): 165.5856984439306')
('Epoch 68', 'Objective: -0.048252518716711316', 'Train Acc: 0.9918833333333333', 'Test Acc: 0.9912', 'Train LL: -0.02405664416921958', 'Test LL: -0.027575428434167788', 'Epoch Time (s): 165.55081550800242')
('Epoch 69', 'Objective: -0.04805288382548281', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9897', 'Train LL: -0.023976079948027057', 'Test LL: -0.029300102215662822', 'Epoch Time (s): 165.52526315511204')
('Epoch 70', 'Objective: -0.04733480147179136', 'Train Acc: 0.99235', 'Test Acc: 0.9911', 'Train LL: -0.023256886923517236', 'Test LL: -0.027998592728465888', 'Epoch Time (s): 165.51423570117913')
('Epoch 71', 'Objective: -0.04757098692377234', 'Train Acc: 0.9925', 'Test Acc: 0.9914', 'Train LL: -0.023644360162146556', 'Test LL: -0.027777220387080494', 'Epoch Time (s): 165.5169001070317')
('Epoch 72', 'Objective: -0.0473963777711663', 'Train Acc: 0.9925', 'Test Acc: 0.9897', 'Train LL: -0.02357744762108772', 'Test LL: -0.0307482682803393', 'Epoch Time (s): 165.53022864786908')
('Epoch 73', 'Objective: -0.0473473576618546', 'Train Acc: 0.9922', 'Test Acc: 0.9913', 'Train LL: -0.02349727714665343', 'Test LL: -0.028308205568991923', 'Epoch Time (s): 165.51277535595')
('Epoch 74', 'Objective: -0.04700103188480036', 'Train Acc: 0.9923', 'Test Acc: 0.9911', 'Train LL: -0.023181895553496406', 'Test LL: -0.02666452249417016', 'Epoch Time (s): 165.5234967051074')
('Epoch 75', 'Objective: -0.04663584371608701', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.9913', 'Train LL: -0.022865500955174457', 'Test LL: -0.02847016695813358', 'Epoch Time (s): 165.49847959796898')
('Epoch 76', 'Objective: -0.04628684206208087', 'Train Acc: 0.9928', 'Test Acc: 0.9903', 'Train LL: -0.022575121239526326', 'Test LL: -0.029415095874339454', 'Epoch Time (s): 165.47095508081838')
('Epoch 77', 'Objective: -0.04660077619274153', 'Train Acc: 0.99255', 'Test Acc: 0.9898', 'Train LL: -0.022951218402290335', 'Test LL: -0.030815352626730776', 'Epoch Time (s): 165.45940817287192')
('Epoch 78', 'Objective: -0.046717178713198394', 'Train Acc: 0.9924', 'Test Acc: 0.9914', 'Train LL: -0.023111985041843173', 'Test LL: -0.02525824350080905', 'Epoch Time (s): 165.5447559459135')
('Epoch 79', 'Objective: -0.04709798904254241', 'Train Acc: 0.9920833333333333', 'Test Acc: 0.9921', 'Train LL: -0.023524042152358773', 'Test LL: -0.025580370470259548', 'Epoch Time (s): 165.52841004589573')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.0442494732603047', 'Train Acc: 0.99305', 'Test Acc: 0.9912', 'Train LL: -0.021156545550381187', 'Test LL: -0.027314215995397153', 'Epoch Time (s): 165.4481481560506')
('Epoch 81', 'Objective: -0.04284945907029841', 'Train Acc: 0.9937166666666667', 'Test Acc: 0.9916', 'Train LL: -0.019771921942269628', 'Test LL: -0.026072038180884154', 'Epoch Time (s): 165.4711769160349')
('Epoch 82', 'Objective: -0.042635723345050815', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.9914', 'Train LL: -0.019520900199625706', 'Test LL: -0.02586811897082576', 'Epoch Time (s): 165.469290019013')
('Epoch 83', 'Objective: -0.04254804739361186', 'Train Acc: 0.9938666666666667', 'Test Acc: 0.9914', 'Train LL: -0.019439561840388277', 'Test LL: -0.026648653704215472', 'Epoch Time (s): 165.4977882639505')
('Epoch 84', 'Objective: -0.04218903852138984', 'Train Acc: 0.9939666666666667', 'Test Acc: 0.9915', 'Train LL: -0.019086518183441505', 'Test LL: -0.02600172684063595', 'Epoch Time (s): 165.50518244109116')
('Epoch 85', 'Objective: -0.042361980849511316', 'Train Acc: 0.9936', 'Test Acc: 0.9917', 'Train LL: -0.019204635161348224', 'Test LL: -0.026044888059544552', 'Epoch Time (s): 165.49153561214916')
('Epoch 86', 'Objective: -0.04209939527458103', 'Train Acc: 0.9938833333333333', 'Test Acc: 0.9918', 'Train LL: -0.018973906310691444', 'Test LL: -0.02658632591917426', 'Epoch Time (s): 165.5074247000739')
('Epoch 87', 'Objective: -0.0419510856581195', 'Train Acc: 0.99375', 'Test Acc: 0.9919', 'Train LL: -0.018840870151430704', 'Test LL: -0.02549111309307447', 'Epoch Time (s): 165.4705722311046')
('Epoch 88', 'Objective: -0.041641177209732656', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.9919', 'Train LL: -0.018548660791710074', 'Test LL: -0.02552280748878057', 'Epoch Time (s): 165.52516287285835')
('Epoch 89', 'Objective: -0.041982373574811396', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9921', 'Train LL: -0.01888814957248368', 'Test LL: -0.02551650035119716', 'Epoch Time (s): 165.52721893810667')
('Epoch 90', 'Objective: -0.04281213029526555', 'Train Acc: 0.9936666666666667', 'Test Acc: 0.9923', 'Train LL: -0.019650228330633686', 'Test LL: -0.024834906569700704', 'Epoch Time (s): 165.47625186410733')
('Epoch 91', 'Objective: -0.042298484640739965', 'Train Acc: 0.99395', 'Test Acc: 0.9917', 'Train LL: -0.01921355918514289', 'Test LL: -0.025299255336221526', 'Epoch Time (s): 165.67185727902688')
('Epoch 92', 'Objective: -0.04142254331770324', 'Train Acc: 0.994', 'Test Acc: 0.9917', 'Train LL: -0.018407070656438918', 'Test LL: -0.026227092024595736', 'Epoch Time (s): 165.78255681996234')
('Epoch 93', 'Objective: -0.0421488252970759', 'Train Acc: 0.9941', 'Test Acc: 0.9917', 'Train LL: -0.019103659382345876', 'Test LL: -0.02595778196157209', 'Epoch Time (s): 165.7434598740656')
('Epoch 94', 'Objective: -0.04193180996438772', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.9916', 'Train LL: -0.01893510528491939', 'Test LL: -0.026411363058234355', 'Epoch Time (s): 165.38809968694113')
('Epoch 95', 'Objective: -0.04155164549127005', 'Train Acc: 0.99375', 'Test Acc: 0.9917', 'Train LL: -0.018534987887564257', 'Test LL: -0.025927865336910685', 'Epoch Time (s): 165.3955920720473')
('Epoch 96', 'Objective: -0.041308509612791006', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9913', 'Train LL: -0.01831485461412981', 'Test LL: -0.027185619715798914', 'Epoch Time (s): 165.53948380379006')
('Epoch 97', 'Objective: -0.041292889418040546', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9916', 'Train LL: -0.0182807307180076', 'Test LL: -0.026199106701264123', 'Epoch Time (s): 165.4217912708409')
('Epoch 98', 'Objective: -0.04180133151077325', 'Train Acc: 0.9937', 'Test Acc: 0.9922', 'Train LL: -0.01875545524551616', 'Test LL: -0.025579901236401036', 'Epoch Time (s): 165.38025077292696')
('Epoch 99', 'Objective: -0.04202007139001971', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.9924', 'Train LL: -0.01898097163597792', 'Test LL: -0.02429054096513297', 'Epoch Time (s): 165.57782090990804')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.041056490182558476
Final Train Accuracy: £0.99435
Final Train LL: £-0.018140799549177595
Final Test Accuracy: £0.9928
Final Test LL: £-0.02433102686419414
