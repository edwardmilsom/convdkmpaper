dataset: MNIST
dtype: float64
dof: 100.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.7864116876978313', 'Train Acc: 0.41195', 'Test Acc: 0.6907', 'Train LL: -1.6206385188433234', 'Test LL: -0.9491257502777953', 'Epoch Time (s): 164.0976149640046')
('Epoch 1', 'Objective: -1.1371805078661512', 'Train Acc: 0.6953666666666667', 'Test Acc: 0.7875', 'Train LL: -0.914226814811514', 'Test LL: -0.6395511424030831', 'Epoch Time (s): 164.2219674240332')
('Epoch 2', 'Objective: -0.8549719437475682', 'Train Acc: 0.7837666666666666', 'Test Acc: 0.751', 'Train LL: -0.6316077227478878', 'Test LL: -0.7338623325672552', 'Epoch Time (s): 164.2244652369991')
('Epoch 3', 'Objective: -0.7458637573838938', 'Train Acc: 0.8203333333333334', 'Test Acc: 0.8451', 'Train LL: -0.527061646225556', 'Test LL: -0.45975597458159917', 'Epoch Time (s): 164.20263709989376')
('Epoch 4', 'Objective: -0.6693350644302117', 'Train Acc: 0.8476666666666667', 'Test Acc: 0.7924', 'Train LL: -0.4582969507326819', 'Test LL: -0.64680402782261', 'Epoch Time (s): 164.2457941470202')
('Epoch 5', 'Objective: -0.6257655075384193', 'Train Acc: 0.8646166666666667', 'Test Acc: 0.8722', 'Train LL: -0.4174819131162006', 'Test LL: -0.4036851798626029', 'Epoch Time (s): 164.23561690794304')
('Epoch 6', 'Objective: -0.5812019079114797', 'Train Acc: 0.8800666666666667', 'Test Acc: 0.8686', 'Train LL: -0.3766146241478889', 'Test LL: -0.4168507736367178', 'Epoch Time (s): 164.2632103441283')
('Epoch 7', 'Objective: -0.5444888915410182', 'Train Acc: 0.8929833333333334', 'Test Acc: 0.9061', 'Train LL: -0.3438661261167251', 'Test LL: -0.30654241253675557', 'Epoch Time (s): 164.2535199378617')
('Epoch 8', 'Objective: -0.5219131736609564', 'Train Acc: 0.9004166666666666', 'Test Acc: 0.9104', 'Train LL: -0.32254449914925054', 'Test LL: -0.29154888545442864', 'Epoch Time (s): 163.88781104283407')
('Epoch 9', 'Objective: -0.49745977531141017', 'Train Acc: 0.9073666666666667', 'Test Acc: 0.9227', 'Train LL: -0.2999602024031085', 'Test LL: -0.2538631591650351', 'Epoch Time (s): 164.59225812205113')
('Epoch 10', 'Objective: -0.47876651055515396', 'Train Acc: 0.9131666666666667', 'Test Acc: 0.9017', 'Train LL: -0.28346672662836814', 'Test LL: -0.3077561573665308', 'Epoch Time (s): 164.2595698889345')
('Epoch 11', 'Objective: -0.46806196332309663', 'Train Acc: 0.9156666666666666', 'Test Acc: 0.9332', 'Train LL: -0.2753170591746158', 'Test LL: -0.21624794402006028', 'Epoch Time (s): 164.2400578300003')
('Epoch 12', 'Objective: -0.44851277186093147', 'Train Acc: 0.9206', 'Test Acc: 0.9387', 'Train LL: -0.25895029920274126', 'Test LL: -0.20393604156947284', 'Epoch Time (s): 164.42131853988394')
('Epoch 13', 'Objective: -0.4369718266222204', 'Train Acc: 0.9231333333333334', 'Test Acc: 0.9269', 'Train LL: -0.2505332646377393', 'Test LL: -0.24803118679448927', 'Epoch Time (s): 164.26779872504994')
('Epoch 14', 'Objective: -0.4285850761735311', 'Train Acc: 0.9261833333333334', 'Test Acc: 0.9412', 'Train LL: -0.24295053443869014', 'Test LL: -0.1906539143858033', 'Epoch Time (s): 164.23659407813102')
('Epoch 15', 'Objective: -0.41799985112373306', 'Train Acc: 0.9279', 'Test Acc: 0.9348', 'Train LL: -0.23598696937024918', 'Test LL: -0.20759839775976052', 'Epoch Time (s): 164.3840502430685')
('Epoch 16', 'Objective: -0.4111072147589897', 'Train Acc: 0.929', 'Test Acc: 0.9465', 'Train LL: -0.2305965887040137', 'Test LL: -0.17831490294265928', 'Epoch Time (s): 164.33681777492166')
('Epoch 17', 'Objective: -0.4010010882090591', 'Train Acc: 0.9330333333333334', 'Test Acc: 0.9298', 'Train LL: -0.22326926276329098', 'Test LL: -0.21846572990705204', 'Epoch Time (s): 164.51302871992812')
('Epoch 18', 'Objective: -0.38874178620392214', 'Train Acc: 0.9350666666666667', 'Test Acc: 0.9469', 'Train LL: -0.21655999943200926', 'Test LL: -0.18072489096250055', 'Epoch Time (s): 164.47924088779837')
('Epoch 19', 'Objective: -0.3792524003426656', 'Train Acc: 0.9362', 'Test Acc: 0.9436', 'Train LL: -0.2112302649992699', 'Test LL: -0.1826853344302508', 'Epoch Time (s): 164.59206007095054')
('Epoch 20', 'Objective: -0.3725764908126455', 'Train Acc: 0.9380166666666667', 'Test Acc: 0.9346', 'Train LL: -0.20520082097423537', 'Test LL: -0.2121867470171579', 'Epoch Time (s): 164.52574636484496')
('Epoch 21', 'Objective: -0.3682646119429568', 'Train Acc: 0.9383833333333333', 'Test Acc: 0.9467', 'Train LL: -0.2009327314047389', 'Test LL: -0.1761890022151393', 'Epoch Time (s): 164.51518266205676')
('Epoch 22', 'Objective: -0.3631580805413232', 'Train Acc: 0.9407', 'Test Acc: 0.9344', 'Train LL: -0.19654391573328467', 'Test LL: -0.21386894934350917', 'Epoch Time (s): 164.51538149500266')
('Epoch 23', 'Objective: -0.363119248975116', 'Train Acc: 0.9402333333333334', 'Test Acc: 0.9491', 'Train LL: -0.19653988152248597', 'Test LL: -0.15846847512278855', 'Epoch Time (s): 164.53158755414188')
('Epoch 24', 'Objective: -0.35745565457982365', 'Train Acc: 0.9419', 'Test Acc: 0.9528', 'Train LL: -0.19188314599018097', 'Test LL: -0.1498270880460075', 'Epoch Time (s): 164.42821996402927')
('Epoch 25', 'Objective: -0.34951585511904043', 'Train Acc: 0.94415', 'Test Acc: 0.9336', 'Train LL: -0.18524059535419468', 'Test LL: -0.20540595196211012', 'Epoch Time (s): 164.28364483895712')
('Epoch 26', 'Objective: -0.3480042086568622', 'Train Acc: 0.9440666666666667', 'Test Acc: 0.9497', 'Train LL: -0.1850714460858806', 'Test LL: -0.15735113175531792', 'Epoch Time (s): 164.3556194768753')
('Epoch 27', 'Objective: -0.34474815041006496', 'Train Acc: 0.94445', 'Test Acc: 0.9449', 'Train LL: -0.18362471321328933', 'Test LL: -0.17598953689242058', 'Epoch Time (s): 164.37071291101165')
('Epoch 28', 'Objective: -0.3409816106144506', 'Train Acc: 0.9442', 'Test Acc: 0.9551', 'Train LL: -0.18068666365761643', 'Test LL: -0.14235080400814146', 'Epoch Time (s): 164.25634682714008')
('Epoch 29', 'Objective: -0.33761399261524044', 'Train Acc: 0.9453', 'Test Acc: 0.9567', 'Train LL: -0.17925476083778136', 'Test LL: -0.14851956811998973', 'Epoch Time (s): 164.44471977395006')
('Epoch 30', 'Objective: -0.33572406975684843', 'Train Acc: 0.9455333333333333', 'Test Acc: 0.94', 'Train LL: -0.17847082059915495', 'Test LL: -0.19266795806384762', 'Epoch Time (s): 164.39160069497302')
('Epoch 31', 'Objective: -0.3311766057624219', 'Train Acc: 0.9467', 'Test Acc: 0.9522', 'Train LL: -0.176295807601998', 'Test LL: -0.14789762735012602', 'Epoch Time (s): 164.37582373502664')
('Epoch 32', 'Objective: -0.3267741464039051', 'Train Acc: 0.9473666666666667', 'Test Acc: 0.9559', 'Train LL: -0.17263765240228335', 'Test LL: -0.1386349113236316', 'Epoch Time (s): 164.38082285504788')
('Epoch 33', 'Objective: -0.3239954430338813', 'Train Acc: 0.9479666666666666', 'Test Acc: 0.9609', 'Train LL: -0.17072760855018354', 'Test LL: -0.12700173187973227', 'Epoch Time (s): 164.46267438912764')
('Epoch 34', 'Objective: -0.3194784598472195', 'Train Acc: 0.9493', 'Test Acc: 0.9545', 'Train LL: -0.1677578279027153', 'Test LL: -0.14448157903651823', 'Epoch Time (s): 164.41949211293831')
('Epoch 35', 'Objective: -0.3179702115526351', 'Train Acc: 0.9496833333333333', 'Test Acc: 0.9514', 'Train LL: -0.16531132192797804', 'Test LL: -0.14824268691192027', 'Epoch Time (s): 164.43245469103567')
('Epoch 36', 'Objective: -0.3156627687102617', 'Train Acc: 0.9492666666666667', 'Test Acc: 0.9556', 'Train LL: -0.16412365526513473', 'Test LL: -0.13900886363815243', 'Epoch Time (s): 164.3882918478921')
('Epoch 37', 'Objective: -0.3156821843850872', 'Train Acc: 0.9497833333333333', 'Test Acc: 0.9538', 'Train LL: -0.16480999453251424', 'Test LL: -0.14126030274569693', 'Epoch Time (s): 164.22591172205284')
('Epoch 38', 'Objective: -0.31156749456416727', 'Train Acc: 0.9518', 'Test Acc: 0.9584', 'Train LL: -0.1603480298999789', 'Test LL: -0.12746920852417484', 'Epoch Time (s): 164.16426835698076')
('Epoch 39', 'Objective: -0.309607366916544', 'Train Acc: 0.95115', 'Test Acc: 0.9539', 'Train LL: -0.1588149235638386', 'Test LL: -0.14876921110212343', 'Epoch Time (s): 164.12197227985598')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.2693550877140076', 'Train Acc: 0.961', 'Test Acc: 0.9677', 'Train LL: -0.1280929879526457', 'Test LL: -0.0995798316697589', 'Epoch Time (s): 164.244873363059')
('Epoch 41', 'Objective: -0.260420169675666', 'Train Acc: 0.9633333333333334', 'Test Acc: 0.9675', 'Train LL: -0.12306559965485415', 'Test LL: -0.0977218609066872', 'Epoch Time (s): 164.21998858009465')
('Epoch 42', 'Objective: -0.25728417684237015', 'Train Acc: 0.9642833333333334', 'Test Acc: 0.9675', 'Train LL: -0.12049640098453261', 'Test LL: -0.1017005781265925', 'Epoch Time (s): 164.1019723750651')
('Epoch 43', 'Objective: -0.2567038343411452', 'Train Acc: 0.9643833333333334', 'Test Acc: 0.9692', 'Train LL: -0.12030074855717494', 'Test LL: -0.09963970363155153', 'Epoch Time (s): 163.93962017912418')
('Epoch 44', 'Objective: -0.25561539640743824', 'Train Acc: 0.9635', 'Test Acc: 0.9659', 'Train LL: -0.11925660296626787', 'Test LL: -0.10347293022474455', 'Epoch Time (s): 164.28518366115168')
('Epoch 45', 'Objective: -0.2549536771846463', 'Train Acc: 0.9648833333333333', 'Test Acc: 0.9697', 'Train LL: -0.11877511035632456', 'Test LL: -0.0966387308328567', 'Epoch Time (s): 164.62593058194034')
('Epoch 46', 'Objective: -0.254048962815463', 'Train Acc: 0.96515', 'Test Acc: 0.9685', 'Train LL: -0.11784666694608137', 'Test LL: -0.0979521088430816', 'Epoch Time (s): 164.14852977497503')
('Epoch 47', 'Objective: -0.25476639141101537', 'Train Acc: 0.9649', 'Test Acc: 0.9682', 'Train LL: -0.11850431864884554', 'Test LL: -0.09673170560952936', 'Epoch Time (s): 164.2975414840039')
('Epoch 48', 'Objective: -0.2540799179973362', 'Train Acc: 0.9653833333333334', 'Test Acc: 0.9684', 'Train LL: -0.11768781229898613', 'Test LL: -0.0943757394705101', 'Epoch Time (s): 164.3610675870441')
('Epoch 49', 'Objective: -0.2519594231421118', 'Train Acc: 0.9653166666666667', 'Test Acc: 0.9678', 'Train LL: -0.11549635133935068', 'Test LL: -0.09693411096461603', 'Epoch Time (s): 164.24555808794685')
('Epoch 50', 'Objective: -0.25372778760000647', 'Train Acc: 0.9649166666666666', 'Test Acc: 0.9688', 'Train LL: -0.11741468617229972', 'Test LL: -0.09723478413616339', 'Epoch Time (s): 164.14673459203914')
('Epoch 51', 'Objective: -0.2519595128045904', 'Train Acc: 0.9655166666666667', 'Test Acc: 0.9695', 'Train LL: -0.11583718646773197', 'Test LL: -0.09374205777900324', 'Epoch Time (s): 164.13009395613335')
('Epoch 52', 'Objective: -0.25230773206513424', 'Train Acc: 0.9656333333333333', 'Test Acc: 0.9695', 'Train LL: -0.11596327566512837', 'Test LL: -0.09101504711561673', 'Epoch Time (s): 164.48232386098243')
('Epoch 53', 'Objective: -0.2508381470252099', 'Train Acc: 0.9659166666666666', 'Test Acc: 0.9702', 'Train LL: -0.1145016251018715', 'Test LL: -0.092966877788005', 'Epoch Time (s): 164.28253404796124')
('Epoch 54', 'Objective: -0.25058843072682524', 'Train Acc: 0.9664166666666667', 'Test Acc: 0.9689', 'Train LL: -0.11452472239756539', 'Test LL: -0.09468746631987521', 'Epoch Time (s): 164.42606900306419')
('Epoch 55', 'Objective: -0.25103604339230223', 'Train Acc: 0.9658166666666667', 'Test Acc: 0.9685', 'Train LL: -0.11490334657852552', 'Test LL: -0.09795464766172507', 'Epoch Time (s): 164.16403710702434')
('Epoch 56', 'Objective: -0.25162003294376367', 'Train Acc: 0.9652666666666667', 'Test Acc: 0.9709', 'Train LL: -0.11529697187127703', 'Test LL: -0.0915795116027529', 'Epoch Time (s): 164.23381408280693')
('Epoch 57', 'Objective: -0.2495970851039057', 'Train Acc: 0.9660833333333333', 'Test Acc: 0.9706', 'Train LL: -0.11354890390387165', 'Test LL: -0.09055587573104341', 'Epoch Time (s): 164.34069277904928')
('Epoch 58', 'Objective: -0.24966274180678832', 'Train Acc: 0.96585', 'Test Acc: 0.9705', 'Train LL: -0.11363185667311271', 'Test LL: -0.08999393596429187', 'Epoch Time (s): 164.63491769810207')
('Epoch 59', 'Objective: -0.24967760826868698', 'Train Acc: 0.96645', 'Test Acc: 0.9685', 'Train LL: -0.11383296020796038', 'Test LL: -0.09626389022234826', 'Epoch Time (s): 164.5751070030965')
('Epoch 60', 'Objective: -0.24839459251386434', 'Train Acc: 0.9664166666666667', 'Test Acc: 0.9708', 'Train LL: -0.11255697436462483', 'Test LL: -0.09378474377423336', 'Epoch Time (s): 164.5694402079098')
('Epoch 61', 'Objective: -0.2492747524501455', 'Train Acc: 0.9666166666666667', 'Test Acc: 0.9686', 'Train LL: -0.11308025905078099', 'Test LL: -0.09517557975500189', 'Epoch Time (s): 164.62967155501246')
('Epoch 62', 'Objective: -0.2486003750445262', 'Train Acc: 0.9665', 'Test Acc: 0.9698', 'Train LL: -0.11299670094736547', 'Test LL: -0.09214839365580156', 'Epoch Time (s): 164.53277157084085')
('Epoch 63', 'Objective: -0.24932737847603206', 'Train Acc: 0.96655', 'Test Acc: 0.968', 'Train LL: -0.11345451892678496', 'Test LL: -0.1009043626971983', 'Epoch Time (s): 164.50931533798575')
('Epoch 64', 'Objective: -0.2483737602951444', 'Train Acc: 0.9659666666666666', 'Test Acc: 0.9707', 'Train LL: -0.11229962458005885', 'Test LL: -0.0921674635346163', 'Epoch Time (s): 164.65037763980217')
('Epoch 65', 'Objective: -0.2476438590118679', 'Train Acc: 0.9667166666666667', 'Test Acc: 0.9693', 'Train LL: -0.11179322843864609', 'Test LL: -0.09335466560043053', 'Epoch Time (s): 164.30930043500848')
('Epoch 66', 'Objective: -0.2476786768526538', 'Train Acc: 0.9667333333333333', 'Test Acc: 0.9705', 'Train LL: -0.11162124615762711', 'Test LL: -0.0919475032446024', 'Epoch Time (s): 164.32246754714288')
('Epoch 67', 'Objective: -0.2466763549286076', 'Train Acc: 0.96715', 'Test Acc: 0.9691', 'Train LL: -0.11105910624309417', 'Test LL: -0.0941083475003156', 'Epoch Time (s): 164.16130053112283')
('Epoch 68', 'Objective: -0.24768856527726915', 'Train Acc: 0.9667', 'Test Acc: 0.9708', 'Train LL: -0.1116598809572265', 'Test LL: -0.09129879280982514', 'Epoch Time (s): 164.52862983103842')
('Epoch 69', 'Objective: -0.24675313317425698', 'Train Acc: 0.96635', 'Test Acc: 0.9705', 'Train LL: -0.11085984156370222', 'Test LL: -0.09287109633472804', 'Epoch Time (s): 164.4283830539789')
('Epoch 70', 'Objective: -0.2473721405643721', 'Train Acc: 0.9662166666666666', 'Test Acc: 0.9708', 'Train LL: -0.1114690972159287', 'Test LL: -0.08888820528529622', 'Epoch Time (s): 164.66947599500418')
('Epoch 71', 'Objective: -0.2457373457459286', 'Train Acc: 0.9672', 'Test Acc: 0.9703', 'Train LL: -0.11009088780202239', 'Test LL: -0.0904690320325392', 'Epoch Time (s): 164.26723333704285')
('Epoch 72', 'Objective: -0.24643578431653113', 'Train Acc: 0.9666833333333333', 'Test Acc: 0.9709', 'Train LL: -0.11049367327745033', 'Test LL: -0.08988629020974477', 'Epoch Time (s): 164.39965166617185')
('Epoch 73', 'Objective: -0.24538284416895184', 'Train Acc: 0.9671166666666666', 'Test Acc: 0.9708', 'Train LL: -0.10965005517223665', 'Test LL: -0.0897007384932854', 'Epoch Time (s): 164.18835547193885')
('Epoch 74', 'Objective: -0.2475323994854879', 'Train Acc: 0.9669666666666666', 'Test Acc: 0.9695', 'Train LL: -0.11170785686048167', 'Test LL: -0.09461408849578835', 'Epoch Time (s): 164.26928779180162')
('Epoch 75', 'Objective: -0.24564867929120032', 'Train Acc: 0.9668833333333333', 'Test Acc: 0.9711', 'Train LL: -0.11001939583305938', 'Test LL: -0.08789656826770835', 'Epoch Time (s): 164.57613533805124')
('Epoch 76', 'Objective: -0.2448284133520988', 'Train Acc: 0.9677666666666667', 'Test Acc: 0.9696', 'Train LL: -0.10949586970979117', 'Test LL: -0.09366667752208832', 'Epoch Time (s): 164.4288619509898')
('Epoch 77', 'Objective: -0.24549048415214345', 'Train Acc: 0.96815', 'Test Acc: 0.9702', 'Train LL: -0.10989465947431902', 'Test LL: -0.09076546771347141', 'Epoch Time (s): 164.4083886218723')
('Epoch 78', 'Objective: -0.24582394201261512', 'Train Acc: 0.9672833333333334', 'Test Acc: 0.9719', 'Train LL: -0.11010542671722254', 'Test LL: -0.08920852182179569', 'Epoch Time (s): 164.38084154599346')
('Epoch 79', 'Objective: -0.24589436250224234', 'Train Acc: 0.9673666666666667', 'Test Acc: 0.9716', 'Train LL: -0.10972782150651701', 'Test LL: -0.08705826375398115', 'Epoch Time (s): 164.29256782704033')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.24046556146148124', 'Train Acc: 0.9683', 'Test Acc: 0.9718', 'Train LL: -0.1058172554150559', 'Test LL: -0.08709413708913075', 'Epoch Time (s): 164.3957531109918')
('Epoch 81', 'Objective: -0.24003876805594032', 'Train Acc: 0.9687', 'Test Acc: 0.9719', 'Train LL: -0.10549402291704525', 'Test LL: -0.08733562829837455', 'Epoch Time (s): 164.38424698798917')
('Epoch 82', 'Objective: -0.24016389373434668', 'Train Acc: 0.9685', 'Test Acc: 0.9725', 'Train LL: -0.10555364191606767', 'Test LL: -0.08594267939635813', 'Epoch Time (s): 164.35901787993498')
('Epoch 83', 'Objective: -0.2394942780258726', 'Train Acc: 0.9691333333333333', 'Test Acc: 0.9723', 'Train LL: -0.10486307764446352', 'Test LL: -0.08657564018992055', 'Epoch Time (s): 164.29904377600178')
('Epoch 84', 'Objective: -0.2384849659864392', 'Train Acc: 0.9692', 'Test Acc: 0.972', 'Train LL: -0.10416164548861974', 'Test LL: -0.08614873874361324', 'Epoch Time (s): 164.35037943604402')
('Epoch 85', 'Objective: -0.23776511072392936', 'Train Acc: 0.9691333333333333', 'Test Acc: 0.9719', 'Train LL: -0.10347787796564506', 'Test LL: -0.08691451418892611', 'Epoch Time (s): 164.3590212869458')
('Epoch 86', 'Objective: -0.23846941775771505', 'Train Acc: 0.9690166666666666', 'Test Acc: 0.9723', 'Train LL: -0.10393817113422177', 'Test LL: -0.08576187546972808', 'Epoch Time (s): 164.2362796701491')
('Epoch 87', 'Objective: -0.23813620366113658', 'Train Acc: 0.96915', 'Test Acc: 0.9723', 'Train LL: -0.10377574223946424', 'Test LL: -0.08621237648863644', 'Epoch Time (s): 164.20635534310713')
('Epoch 88', 'Objective: -0.23728773721913518', 'Train Acc: 0.9695833333333334', 'Test Acc: 0.9721', 'Train LL: -0.10298774874106424', 'Test LL: -0.0862506321749085', 'Epoch Time (s): 164.21523215505295')
('Epoch 89', 'Objective: -0.23751916969079256', 'Train Acc: 0.9695', 'Test Acc: 0.9725', 'Train LL: -0.10302481662671416', 'Test LL: -0.08564720046883376', 'Epoch Time (s): 164.24876237194985')
('Epoch 90', 'Objective: -0.23770414951213314', 'Train Acc: 0.9693166666666667', 'Test Acc: 0.972', 'Train LL: -0.10336458378866015', 'Test LL: -0.08680250241289887', 'Epoch Time (s): 164.24324684706517')
('Epoch 91', 'Objective: -0.2379416162019876', 'Train Acc: 0.9687166666666667', 'Test Acc: 0.9724', 'Train LL: -0.10338835360745931', 'Test LL: -0.08557747467199986', 'Epoch Time (s): 164.2030347790569')
('Epoch 92', 'Objective: -0.23864363145892165', 'Train Acc: 0.9688833333333333', 'Test Acc: 0.9728', 'Train LL: -0.10398011373571288', 'Test LL: -0.08599562174057523', 'Epoch Time (s): 164.26502245501615')
('Epoch 93', 'Objective: -0.23780678795487656', 'Train Acc: 0.9698333333333333', 'Test Acc: 0.972', 'Train LL: -0.10344406196731917', 'Test LL: -0.08686833575547694', 'Epoch Time (s): 164.18041981593706')
('Epoch 94', 'Objective: -0.23761671254674926', 'Train Acc: 0.9693', 'Test Acc: 0.9724', 'Train LL: -0.10295642120379873', 'Test LL: -0.085149835363644', 'Epoch Time (s): 164.24205623194575')
('Epoch 95', 'Objective: -0.2384657145698793', 'Train Acc: 0.9685', 'Test Acc: 0.9719', 'Train LL: -0.10385472293102878', 'Test LL: -0.08561101936106509', 'Epoch Time (s): 164.25661637308076')
('Epoch 96', 'Objective: -0.23613446502250723', 'Train Acc: 0.9696833333333333', 'Test Acc: 0.9721', 'Train LL: -0.10178886547922135', 'Test LL: -0.08639482349473177', 'Epoch Time (s): 164.34837152413093')
('Epoch 97', 'Objective: -0.23864562231778216', 'Train Acc: 0.96885', 'Test Acc: 0.9717', 'Train LL: -0.10402218454248154', 'Test LL: -0.08548256914464955', 'Epoch Time (s): 164.2635187979322')
('Epoch 98', 'Objective: -0.23651009178829596', 'Train Acc: 0.9699333333333333', 'Test Acc: 0.9723', 'Train LL: -0.10231771515468928', 'Test LL: -0.086074649656609', 'Epoch Time (s): 164.1853518069256')
('Epoch 99', 'Objective: -0.23841619125613833', 'Train Acc: 0.9696166666666667', 'Test Acc: 0.9725', 'Train LL: -0.1038368668145163', 'Test LL: -0.0857985979412411', 'Epoch Time (s): 164.54300356493331')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.23733980499422783
Final Train Accuracy: £0.96985
Final Train LL: £-0.1027893275551973
Final Test Accuracy: £0.9723
Final Test LL: £-0.08577832955515988
