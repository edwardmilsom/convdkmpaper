dataset: MNIST
dtype: float64
dof: 0.0001
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2607012033539184', 'Train Acc: 0.56235', 'Test Acc: 0.8347', 'Train LL: -1.2302415089420977', 'Test LL: -0.48587660657086945', 'Epoch Time (s): 171.20018178597093')
('Epoch 1', 'Objective: -0.4168268182000786', 'Train Acc: 0.86685', 'Test Acc: 0.9201', 'Train LL: -0.4006486426873672', 'Test LL: -0.254464975754228', 'Epoch Time (s): 170.8352549201809')
('Epoch 2', 'Objective: -0.22930514253137993', 'Train Acc: 0.9316666666666666', 'Test Acc: 0.9443', 'Train LL: -0.21856904844765696', 'Test LL: -0.17159611258296692', 'Epoch Time (s): 170.8066562730819')
('Epoch 3', 'Objective: -0.1797320049774004', 'Train Acc: 0.94665', 'Test Acc: 0.9454', 'Train LL: -0.17120058960180928', 'Test LL: -0.17197226249963254', 'Epoch Time (s): 170.84814776433632')
('Epoch 4', 'Objective: -0.15019553853806644', 'Train Acc: 0.9559833333333333', 'Test Acc: 0.9587', 'Train LL: -0.14296419343526298', 'Test LL: -0.12930563255958588', 'Epoch Time (s): 170.82835000101477')
('Epoch 5', 'Objective: -0.1279121340957029', 'Train Acc: 0.9626333333333333', 'Test Acc: 0.9649', 'Train LL: -0.12161649865259412', 'Test LL: -0.11056149921908914', 'Epoch Time (s): 170.85689446376637')
('Epoch 6', 'Objective: -0.11680077012300188', 'Train Acc: 0.9653833333333334', 'Test Acc: 0.9615', 'Train LL: -0.11106856060104417', 'Test LL: -0.1169833895458069', 'Epoch Time (s): 170.84486417099833')
('Epoch 7', 'Objective: -0.10532051965990344', 'Train Acc: 0.96815', 'Test Acc: 0.9751', 'Train LL: -0.10010490392529152', 'Test LL: -0.07762410273754235', 'Epoch Time (s): 170.83181595383212')
('Epoch 8', 'Objective: -0.09848694090472668', 'Train Acc: 0.9706333333333333', 'Test Acc: 0.9793', 'Train LL: -0.0934823099782987', 'Test LL: -0.06372719638235143', 'Epoch Time (s): 170.8446126380004')
('Epoch 9', 'Objective: -0.09222986094062884', 'Train Acc: 0.9722666666666666', 'Test Acc: 0.9677', 'Train LL: -0.08760923567211845', 'Test LL: -0.09566441197815576', 'Epoch Time (s): 170.81560270814225')
('Epoch 10', 'Objective: -0.08757594420542059', 'Train Acc: 0.9737', 'Test Acc: 0.9817', 'Train LL: -0.08317698988587904', 'Test LL: -0.05730984078529244', 'Epoch Time (s): 170.84765752218664')
('Epoch 11', 'Objective: -0.08183930115896776', 'Train Acc: 0.97585', 'Test Acc: 0.9798', 'Train LL: -0.07768594839952624', 'Test LL: -0.06857398046981686', 'Epoch Time (s): 170.80090909823775')
('Epoch 12', 'Objective: -0.0777789263358114', 'Train Acc: 0.9760166666666666', 'Test Acc: 0.9792', 'Train LL: -0.07377079340344266', 'Test LL: -0.068656884928884', 'Epoch Time (s): 170.9683278389275')
('Epoch 13', 'Objective: -0.0756445960484534', 'Train Acc: 0.9772', 'Test Acc: 0.9812', 'Train LL: -0.07179622105939494', 'Test LL: -0.059752521780103804', 'Epoch Time (s): 170.85069641377777')
('Epoch 14', 'Objective: -0.07346214542950905', 'Train Acc: 0.9780166666666666', 'Test Acc: 0.9723', 'Train LL: -0.06974338909519832', 'Test LL: -0.08778208159308362', 'Epoch Time (s): 170.81477322801948')
('Epoch 15', 'Objective: -0.0705072606932538', 'Train Acc: 0.97805', 'Test Acc: 0.9775', 'Train LL: -0.06693329546542139', 'Test LL: -0.06600483837008608', 'Epoch Time (s): 170.81602104287595')
('Epoch 16', 'Objective: -0.06719210743319758', 'Train Acc: 0.9796166666666667', 'Test Acc: 0.9725', 'Train LL: -0.06373579347906162', 'Test LL: -0.0796413250156668', 'Epoch Time (s): 170.84826341085136')
('Epoch 17', 'Objective: -0.06635500376332505', 'Train Acc: 0.9798333333333333', 'Test Acc: 0.9772', 'Train LL: -0.0629796802397549', 'Test LL: -0.07223064309605584', 'Epoch Time (s): 170.84299098094925')
('Epoch 18', 'Objective: -0.06565028627322775', 'Train Acc: 0.9805', 'Test Acc: 0.9798', 'Train LL: -0.062418282916571054', 'Test LL: -0.0623949354165384', 'Epoch Time (s): 170.81965936534107')
('Epoch 19', 'Objective: -0.061375609060699485', 'Train Acc: 0.9815333333333334', 'Test Acc: 0.9826', 'Train LL: -0.058252107226812934', 'Test LL: -0.051218822731608236', 'Epoch Time (s): 170.79745737090707')
('Epoch 20', 'Objective: -0.06043645689239722', 'Train Acc: 0.9810666666666666', 'Test Acc: 0.9808', 'Train LL: -0.05739549492496', 'Test LL: -0.06200776069302317', 'Epoch Time (s): 170.86821579700336')
('Epoch 21', 'Objective: -0.061309749544279195', 'Train Acc: 0.9813833333333334', 'Test Acc: 0.984', 'Train LL: -0.05837995990529686', 'Test LL: -0.04502171221316961', 'Epoch Time (s): 170.831050937064')
('Epoch 22', 'Objective: -0.058622069969813416', 'Train Acc: 0.9826', 'Test Acc: 0.9885', 'Train LL: -0.05576986996041642', 'Test LL: -0.03527688509328609', 'Epoch Time (s): 170.84129515383393')
('Epoch 23', 'Objective: -0.054767231894486464', 'Train Acc: 0.9832', 'Test Acc: 0.9808', 'Train LL: -0.05199860379901287', 'Test LL: -0.058203976951579396', 'Epoch Time (s): 170.80182087328285')
('Epoch 24', 'Objective: -0.05482659963359277', 'Train Acc: 0.98325', 'Test Acc: 0.9855', 'Train LL: -0.0521721195546028', 'Test LL: -0.04524393045171693', 'Epoch Time (s): 170.83851865585893')
('Epoch 25', 'Objective: -0.053764733815263734', 'Train Acc: 0.9837833333333333', 'Test Acc: 0.9847', 'Train LL: -0.0511342394132879', 'Test LL: -0.04509387801729649', 'Epoch Time (s): 170.78696713084355')
('Epoch 26', 'Objective: -0.05218088804536671', 'Train Acc: 0.9843333333333333', 'Test Acc: 0.9845', 'Train LL: -0.04962580940986668', 'Test LL: -0.047553875425880264', 'Epoch Time (s): 170.8063965239562')
('Epoch 27', 'Objective: -0.05011562485325751', 'Train Acc: 0.9845333333333334', 'Test Acc: 0.9828', 'Train LL: -0.04763082456698901', 'Test LL: -0.05004365280067345', 'Epoch Time (s): 170.79943998809904')
('Epoch 28', 'Objective: -0.049370340074897295', 'Train Acc: 0.9846666666666667', 'Test Acc: 0.9798', 'Train LL: -0.04693130124616344', 'Test LL: -0.06387434474079005', 'Epoch Time (s): 170.79099853010848')
('Epoch 29', 'Objective: -0.0521797069258203', 'Train Acc: 0.9836333333333334', 'Test Acc: 0.9833', 'Train LL: -0.04980650947669853', 'Test LL: -0.04732087372034419', 'Epoch Time (s): 170.8186244778335')
('Epoch 30', 'Objective: -0.04877611995944283', 'Train Acc: 0.9849333333333333', 'Test Acc: 0.9902', 'Train LL: -0.046430966667908996', 'Test LL: -0.03444741388301418', 'Epoch Time (s): 170.79724502982572')
('Epoch 31', 'Objective: nan', 'Train Acc: 0.9845833333333334', 'Test Acc: 0.9882', 'Train LL: -0.04743433572538838', 'Test LL: -0.03611632743223853', 'Epoch Time (s): 170.7527379570529')
('Epoch 32', 'Objective: -0.048314224423761286', 'Train Acc: 0.98525', 'Test Acc: 0.9876', 'Train LL: -0.04604377977015312', 'Test LL: -0.03997089198458241', 'Epoch Time (s): 170.8064426081255')
('Epoch 33', 'Objective: -0.04601801579068113', 'Train Acc: 0.9860333333333333', 'Test Acc: 0.9863', 'Train LL: -0.04379660787196117', 'Test LL: -0.045870382405048794', 'Epoch Time (s): 170.80978444078937')
('Epoch 34', 'Objective: -0.04541703786814666', 'Train Acc: 0.9864666666666667', 'Test Acc: 0.9834', 'Train LL: -0.043285068298499006', 'Test LL: -0.05464762783899098', 'Epoch Time (s): 170.82516275998205')
('Epoch 35', 'Objective: -0.04623444502425967', 'Train Acc: 0.9861333333333333', 'Test Acc: 0.9851', 'Train LL: -0.04412852015319092', 'Test LL: -0.042912225595817644', 'Epoch Time (s): 170.7916713617742')
('Epoch 36', 'Objective: -0.04332658591424927', 'Train Acc: 0.98625', 'Test Acc: 0.9891', 'Train LL: -0.041243309473206036', 'Test LL: -0.037156843793380426', 'Epoch Time (s): 170.64374306285754')
('Epoch 37', 'Objective: -0.04496414687820731', 'Train Acc: 0.9861666666666666', 'Test Acc: 0.9843', 'Train LL: -0.042878092109899006', 'Test LL: -0.050564153930705624', 'Epoch Time (s): 170.65118013275787')
('Epoch 38', 'Objective: -0.0438513815446088', 'Train Acc: 0.98655', 'Test Acc: 0.9866', 'Train LL: -0.04183743795325605', 'Test LL: -0.04309624582708704', 'Epoch Time (s): 170.67095949314535')
('Epoch 39', 'Objective: -0.043038689719614276', 'Train Acc: 0.9870666666666666', 'Test Acc: 0.9879', 'Train LL: -0.04105611662354598', 'Test LL: -0.04028052892832245', 'Epoch Time (s): 170.67877135705203')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.02700146498965182', 'Train Acc: 0.99215', 'Test Acc: 0.9925', 'Train LL: -0.025277989085749523', 'Test LL: -0.02453985693070184', 'Epoch Time (s): 170.62971170712262')
('Epoch 41', 'Objective: -0.02177162506752135', 'Train Acc: 0.9936', 'Test Acc: 0.9914', 'Train LL: -0.020118878545099847', 'Test LL: -0.026135557656441107', 'Epoch Time (s): 170.71438389783725')
('Epoch 42', 'Objective: -0.02036291350106767', 'Train Acc: 0.9938333333333333', 'Test Acc: 0.9916', 'Train LL: -0.018720378116008417', 'Test LL: -0.025566147627281002', 'Epoch Time (s): 170.674920857884')
('Epoch 43', 'Objective: -0.019275055692410153', 'Train Acc: 0.9942333333333333', 'Test Acc: 0.9908', 'Train LL: -0.017648946472056462', 'Test LL: -0.02715736433062699', 'Epoch Time (s): 170.6697027888149')
('Epoch 44', 'Objective: -0.01766754182504961', 'Train Acc: 0.9948', 'Test Acc: 0.9909', 'Train LL: -0.016064065658140773', 'Test LL: -0.026620907298887157', 'Epoch Time (s): 170.6472392929718')
('Epoch 45', 'Objective: -0.017494615442398397', 'Train Acc: 0.9951166666666666', 'Test Acc: 0.9907', 'Train LL: -0.015909869112843263', 'Test LL: -0.027813502971150428', 'Epoch Time (s): 170.71343658911064')
('Epoch 46', 'Objective: -0.017650950514686545', 'Train Acc: 0.9946', 'Test Acc: 0.9924', 'Train LL: -0.016058090650487647', 'Test LL: -0.023763010035772355', 'Epoch Time (s): 170.6099673518911')
('Epoch 47', 'Objective: -0.016769386411614726', 'Train Acc: 0.9951666666666666', 'Test Acc: 0.9915', 'Train LL: -0.01518986641653974', 'Test LL: -0.024645906289993094', 'Epoch Time (s): 170.640952183865')
('Epoch 48', 'Objective: -0.015977686438416707', 'Train Acc: 0.99535', 'Test Acc: 0.9911', 'Train LL: -0.014406134362813272', 'Test LL: -0.0253278364464274', 'Epoch Time (s): 170.70040920330212')
('Epoch 49', 'Objective: -0.015348935479923507', 'Train Acc: 0.9955166666666667', 'Test Acc: 0.9901', 'Train LL: -0.013787883604663868', 'Test LL: -0.0313303697370598', 'Epoch Time (s): 170.68127782596275')
('Epoch 50', 'Objective: -0.015573547407089602', 'Train Acc: 0.9954666666666667', 'Test Acc: 0.992', 'Train LL: -0.01399417503502499', 'Test LL: -0.024240425516777384', 'Epoch Time (s): 170.6856876378879')
('Epoch 51', 'Objective: -0.014611540589866929', 'Train Acc: 0.9956', 'Test Acc: 0.9912', 'Train LL: -0.01303828778329517', 'Test LL: -0.02633231610706602', 'Epoch Time (s): 170.6666799322702')
('Epoch 52', 'Objective: -0.014171202710322404', 'Train Acc: 0.9961666666666666', 'Test Acc: 0.9907', 'Train LL: -0.0126118948728862', 'Test LL: -0.028680772618117516', 'Epoch Time (s): 170.6875118096359')
('Epoch 53', 'Objective: -0.013912096149384224', 'Train Acc: 0.9958', 'Test Acc: 0.9912', 'Train LL: -0.012356803568592437', 'Test LL: -0.02512420363531295', 'Epoch Time (s): 170.635284694843')
('Epoch 54', 'Objective: -0.01366318847094348', 'Train Acc: 0.9960166666666667', 'Test Acc: 0.9915', 'Train LL: -0.012103491387474245', 'Test LL: -0.026424412908010526', 'Epoch Time (s): 170.68703470285982')
('Epoch 55', 'Objective: -0.0137244837172897', 'Train Acc: 0.996', 'Test Acc: 0.9919', 'Train LL: -0.012174853206406364', 'Test LL: -0.025648889349816066', 'Epoch Time (s): 170.68317262269557')
('Epoch 56', 'Objective: -0.012766054723783232', 'Train Acc: 0.9962166666666666', 'Test Acc: 0.991', 'Train LL: -0.01123251819971357', 'Test LL: -0.02895925600995668', 'Epoch Time (s): 170.65234186826274')
('Epoch 57', 'Objective: -0.013165109019033767', 'Train Acc: 0.9962666666666666', 'Test Acc: 0.9918', 'Train LL: -0.011615176621233271', 'Test LL: -0.025543629183136643', 'Epoch Time (s): 170.6921092220582')
('Epoch 58', 'Objective: -0.012621412842294396', 'Train Acc: 0.9965', 'Test Acc: 0.9907', 'Train LL: -0.011089648536730537', 'Test LL: -0.027691325528416907', 'Epoch Time (s): 170.66494918009266')
('Epoch 59', 'Objective: -0.011707111680061997', 'Train Acc: 0.9966166666666667', 'Test Acc: 0.9905', 'Train LL: -0.010189774282972337', 'Test LL: -0.027485858882594853', 'Epoch Time (s): 170.7092869952321')
('Epoch 60', 'Objective: -0.012966943115477731', 'Train Acc: 0.9960833333333333', 'Test Acc: 0.9908', 'Train LL: -0.011428550134998309', 'Test LL: -0.02848126334025702', 'Epoch Time (s): 170.67465962283313')
('Epoch 61', 'Objective: -0.01159617036801951', 'Train Acc: 0.9967', 'Test Acc: 0.9897', 'Train LL: -0.010109288315160881', 'Test LL: -0.03175179492330121', 'Epoch Time (s): 170.6657492541708')
('Epoch 62', 'Objective: -0.011361378733214465', 'Train Acc: 0.99655', 'Test Acc: 0.9903', 'Train LL: -0.009853342027458786', 'Test LL: -0.030538765457392276', 'Epoch Time (s): 170.67051865998656')
('Epoch 63', 'Objective: -0.012040346533661756', 'Train Acc: 0.9965833333333334', 'Test Acc: 0.9922', 'Train LL: -0.010514372295152305', 'Test LL: -0.028222446440650577', 'Epoch Time (s): 170.65628516161814')
('Epoch 64', 'Objective: -0.0110101532338388', 'Train Acc: 0.9967166666666667', 'Test Acc: 0.9903', 'Train LL: -0.009510195651631071', 'Test LL: -0.02970474677542576', 'Epoch Time (s): 170.66012843512')
('Epoch 65', 'Objective: -0.010987720613879343', 'Train Acc: 0.9968833333333333', 'Test Acc: 0.9908', 'Train LL: -0.009505220655562736', 'Test LL: -0.02945245100763409', 'Epoch Time (s): 170.68063196726143')
('Epoch 66', 'Objective: -0.011203698754402096', 'Train Acc: 0.9967', 'Test Acc: 0.991', 'Train LL: -0.00968726155463808', 'Test LL: -0.028767812803867', 'Epoch Time (s): 170.6663130200468')
('Epoch 67', 'Objective: -0.010462032017231707', 'Train Acc: 0.997', 'Test Acc: 0.991', 'Train LL: -0.008961209608639657', 'Test LL: -0.029439135086860507', 'Epoch Time (s): 170.72657175175846')
('Epoch 68', 'Objective: -0.010517492202027204', 'Train Acc: 0.9969', 'Test Acc: 0.9907', 'Train LL: -0.009046306084356638', 'Test LL: -0.030913792813359216', 'Epoch Time (s): 170.68665894586593')
('Epoch 69', 'Objective: -0.01028748742572751', 'Train Acc: 0.997', 'Test Acc: 0.9903', 'Train LL: -0.008797862949690531', 'Test LL: -0.03315809960949568', 'Epoch Time (s): 170.65680812997743')
('Epoch 70', 'Objective: -0.01010391877571439', 'Train Acc: 0.9969333333333333', 'Test Acc: 0.9907', 'Train LL: -0.008628753370453728', 'Test LL: -0.032701860800764544', 'Epoch Time (s): 170.61742476699874')
('Epoch 71', 'Objective: -0.010162179430110233', 'Train Acc: 0.997', 'Test Acc: 0.9912', 'Train LL: -0.008678393262787219', 'Test LL: -0.03130617252534279', 'Epoch Time (s): 170.67191303288564')
('Epoch 72', 'Objective: -0.009975847690742282', 'Train Acc: 0.9971166666666667', 'Test Acc: 0.991', 'Train LL: -0.008503305437270651', 'Test LL: -0.03168143917090377', 'Epoch Time (s): 170.6712759360671')
('Epoch 73', 'Objective: -0.009638290301239793', 'Train Acc: 0.9971166666666667', 'Test Acc: 0.9901', 'Train LL: -0.008165498427099318', 'Test LL: -0.03470758525277993', 'Epoch Time (s): 170.66444801958278')
('Epoch 74', 'Objective: -0.009413616908965495', 'Train Acc: 0.99725', 'Test Acc: 0.9904', 'Train LL: -0.007935756145966269', 'Test LL: -0.03327787318547151', 'Epoch Time (s): 170.73006233014166')
('Epoch 75', 'Objective: -0.00906527796276307', 'Train Acc: 0.9974833333333334', 'Test Acc: 0.9909', 'Train LL: -0.007622487694262111', 'Test LL: -0.03355543570372822', 'Epoch Time (s): 170.63327670888975')
('Epoch 76', 'Objective: -0.009151567912722846', 'Train Acc: 0.9973', 'Test Acc: 0.9893', 'Train LL: -0.0077050877547958484', 'Test LL: -0.03677983137187216', 'Epoch Time (s): 170.68906070804223')
('Epoch 77', 'Objective: -0.00874287120610968', 'Train Acc: 0.9974166666666666', 'Test Acc: 0.9903', 'Train LL: -0.007309004916108141', 'Test LL: -0.0368911470016258', 'Epoch Time (s): 170.64726116368547')
('Epoch 78', 'Objective: -0.008757152827184655', 'Train Acc: 0.9975333333333334', 'Test Acc: 0.9914', 'Train LL: -0.0073133284254313065', 'Test LL: -0.03037200799914229', 'Epoch Time (s): 170.6741613796912')
('Epoch 79', 'Objective: -0.008810121076463113', 'Train Acc: 0.9975333333333334', 'Test Acc: 0.9902', 'Train LL: -0.007367010250234477', 'Test LL: -0.03608630470947101', 'Epoch Time (s): 170.71016006963328')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.007256729302835491', 'Train Acc: 0.9978833333333333', 'Test Acc: 0.9903', 'Train LL: -0.005879529992054334', 'Test LL: -0.03481530467497168', 'Epoch Time (s): 170.65320086479187')
('Epoch 81', 'Objective: -0.006526861629083492', 'Train Acc: 0.9982', 'Test Acc: 0.9909', 'Train LL: -0.005179205856941626', 'Test LL: -0.03328523868095908', 'Epoch Time (s): 170.69481995888054')
('Epoch 82', 'Objective: -0.00614202896741715', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9907', 'Train LL: -0.004799598737005184', 'Test LL: -0.034365950036013566', 'Epoch Time (s): 170.68629456311464')
('Epoch 83', 'Objective: -0.005906487321830762', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9903', 'Train LL: -0.0045795276993836325', 'Test LL: -0.03546663561737099', 'Epoch Time (s): 170.69577708933502')
('Epoch 84', 'Objective: -0.005820799265716601', 'Train Acc: 0.9986166666666667', 'Test Acc: 0.9902', 'Train LL: -0.004491335934038601', 'Test LL: -0.034378719445990365', 'Epoch Time (s): 170.69696344900876')
('Epoch 85', 'Objective: -0.005396516654405277', 'Train Acc: 0.9987', 'Test Acc: 0.9904', 'Train LL: -0.0040702501695915536', 'Test LL: -0.035889641347532836', 'Epoch Time (s): 170.67072617914528')
('Epoch 86', 'Objective: -0.005803222640200501', 'Train Acc: 0.9986166666666667', 'Test Acc: 0.9905', 'Train LL: -0.0044659159205173654', 'Test LL: -0.03655816939745546', 'Epoch Time (s): 170.63850154588')
('Epoch 87', 'Objective: -0.0055034215257022566', 'Train Acc: 0.99875', 'Test Acc: 0.9903', 'Train LL: -0.004151883373506323', 'Test LL: -0.037529148033130164', 'Epoch Time (s): 170.66020904807374')
('Epoch 88', 'Objective: -0.005311316162054683', 'Train Acc: 0.9988666666666667', 'Test Acc: 0.991', 'Train LL: -0.003971181951131919', 'Test LL: -0.03603975202918453', 'Epoch Time (s): 170.66757483407855')
('Epoch 89', 'Objective: -0.005366198010461105', 'Train Acc: 0.9987333333333334', 'Test Acc: 0.9906', 'Train LL: -0.004028185119980847', 'Test LL: -0.037209284059287584', 'Epoch Time (s): 170.6548044262454')
('Epoch 90', 'Objective: -0.005813914009345196', 'Train Acc: 0.9986', 'Test Acc: 0.9905', 'Train LL: -0.004454308878994923', 'Test LL: -0.03765043232550477', 'Epoch Time (s): 170.60423773620278')
('Epoch 91', 'Objective: -0.005431509166053356', 'Train Acc: 0.9986333333333334', 'Test Acc: 0.9908', 'Train LL: -0.00407472427403146', 'Test LL: -0.03616521420172023', 'Epoch Time (s): 170.6509640412405')
('Epoch 92', 'Objective: -0.0050352724801002195', 'Train Acc: 0.9990166666666667', 'Test Acc: 0.9906', 'Train LL: -0.003707346095937759', 'Test LL: -0.03728859533144969', 'Epoch Time (s): 170.6503174919635')
('Epoch 93', 'Objective: -0.00505470838574174', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.99', 'Train LL: -0.0037211578848502847', 'Test LL: -0.039109994557891846', 'Epoch Time (s): 170.58145656529814')
('Epoch 94', 'Objective: -0.004758237920560734', 'Train Acc: 0.9988166666666667', 'Test Acc: 0.9904', 'Train LL: -0.0034266321684746875', 'Test LL: -0.0384840677202855', 'Epoch Time (s): 170.66776603274047')
('Epoch 95', 'Objective: -0.005295481159164277', 'Train Acc: 0.9988333333333334', 'Test Acc: 0.9903', 'Train LL: -0.003929274542623408', 'Test LL: -0.038592219747557534', 'Epoch Time (s): 170.6406953902915')
('Epoch 96', 'Objective: -0.004455155358571543', 'Train Acc: 0.9990333333333333', 'Test Acc: 0.9906', 'Train LL: -0.0031346807701934944', 'Test LL: -0.03956582899771656', 'Epoch Time (s): 170.60430344799533')
('Epoch 97', 'Objective: -0.00491266963683435', 'Train Acc: 0.9989', 'Test Acc: 0.9908', 'Train LL: -0.0035593545112649005', 'Test LL: -0.03828238466153781', 'Epoch Time (s): 170.6352102062665')
('Epoch 98', 'Objective: -0.005069607330002929', 'Train Acc: 0.9988333333333334', 'Test Acc: 0.9898', 'Train LL: -0.0037110591997936656', 'Test LL: -0.04147444674996365', 'Epoch Time (s): 170.66876473277807')
('Epoch 99', 'Objective: -0.005104758473322327', 'Train Acc: 0.99875', 'Test Acc: 0.9901', 'Train LL: -0.0037374022790474374', 'Test LL: -0.040590749901966545', 'Epoch Time (s): 170.66851067822427')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.004715889091251572
Final Train Accuracy: £0.9989666666666667
Final Train LL: £-0.003381951709557806
Final Test Accuracy: £0.9905
Final Test LL: £-0.04060285641366122
