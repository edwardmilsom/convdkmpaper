dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: local
bn_tscale: location
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2578813573984176', 'Train Acc: 0.5618166666666666', 'Test Acc: 0.8487', 'Train LL: -1.2046692988047372', 'Test LL: -0.48317564156451315', 'Epoch Time (s): 163.63506526499987')
('Epoch 1', 'Objective: -0.47912547459994204', 'Train Acc: 0.8556', 'Test Acc: 0.8696', 'Train LL: -0.4284421143504832', 'Test LL: -0.4086750045714341', 'Epoch Time (s): 163.77632520510815')
('Epoch 2', 'Objective: -0.32976050877174673', 'Train Acc: 0.9094333333333333', 'Test Acc: 0.9385', 'Train LL: -0.28228915769953516', 'Test LL: -0.2032379667511638', 'Epoch Time (s): 163.8138372451067')
('Epoch 3', 'Objective: -0.25190941276514145', 'Train Acc: 0.9358', 'Test Acc: 0.9486', 'Train LL: -0.20670474072749384', 'Test LL: -0.1682582733736918', 'Epoch Time (s): 163.81436955207027')
('Epoch 4', 'Objective: -0.21494115160001698', 'Train Acc: 0.9459166666666666', 'Test Acc: 0.9576', 'Train LL: -0.17155457010953906', 'Test LL: -0.14374525812503097', 'Epoch Time (s): 163.82447441201657')
('Epoch 5', 'Objective: -0.1869366714341311', 'Train Acc: 0.9543333333333334', 'Test Acc: 0.9459', 'Train LL: -0.14529799788065076', 'Test LL: -0.17433800284795456', 'Epoch Time (s): 163.7244086440187')
('Epoch 6', 'Objective: -0.17349703201893418', 'Train Acc: 0.9574166666666667', 'Test Acc: 0.9748', 'Train LL: -0.13379074902314864', 'Test LL: -0.08165237798499701', 'Epoch Time (s): 163.7526646067854')
('Epoch 7', 'Objective: -0.15981515613223068', 'Train Acc: 0.9629333333333333', 'Test Acc: 0.9638', 'Train LL: -0.12112100160120232', 'Test LL: -0.11931928778773426', 'Epoch Time (s): 163.7853424870409')
('Epoch 8', 'Objective: -0.15159378157112136', 'Train Acc: 0.9647', 'Test Acc: 0.9713', 'Train LL: -0.1134904282975549', 'Test LL: -0.09409707936145466', 'Epoch Time (s): 163.79484558315016')
('Epoch 9', 'Objective: -0.1431669839225433', 'Train Acc: 0.9675833333333334', 'Test Acc: 0.9603', 'Train LL: -0.10609230481931792', 'Test LL: -0.122512219443794', 'Epoch Time (s): 163.8193480768241')
('Epoch 10', 'Objective: -0.1385308344965628', 'Train Acc: 0.9679', 'Test Acc: 0.9766', 'Train LL: -0.10217548256632605', 'Test LL: -0.076879261260789', 'Epoch Time (s): 163.76949661504477')
('Epoch 11', 'Objective: -0.13249790413346904', 'Train Acc: 0.9694333333333334', 'Test Acc: 0.9667', 'Train LL: -0.09647541655977417', 'Test LL: -0.1048914530089114', 'Epoch Time (s): 163.79596009594388')
('Epoch 12', 'Objective: -0.12954599647548112', 'Train Acc: 0.9702166666666666', 'Test Acc: 0.9767', 'Train LL: -0.09426199073132692', 'Test LL: -0.07408225458762974', 'Epoch Time (s): 163.7801498491317')
('Epoch 13', 'Objective: -0.12544851027713022', 'Train Acc: 0.9717', 'Test Acc: 0.9781', 'Train LL: -0.09059240921757455', 'Test LL: -0.06916831535327742', 'Epoch Time (s): 163.78610563790426')
('Epoch 14', 'Objective: -0.11867156044615562', 'Train Acc: 0.9738666666666667', 'Test Acc: 0.9761', 'Train LL: -0.08472730150895634', 'Test LL: -0.07642161223740465', 'Epoch Time (s): 163.79209050396457')
('Epoch 15', 'Objective: -0.11580444825336236', 'Train Acc: 0.9738333333333333', 'Test Acc: 0.9782', 'Train LL: -0.08198624824839928', 'Test LL: -0.07233728194110038', 'Epoch Time (s): 163.8656606830191')
('Epoch 16', 'Objective: -0.11508827131037254', 'Train Acc: 0.9738833333333333', 'Test Acc: 0.9812', 'Train LL: -0.08171394946555313', 'Test LL: -0.05617584743241252', 'Epoch Time (s): 163.7989201392047')
('Epoch 17', 'Objective: -0.1111113875237198', 'Train Acc: 0.9755166666666667', 'Test Acc: 0.979', 'Train LL: -0.07826066172594938', 'Test LL: -0.06378978437409218', 'Epoch Time (s): 163.78041208698414')
('Epoch 18', 'Objective: -0.11074610490439371', 'Train Acc: 0.9751166666666666', 'Test Acc: 0.9822', 'Train LL: -0.0783814567717298', 'Test LL: -0.05678911892592137', 'Epoch Time (s): 163.81871719215997')
('Epoch 19', 'Objective: -0.10646553665379567', 'Train Acc: 0.9765', 'Test Acc: 0.982', 'Train LL: -0.07430330576315686', 'Test LL: -0.05310640994609787', 'Epoch Time (s): 163.84841812588274')
('Epoch 20', 'Objective: -0.10413857650628344', 'Train Acc: 0.9769', 'Test Acc: 0.975', 'Train LL: -0.07209009882807185', 'Test LL: -0.07993535801596954', 'Epoch Time (s): 163.8341171760112')
('Epoch 21', 'Objective: -0.10285678746151165', 'Train Acc: 0.9775666666666667', 'Test Acc: 0.977', 'Train LL: -0.07118557353497307', 'Test LL: -0.07162763887695317', 'Epoch Time (s): 163.75688884593546')
('Epoch 22', 'Objective: -0.09923570192737033', 'Train Acc: 0.9785666666666667', 'Test Acc: 0.9763', 'Train LL: -0.06813611947601035', 'Test LL: -0.07746655544223624', 'Epoch Time (s): 163.7989045381546')
('Epoch 23', 'Objective: -0.09848730305067721', 'Train Acc: 0.9786', 'Test Acc: 0.977', 'Train LL: -0.06734940604334583', 'Test LL: -0.07093692214196856', 'Epoch Time (s): 163.98083156719804')
('Epoch 24', 'Objective: -0.0978554622152891', 'Train Acc: 0.9784833333333334', 'Test Acc: 0.9748', 'Train LL: -0.0672453875650763', 'Test LL: -0.07188247113117584', 'Epoch Time (s): 163.5798854001332')
('Epoch 25', 'Objective: -0.09640223448047136', 'Train Acc: 0.9787333333333333', 'Test Acc: 0.9784', 'Train LL: -0.06588670156589155', 'Test LL: -0.06903835556576167', 'Epoch Time (s): 163.53340176283382')
('Epoch 26', 'Objective: -0.09495600540533243', 'Train Acc: 0.9795666666666667', 'Test Acc: 0.9832', 'Train LL: -0.06477153757148041', 'Test LL: -0.05161188846638067', 'Epoch Time (s): 163.50189355295151')
('Epoch 27', 'Objective: -0.09418935571108149', 'Train Acc: 0.9797166666666667', 'Test Acc: 0.9859', 'Train LL: -0.06402002716836075', 'Test LL: -0.043102790030821486', 'Epoch Time (s): 163.6549571789801')
('Epoch 28', 'Objective: -0.09198742535794267', 'Train Acc: 0.9809', 'Test Acc: 0.9736', 'Train LL: -0.06219138446341125', 'Test LL: -0.07726702349757057', 'Epoch Time (s): 163.50261258496903')
('Epoch 29', 'Objective: -0.0915513565922432', 'Train Acc: 0.9806333333333334', 'Test Acc: 0.983', 'Train LL: -0.06195565760961108', 'Test LL: -0.050502204971459935', 'Epoch Time (s): 163.53850663197227')
('Epoch 30', 'Objective: -0.08907831709886804', 'Train Acc: 0.9814333333333334', 'Test Acc: 0.9778', 'Train LL: -0.05953295803277589', 'Test LL: -0.06497432681529189', 'Epoch Time (s): 163.51145669608377')
('Epoch 31', 'Objective: -0.08826674715298477', 'Train Acc: 0.9817833333333333', 'Test Acc: 0.9859', 'Train LL: -0.05923113379834784', 'Test LL: -0.04119491985915726', 'Epoch Time (s): 163.50991842197254')
('Epoch 32', 'Objective: -0.08892583786297983', 'Train Acc: 0.9811', 'Test Acc: 0.9826', 'Train LL: -0.05988090394747167', 'Test LL: -0.05177990942276606', 'Epoch Time (s): 163.54858993995003')
('Epoch 33', 'Objective: -0.08743947502629262', 'Train Acc: 0.9810833333333333', 'Test Acc: 0.9833', 'Train LL: -0.058558501629400975', 'Test LL: -0.05227651112095058', 'Epoch Time (s): 163.54357064096257')
('Epoch 34', 'Objective: -0.08750922067036689', 'Train Acc: 0.9812', 'Test Acc: 0.9867', 'Train LL: -0.05868923747248606', 'Test LL: -0.039773515397606346', 'Epoch Time (s): 163.52459302311763')
('Epoch 35', 'Objective: -0.08571420888767638', 'Train Acc: 0.9811666666666666', 'Test Acc: 0.9843', 'Train LL: -0.05721653700925265', 'Test LL: -0.04555679940178942', 'Epoch Time (s): 163.5289767831564')
('Epoch 36', 'Objective: -0.0846166669271586', 'Train Acc: 0.983', 'Test Acc: 0.9867', 'Train LL: -0.05653359321052545', 'Test LL: -0.04077972482447122', 'Epoch Time (s): 163.48621508688666')
('Epoch 37', 'Objective: -0.08423113338644474', 'Train Acc: 0.9824166666666667', 'Test Acc: 0.9853', 'Train LL: -0.05618738171447757', 'Test LL: -0.04407901284243774', 'Epoch Time (s): 163.50293154688552')
('Epoch 38', 'Objective: -0.08338838894472023', 'Train Acc: 0.9825833333333334', 'Test Acc: 0.9841', 'Train LL: -0.05550417908456217', 'Test LL: -0.048078839324260846', 'Epoch Time (s): 163.49331827298738')
('Epoch 39', 'Objective: -0.08160868082361503', 'Train Acc: 0.98305', 'Test Acc: 0.9768', 'Train LL: -0.05387075611214454', 'Test LL: -0.07082568354246044', 'Epoch Time (s): 163.54185193800367')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06253580386887975', 'Train Acc: 0.9883166666666666', 'Test Acc: 0.9913', 'Train LL: -0.036308927889806004', 'Test LL: -0.02909897177196875', 'Epoch Time (s): 163.5241527899634')
('Epoch 41', 'Objective: -0.05580055390273895', 'Train Acc: 0.9902666666666666', 'Test Acc: 0.9914', 'Train LL: -0.030771907799834478', 'Test LL: -0.026780631838116985', 'Epoch Time (s): 163.52649341593497')
('Epoch 42', 'Objective: -0.05409373697145747', 'Train Acc: 0.9910166666666667', 'Test Acc: 0.9904', 'Train LL: -0.02958234618387227', 'Test LL: -0.030047646105815142', 'Epoch Time (s): 163.55885301996022')
('Epoch 43', 'Objective: -0.05274069651040494', 'Train Acc: 0.9904666666666667', 'Test Acc: 0.9906', 'Train LL: -0.028423796553978014', 'Test LL: -0.02909289524291746', 'Epoch Time (s): 163.49700467195362')
('Epoch 44', 'Objective: -0.051944149707666934', 'Train Acc: 0.9913333333333333', 'Test Acc: 0.9902', 'Train LL: -0.02786540520479275', 'Test LL: -0.02970534806988675', 'Epoch Time (s): 163.5152401709929')
('Epoch 45', 'Objective: -0.05148027043825754', 'Train Acc: 0.9912166666666666', 'Test Acc: 0.9899', 'Train LL: -0.027585991866901104', 'Test LL: -0.028748519780396962', 'Epoch Time (s): 163.5104166790843')
('Epoch 46', 'Objective: -0.05066774663316615', 'Train Acc: 0.9913166666666666', 'Test Acc: 0.9906', 'Train LL: -0.027000784488296837', 'Test LL: -0.029813826112874222', 'Epoch Time (s): 163.47700920095667')
('Epoch 47', 'Objective: -0.050538781352375724', 'Train Acc: 0.99125', 'Test Acc: 0.9916', 'Train LL: -0.027014028504701068', 'Test LL: -0.02718654655633976', 'Epoch Time (s): 163.50828594411723')
('Epoch 48', 'Objective: -0.049523207427822104', 'Train Acc: 0.99165', 'Test Acc: 0.9917', 'Train LL: -0.026113181341467402', 'Test LL: -0.026673780481468543', 'Epoch Time (s): 163.47392354300246')
('Epoch 49', 'Objective: -0.0489017898902758', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.9911', 'Train LL: -0.02570982184160717', 'Test LL: -0.028652879021250056', 'Epoch Time (s): 163.50418024300598')
('Epoch 50', 'Objective: -0.04859044988836832', 'Train Acc: 0.9918', 'Test Acc: 0.9908', 'Train LL: -0.025446315062372344', 'Test LL: -0.02819244970486204', 'Epoch Time (s): 163.47944402392022')
('Epoch 51', 'Objective: -0.04872781252308367', 'Train Acc: 0.9915833333333334', 'Test Acc: 0.9908', 'Train LL: -0.02564597953842531', 'Test LL: -0.029746600089605738', 'Epoch Time (s): 163.51563619612716')
('Epoch 52', 'Objective: -0.048413194836221564', 'Train Acc: 0.9917166666666667', 'Test Acc: 0.9922', 'Train LL: -0.025429951017391494', 'Test LL: -0.026203804093302033', 'Epoch Time (s): 163.52713945391588')
('Epoch 53', 'Objective: -0.04838341691994562', 'Train Acc: 0.99165', 'Test Acc: 0.9901', 'Train LL: -0.025448697671914614', 'Test LL: -0.028873289948826073', 'Epoch Time (s): 163.5272703859955')
('Epoch 54', 'Objective: -0.04770820214007973', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9899', 'Train LL: -0.02491946872367067', 'Test LL: -0.028626506065007277', 'Epoch Time (s): 163.55755006009713')
('Epoch 55', 'Objective: -0.04713868164888871', 'Train Acc: 0.992', 'Test Acc: 0.9914', 'Train LL: -0.024396930558505194', 'Test LL: -0.02648911630841174', 'Epoch Time (s): 163.54561022506095')
('Epoch 56', 'Objective: -0.04686434905632548', 'Train Acc: 0.99205', 'Test Acc: 0.9921', 'Train LL: -0.02429159938313303', 'Test LL: -0.02517822376920703', 'Epoch Time (s): 163.53963351994753')
('Epoch 57', 'Objective: -0.04724730804625248', 'Train Acc: 0.9920666666666667', 'Test Acc: 0.9918', 'Train LL: -0.024694189946416308', 'Test LL: -0.026840116694893668', 'Epoch Time (s): 163.54773517791182')
('Epoch 58', 'Objective: -0.04649580770439542', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9901', 'Train LL: -0.02408614163318267', 'Test LL: -0.028441438838141146', 'Epoch Time (s): 163.52965259505436')
('Epoch 59', 'Objective: -0.04613520243338386', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.993', 'Train LL: -0.023803123947694727', 'Test LL: -0.024290327951397316', 'Epoch Time (s): 163.47683188598603')
('Epoch 60', 'Objective: -0.046748990074908826', 'Train Acc: 0.99195', 'Test Acc: 0.9891', 'Train LL: -0.024407302122536886', 'Test LL: -0.03067307100045761', 'Epoch Time (s): 163.53955872915685')
('Epoch 61', 'Objective: -0.04609208097670239', 'Train Acc: 0.9922166666666666', 'Test Acc: 0.9885', 'Train LL: -0.023842386889949406', 'Test LL: -0.03351554013423098', 'Epoch Time (s): 163.5552096629981')
('Epoch 62', 'Objective: -0.04598747023420852', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9904', 'Train LL: -0.023709037683791477', 'Test LL: -0.02906634019037011', 'Epoch Time (s): 163.50809403602034')
('Epoch 63', 'Objective: -0.046194044124773244', 'Train Acc: 0.99215', 'Test Acc: 0.9908', 'Train LL: -0.024116721951724162', 'Test LL: -0.027778149085238322', 'Epoch Time (s): 163.5352277418133')
('Epoch 64', 'Objective: -0.04552520285646747', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9888', 'Train LL: -0.02353349225948293', 'Test LL: -0.03173741364736292', 'Epoch Time (s): 163.51308912597597')
('Epoch 65', 'Objective: -0.0458851966122311', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9929', 'Train LL: -0.02388936772948779', 'Test LL: -0.024050752371064715', 'Epoch Time (s): 163.46342697413638')
('Epoch 66', 'Objective: -0.045149366348252395', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9918', 'Train LL: -0.02321768559025079', 'Test LL: -0.025608010779036697', 'Epoch Time (s): 163.4787782880012')
('Epoch 67', 'Objective: -0.045787492716339', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9888', 'Train LL: -0.023859919799723548', 'Test LL: -0.032200267922168145', 'Epoch Time (s): 163.4878247200977')
('Epoch 68', 'Objective: -0.04522066792456799', 'Train Acc: 0.99245', 'Test Acc: 0.9918', 'Train LL: -0.02341795793871324', 'Test LL: -0.025983785553640167', 'Epoch Time (s): 163.51468017604202')
('Epoch 69', 'Objective: -0.04521266190559426', 'Train Acc: 0.99235', 'Test Acc: 0.9901', 'Train LL: -0.023446541780133372', 'Test LL: -0.02882208353913145', 'Epoch Time (s): 163.5361252289731')
('Epoch 70', 'Objective: -0.04554011514324922', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.9908', 'Train LL: -0.023767096032124985', 'Test LL: -0.02712553771415753', 'Epoch Time (s): 163.5114795139525')
('Epoch 71', 'Objective: -0.044323321718400636', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9891', 'Train LL: -0.022658871183186952', 'Test LL: -0.0313437294546672', 'Epoch Time (s): 163.59146380797029')
('Epoch 72', 'Objective: -0.04464226031830432', 'Train Acc: 0.99235', 'Test Acc: 0.9913', 'Train LL: -0.022984964491425775', 'Test LL: -0.026749567541746747', 'Epoch Time (s): 163.42356924898922')
('Epoch 73', 'Objective: -0.044326059478310996', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9914', 'Train LL: -0.02266243327375605', 'Test LL: -0.02771476728326458', 'Epoch Time (s): 163.58198740100488')
('Epoch 74', 'Objective: -0.044222373973680736', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9896', 'Train LL: -0.022660925427150588', 'Test LL: -0.031535702724712567', 'Epoch Time (s): 163.4863342519384')
('Epoch 75', 'Objective: -0.0449973828753787', 'Train Acc: 0.99215', 'Test Acc: 0.9894', 'Train LL: -0.02339533710935787', 'Test LL: -0.03188666360120578', 'Epoch Time (s): 163.48875930788927')
('Epoch 76', 'Objective: -0.0432442191484554', 'Train Acc: 0.99285', 'Test Acc: 0.9903', 'Train LL: -0.02175855654150131', 'Test LL: -0.030865975993762174', 'Epoch Time (s): 163.57380622881465')
('Epoch 77', 'Objective: -0.04438458019376482', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9899', 'Train LL: -0.022829214863613057', 'Test LL: -0.029774227484556774', 'Epoch Time (s): 163.5634169750847')
('Epoch 78', 'Objective: -0.044148200391522945', 'Train Acc: 0.99245', 'Test Acc: 0.989', 'Train LL: -0.022693227294565604', 'Test LL: -0.029427605411167422', 'Epoch Time (s): 163.5103496699594')
('Epoch 79', 'Objective: -0.04344456660129051', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9896', 'Train LL: -0.02201523505799803', 'Test LL: -0.030975778701101016', 'Epoch Time (s): 163.4961867998354')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.041793859553026044', 'Train Acc: 0.9932833333333333', 'Test Acc: 0.9899', 'Train LL: -0.020569312995985627', 'Test LL: -0.028173232297613766', 'Epoch Time (s): 163.51788939302787')
('Epoch 81', 'Objective: -0.041099862259697154', 'Train Acc: 0.9937166666666667', 'Test Acc: 0.9905', 'Train LL: -0.01995604498996734', 'Test LL: -0.027030618506492958', 'Epoch Time (s): 163.51896007405594')
('Epoch 82', 'Objective: -0.04064100462644116', 'Train Acc: 0.9938666666666667', 'Test Acc: 0.9906', 'Train LL: -0.019556701171734546', 'Test LL: -0.027841394376278077', 'Epoch Time (s): 163.5595996270422')
('Epoch 83', 'Objective: -0.04023654596869685', 'Train Acc: 0.9941', 'Test Acc: 0.9906', 'Train LL: -0.01918335999534244', 'Test LL: -0.026879585090170053', 'Epoch Time (s): 163.5230412299279')
('Epoch 84', 'Objective: -0.04002599910822572', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.991', 'Train LL: -0.01899225215971718', 'Test LL: -0.02706409398629926', 'Epoch Time (s): 163.47946208203211')
('Epoch 85', 'Objective: -0.03984839774667085', 'Train Acc: 0.994', 'Test Acc: 0.991', 'Train LL: -0.018849535930021966', 'Test LL: -0.02747175298443251', 'Epoch Time (s): 163.520466448972')
('Epoch 86', 'Objective: -0.03991450083372914', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9904', 'Train LL: -0.01893480682844215', 'Test LL: -0.02671123830237653', 'Epoch Time (s): 163.53722614282742')
('Epoch 87', 'Objective: -0.03996961048205599', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.991', 'Train LL: -0.018986107630803894', 'Test LL: -0.02718852200726605', 'Epoch Time (s): 163.50656534405425')
('Epoch 88', 'Objective: -0.039812467217967294', 'Train Acc: 0.99405', 'Test Acc: 0.9911', 'Train LL: -0.018824055244431186', 'Test LL: -0.026576739561169165', 'Epoch Time (s): 163.54584010504186')
('Epoch 89', 'Objective: -0.03918752096266588', 'Train Acc: 0.9943', 'Test Acc: 0.9905', 'Train LL: -0.01823839983739104', 'Test LL: -0.028068417311276937', 'Epoch Time (s): 163.5329706389457')
('Epoch 90', 'Objective: -0.0396246432549325', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9911', 'Train LL: -0.018613485258563923', 'Test LL: -0.0271026468372624', 'Epoch Time (s): 163.56846688198857')
('Epoch 91', 'Objective: -0.0396626084812493', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.9906', 'Train LL: -0.018627142003684427', 'Test LL: -0.027661486690093398', 'Epoch Time (s): 163.5078522709664')
('Epoch 92', 'Objective: -0.03980832513316977', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9909', 'Train LL: -0.018769787717976043', 'Test LL: -0.027368855427290787', 'Epoch Time (s): 163.54470242303796')
('Epoch 93', 'Objective: -0.03922088669664415', 'Train Acc: 0.99425', 'Test Acc: 0.9905', 'Train LL: -0.018254879055575615', 'Test LL: -0.02742032449528783', 'Epoch Time (s): 163.49747122987173')
('Epoch 94', 'Objective: -0.039747245368197674', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9908', 'Train LL: -0.018688520243250576', 'Test LL: -0.02757102524724882', 'Epoch Time (s): 163.49868068587966')
('Epoch 95', 'Objective: -0.03955311941799655', 'Train Acc: 0.9939166666666667', 'Test Acc: 0.9907', 'Train LL: -0.018548445957718845', 'Test LL: -0.027493466037250766', 'Epoch Time (s): 163.53164147003554')
('Epoch 96', 'Objective: -0.03945282619654808', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9904', 'Train LL: -0.018475705332882092', 'Test LL: -0.02776912485197941', 'Epoch Time (s): 163.5275124188047')
('Epoch 97', 'Objective: -0.03970212389501751', 'Train Acc: 0.99435', 'Test Acc: 0.9905', 'Train LL: -0.018716721307565354', 'Test LL: -0.027261531123688305', 'Epoch Time (s): 163.5405875579454')
('Epoch 98', 'Objective: -0.03950127884327142', 'Train Acc: 0.9942', 'Test Acc: 0.9902', 'Train LL: -0.01851995133517033', 'Test LL: -0.02808928930322547', 'Epoch Time (s): 163.52586504700594')
('Epoch 99', 'Objective: -0.039330985412246236', 'Train Acc: 0.99415', 'Test Acc: 0.9907', 'Train LL: -0.018379302978420452', 'Test LL: -0.02695858948526943', 'Epoch Time (s): 163.5155255929567')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03902969742699838
Final Train Accuracy: £0.99445
Final Train LL: £-0.01809506000216809
Final Test Accuracy: £0.9905
Final Test LL: £-0.027026396007376143
