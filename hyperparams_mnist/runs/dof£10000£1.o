dataset: MNIST
dtype: float64
dof: 10000.0
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -2.4125655908022323', 'Train Acc: 0.2198', 'Test Acc: 0.2575', 'Train LL: -2.1037415378210453', 'Test LL: -1.9583142437860765', 'Epoch Time (s): 171.59358089836314')
('Epoch 1', 'Objective: -2.066019782880823', 'Train Acc: 0.3135', 'Test Acc: 0.3406', 'Train LL: -1.879683948573225', 'Test LL: -1.8338513469861006', 'Epoch Time (s): 170.83958580391482')
('Epoch 2', 'Objective: -1.9727361382440662', 'Train Acc: 0.3718166666666667', 'Test Acc: 0.3531', 'Train LL: -1.7575463226821302', 'Test LL: -1.8271650192047337', 'Epoch Time (s): 170.86729039205238')
('Epoch 3', 'Objective: -1.8127891501329096', 'Train Acc: 0.45643333333333336', 'Test Acc: 0.4702', 'Train LL: -1.5456643369799754', 'Test LL: -1.510076339020446', 'Epoch Time (s): 170.95344459684566')
('Epoch 4', 'Objective: -1.725860829955357', 'Train Acc: 0.49595', 'Test Acc: 0.4509', 'Train LL: -1.4402622509972678', 'Test LL: -1.481189253371535', 'Epoch Time (s): 170.92482367297634')
('Epoch 5', 'Objective: -1.6419166726174945', 'Train Acc: 0.54325', 'Test Acc: 0.5888', 'Train LL: -1.3158227943811232', 'Test LL: -1.2274692709482196', 'Epoch Time (s): 170.90462293894961')
('Epoch 6', 'Objective: -1.570791762297813', 'Train Acc: 0.5846', 'Test Acc: 0.5043', 'Train LL: -1.21661909708905', 'Test LL: -1.379516727499418', 'Epoch Time (s): 170.9764795587398')
('Epoch 7', 'Objective: -1.5184864525819501', 'Train Acc: 0.6085', 'Test Acc: 0.589', 'Train LL: -1.1533292649897786', 'Test LL: -1.1852936687098614', 'Epoch Time (s): 170.90158304804936')
('Epoch 8', 'Objective: -1.475038705281909', 'Train Acc: 0.6308', 'Test Acc: 0.5507', 'Train LL: -1.102637747930444', 'Test LL: -1.2578320039941957', 'Epoch Time (s): 170.9213959123008')
('Epoch 9', 'Objective: -1.4454567832203653', 'Train Acc: 0.6439166666666667', 'Test Acc: 0.6931', 'Train LL: -1.0687192145265463', 'Test LL: -0.9648435431324096', 'Epoch Time (s): 170.85725094890222')
('Epoch 10', 'Objective: -1.4108278734937927', 'Train Acc: 0.6618666666666667', 'Test Acc: 0.654', 'Train LL: -1.0250855916913333', 'Test LL: -1.0498725791115848', 'Epoch Time (s): 170.8755972511135')
('Epoch 11', 'Objective: -1.3908586042661588', 'Train Acc: 0.6728833333333334', 'Test Acc: 0.6781', 'Train LL: -0.9989651313662107', 'Test LL: -1.0025414523122713', 'Epoch Time (s): 170.8761862278916')
('Epoch 12', 'Objective: -1.3730365432453753', 'Train Acc: 0.6795166666666667', 'Test Acc: 0.5978', 'Train LL: -0.9777326695755622', 'Test LL: -1.1381883571087748', 'Epoch Time (s): 170.99226803286')
('Epoch 13', 'Objective: -1.3491344700456893', 'Train Acc: 0.6940833333333334', 'Test Acc: 0.733', 'Train LL: -0.9490520583375046', 'Test LL: -0.8630752753317572', 'Epoch Time (s): 170.98107397789136')
('Epoch 14', 'Objective: -1.3292098416142621', 'Train Acc: 0.70035', 'Test Acc: 0.682', 'Train LL: -0.9269826821859839', 'Test LL: -0.9880358825826566', 'Epoch Time (s): 170.98022254696116')
('Epoch 15', 'Objective: -1.3206782920986542', 'Train Acc: 0.70605', 'Test Acc: 0.6707', 'Train LL: -0.9146776962902925', 'Test LL: -0.9360442442449642', 'Epoch Time (s): 170.8564513977617')
('Epoch 16', 'Objective: -1.3080758393168854', 'Train Acc: 0.7120833333333333', 'Test Acc: 0.6866', 'Train LL: -0.9002508892730664', 'Test LL: -0.9366019142213099', 'Epoch Time (s): 170.97922744508833')
('Epoch 17', 'Objective: -1.2982268924016223', 'Train Acc: 0.7181333333333333', 'Test Acc: 0.6743', 'Train LL: -0.8868136786259756', 'Test LL: -0.9760223962886974', 'Epoch Time (s): 170.87233054218814')
('Epoch 18', 'Objective: -1.2904613716331335', 'Train Acc: 0.7197', 'Test Acc: 0.7155', 'Train LL: -0.8782506385671528', 'Test LL: -0.8576065555464067', 'Epoch Time (s): 170.90005781687796')
('Epoch 19', 'Objective: -1.2775120664358455', 'Train Acc: 0.7265166666666667', 'Test Acc: 0.7078', 'Train LL: -0.8653952680666317', 'Test LL: -0.9273475846081713', 'Epoch Time (s): 170.82671378785744')
('Epoch 20', 'Objective: -1.2738924301624348', 'Train Acc: 0.7275', 'Test Acc: 0.7408', 'Train LL: -0.8592884453296218', 'Test LL: -0.8524602175171548', 'Epoch Time (s): 170.885140334256')
('Epoch 21', 'Objective: -1.2614526301295361', 'Train Acc: 0.7317666666666667', 'Test Acc: 0.7163', 'Train LL: -0.8471420110264937', 'Test LL: -0.866303094950189', 'Epoch Time (s): 170.88601728901267')
('Epoch 22', 'Objective: -1.2590096522935286', 'Train Acc: 0.7331833333333333', 'Test Acc: 0.6898', 'Train LL: -0.8438402731176406', 'Test LL: -0.9283770780328483', 'Epoch Time (s): 170.93900099629536')
('Epoch 23', 'Objective: -1.2504460284032224', 'Train Acc: 0.7359833333333333', 'Test Acc: 0.7116', 'Train LL: -0.8334878562817096', 'Test LL: -0.863086113424942', 'Epoch Time (s): 170.92036702809855')
('Epoch 24', 'Objective: -1.2421636984544548', 'Train Acc: 0.73925', 'Test Acc: 0.7245', 'Train LL: -0.8256600510867785', 'Test LL: -0.8536031399616146', 'Epoch Time (s): 170.91630795691162')
('Epoch 25', 'Objective: -1.237130483504285', 'Train Acc: 0.7427166666666667', 'Test Acc: 0.7273', 'Train LL: -0.8199390850792442', 'Test LL: -0.8341866956518396', 'Epoch Time (s): 170.88520013308153')
('Epoch 26', 'Objective: -1.232695826765738', 'Train Acc: 0.7468833333333333', 'Test Acc: 0.7326', 'Train LL: -0.8134216204379836', 'Test LL: -0.8015074554279299', 'Epoch Time (s): 170.91581265069544')
('Epoch 27', 'Objective: -1.2293251269585495', 'Train Acc: 0.7474', 'Test Acc: 0.7465', 'Train LL: -0.8080256685515769', 'Test LL: -0.785726724510621', 'Epoch Time (s): 170.94342040782794')
('Epoch 28', 'Objective: -1.2246075770783251', 'Train Acc: 0.7469333333333333', 'Test Acc: 0.7709', 'Train LL: -0.8043974138316389', 'Test LL: -0.7697031295693404', 'Epoch Time (s): 170.87152516283095')
('Epoch 29', 'Objective: -1.224600928808973', 'Train Acc: 0.74915', 'Test Acc: 0.7258', 'Train LL: -0.803952542764018', 'Test LL: -0.8491980667955775', 'Epoch Time (s): 170.91492620669305')
('Epoch 30', 'Objective: -1.2118648271802002', 'Train Acc: 0.7535333333333334', 'Test Acc: 0.7539', 'Train LL: -0.7904204828638437', 'Test LL: -0.7763240915879581', 'Epoch Time (s): 170.88013344304636')
('Epoch 31', 'Objective: -1.2122553924102384', 'Train Acc: 0.7546833333333334', 'Test Acc: 0.77', 'Train LL: -0.7924819409780025', 'Test LL: -0.7648448896333564', 'Epoch Time (s): 170.89048830606043')
('Epoch 32', 'Objective: -1.2039414078472166', 'Train Acc: 0.7578', 'Test Acc: 0.7426', 'Train LL: -0.7824878770737306', 'Test LL: -0.8077113068923818', 'Epoch Time (s): 170.90719583490863')
('Epoch 33', 'Objective: -1.204005893442767', 'Train Acc: 0.7564333333333333', 'Test Acc: 0.7536', 'Train LL: -0.7814531318819269', 'Test LL: -0.7621440546934595', 'Epoch Time (s): 170.9334813482128')
('Epoch 34', 'Objective: -1.1991599204580083', 'Train Acc: 0.7602166666666667', 'Test Acc: 0.7597', 'Train LL: -0.7767596441536373', 'Test LL: -0.8000497986407956', 'Epoch Time (s): 170.9259860799648')
('Epoch 35', 'Objective: -1.1913136096005916', 'Train Acc: 0.7618166666666667', 'Test Acc: 0.7544', 'Train LL: -0.7688211272360873', 'Test LL: -0.7646131094766377', 'Epoch Time (s): 170.8979295939207')
('Epoch 36', 'Objective: -1.1902157934637823', 'Train Acc: 0.7626333333333334', 'Test Acc: 0.7618', 'Train LL: -0.7690443188587192', 'Test LL: -0.7707376622450042', 'Epoch Time (s): 170.83903300017118')
('Epoch 37', 'Objective: -1.189117445763966', 'Train Acc: 0.7624', 'Test Acc: 0.7519', 'Train LL: -0.7659868982154454', 'Test LL: -0.8082483566281998', 'Epoch Time (s): 170.92012174800038')
('Epoch 38', 'Objective: -1.1881998842519197', 'Train Acc: 0.7628666666666667', 'Test Acc: 0.758', 'Train LL: -0.7675372635652384', 'Test LL: -0.7651597852987458', 'Epoch Time (s): 170.93079399410635')
('Epoch 39', 'Objective: -1.1775805171966345', 'Train Acc: 0.7684666666666666', 'Test Acc: 0.7753', 'Train LL: -0.7544979914445537', 'Test LL: -0.7525766471771534', 'Epoch Time (s): 170.92610089108348')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -1.0430271731492682', 'Train Acc: 0.7872166666666667', 'Test Acc: 0.7876', 'Train LL: -0.7101147431746476', 'Test LL: -0.7042236051939847', 'Epoch Time (s): 170.8870743829757')
('Epoch 41', 'Objective: -1.0255243752174679', 'Train Acc: 0.79405', 'Test Acc: 0.788', 'Train LL: -0.6888281150206721', 'Test LL: -0.6978015709845968', 'Epoch Time (s): 170.94906556699425')
('Epoch 42', 'Objective: -1.0239296203066615', 'Train Acc: 0.7951166666666667', 'Test Acc: 0.7769', 'Train LL: -0.6855802166176852', 'Test LL: -0.711818115812509', 'Epoch Time (s): 170.9076998140663')
('Epoch 43', 'Objective: -1.022111269183332', 'Train Acc: 0.7978666666666666', 'Test Acc: 0.7937', 'Train LL: -0.6816856716263578', 'Test LL: -0.6767295115299305', 'Epoch Time (s): 170.94272028282285')
('Epoch 44', 'Objective: -1.0187162682391633', 'Train Acc: 0.7958166666666666', 'Test Acc: 0.7861', 'Train LL: -0.6782322727095529', 'Test LL: -0.6937169351236611', 'Epoch Time (s): 170.8882902492769')
('Epoch 45', 'Objective: -1.0200696634665005', 'Train Acc: 0.79595', 'Test Acc: 0.7941', 'Train LL: -0.6782786320524408', 'Test LL: -0.6778465891057466', 'Epoch Time (s): 170.91461302386597')
('Epoch 46', 'Objective: -1.020036089493776', 'Train Acc: 0.7990166666666667', 'Test Acc: 0.7862', 'Train LL: -0.6790245805579451', 'Test LL: -0.6945416970834646', 'Epoch Time (s): 170.85590148111805')
('Epoch 47', 'Objective: -1.0182030888769236', 'Train Acc: 0.7993333333333333', 'Test Acc: 0.7759', 'Train LL: -0.6754075841232414', 'Test LL: -0.7200378980193174', 'Epoch Time (s): 170.91117687383667')
('Epoch 48', 'Objective: -1.0166993131107234', 'Train Acc: 0.7981333333333334', 'Test Acc: 0.7935', 'Train LL: -0.673026451581144', 'Test LL: -0.6801163814269163', 'Epoch Time (s): 170.90648842183873')
('Epoch 49', 'Objective: -1.0162751418912808', 'Train Acc: 0.7996666666666666', 'Test Acc: 0.7919', 'Train LL: -0.672941176301983', 'Test LL: -0.680596414583282', 'Epoch Time (s): 170.92829512804747')
('Epoch 50', 'Objective: -1.0149295738031852', 'Train Acc: 0.8014333333333333', 'Test Acc: 0.8008', 'Train LL: -0.6714398610347154', 'Test LL: -0.6786805860478962', 'Epoch Time (s): 170.91850864095613')
('Epoch 51', 'Objective: -1.0159714604441688', 'Train Acc: 0.8009833333333334', 'Test Acc: 0.7793', 'Train LL: -0.6717289791546772', 'Test LL: -0.6967160907427237', 'Epoch Time (s): 170.9144590990618')
('Epoch 52', 'Objective: -1.0187595719084226', 'Train Acc: 0.7990333333333334', 'Test Acc: 0.7788', 'Train LL: -0.6749044865410351', 'Test LL: -0.7093275492700059', 'Epoch Time (s): 170.84991222107783')
('Epoch 53', 'Objective: -1.0146648284381596', 'Train Acc: 0.8003666666666667', 'Test Acc: 0.7925', 'Train LL: -0.6707966890086119', 'Test LL: -0.6844112472452846', 'Epoch Time (s): 170.87163084326312')
('Epoch 54', 'Objective: -1.0129343635818122', 'Train Acc: 0.80055', 'Test Acc: 0.7881', 'Train LL: -0.6696267729211389', 'Test LL: -0.6910791588664883', 'Epoch Time (s): 170.89637262187898')
('Epoch 55', 'Objective: -1.0128439844349812', 'Train Acc: 0.8006833333333333', 'Test Acc: 0.7916', 'Train LL: -0.6685597548176727', 'Test LL: -0.6739541621303445', 'Epoch Time (s): 170.8290816731751')
('Epoch 56', 'Objective: -1.0119749589190923', 'Train Acc: 0.8021666666666667', 'Test Acc: 0.7852', 'Train LL: -0.6678043313944756', 'Test LL: -0.6903360083367174', 'Epoch Time (s): 170.80320690898225')
('Epoch 57', 'Objective: -1.0110894011614184', 'Train Acc: 0.8027166666666666', 'Test Acc: 0.7837', 'Train LL: -0.6659952123687655', 'Test LL: -0.6884576270955359', 'Epoch Time (s): 170.88417033012956')
('Epoch 58', 'Objective: -1.0099967574768434', 'Train Acc: 0.80155', 'Test Acc: 0.7868', 'Train LL: -0.6651388625147496', 'Test LL: -0.6982711931433805', 'Epoch Time (s): 170.86337852478027')
('Epoch 59', 'Objective: -1.0108536102326557', 'Train Acc: 0.8010666666666667', 'Test Acc: 0.8019', 'Train LL: -0.6668440977043685', 'Test LL: -0.6616546551545446', 'Epoch Time (s): 170.91327681811526')
('Epoch 60', 'Objective: -1.00965610632045', 'Train Acc: 0.8018166666666666', 'Test Acc: 0.7978', 'Train LL: -0.6646528098909824', 'Test LL: -0.6661870241613388', 'Epoch Time (s): 170.85187925584614')
('Epoch 61', 'Objective: -1.008001157536251', 'Train Acc: 0.8029333333333334', 'Test Acc: 0.7922', 'Train LL: -0.6629808339883344', 'Test LL: -0.6852048764296375', 'Epoch Time (s): 170.87958334805444')
('Epoch 62', 'Objective: -1.0095754264569357', 'Train Acc: 0.8023833333333333', 'Test Acc: 0.8', 'Train LL: -0.6654395140769896', 'Test LL: -0.6615100409629913', 'Epoch Time (s): 170.8955667829141')
('Epoch 63', 'Objective: -1.0111250491203962', 'Train Acc: 0.8005166666666667', 'Test Acc: 0.8021', 'Train LL: -0.6664664044450983', 'Test LL: -0.6661080255603418', 'Epoch Time (s): 170.84006720688194')
('Epoch 64', 'Objective: -1.0055885173277481', 'Train Acc: 0.8070666666666667', 'Test Acc: 0.7884', 'Train LL: -0.659933324791711', 'Test LL: -0.6917374660843585', 'Epoch Time (s): 170.83514128159732')
('Epoch 65', 'Objective: -1.009693511880817', 'Train Acc: 0.80235', 'Test Acc: 0.7788', 'Train LL: -0.6638944449192901', 'Test LL: -0.706062967127294', 'Epoch Time (s): 170.85965351993218')
('Epoch 66', 'Objective: -1.0047537297974232', 'Train Acc: 0.8040833333333334', 'Test Acc: 0.7943', 'Train LL: -0.6587567051028452', 'Test LL: -0.6654950995270927', 'Epoch Time (s): 170.87739887833595')
('Epoch 67', 'Objective: -1.0049691018880043', 'Train Acc: 0.8037333333333333', 'Test Acc: 0.7995', 'Train LL: -0.6589994907136745', 'Test LL: -0.6536489062590057', 'Epoch Time (s): 170.80610268795863')
('Epoch 68', 'Objective: -1.0080013630572218', 'Train Acc: 0.80305', 'Test Acc: 0.7839', 'Train LL: -0.6611069107179147', 'Test LL: -0.697997751866017', 'Epoch Time (s): 170.7646310320124')
('Epoch 69', 'Objective: -1.0078246889773994', 'Train Acc: 0.8048333333333333', 'Test Acc: 0.7868', 'Train LL: -0.6616458033849982', 'Test LL: -0.6854883137406105', 'Epoch Time (s): 170.71725739026442')
('Epoch 70', 'Objective: -1.004400785671493', 'Train Acc: 0.8050833333333334', 'Test Acc: 0.7839', 'Train LL: -0.6575733349248992', 'Test LL: -0.6962316285873817', 'Epoch Time (s): 170.76152178505436')
('Epoch 71', 'Objective: -1.0026630865619603', 'Train Acc: 0.8077166666666666', 'Test Acc: 0.7939', 'Train LL: -0.656445703368603', 'Test LL: -0.6873890031504503', 'Epoch Time (s): 170.70111930882558')
('Epoch 72', 'Objective: -1.0060325687824436', 'Train Acc: 0.8045833333333333', 'Test Acc: 0.7963', 'Train LL: -0.6588282066834931', 'Test LL: -0.6822036196408963', 'Epoch Time (s): 170.7176735769026')
('Epoch 73', 'Objective: -1.0035329107186997', 'Train Acc: 0.8051666666666667', 'Test Acc: 0.7854', 'Train LL: -0.6565252658733813', 'Test LL: -0.6838547430551042', 'Epoch Time (s): 170.70554940635338')
('Epoch 74', 'Objective: -1.004639063695806', 'Train Acc: 0.8038', 'Test Acc: 0.7912', 'Train LL: -0.6574900037018948', 'Test LL: -0.6813672212439574', 'Epoch Time (s): 170.84701212123036')
('Epoch 75', 'Objective: -1.0048879408991904', 'Train Acc: 0.8054166666666667', 'Test Acc: 0.7914', 'Train LL: -0.6582030607207144', 'Test LL: -0.6866025055346049', 'Epoch Time (s): 170.7319669551216')
('Epoch 76', 'Objective: -1.0053677359803297', 'Train Acc: 0.80555', 'Test Acc: 0.7906', 'Train LL: -0.6581014390152722', 'Test LL: -0.6860053952638973', 'Epoch Time (s): 170.76881965482607')
('Epoch 77', 'Objective: -1.0027048927810662', 'Train Acc: 0.8051833333333334', 'Test Acc: 0.7821', 'Train LL: -0.655688943985543', 'Test LL: -0.6902274671604917', 'Epoch Time (s): 170.75120874121785')
('Epoch 78', 'Objective: -1.0025556584844992', 'Train Acc: 0.8065166666666667', 'Test Acc: 0.8001', 'Train LL: -0.6537676515309336', 'Test LL: -0.6675053916152301', 'Epoch Time (s): 170.80655218288302')
('Epoch 79', 'Objective: -1.0041586785799548', 'Train Acc: 0.8051833333333334', 'Test Acc: 0.7968', 'Train LL: -0.6568342610486426', 'Test LL: -0.6598653626917874', 'Epoch Time (s): 170.7637722468935')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.9892543860052142', 'Train Acc: 0.8090333333333334', 'Test Acc: 0.799', 'Train LL: -0.6507227299067708', 'Test LL: -0.6649088218851675', 'Epoch Time (s): 170.78600035980344')
('Epoch 81', 'Objective: -0.9864346871155698', 'Train Acc: 0.8105666666666667', 'Test Acc: 0.8026', 'Train LL: -0.648081750684421', 'Test LL: -0.6602501942187903', 'Epoch Time (s): 170.73554163891822')
('Epoch 82', 'Objective: -0.9845882977525146', 'Train Acc: 0.8104833333333333', 'Test Acc: 0.8024', 'Train LL: -0.6456109321474345', 'Test LL: -0.6623381580601141', 'Epoch Time (s): 170.75675615482032')
('Epoch 83', 'Objective: -0.9815023257092786', 'Train Acc: 0.8121', 'Test Acc: 0.7984', 'Train LL: -0.641986622475685', 'Test LL: -0.6638192362100006', 'Epoch Time (s): 170.72165425214916')
('Epoch 84', 'Objective: -0.9831477466312674', 'Train Acc: 0.8115666666666667', 'Test Acc: 0.7971', 'Train LL: -0.6422856635378856', 'Test LL: -0.6709099906766419', 'Epoch Time (s): 170.71938598901033')
('Epoch 85', 'Objective: -0.9815055541697122', 'Train Acc: 0.81075', 'Test Acc: 0.7952', 'Train LL: -0.6409736954259689', 'Test LL: -0.6710384913207594', 'Epoch Time (s): 170.73314386978745')
('Epoch 86', 'Objective: -0.9838329661434756', 'Train Acc: 0.8106166666666667', 'Test Acc: 0.7954', 'Train LL: -0.6430144021967208', 'Test LL: -0.6714498881550529', 'Epoch Time (s): 170.73971866816282')
('Epoch 87', 'Objective: -0.9821327769053176', 'Train Acc: 0.8115666666666667', 'Test Acc: 0.7993', 'Train LL: -0.6414931938664139', 'Test LL: -0.6643757354686698', 'Epoch Time (s): 170.76193394092843')
('Epoch 88', 'Objective: -0.9806530060004235', 'Train Acc: 0.8130333333333334', 'Test Acc: 0.7986', 'Train LL: -0.6403234235765556', 'Test LL: -0.6643830384263315', 'Epoch Time (s): 170.7422471609898')
('Epoch 89', 'Objective: -0.9845677587016076', 'Train Acc: 0.8122333333333334', 'Test Acc: 0.7923', 'Train LL: -0.643511486321025', 'Test LL: -0.6758389545396033', 'Epoch Time (s): 170.82559410389513')
('Epoch 90', 'Objective: -0.9835336164514353', 'Train Acc: 0.8106166666666667', 'Test Acc: 0.7968', 'Train LL: -0.642600101016291', 'Test LL: -0.6671158544569391', 'Epoch Time (s): 170.70319386105984')
('Epoch 91', 'Objective: -0.9811600579382318', 'Train Acc: 0.8122666666666667', 'Test Acc: 0.7968', 'Train LL: -0.6403332410463662', 'Test LL: -0.666760484033198', 'Epoch Time (s): 170.72264984296635')
('Epoch 92', 'Objective: -0.9800085422173701', 'Train Acc: 0.81155', 'Test Acc: 0.7997', 'Train LL: -0.6392395313316527', 'Test LL: -0.6608435472063631', 'Epoch Time (s): 170.69594923220575')
('Epoch 93', 'Objective: -0.9847435716869732', 'Train Acc: 0.81075', 'Test Acc: 0.7954', 'Train LL: -0.6430496822034178', 'Test LL: -0.6722183588593037', 'Epoch Time (s): 170.6561142699793')
('Epoch 94', 'Objective: -0.9820095983142064', 'Train Acc: 0.8114833333333333', 'Test Acc: 0.801', 'Train LL: -0.6410074236436273', 'Test LL: -0.658366494692497', 'Epoch Time (s): 170.80979897500947')
('Epoch 95', 'Objective: -0.982238421392307', 'Train Acc: 0.8112', 'Test Acc: 0.799', 'Train LL: -0.6409867841040215', 'Test LL: -0.6619918417386426', 'Epoch Time (s): 170.75627409107983')
('Epoch 96', 'Objective: -0.978256220973179', 'Train Acc: 0.8107333333333333', 'Test Acc: 0.8018', 'Train LL: -0.6373160226119454', 'Test LL: -0.6571596882085531', 'Epoch Time (s): 170.7084076111205')
('Epoch 97', 'Objective: -0.9859322086015168', 'Train Acc: 0.8128', 'Test Acc: 0.7922', 'Train LL: -0.643814017782338', 'Test LL: -0.6694034975979245', 'Epoch Time (s): 170.76784731075168')
('Epoch 98', 'Objective: -0.9816184487435643', 'Train Acc: 0.8125333333333333', 'Test Acc: 0.7986', 'Train LL: -0.6407423412232929', 'Test LL: -0.6618081831820019', 'Epoch Time (s): 170.79050283925608')
('Epoch 99', 'Objective: -0.9855409204276429', 'Train Acc: 0.80935', 'Test Acc: 0.7979', 'Train LL: -0.6434378399924627', 'Test LL: -0.6662673029703202', 'Epoch Time (s): 170.70931191183627')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.9833595090823974
Final Train Accuracy: £0.8113166666666667
Final Train LL: £-0.6422186315489786
Final Test Accuracy: £0.7987
Final Test LL: £-0.6659514002818645
