dataset: MNIST
dtype: float64
dof: 100.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.80486027612446', 'Train Acc: 0.39925', 'Test Acc: 0.6595', 'Train LL: -1.6424949104062825', 'Test LL: -1.0844609427578982', 'Epoch Time (s): 171.09399451408535')
('Epoch 1', 'Objective: -1.2022925489415053', 'Train Acc: 0.6651', 'Test Acc: 0.6425', 'Train LL: -0.9909327871849715', 'Test LL: -1.1243226141265172', 'Epoch Time (s): 170.86028232891113')
('Epoch 2', 'Objective: -0.8619823266569373', 'Train Acc: 0.7799833333333334', 'Test Acc: 0.8054', 'Train LL: -0.643850492847414', 'Test LL: -0.5683142841911432', 'Epoch Time (s): 170.9419157882221')
('Epoch 3', 'Objective: -0.7375639032612221', 'Train Acc: 0.8267166666666667', 'Test Acc: 0.8589', 'Train LL: -0.5249947682017054', 'Test LL: -0.4404066669951134', 'Epoch Time (s): 170.86385434307158')
('Epoch 4', 'Objective: -0.6615208272671946', 'Train Acc: 0.8536833333333333', 'Test Acc: 0.8658', 'Train LL: -0.4508470439383868', 'Test LL: -0.4229016864516921', 'Epoch Time (s): 170.8960536280647')
('Epoch 5', 'Objective: -0.6119772493304761', 'Train Acc: 0.8693666666666666', 'Test Acc: 0.8249', 'Train LL: -0.40786155237478505', 'Test LL: -0.5636787931695387', 'Epoch Time (s): 170.8697953079827')
('Epoch 6', 'Objective: -0.572985035591938', 'Train Acc: 0.8786166666666667', 'Test Acc: 0.8873', 'Train LL: -0.3777183888027985', 'Test LL: -0.33882427344270877', 'Epoch Time (s): 170.85083002783358')
('Epoch 7', 'Objective: -0.5368319029754652', 'Train Acc: 0.8909833333333333', 'Test Acc: 0.8947', 'Train LL: -0.34681119089221285', 'Test LL: -0.32877287211110745', 'Epoch Time (s): 170.86192884808406')
('Epoch 8', 'Objective: -0.5099338954307736', 'Train Acc: 0.8987666666666667', 'Test Acc: 0.9115', 'Train LL: -0.32168328975886856', 'Test LL: -0.2865484122501756', 'Epoch Time (s): 170.874951667618')
('Epoch 9', 'Objective: -0.4874420720960701', 'Train Acc: 0.9053666666666667', 'Test Acc: 0.9075', 'Train LL: -0.301469956868841', 'Test LL: -0.28289597315533926', 'Epoch Time (s): 170.94259199593216')
('Epoch 10', 'Objective: -0.46920345265804986', 'Train Acc: 0.9112833333333333', 'Test Acc: 0.9171', 'Train LL: -0.2847166338280774', 'Test LL: -0.2518586828553904', 'Epoch Time (s): 170.9065246586688')
('Epoch 11', 'Objective: -0.45712958298779044', 'Train Acc: 0.9146333333333333', 'Test Acc: 0.9301', 'Train LL: -0.2740028548241594', 'Test LL: -0.227977526797229', 'Epoch Time (s): 170.85567910876125')
('Epoch 12', 'Objective: -0.4452674133501811', 'Train Acc: 0.9183333333333333', 'Test Acc: 0.9069', 'Train LL: -0.265306818557989', 'Test LL: -0.29631566018389266', 'Epoch Time (s): 170.83658737502992')
('Epoch 13', 'Objective: -0.43473368082313724', 'Train Acc: 0.9211166666666667', 'Test Acc: 0.9248', 'Train LL: -0.2561033739260088', 'Test LL: -0.24476912911406962', 'Epoch Time (s): 170.91421949584037')
('Epoch 14', 'Objective: -0.4240426082020472', 'Train Acc: 0.9240333333333334', 'Test Acc: 0.9345', 'Train LL: -0.24678050986116595', 'Test LL: -0.22022998240160105', 'Epoch Time (s): 170.85218948405236')
('Epoch 15', 'Objective: -0.41642064690929803', 'Train Acc: 0.9266', 'Test Acc: 0.9355', 'Train LL: -0.23957498681307818', 'Test LL: -0.209679807771078', 'Epoch Time (s): 170.86327067296952')
('Epoch 16', 'Objective: -0.4104762477437188', 'Train Acc: 0.9285666666666667', 'Test Acc: 0.9384', 'Train LL: -0.23309600182640985', 'Test LL: -0.20717711971715297', 'Epoch Time (s): 170.8866207501851')
('Epoch 17', 'Objective: -0.40369973740229914', 'Train Acc: 0.93125', 'Test Acc: 0.9429', 'Train LL: -0.22791684089839065', 'Test LL: -0.1873669593285083', 'Epoch Time (s): 170.83828846784309')
('Epoch 18', 'Objective: -0.3972633935173971', 'Train Acc: 0.9308', 'Test Acc: 0.9368', 'Train LL: -0.2221706019472956', 'Test LL: -0.207744559017847', 'Epoch Time (s): 170.83592440420762')
('Epoch 19', 'Objective: -0.3926190153612769', 'Train Acc: 0.9333166666666667', 'Test Acc: 0.947', 'Train LL: -0.21817898270774713', 'Test LL: -0.1637844845514635', 'Epoch Time (s): 170.87875875318423')
('Epoch 20', 'Objective: -0.38787697713822683', 'Train Acc: 0.93485', 'Test Acc: 0.9423', 'Train LL: -0.21366929822542516', 'Test LL: -0.1822391317755255', 'Epoch Time (s): 170.8248787112534')
('Epoch 21', 'Objective: -0.3854931970659176', 'Train Acc: 0.9355', 'Test Acc: 0.9426', 'Train LL: -0.2115127961310378', 'Test LL: -0.1892568620464377', 'Epoch Time (s): 170.84250255068764')
('Epoch 22', 'Objective: -0.37775532252680494', 'Train Acc: 0.9377', 'Test Acc: 0.9395', 'Train LL: -0.20501472769126208', 'Test LL: -0.1938178228539526', 'Epoch Time (s): 170.84152274299413')
('Epoch 23', 'Objective: -0.37593159967015916', 'Train Acc: 0.9379666666666666', 'Test Acc: 0.9431', 'Train LL: -0.20304638437894498', 'Test LL: -0.18161183060237313', 'Epoch Time (s): 170.92494493583217')
('Epoch 24', 'Objective: -0.3745971011077507', 'Train Acc: 0.9387166666666666', 'Test Acc: 0.9416', 'Train LL: -0.20122425212482853', 'Test LL: -0.18661510561068895', 'Epoch Time (s): 170.91871908586472')
('Epoch 25', 'Objective: -0.3688602934108068', 'Train Acc: 0.9408166666666666', 'Test Acc: 0.9419', 'Train LL: -0.1967739908742893', 'Test LL: -0.17779288757239278', 'Epoch Time (s): 170.84883520705625')
('Epoch 26', 'Objective: -0.36342474728257496', 'Train Acc: 0.9424666666666667', 'Test Acc: 0.9523', 'Train LL: -0.19174211452172138', 'Test LL: -0.1583715910278719', 'Epoch Time (s): 170.90165038686246')
('Epoch 27', 'Objective: -0.363065451590515', 'Train Acc: 0.9426', 'Test Acc: 0.9528', 'Train LL: -0.19164480040144088', 'Test LL: -0.1470244986001308', 'Epoch Time (s): 170.87607479002327')
('Epoch 28', 'Objective: -0.3604654669037726', 'Train Acc: 0.94235', 'Test Acc: 0.9495', 'Train LL: -0.1885103964484065', 'Test LL: -0.17125533404926', 'Epoch Time (s): 170.7539670667611')
('Epoch 29', 'Objective: -0.35925076252273347', 'Train Acc: 0.94325', 'Test Acc: 0.9564', 'Train LL: -0.18788054980053576', 'Test LL: -0.1444898101303602', 'Epoch Time (s): 170.8449096083641')
('Epoch 30', 'Objective: -0.35817658157246046', 'Train Acc: 0.9438833333333333', 'Test Acc: 0.9402', 'Train LL: -0.18677351105497655', 'Test LL: -0.18840794938913413', 'Epoch Time (s): 170.89594491571188')
('Epoch 31', 'Objective: -0.35084765183975947', 'Train Acc: 0.9453', 'Test Acc: 0.9553', 'Train LL: -0.18113899986095766', 'Test LL: -0.14088622291794714', 'Epoch Time (s): 170.85680489521474')
('Epoch 32', 'Objective: -0.35016690504002373', 'Train Acc: 0.9458333333333333', 'Test Acc: 0.9503', 'Train LL: -0.17948863156228442', 'Test LL: -0.15863005275059053', 'Epoch Time (s): 170.86519002681598')
('Epoch 33', 'Objective: -0.35119673795827705', 'Train Acc: 0.9461', 'Test Acc: 0.9517', 'Train LL: -0.1805427342063478', 'Test LL: -0.14719849218857517', 'Epoch Time (s): 170.91033731400967')
('Epoch 34', 'Objective: -0.34602358852371995', 'Train Acc: 0.9468', 'Test Acc: 0.9601', 'Train LL: -0.17575240309732254', 'Test LL: -0.13190512371321003', 'Epoch Time (s): 170.83602878218517')
('Epoch 35', 'Objective: -0.3433873476083462', 'Train Acc: 0.9470166666666666', 'Test Acc: 0.9531', 'Train LL: -0.1739906323814263', 'Test LL: -0.15001138459306285', 'Epoch Time (s): 170.77701404783875')
('Epoch 36', 'Objective: -0.34212539180362056', 'Train Acc: 0.94775', 'Test Acc: 0.9588', 'Train LL: -0.17323105092444305', 'Test LL: -0.12849994980732413', 'Epoch Time (s): 170.78971380088478')
('Epoch 37', 'Objective: -0.3419891186965249', 'Train Acc: 0.9485', 'Test Acc: 0.9516', 'Train LL: -0.1721789443837184', 'Test LL: -0.15763988576570334', 'Epoch Time (s): 170.81764463568106')
('Epoch 38', 'Objective: -0.33871739457686345', 'Train Acc: 0.949', 'Test Acc: 0.9431', 'Train LL: -0.17011257089906676', 'Test LL: -0.1716002205879463', 'Epoch Time (s): 170.80744439177215')
('Epoch 39', 'Objective: -0.3398882617573843', 'Train Acc: 0.9480166666666666', 'Test Acc: 0.9579', 'Train LL: -0.17091803958463722', 'Test LL: -0.13571389067712056', 'Epoch Time (s): 170.74958695378155')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.2965953799666074', 'Train Acc: 0.9583833333333334', 'Test Acc: 0.9661', 'Train LL: -0.1395078996273287', 'Test LL: -0.10995853035868597', 'Epoch Time (s): 170.77738940622658')
('Epoch 41', 'Objective: -0.28859042349093655', 'Train Acc: 0.9596666666666667', 'Test Acc: 0.9659', 'Train LL: -0.13493055215815256', 'Test LL: -0.10772865252417443', 'Epoch Time (s): 170.8707987437956')
('Epoch 42', 'Objective: -0.2851355293955492', 'Train Acc: 0.96055', 'Test Acc: 0.9668', 'Train LL: -0.1319797228665649', 'Test LL: -0.1072746787299122', 'Epoch Time (s): 170.79147815611213')
('Epoch 43', 'Objective: -0.2835439229250132', 'Train Acc: 0.9612166666666667', 'Test Acc: 0.9664', 'Train LL: -0.13096516375940337', 'Test LL: -0.10741257369749663', 'Epoch Time (s): 170.81172629119828')
('Epoch 44', 'Objective: -0.2834340398558747', 'Train Acc: 0.9613333333333334', 'Test Acc: 0.9656', 'Train LL: -0.13077221916507967', 'Test LL: -0.1091869248562137', 'Epoch Time (s): 170.75395303079858')
('Epoch 45', 'Objective: -0.28255092134454446', 'Train Acc: 0.96125', 'Test Acc: 0.9665', 'Train LL: -0.1298283133010878', 'Test LL: -0.10827167761998144', 'Epoch Time (s): 170.71407329570502')
('Epoch 46', 'Objective: -0.28087257417219036', 'Train Acc: 0.9622333333333334', 'Test Acc: 0.9667', 'Train LL: -0.12828247497758968', 'Test LL: -0.10533530614313716', 'Epoch Time (s): 170.75948064168915')
('Epoch 47', 'Objective: -0.28109108969402485', 'Train Acc: 0.9618833333333333', 'Test Acc: 0.9645', 'Train LL: -0.12808914296133184', 'Test LL: -0.1088918726891884', 'Epoch Time (s): 170.78979452420026')
('Epoch 48', 'Objective: -0.2809706145838254', 'Train Acc: 0.9620666666666666', 'Test Acc: 0.9669', 'Train LL: -0.1284961834898829', 'Test LL: -0.10392699681662505', 'Epoch Time (s): 170.80845302389935')
('Epoch 49', 'Objective: -0.2817284667960816', 'Train Acc: 0.9617333333333333', 'Test Acc: 0.9668', 'Train LL: -0.12890106396261455', 'Test LL: -0.10561335015287364', 'Epoch Time (s): 170.7639058358036')
('Epoch 50', 'Objective: -0.2790836103512252', 'Train Acc: 0.96255', 'Test Acc: 0.9659', 'Train LL: -0.12672652325961525', 'Test LL: -0.10500320509888615', 'Epoch Time (s): 170.8044634750113')
('Epoch 51', 'Objective: -0.27955779008634285', 'Train Acc: 0.9620166666666666', 'Test Acc: 0.9667', 'Train LL: -0.12704243849427557', 'Test LL: -0.10574257094647369', 'Epoch Time (s): 170.70013325894251')
('Epoch 52', 'Objective: -0.278260594334933', 'Train Acc: 0.9630333333333333', 'Test Acc: 0.9666', 'Train LL: -0.12607134133346998', 'Test LL: -0.10740621483766588', 'Epoch Time (s): 170.72006900329143')
('Epoch 53', 'Objective: -0.2788812395984631', 'Train Acc: 0.9622166666666667', 'Test Acc: 0.9665', 'Train LL: -0.12665980669169502', 'Test LL: -0.10691376652409958', 'Epoch Time (s): 170.69788979925215')
('Epoch 54', 'Objective: -0.27786827334305103', 'Train Acc: 0.9630666666666666', 'Test Acc: 0.969', 'Train LL: -0.12560339299717474', 'Test LL: -0.09954463678611578', 'Epoch Time (s): 170.75736355036497')
('Epoch 55', 'Objective: -0.2786316647900505', 'Train Acc: 0.9629333333333333', 'Test Acc: 0.9666', 'Train LL: -0.12626626763093696', 'Test LL: -0.10402373451014253', 'Epoch Time (s): 170.76638021878898')
('Epoch 56', 'Objective: -0.2776476812651148', 'Train Acc: 0.9628833333333333', 'Test Acc: 0.9675', 'Train LL: -0.12534541257098147', 'Test LL: -0.10364691500918538', 'Epoch Time (s): 170.72079466981813')
('Epoch 57', 'Objective: -0.27769948136355926', 'Train Acc: 0.9632', 'Test Acc: 0.9672', 'Train LL: -0.12538027254234396', 'Test LL: -0.10340375754585343', 'Epoch Time (s): 170.7486155857332')
('Epoch 58', 'Objective: -0.27577131479106615', 'Train Acc: 0.9641833333333333', 'Test Acc: 0.9683', 'Train LL: -0.12330882880497653', 'Test LL: -0.09976428969185099', 'Epoch Time (s): 170.74939208617434')
('Epoch 59', 'Objective: -0.2755052385641389', 'Train Acc: 0.963', 'Test Acc: 0.9692', 'Train LL: -0.12311020073768889', 'Test LL: -0.10052463050020065', 'Epoch Time (s): 170.7817697711289')
('Epoch 60', 'Objective: -0.27601578707745944', 'Train Acc: 0.9626666666666667', 'Test Acc: 0.9691', 'Train LL: -0.12389495651486283', 'Test LL: -0.09859152620622758', 'Epoch Time (s): 170.77398801082745')
('Epoch 61', 'Objective: -0.27618652240828245', 'Train Acc: 0.963', 'Test Acc: 0.9664', 'Train LL: -0.12407598256036148', 'Test LL: -0.10448958021093384', 'Epoch Time (s): 170.76115055102855')
('Epoch 62', 'Objective: -0.27580592137137383', 'Train Acc: 0.9631166666666666', 'Test Acc: 0.9695', 'Train LL: -0.12395002083605786', 'Test LL: -0.09976804803910397', 'Epoch Time (s): 170.73098719120026')
('Epoch 63', 'Objective: -0.27463598515591087', 'Train Acc: 0.9629', 'Test Acc: 0.9665', 'Train LL: -0.12259948925800289', 'Test LL: -0.10384626058100635', 'Epoch Time (s): 170.71328509459272')
('Epoch 64', 'Objective: -0.27463320760626503', 'Train Acc: 0.9626', 'Test Acc: 0.9669', 'Train LL: -0.1221494892484053', 'Test LL: -0.104333398045689', 'Epoch Time (s): 170.76430098200217')
('Epoch 65', 'Objective: -0.27566966900737716', 'Train Acc: 0.9637333333333333', 'Test Acc: 0.9688', 'Train LL: -0.1235932575975611', 'Test LL: -0.10050077590064661', 'Epoch Time (s): 170.75110774161294')
('Epoch 66', 'Objective: -0.2749452578254657', 'Train Acc: 0.96355', 'Test Acc: 0.9679', 'Train LL: -0.12260385425887724', 'Test LL: -0.09974565800196349', 'Epoch Time (s): 170.75480176880956')
('Epoch 67', 'Objective: -0.27382994543877126', 'Train Acc: 0.9631833333333333', 'Test Acc: 0.9681', 'Train LL: -0.12169037362457512', 'Test LL: -0.09952515339942086', 'Epoch Time (s): 170.7166080540046')
('Epoch 68', 'Objective: -0.2747165402473549', 'Train Acc: 0.9634833333333334', 'Test Acc: 0.9689', 'Train LL: -0.12277156433070374', 'Test LL: -0.10144893724891835', 'Epoch Time (s): 170.6965799657628')
('Epoch 69', 'Objective: -0.27426283425241793', 'Train Acc: 0.9648166666666667', 'Test Acc: 0.9686', 'Train LL: -0.12255087097577232', 'Test LL: -0.10066813623723546', 'Epoch Time (s): 170.70408464269713')
('Epoch 70', 'Objective: -0.27341618940960133', 'Train Acc: 0.9640166666666666', 'Test Acc: 0.9669', 'Train LL: -0.12153765740499642', 'Test LL: -0.10881144548205969', 'Epoch Time (s): 170.68263415200636')
('Epoch 71', 'Objective: -0.2742183868755098', 'Train Acc: 0.9643333333333334', 'Test Acc: 0.9674', 'Train LL: -0.12263679942427118', 'Test LL: -0.10237901131044189', 'Epoch Time (s): 170.73834828985855')
('Epoch 72', 'Objective: -0.2742725274848723', 'Train Acc: 0.9635833333333333', 'Test Acc: 0.9684', 'Train LL: -0.12273445476176335', 'Test LL: -0.09814792633324826', 'Epoch Time (s): 170.7146438821219')
('Epoch 73', 'Objective: -0.27272410465735625', 'Train Acc: 0.9642', 'Test Acc: 0.9692', 'Train LL: -0.12126462629311154', 'Test LL: -0.09746228903908816', 'Epoch Time (s): 170.74874605610967')
('Epoch 74', 'Objective: -0.27401752828014037', 'Train Acc: 0.9640166666666666', 'Test Acc: 0.9668', 'Train LL: -0.12258328448894071', 'Test LL: -0.1094131392716149', 'Epoch Time (s): 170.7236706102267')
('Epoch 75', 'Objective: -0.2722022708232914', 'Train Acc: 0.9647', 'Test Acc: 0.9675', 'Train LL: -0.12057901847578302', 'Test LL: -0.09957451756100992', 'Epoch Time (s): 170.78327005170286')
('Epoch 76', 'Objective: -0.27360236082800105', 'Train Acc: 0.9635833333333333', 'Test Acc: 0.9678', 'Train LL: -0.12184589291514158', 'Test LL: -0.10449236748976955', 'Epoch Time (s): 170.79396615130827')
('Epoch 77', 'Objective: -0.27211154057002684', 'Train Acc: 0.9644166666666667', 'Test Acc: 0.9687', 'Train LL: -0.12047892554437782', 'Test LL: -0.10062151172472286', 'Epoch Time (s): 170.82021018210799')
('Epoch 78', 'Objective: -0.27244533176448477', 'Train Acc: 0.9640166666666666', 'Test Acc: 0.9674', 'Train LL: -0.12070442314551323', 'Test LL: -0.1017384193982844', 'Epoch Time (s): 170.76771669695154')
('Epoch 79', 'Objective: -0.2719412016288421', 'Train Acc: 0.96385', 'Test Acc: 0.9681', 'Train LL: -0.12021536456373318', 'Test LL: -0.0987737403976138', 'Epoch Time (s): 170.75259919976816')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.2671743904019578', 'Train Acc: 0.96505', 'Test Acc: 0.9684', 'Train LL: -0.11649286999140135', 'Test LL: -0.09865839903630375', 'Epoch Time (s): 170.76450165268034')
('Epoch 81', 'Objective: -0.26614136985172204', 'Train Acc: 0.9656666666666667', 'Test Acc: 0.9688', 'Train LL: -0.11602304112651488', 'Test LL: -0.0968295690782574', 'Epoch Time (s): 170.77615751419216')
('Epoch 82', 'Objective: -0.265322921234452', 'Train Acc: 0.9660166666666666', 'Test Acc: 0.9693', 'Train LL: -0.11505079436416887', 'Test LL: -0.09689381920643805', 'Epoch Time (s): 170.75355061003938')
('Epoch 83', 'Objective: -0.2651864982246158', 'Train Acc: 0.9667833333333333', 'Test Acc: 0.9687', 'Train LL: -0.11544446572109693', 'Test LL: -0.0970600958485531', 'Epoch Time (s): 170.7980210580863')
('Epoch 84', 'Objective: -0.26629690629395175', 'Train Acc: 0.9654333333333334', 'Test Acc: 0.9685', 'Train LL: -0.1158923681185809', 'Test LL: -0.09660395735881235', 'Epoch Time (s): 170.76842499524355')
('Epoch 85', 'Objective: -0.2648137274283889', 'Train Acc: 0.9654666666666667', 'Test Acc: 0.9692', 'Train LL: -0.114912219212347', 'Test LL: -0.09639363757124898', 'Epoch Time (s): 170.68372017983347')
('Epoch 86', 'Objective: -0.2653189229529605', 'Train Acc: 0.9661', 'Test Acc: 0.9684', 'Train LL: -0.11535151634051596', 'Test LL: -0.09667085256897964', 'Epoch Time (s): 170.73417646577582')
('Epoch 87', 'Objective: -0.26447283324061904', 'Train Acc: 0.9661', 'Test Acc: 0.969', 'Train LL: -0.11465658260825128', 'Test LL: -0.09677724523835811', 'Epoch Time (s): 170.70439606625587')
('Epoch 88', 'Objective: -0.2646460698453821', 'Train Acc: 0.96565', 'Test Acc: 0.9697', 'Train LL: -0.11495504432290554', 'Test LL: -0.09681804608519974', 'Epoch Time (s): 170.73738291393965')
('Epoch 89', 'Objective: -0.2653330037355699', 'Train Acc: 0.9657666666666667', 'Test Acc: 0.9689', 'Train LL: -0.11541635766346336', 'Test LL: -0.09635245392812723', 'Epoch Time (s): 170.7359822653234')
('Epoch 90', 'Objective: -0.2657172349669277', 'Train Acc: 0.96595', 'Test Acc: 0.9692', 'Train LL: -0.11559984408211503', 'Test LL: -0.09685918427230583', 'Epoch Time (s): 170.7453974429518')
('Epoch 91', 'Objective: -0.2644367479532219', 'Train Acc: 0.9664', 'Test Acc: 0.9685', 'Train LL: -0.11472535507200489', 'Test LL: -0.09601679872416188', 'Epoch Time (s): 170.7503844271414')
('Epoch 92', 'Objective: -0.26580764525399503', 'Train Acc: 0.9664', 'Test Acc: 0.9693', 'Train LL: -0.11573954990078224', 'Test LL: -0.0952465319889134', 'Epoch Time (s): 170.72276164311916')
('Epoch 93', 'Objective: -0.2636737476950446', 'Train Acc: 0.9667333333333333', 'Test Acc: 0.9692', 'Train LL: -0.11394344677091364', 'Test LL: -0.09661893713519452', 'Epoch Time (s): 170.7082667457871')
('Epoch 94', 'Objective: -0.2644772055694087', 'Train Acc: 0.96615', 'Test Acc: 0.9693', 'Train LL: -0.11449396964174248', 'Test LL: -0.09644234320643408', 'Epoch Time (s): 170.8762098052539')
('Epoch 95', 'Objective: -0.2630200892528716', 'Train Acc: 0.96595', 'Test Acc: 0.9693', 'Train LL: -0.11333344161315069', 'Test LL: -0.09587649599975516', 'Epoch Time (s): 170.79583407193422')
('Epoch 96', 'Objective: -0.2655703167574634', 'Train Acc: 0.9665333333333334', 'Test Acc: 0.9697', 'Train LL: -0.11555810123464774', 'Test LL: -0.09548767082682585', 'Epoch Time (s): 170.72271357290447')
('Epoch 97', 'Objective: -0.26496091102199426', 'Train Acc: 0.9660833333333333', 'Test Acc: 0.9695', 'Train LL: -0.11488916504182958', 'Test LL: -0.09605938885377864', 'Epoch Time (s): 170.79672586917877')
('Epoch 98', 'Objective: -0.263422738132398', 'Train Acc: 0.96655', 'Test Acc: 0.9697', 'Train LL: -0.11365675087141208', 'Test LL: -0.09541164764387629', 'Epoch Time (s): 170.7454953682609')
('Epoch 99', 'Objective: -0.2630739161907659', 'Train Acc: 0.9667', 'Test Acc: 0.9694', 'Train LL: -0.11334695838517707', 'Test LL: -0.09623182800143183', 'Epoch Time (s): 170.69017669884488')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.2645349503615415
Final Train Accuracy: £0.96565
Final Train LL: £-0.11447716632070513
Final Test Accuracy: £0.969
Final Test LL: £-0.09614057303761996
