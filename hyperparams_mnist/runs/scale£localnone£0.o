dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: local
bn_tscale: none
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2911804062204277', 'Train Acc: 0.5541833333333334', 'Test Acc: 0.7911', 'Train LL: -1.2371507448303392', 'Test LL: -0.6360317544192963', 'Epoch Time (s): 162.70385504188016')
('Epoch 1', 'Objective: -0.5332794970938043', 'Train Acc: 0.8386166666666667', 'Test Acc: 0.9031', 'Train LL: -0.48036983817764484', 'Test LL: -0.299573074567925', 'Epoch Time (s): 162.80721877608448')
('Epoch 2', 'Objective: -0.32482064535327626', 'Train Acc: 0.9134666666666666', 'Test Acc: 0.9357', 'Train LL: -0.27534918103705136', 'Test LL: -0.20020575922297276', 'Epoch Time (s): 162.80523967603222')
('Epoch 3', 'Objective: -0.25840153981607017', 'Train Acc: 0.93485', 'Test Acc: 0.9501', 'Train LL: -0.21178263209702447', 'Test LL: -0.1532343711981668', 'Epoch Time (s): 162.78178955498151')
('Epoch 4', 'Objective: -0.22164711337148865', 'Train Acc: 0.94405', 'Test Acc: 0.9559', 'Train LL: -0.1760863889032939', 'Test LL: -0.14352960151390173', 'Epoch Time (s): 162.81425391486846')
('Epoch 5', 'Objective: -0.1982214108494386', 'Train Acc: 0.9526833333333333', 'Test Acc: 0.9548', 'Train LL: -0.15435572793174046', 'Test LL: -0.14436948953258796', 'Epoch Time (s): 162.79458347917534')
('Epoch 6', 'Objective: -0.17765603263163926', 'Train Acc: 0.9577333333333333', 'Test Acc: 0.9567', 'Train LL: -0.13523631915361417', 'Test LL: -0.1323526663377933', 'Epoch Time (s): 162.80988384597003')
('Epoch 7', 'Objective: -0.16670414863398297', 'Train Acc: 0.9612166666666667', 'Test Acc: 0.9705', 'Train LL: -0.12482176229354394', 'Test LL: -0.09309035530839445', 'Epoch Time (s): 162.85162278218195')
('Epoch 8', 'Objective: -0.15313088322181087', 'Train Acc: 0.9648833333333333', 'Test Acc: 0.9694', 'Train LL: -0.11285860445037171', 'Test LL: -0.09351606904459048', 'Epoch Time (s): 162.87790722795762')
('Epoch 9', 'Objective: -0.14765026522761493', 'Train Acc: 0.9660166666666666', 'Test Acc: 0.9698', 'Train LL: -0.1077497305771315', 'Test LL: -0.09360996761917396', 'Epoch Time (s): 162.7984730640892')
('Epoch 10', 'Objective: -0.1402395419869828', 'Train Acc: 0.9681666666666666', 'Test Acc: 0.9576', 'Train LL: -0.10137914326843578', 'Test LL: -0.12968329270768592', 'Epoch Time (s): 162.7910636239685')
('Epoch 11', 'Objective: -0.13489734350484586', 'Train Acc: 0.96935', 'Test Acc: 0.9707', 'Train LL: -0.0964384629022833', 'Test LL: -0.09100586534330801', 'Epoch Time (s): 162.80653204605915')
('Epoch 12', 'Objective: -0.1296105836930326', 'Train Acc: 0.9708166666666667', 'Test Acc: 0.9779', 'Train LL: -0.09151365373702022', 'Test LL: -0.06719419483707668', 'Epoch Time (s): 162.84821431501769')
('Epoch 13', 'Objective: -0.12345454358562447', 'Train Acc: 0.9723333333333334', 'Test Acc: 0.9705', 'Train LL: -0.08597508894131208', 'Test LL: -0.08990114930992565', 'Epoch Time (s): 162.83602262893692')
('Epoch 14', 'Objective: -0.12305418329649682', 'Train Acc: 0.9734333333333334', 'Test Acc: 0.9751', 'Train LL: -0.08569776028385073', 'Test LL: -0.07505854679211577', 'Epoch Time (s): 162.81254061916843')
('Epoch 15', 'Objective: -0.11892558221158547', 'Train Acc: 0.9739333333333333', 'Test Acc: 0.9692', 'Train LL: -0.08228075829730165', 'Test LL: -0.09908357516211526', 'Epoch Time (s): 162.9007489681244')
('Epoch 16', 'Objective: -0.11554971129093189', 'Train Acc: 0.9749333333333333', 'Test Acc: 0.9805', 'Train LL: -0.07920776615858634', 'Test LL: -0.06215044402869163', 'Epoch Time (s): 162.87037104112096')
('Epoch 17', 'Objective: -0.11499057968510953', 'Train Acc: 0.97515', 'Test Acc: 0.9822', 'Train LL: -0.07887726861623509', 'Test LL: -0.05562450254130211', 'Epoch Time (s): 162.8489429592155')
('Epoch 18', 'Objective: -0.10923485984125807', 'Train Acc: 0.9765833333333334', 'Test Acc: 0.9805', 'Train LL: -0.07364799881127926', 'Test LL: -0.06129334049590143', 'Epoch Time (s): 162.77542400802486')
('Epoch 19', 'Objective: -0.10939389693022472', 'Train Acc: 0.9762', 'Test Acc: 0.9677', 'Train LL: -0.07377045404859386', 'Test LL: -0.09375819368088543', 'Epoch Time (s): 162.81736739492044')
('Epoch 20', 'Objective: -0.106520608550408', 'Train Acc: 0.9771166666666666', 'Test Acc: 0.9721', 'Train LL: -0.07135590059649644', 'Test LL: -0.08033845046121973', 'Epoch Time (s): 162.80197273590602')
('Epoch 21', 'Objective: -0.10439226854159302', 'Train Acc: 0.9777', 'Test Acc: 0.9829', 'Train LL: -0.06937247066783225', 'Test LL: -0.055324698281230794', 'Epoch Time (s): 162.8423311628867')
('Epoch 22', 'Objective: -0.10227312122939201', 'Train Acc: 0.9788', 'Test Acc: 0.9778', 'Train LL: -0.06776455651382789', 'Test LL: -0.06862428320416257', 'Epoch Time (s): 162.89511087397113')
('Epoch 23', 'Objective: -0.1021973447810822', 'Train Acc: 0.9784833333333334', 'Test Acc: 0.9748', 'Train LL: -0.06795168440288521', 'Test LL: -0.07662007647501784', 'Epoch Time (s): 162.84802774200216')
('Epoch 24', 'Objective: -0.1010754398553646', 'Train Acc: 0.9787666666666667', 'Test Acc: 0.9749', 'Train LL: -0.06673009009400264', 'Test LL: -0.07449779545271767', 'Epoch Time (s): 162.87794428807683')
('Epoch 25', 'Objective: -0.09776931061500545', 'Train Acc: 0.9801', 'Test Acc: 0.9837', 'Train LL: -0.06381606799476272', 'Test LL: -0.05366622070907141', 'Epoch Time (s): 162.87701485515572')
('Epoch 26', 'Objective: -0.0980530762800234', 'Train Acc: 0.9795166666666667', 'Test Acc: 0.9806', 'Train LL: -0.06425478832077196', 'Test LL: -0.06282166146115149', 'Epoch Time (s): 162.8260237427894')
('Epoch 27', 'Objective: -0.09573943973758478', 'Train Acc: 0.9802333333333333', 'Test Acc: 0.9838', 'Train LL: -0.06198123275343195', 'Test LL: -0.04913209402580364', 'Epoch Time (s): 162.88250213302672')
('Epoch 28', 'Objective: -0.09575475225587247', 'Train Acc: 0.98005', 'Test Acc: 0.9806', 'Train LL: -0.06239888446701319', 'Test LL: -0.0570342554056108', 'Epoch Time (s): 162.80301185091957')
('Epoch 29', 'Objective: -0.09462123880217384', 'Train Acc: 0.9809', 'Test Acc: 0.982', 'Train LL: -0.061448338743593664', 'Test LL: -0.05607135814769888', 'Epoch Time (s): 162.8284167679958')
('Epoch 30', 'Objective: -0.09366836628616931', 'Train Acc: 0.9812833333333333', 'Test Acc: 0.9847', 'Train LL: -0.06065082298349156', 'Test LL: -0.05335965551724516', 'Epoch Time (s): 162.86466427799314')
('Epoch 31', 'Objective: -0.09132621251884675', 'Train Acc: 0.9813666666666667', 'Test Acc: 0.9793', 'Train LL: -0.058646603627314095', 'Test LL: -0.06475364196082833', 'Epoch Time (s): 162.80560397612862')
('Epoch 32', 'Objective: -0.09106793524225326', 'Train Acc: 0.9811', 'Test Acc: 0.978', 'Train LL: -0.058480983594687314', 'Test LL: -0.06290061115722083', 'Epoch Time (s): 162.8321132780984')
('Epoch 33', 'Objective: -0.09013106700898735', 'Train Acc: 0.982', 'Test Acc: 0.9836', 'Train LL: -0.05754079883703683', 'Test LL: -0.04729775400397749', 'Epoch Time (s): 162.82423953618854')
('Epoch 34', 'Objective: -0.0895016598959311', 'Train Acc: 0.9819166666666667', 'Test Acc: 0.9847', 'Train LL: -0.056987142868452884', 'Test LL: -0.04818897912538174', 'Epoch Time (s): 162.80057511804625')
('Epoch 35', 'Objective: -0.08875208623750365', 'Train Acc: 0.9817833333333333', 'Test Acc: 0.9745', 'Train LL: -0.05649531047759999', 'Test LL: -0.07748241673345929', 'Epoch Time (s): 162.83394348993897')
('Epoch 36', 'Objective: -0.08735251441157943', 'Train Acc: 0.9823166666666666', 'Test Acc: 0.9854', 'Train LL: -0.0552078494711753', 'Test LL: -0.044368961221017085', 'Epoch Time (s): 162.83357991208322')
('Epoch 37', 'Objective: -0.08838159451684317', 'Train Acc: 0.9821666666666666', 'Test Acc: 0.9801', 'Train LL: -0.056136282464305076', 'Test LL: -0.06019393853500459', 'Epoch Time (s): 162.76904108398594')
('Epoch 38', 'Objective: -0.08683455985588476', 'Train Acc: 0.9825', 'Test Acc: 0.9885', 'Train LL: -0.054734320499300625', 'Test LL: -0.035019197413867005', 'Epoch Time (s): 162.84815564891323')
('Epoch 39', 'Objective: -0.08416575246469812', 'Train Acc: 0.9829166666666667', 'Test Acc: 0.9799', 'Train LL: -0.05233950748093912', 'Test LL: -0.06500282828069923', 'Epoch Time (s): 162.82434014393948')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06545064495760498', 'Train Acc: 0.9886833333333334', 'Test Acc: 0.9896', 'Train LL: -0.03533359973332554', 'Test LL: -0.0325417549381577', 'Epoch Time (s): 162.84396842913702')
('Epoch 41', 'Objective: -0.05879441625906428', 'Train Acc: 0.9899166666666667', 'Test Acc: 0.9903', 'Train LL: -0.030052323812230202', 'Test LL: -0.03094514113540954', 'Epoch Time (s): 162.80562680517323')
('Epoch 42', 'Objective: -0.05735519755834648', 'Train Acc: 0.99085', 'Test Acc: 0.9888', 'Train LL: -0.028981854438990793', 'Test LL: -0.03232316236900969', 'Epoch Time (s): 162.8625354480464')
('Epoch 43', 'Objective: -0.05594688335665156', 'Train Acc: 0.9912833333333333', 'Test Acc: 0.9902', 'Train LL: -0.0278072805982148', 'Test LL: -0.030948153386121214', 'Epoch Time (s): 162.8660876781214')
('Epoch 44', 'Objective: -0.055578097998695314', 'Train Acc: 0.9913166666666666', 'Test Acc: 0.9907', 'Train LL: -0.02761348866290941', 'Test LL: -0.02904026950485316', 'Epoch Time (s): 162.85841380083002')
('Epoch 45', 'Objective: -0.05372687801027412', 'Train Acc: 0.9915166666666667', 'Test Acc: 0.9896', 'Train LL: -0.02613609110212879', 'Test LL: -0.031253140182388714', 'Epoch Time (s): 162.8510444238782')
('Epoch 46', 'Objective: -0.05376810831387386', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9889', 'Train LL: -0.02633355229004154', 'Test LL: -0.03363122468068605', 'Epoch Time (s): 162.81163174309768')
('Epoch 47', 'Objective: -0.05391400944264344', 'Train Acc: 0.9916', 'Test Acc: 0.9895', 'Train LL: -0.026549132375593004', 'Test LL: -0.030516270523570716', 'Epoch Time (s): 162.88294422999024')
('Epoch 48', 'Objective: -0.05324902881800739', 'Train Acc: 0.9916666666666667', 'Test Acc: 0.9909', 'Train LL: -0.026047108155451897', 'Test LL: -0.02888846447921724', 'Epoch Time (s): 162.84745888691396')
('Epoch 49', 'Objective: -0.052950059232319435', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.9892', 'Train LL: -0.02592661368436405', 'Test LL: -0.03365788494927286', 'Epoch Time (s): 162.8892258470878')
('Epoch 50', 'Objective: -0.05292253565543991', 'Train Acc: 0.9918', 'Test Acc: 0.9898', 'Train LL: -0.025962049659763373', 'Test LL: -0.030515594076346263', 'Epoch Time (s): 162.8349087201059')
('Epoch 51', 'Objective: -0.05159313044180228', 'Train Acc: 0.99225', 'Test Acc: 0.9896', 'Train LL: -0.024745039736562505', 'Test LL: -0.032952411184068345', 'Epoch Time (s): 162.93235755199566')
('Epoch 52', 'Objective: -0.05185585765307733', 'Train Acc: 0.9917', 'Test Acc: 0.9898', 'Train LL: -0.025076077772139445', 'Test LL: -0.030907505654626414', 'Epoch Time (s): 162.84348695306107')
('Epoch 53', 'Objective: -0.05033819727036245', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9907', 'Train LL: -0.023842658329215623', 'Test LL: -0.02877395452993025', 'Epoch Time (s): 162.77471445384435')
('Epoch 54', 'Objective: -0.050960021069284524', 'Train Acc: 0.99225', 'Test Acc: 0.9899', 'Train LL: -0.024489809242782393', 'Test LL: -0.029369728639247666', 'Epoch Time (s): 162.8143038279377')
('Epoch 55', 'Objective: -0.05007195430029359', 'Train Acc: 0.99245', 'Test Acc: 0.9903', 'Train LL: -0.0236355883862681', 'Test LL: -0.03160072630540437', 'Epoch Time (s): 162.84402302792296')
('Epoch 56', 'Objective: -0.05004575770928029', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.9907', 'Train LL: -0.023740951041194155', 'Test LL: -0.028403022488030304', 'Epoch Time (s): 162.89223244297318')
('Epoch 57', 'Objective: -0.050177652251491706', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9894', 'Train LL: -0.02388890992727519', 'Test LL: -0.031014708906364985', 'Epoch Time (s): 162.8294454170391')
('Epoch 58', 'Objective: -0.04959124850931793', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9891', 'Train LL: -0.023391796145043782', 'Test LL: -0.03225232637615345', 'Epoch Time (s): 162.79324314417318')
('Epoch 59', 'Objective: -0.04981731623009624', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.9895', 'Train LL: -0.023658440606500825', 'Test LL: -0.03139195473404671', 'Epoch Time (s): 162.7866421379149')
('Epoch 60', 'Objective: -0.05017989557414355', 'Train Acc: 0.9922166666666666', 'Test Acc: 0.9901', 'Train LL: -0.02422514478706334', 'Test LL: -0.0312726468355544', 'Epoch Time (s): 162.79868421284482')
('Epoch 61', 'Objective: -0.04960382193082077', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.989', 'Train LL: -0.023671561047590196', 'Test LL: -0.031207588136322847', 'Epoch Time (s): 162.85781300999224')
('Epoch 62', 'Objective: -0.04953057665503006', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.99', 'Train LL: -0.023707341572999245', 'Test LL: -0.03131263315012287', 'Epoch Time (s): 162.82995435083285')
('Epoch 63', 'Objective: -0.04922300025848598', 'Train Acc: 0.9922', 'Test Acc: 0.9891', 'Train LL: -0.02345010158021418', 'Test LL: -0.03297455415085333', 'Epoch Time (s): 162.8400332769379')
('Epoch 64', 'Objective: -0.04859139297556897', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9907', 'Train LL: -0.022859483319089883', 'Test LL: -0.02850366039398549', 'Epoch Time (s): 162.84712215699255')
('Epoch 65', 'Objective: -0.04889296986759154', 'Train Acc: 0.9924', 'Test Acc: 0.9903', 'Train LL: -0.02320434209582982', 'Test LL: -0.02803504285894677', 'Epoch Time (s): 162.8351017399691')
('Epoch 66', 'Objective: -0.048604852435931496', 'Train Acc: 0.99235', 'Test Acc: 0.9895', 'Train LL: -0.022894325133647787', 'Test LL: -0.03122999870343475', 'Epoch Time (s): 162.80704398383386')
('Epoch 67', 'Objective: -0.049052506640421455', 'Train Acc: 0.9923', 'Test Acc: 0.9896', 'Train LL: -0.023417828456246497', 'Test LL: -0.030155492371575023', 'Epoch Time (s): 162.80377760110423')
('Epoch 68', 'Objective: -0.04845133776010599', 'Train Acc: 0.9923166666666666', 'Test Acc: 0.9891', 'Train LL: -0.022895964030161517', 'Test LL: -0.031246585012612217', 'Epoch Time (s): 162.84494910994545')
('Epoch 69', 'Objective: -0.04779008042922926', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9888', 'Train LL: -0.022266063631706242', 'Test LL: -0.03283601875322726', 'Epoch Time (s): 162.87598633999005')
('Epoch 70', 'Objective: -0.04827937439346364', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9907', 'Train LL: -0.02281824728488353', 'Test LL: -0.028421902199896033', 'Epoch Time (s): 162.9182027070783')
('Epoch 71', 'Objective: -0.04861780162594875', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9897', 'Train LL: -0.0232221749054311', 'Test LL: -0.03125181487254764', 'Epoch Time (s): 163.17796671995893')
('Epoch 72', 'Objective: -0.047219078285872775', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9898', 'Train LL: -0.022021604826566045', 'Test LL: -0.03216112194560849', 'Epoch Time (s): 162.83068737690337')
('Epoch 73', 'Objective: -0.04785164914724351', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9899', 'Train LL: -0.022482272198928153', 'Test LL: -0.031230042629281536', 'Epoch Time (s): 162.88023336511105')
('Epoch 74', 'Objective: -0.04719288547064392', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9893', 'Train LL: -0.022000113042906385', 'Test LL: -0.031076267667765747', 'Epoch Time (s): 162.84614654583856')
('Epoch 75', 'Objective: -0.04708380722646677', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9896', 'Train LL: -0.02183161086666059', 'Test LL: -0.03172045498437291', 'Epoch Time (s): 162.86308343079872')
('Epoch 76', 'Objective: -0.04659974950796601', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9895', 'Train LL: -0.021424944672970632', 'Test LL: -0.03146739954551374', 'Epoch Time (s): 162.8517744881101')
('Epoch 77', 'Objective: -0.046871435645711224', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9884', 'Train LL: -0.021696839984647148', 'Test LL: -0.03554204289413899', 'Epoch Time (s): 162.8524977848865')
('Epoch 78', 'Objective: -0.04698023455735785', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9895', 'Train LL: -0.021886829040781947', 'Test LL: -0.03073560299791831', 'Epoch Time (s): 162.83259596093558')
('Epoch 79', 'Objective: -0.046896301446787435', 'Train Acc: 0.99275', 'Test Acc: 0.9907', 'Train LL: -0.021851387621381026', 'Test LL: -0.02864078937672974', 'Epoch Time (s): 162.88308167085052')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.044700438838853496', 'Train Acc: 0.99365', 'Test Acc: 0.9905', 'Train LL: -0.019900999156999978', 'Test LL: -0.02935638055069055', 'Epoch Time (s): 162.85372097510844')
('Epoch 81', 'Objective: -0.043323606372080686', 'Train Acc: 0.9939', 'Test Acc: 0.9904', 'Train LL: -0.01864728094421197', 'Test LL: -0.029287543058749577', 'Epoch Time (s): 162.79096343414858')
('Epoch 82', 'Objective: -0.0432438013709487', 'Train Acc: 0.99425', 'Test Acc: 0.9903', 'Train LL: -0.018554317317531405', 'Test LL: -0.028747896219521438', 'Epoch Time (s): 162.83167436998338')
('Epoch 83', 'Objective: -0.04347605744821218', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9903', 'Train LL: -0.018780492539096996', 'Test LL: -0.02900107463226824', 'Epoch Time (s): 162.8148904030677')
('Epoch 84', 'Objective: -0.04291124250348828', 'Train Acc: 0.99415', 'Test Acc: 0.9901', 'Train LL: -0.018244611773009494', 'Test LL: -0.03025006956513172', 'Epoch Time (s): 162.81430420302786')
('Epoch 85', 'Objective: -0.04264764727091357', 'Train Acc: 0.9945', 'Test Acc: 0.9906', 'Train LL: -0.018006138917691577', 'Test LL: -0.029450709328113136', 'Epoch Time (s): 162.9646596009843')
('Epoch 86', 'Objective: -0.042937392174149984', 'Train Acc: 0.99405', 'Test Acc: 0.9902', 'Train LL: -0.018236534199231807', 'Test LL: -0.029145446995453357', 'Epoch Time (s): 162.87693020398729')
('Epoch 87', 'Objective: -0.042901878434358054', 'Train Acc: 0.9944833333333334', 'Test Acc: 0.9904', 'Train LL: -0.01822915667474337', 'Test LL: -0.02870255277012535', 'Epoch Time (s): 162.89682774804533')
('Epoch 88', 'Objective: -0.04302765509742856', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.99', 'Train LL: -0.01836595250584013', 'Test LL: -0.029838899286078253', 'Epoch Time (s): 162.94892427977175')
('Epoch 89', 'Objective: -0.04291608690862965', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9902', 'Train LL: -0.018252517302814134', 'Test LL: -0.02898352810730792', 'Epoch Time (s): 162.95169438282028')
('Epoch 90', 'Objective: -0.043566800839336416', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9901', 'Train LL: -0.018865562556196418', 'Test LL: -0.02862612106148888', 'Epoch Time (s): 162.82657877495512')
('Epoch 91', 'Objective: -0.04254398844391719', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9907', 'Train LL: -0.017952120624372934', 'Test LL: -0.028632213515734015', 'Epoch Time (s): 162.78576523903757')
('Epoch 92', 'Objective: -0.04246265684679783', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9901', 'Train LL: -0.017862738954146484', 'Test LL: -0.0299898911723923', 'Epoch Time (s): 162.8162307960447')
('Epoch 93', 'Objective: -0.04308714326659237', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9901', 'Train LL: -0.018460971061473378', 'Test LL: -0.029754210673541462', 'Epoch Time (s): 162.81659912713803')
('Epoch 94', 'Objective: -0.04180886702131099', 'Train Acc: 0.99475', 'Test Acc: 0.9906', 'Train LL: -0.017256711934262963', 'Test LL: -0.02964094403698465', 'Epoch Time (s): 162.88170847599395')
('Epoch 95', 'Objective: -0.042204672523160666', 'Train Acc: 0.99435', 'Test Acc: 0.9906', 'Train LL: -0.017593918789374902', 'Test LL: -0.02967845719133102', 'Epoch Time (s): 162.77787031698972')
('Epoch 96', 'Objective: -0.04203265990733323', 'Train Acc: 0.99435', 'Test Acc: 0.9899', 'Train LL: -0.017456681148882797', 'Test LL: -0.03073199288404486', 'Epoch Time (s): 162.8662534521427')
('Epoch 97', 'Objective: -0.04241524665718924', 'Train Acc: 0.9946', 'Test Acc: 0.9902', 'Train LL: -0.017807471722071748', 'Test LL: -0.02976119816429749', 'Epoch Time (s): 162.94038448482752')
('Epoch 98', 'Objective: -0.04262281796061117', 'Train Acc: 0.9943166666666666', 'Test Acc: 0.9905', 'Train LL: -0.018015331787006476', 'Test LL: -0.02844625075384614', 'Epoch Time (s): 162.87186053511687')
('Epoch 99', 'Objective: -0.04287077597730295', 'Train Acc: 0.9942', 'Test Acc: 0.9906', 'Train LL: -0.018258787136866086', 'Test LL: -0.028298180186242677', 'Epoch Time (s): 162.92352093895897')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04184497451190929
Final Train Accuracy: £0.9945333333333334
Final Train LL: £-0.017298985907231258
Final Test Accuracy: £0.9908
Final Test LL: £-0.02796715678522271
