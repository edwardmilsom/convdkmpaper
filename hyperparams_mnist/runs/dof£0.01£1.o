dataset: MNIST
dtype: float64
dof: 0.01
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2700653449995907', 'Train Acc: 0.5584333333333333', 'Test Acc: 0.8306', 'Train LL: -1.2391373192845956', 'Test LL: -0.5237527645809953', 'Epoch Time (s): 163.71729592280462')
('Epoch 1', 'Objective: -0.4284096890835472', 'Train Acc: 0.8623833333333333', 'Test Acc: 0.9316', 'Train LL: -0.4097847097159572', 'Test LL: -0.22506610167442231', 'Epoch Time (s): 163.88257130910642')
('Epoch 2', 'Objective: -0.2400251362561229', 'Train Acc: 0.9281166666666667', 'Test Acc: 0.9514', 'Train LL: -0.2248563742959718', 'Test LL: -0.16213338596912763', 'Epoch Time (s): 163.8327308241278')
('Epoch 3', 'Objective: -0.18740082712346648', 'Train Acc: 0.9459', 'Test Acc: 0.9495', 'Train LL: -0.17380474769931184', 'Test LL: -0.16041643759994412', 'Epoch Time (s): 163.80621280381456')
('Epoch 4', 'Objective: -0.15657217906394574', 'Train Acc: 0.9550666666666666', 'Test Acc: 0.9502', 'Train LL: -0.14410569130400472', 'Test LL: -0.16245600949254227', 'Epoch Time (s): 163.78487745579332')
('Epoch 5', 'Objective: -0.13370230087505236', 'Train Acc: 0.9616833333333333', 'Test Acc: 0.9733', 'Train LL: -0.12222577310819419', 'Test LL: -0.08445949004410828', 'Epoch Time (s): 163.80939450487494')
('Epoch 6', 'Objective: -0.12322668856973544', 'Train Acc: 0.9643666666666667', 'Test Acc: 0.9665', 'Train LL: -0.11244115454096422', 'Test LL: -0.09952043061800261', 'Epoch Time (s): 163.80000528716482')
('Epoch 7', 'Objective: -0.11013527486772315', 'Train Acc: 0.9689666666666666', 'Test Acc: 0.9769', 'Train LL: -0.0999487959485973', 'Test LL: -0.0772623674255256', 'Epoch Time (s): 163.87531436001882')
('Epoch 8', 'Objective: -0.10596226088674737', 'Train Acc: 0.9698333333333333', 'Test Acc: 0.9715', 'Train LL: -0.0961198085859544', 'Test LL: -0.09607566338904086', 'Epoch Time (s): 163.89195462688804')
('Epoch 9', 'Objective: -0.09791516574166624', 'Train Acc: 0.9721', 'Test Acc: 0.9689', 'Train LL: -0.08856725369910066', 'Test LL: -0.09332335843929225', 'Epoch Time (s): 163.81914882198907')
('Epoch 10', 'Objective: -0.09291197521990104', 'Train Acc: 0.97375', 'Test Acc: 0.9808', 'Train LL: -0.08395458629453079', 'Test LL: -0.05495400682608215', 'Epoch Time (s): 163.82631310401484')
('Epoch 11', 'Objective: -0.08653747194811352', 'Train Acc: 0.97565', 'Test Acc: 0.9793', 'Train LL: -0.07796695392664568', 'Test LL: -0.06332068893245371', 'Epoch Time (s): 163.83127905405127')
('Epoch 12', 'Objective: -0.08409126249486185', 'Train Acc: 0.9754333333333334', 'Test Acc: 0.977', 'Train LL: -0.07578126012940906', 'Test LL: -0.07087907491247747', 'Epoch Time (s): 163.86119587300345')
('Epoch 13', 'Objective: -0.0807331826853518', 'Train Acc: 0.9773', 'Test Acc: 0.9818', 'Train LL: -0.07266900133114264', 'Test LL: -0.05795760284731407', 'Epoch Time (s): 163.85433189407922')
('Epoch 14', 'Objective: -0.07877982661486788', 'Train Acc: 0.9768333333333333', 'Test Acc: 0.9802', 'Train LL: -0.07092865470671306', 'Test LL: -0.058529360812712046', 'Epoch Time (s): 163.80821696296334')
('Epoch 15', 'Objective: -0.07480942140013434', 'Train Acc: 0.9787666666666667', 'Test Acc: 0.9789', 'Train LL: -0.06721707721422014', 'Test LL: -0.0622264061526623', 'Epoch Time (s): 163.89621985703707')
('Epoch 16', 'Objective: -0.07165251621838385', 'Train Acc: 0.9788666666666667', 'Test Acc: 0.9741', 'Train LL: -0.06428286617657328', 'Test LL: -0.07610524780542806', 'Epoch Time (s): 163.85158016881905')
('Epoch 17', 'Objective: -0.06942944064864169', 'Train Acc: 0.9801833333333333', 'Test Acc: 0.9799', 'Train LL: -0.062243808772452724', 'Test LL: -0.06291907890699146', 'Epoch Time (s): 163.86698852083646')
('Epoch 18', 'Objective: -0.06866638772595669', 'Train Acc: 0.98065', 'Test Acc: 0.9824', 'Train LL: -0.06170956055088092', 'Test LL: -0.05615456649685302', 'Epoch Time (s): 163.82467943103984')
('Epoch 19', 'Objective: -0.06612189857063631', 'Train Acc: 0.9817666666666667', 'Test Acc: 0.9825', 'Train LL: -0.059332632272915624', 'Test LL: -0.05190618621518544', 'Epoch Time (s): 163.85404055705294')
('Epoch 20', 'Objective: -0.06427280430719946', 'Train Acc: 0.9811333333333333', 'Test Acc: 0.9801', 'Train LL: -0.05755086293438215', 'Test LL: -0.06269537778447855', 'Epoch Time (s): 163.86881503113545')
('Epoch 21', 'Objective: -0.06546742854867754', 'Train Acc: 0.9814', 'Test Acc: 0.9801', 'Train LL: -0.05891053247809195', 'Test LL: -0.057088204957141474', 'Epoch Time (s): 163.88116732193157')
('Epoch 22', 'Objective: -0.0625626841014043', 'Train Acc: 0.9823166666666666', 'Test Acc: 0.9877', 'Train LL: -0.056124585925897204', 'Test LL: -0.038407016868030164', 'Epoch Time (s): 163.86230090004392')
('Epoch 23', 'Objective: -0.06037348404339483', 'Train Acc: 0.982', 'Test Acc: 0.9778', 'Train LL: -0.054111588043862686', 'Test LL: -0.0697225957365488', 'Epoch Time (s): 164.00438535003923')
('Epoch 24', 'Objective: -0.059630369154306', 'Train Acc: 0.9835166666666667', 'Test Acc: 0.985', 'Train LL: -0.05346563940708565', 'Test LL: -0.04636476815642645', 'Epoch Time (s): 163.885764290113')
('Epoch 25', 'Objective: -0.057859009206543924', 'Train Acc: 0.9831166666666666', 'Test Acc: 0.9847', 'Train LL: -0.05182665998843448', 'Test LL: -0.04469887361788696', 'Epoch Time (s): 163.8341673410032')
('Epoch 26', 'Objective: -0.056917742997482916', 'Train Acc: 0.9838', 'Test Acc: 0.9849', 'Train LL: -0.05101237113516663', 'Test LL: -0.04593214950280021', 'Epoch Time (s): 163.8116218871437')
('Epoch 27', 'Objective: -0.05520573827679531', 'Train Acc: 0.9843333333333333', 'Test Acc: 0.979', 'Train LL: -0.04927974093342354', 'Test LL: -0.06176478227960675', 'Epoch Time (s): 163.86989946104586')
('Epoch 28', 'Objective: -0.05458262709413005', 'Train Acc: 0.9845', 'Test Acc: 0.9809', 'Train LL: -0.04877589932680053', 'Test LL: -0.057590633585796136', 'Epoch Time (s): 163.9273645260837')
('Epoch 29', 'Objective: -0.054729732721872766', 'Train Acc: 0.9844833333333334', 'Test Acc: 0.9822', 'Train LL: -0.04906078845514578', 'Test LL: -0.049385203617096377', 'Epoch Time (s): 163.87675322499126')
('Epoch 30', 'Objective: -0.05266256865102735', 'Train Acc: 0.9854666666666667', 'Test Acc: 0.9883', 'Train LL: -0.047138987196748694', 'Test LL: -0.035076273872782844', 'Epoch Time (s): 163.84647956304252')
('Epoch 31', 'Objective: -0.05363784573274346', 'Train Acc: 0.9842333333333333', 'Test Acc: 0.9853', 'Train LL: -0.04816470816942915', 'Test LL: -0.04306867578051945', 'Epoch Time (s): 163.85663881897926')
('Epoch 32', 'Objective: -0.051939119746434906', 'Train Acc: 0.9850333333333333', 'Test Acc: 0.9862', 'Train LL: -0.04653266265671323', 'Test LL: -0.04328802006496752', 'Epoch Time (s): 163.89269506186247')
('Epoch 33', 'Objective: -0.05050655010767268', 'Train Acc: 0.9857833333333333', 'Test Acc: 0.9876', 'Train LL: -0.04515388435149596', 'Test LL: -0.0408801248253523', 'Epoch Time (s): 163.8466942110099')
('Epoch 34', 'Objective: -0.050357603505645984', 'Train Acc: 0.9852833333333333', 'Test Acc: 0.9816', 'Train LL: -0.04505312869187691', 'Test LL: -0.05837661982801114', 'Epoch Time (s): 163.86517264391296')
('Epoch 35', 'Objective: -0.049689570104267465', 'Train Acc: 0.9857666666666667', 'Test Acc: 0.9856', 'Train LL: -0.04444394288198029', 'Test LL: -0.04602765063437145', 'Epoch Time (s): 163.8622708208859')
('Epoch 36', 'Objective: -0.04756899547720536', 'Train Acc: 0.9861833333333333', 'Test Acc: 0.9881', 'Train LL: -0.0424395325766943', 'Test LL: -0.035978261210327774', 'Epoch Time (s): 163.85852963896468')
('Epoch 37', 'Objective: -0.049725406871373994', 'Train Acc: 0.9857333333333334', 'Test Acc: 0.9836', 'Train LL: -0.04459332737388375', 'Test LL: -0.05297115912104914', 'Epoch Time (s): 163.8275500559248')
('Epoch 38', 'Objective: -0.04795945695939968', 'Train Acc: 0.9862833333333333', 'Test Acc: 0.9897', 'Train LL: -0.042875987462235206', 'Test LL: -0.03269627083120124', 'Epoch Time (s): 163.79970668582246')
('Epoch 39', 'Objective: -0.04658255128215317', 'Train Acc: 0.9865666666666667', 'Test Acc: 0.981', 'Train LL: -0.04153590013716048', 'Test LL: -0.05873706721469532', 'Epoch Time (s): 163.84724278608337')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.031100832972723622', 'Train Acc: 0.9915166666666667', 'Test Acc: 0.9926', 'Train LL: -0.026510492751707516', 'Test LL: -0.025079073669130328', 'Epoch Time (s): 163.7687906229403')
('Epoch 41', 'Objective: -0.025555770413858897', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9926', 'Train LL: -0.021211228982378486', 'Test LL: -0.02506414241707105', 'Epoch Time (s): 163.91429848689586')
('Epoch 42', 'Objective: -0.02327205046805425', 'Train Acc: 0.9938833333333333', 'Test Acc: 0.9917', 'Train LL: -0.019039545653312045', 'Test LL: -0.026135030366121224', 'Epoch Time (s): 163.84625582606532')
('Epoch 43', 'Objective: -0.022852997948049347', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.9909', 'Train LL: -0.018673149881003423', 'Test LL: -0.028003186009551935', 'Epoch Time (s): 163.88315501390025')
('Epoch 44', 'Objective: -0.020801830335086435', 'Train Acc: 0.9946166666666667', 'Test Acc: 0.9917', 'Train LL: -0.016713733151478942', 'Test LL: -0.027392912493268112', 'Epoch Time (s): 163.84628040809184')
('Epoch 45', 'Objective: -0.020753977668476378', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9899', 'Train LL: -0.0167269644196625', 'Test LL: -0.030273945479883296', 'Epoch Time (s): 163.794246932026')
('Epoch 46', 'Objective: -0.020604509955849126', 'Train Acc: 0.99455', 'Test Acc: 0.9917', 'Train LL: -0.01658187644799125', 'Test LL: -0.02682561910402087', 'Epoch Time (s): 163.82124196900986')
('Epoch 47', 'Objective: -0.019574875551270146', 'Train Acc: 0.995', 'Test Acc: 0.9921', 'Train LL: -0.015575105432708921', 'Test LL: -0.024682502098087266', 'Epoch Time (s): 163.79857867001556')
('Epoch 48', 'Objective: -0.018830077158920554', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9911', 'Train LL: -0.01483914231490408', 'Test LL: -0.026211909946418054', 'Epoch Time (s): 163.81569222616963')
('Epoch 49', 'Objective: -0.018447975356169825', 'Train Acc: 0.9953333333333333', 'Test Acc: 0.9906', 'Train LL: -0.014498703952599546', 'Test LL: -0.03118675767685429', 'Epoch Time (s): 163.79896119004115')
('Epoch 50', 'Objective: -0.01915061128848991', 'Train Acc: 0.9948833333333333', 'Test Acc: 0.9919', 'Train LL: -0.015177198906125018', 'Test LL: -0.02496452148737787', 'Epoch Time (s): 163.82990416395478')
('Epoch 51', 'Objective: -0.017633351000689575', 'Train Acc: 0.9953166666666666', 'Test Acc: 0.9902', 'Train LL: -0.013730956249076774', 'Test LL: -0.02898452481563943', 'Epoch Time (s): 163.82001022202894')
('Epoch 52', 'Objective: -0.01778144999605777', 'Train Acc: 0.9955333333333334', 'Test Acc: 0.9903', 'Train LL: -0.013877134925014762', 'Test LL: -0.029323599592479762', 'Epoch Time (s): 163.8831593329087')
('Epoch 53', 'Objective: -0.016770690759662286', 'Train Acc: 0.9960333333333333', 'Test Acc: 0.9922', 'Train LL: -0.012897193565844366', 'Test LL: -0.026440262402837648', 'Epoch Time (s): 163.88109211297706')
('Epoch 54', 'Objective: -0.016357004952208622', 'Train Acc: 0.9958666666666667', 'Test Acc: 0.9911', 'Train LL: -0.012456718549736713', 'Test LL: -0.027409752023001686', 'Epoch Time (s): 163.83934616693296')
('Epoch 55', 'Objective: -0.017093022072500953', 'Train Acc: 0.9957166666666667', 'Test Acc: 0.9918', 'Train LL: -0.013167104712942825', 'Test LL: -0.026956650430868666', 'Epoch Time (s): 163.85592268500477')
('Epoch 56', 'Objective: -0.01593661686951608', 'Train Acc: 0.9959166666666667', 'Test Acc: 0.9913', 'Train LL: -0.01209028668235586', 'Test LL: -0.027658110838418508', 'Epoch Time (s): 163.85773235210218')
('Epoch 57', 'Objective: -0.01632346452866373', 'Train Acc: 0.9959666666666667', 'Test Acc: 0.9916', 'Train LL: -0.012440727826777978', 'Test LL: -0.028603278906828684', 'Epoch Time (s): 163.83434405899607')
('Epoch 58', 'Objective: -0.015934215533470623', 'Train Acc: 0.99595', 'Test Acc: 0.9916', 'Train LL: -0.012054216815170162', 'Test LL: -0.02801893705966487', 'Epoch Time (s): 163.85635026707314')
('Epoch 59', 'Objective: -0.015341283834289926', 'Train Acc: 0.9959666666666667', 'Test Acc: 0.991', 'Train LL: -0.01147250275352254', 'Test LL: -0.027171998077366907', 'Epoch Time (s): 163.8481590319425')
('Epoch 60', 'Objective: -0.015787251182784956', 'Train Acc: 0.99625', 'Test Acc: 0.9915', 'Train LL: -0.011957306976771059', 'Test LL: -0.029539930604844035', 'Epoch Time (s): 163.8426512859296')
('Epoch 61', 'Objective: -0.014811041546246927', 'Train Acc: 0.9963666666666666', 'Test Acc: 0.9903', 'Train LL: -0.010991543206635363', 'Test LL: -0.03225620095111138', 'Epoch Time (s): 163.8821272039786')
('Epoch 62', 'Objective: -0.014182083465764288', 'Train Acc: 0.9963833333333333', 'Test Acc: 0.9897', 'Train LL: -0.010361882617463179', 'Test LL: -0.0346060812126144', 'Epoch Time (s): 163.8497654730454')
('Epoch 63', 'Objective: -0.01492369318792455', 'Train Acc: 0.9965', 'Test Acc: 0.9912', 'Train LL: -0.011099603656772698', 'Test LL: -0.03134574945604835', 'Epoch Time (s): 163.86951620387845')
('Epoch 64', 'Objective: -0.014308630992882869', 'Train Acc: 0.9965', 'Test Acc: 0.9904', 'Train LL: -0.010484012613981557', 'Test LL: -0.028340392825583167', 'Epoch Time (s): 163.8843147100415')
('Epoch 65', 'Objective: -0.01436536492891116', 'Train Acc: 0.9966333333333334', 'Test Acc: 0.9904', 'Train LL: -0.01057199887841771', 'Test LL: -0.03259815896408511', 'Epoch Time (s): 163.87106132204644')
('Epoch 66', 'Objective: -0.013985734015387274', 'Train Acc: 0.9966166666666667', 'Test Acc: 0.9906', 'Train LL: -0.010165733661653784', 'Test LL: -0.030299554646501473', 'Epoch Time (s): 163.80378431500867')
('Epoch 67', 'Objective: -0.0137724511577782', 'Train Acc: 0.9966833333333334', 'Test Acc: 0.9907', 'Train LL: -0.009968654989741784', 'Test LL: -0.032579284040459955', 'Epoch Time (s): 163.87791618914343')
('Epoch 68', 'Objective: -0.013406210823929336', 'Train Acc: 0.9967333333333334', 'Test Acc: 0.9909', 'Train LL: -0.009636299589610818', 'Test LL: -0.032157122805271256', 'Epoch Time (s): 163.88375229085796')
('Epoch 69', 'Objective: -0.012825154348384146', 'Train Acc: 0.9969666666666667', 'Test Acc: 0.9909', 'Train LL: -0.009036127055642251', 'Test LL: -0.03487587023390292', 'Epoch Time (s): 163.84294356009923')
('Epoch 70', 'Objective: -0.01329029571828685', 'Train Acc: 0.9967333333333334', 'Test Acc: 0.9918', 'Train LL: -0.00951006889925796', 'Test LL: -0.02862122025979623', 'Epoch Time (s): 163.85758282290772')
('Epoch 71', 'Objective: -0.013120568647641141', 'Train Acc: 0.9965666666666667', 'Test Acc: 0.9914', 'Train LL: -0.00934771542288515', 'Test LL: -0.03230967850417376', 'Epoch Time (s): 163.8519643198233')
('Epoch 72', 'Objective: -0.012943250392337595', 'Train Acc: 0.9965333333333334', 'Test Acc: 0.9914', 'Train LL: -0.009153624955260972', 'Test LL: -0.03046905609947442', 'Epoch Time (s): 163.84786716802046')
('Epoch 73', 'Objective: -0.01323244318855473', 'Train Acc: 0.99665', 'Test Acc: 0.9907', 'Train LL: -0.009449230958651734', 'Test LL: -0.03370410512195682', 'Epoch Time (s): 163.8556469839532')
('Epoch 74', 'Objective: -0.012974187187748069', 'Train Acc: 0.9969', 'Test Acc: 0.9905', 'Train LL: -0.009196243581879199', 'Test LL: -0.03374084597188249', 'Epoch Time (s): 163.86110192909837')
('Epoch 75', 'Objective: -0.011911877789306033', 'Train Acc: 0.99725', 'Test Acc: 0.9907', 'Train LL: -0.00821300861160713', 'Test LL: -0.034532170826765164', 'Epoch Time (s): 163.8370822861325')
('Epoch 76', 'Objective: -0.012881364782211977', 'Train Acc: 0.9969166666666667', 'Test Acc: 0.9913', 'Train LL: -0.00913296158953433', 'Test LL: -0.03201616773569636', 'Epoch Time (s): 163.86145190498792')
('Epoch 77', 'Objective: -0.011456271115533089', 'Train Acc: 0.9976333333333334', 'Test Acc: 0.9901', 'Train LL: -0.007788843635848059', 'Test LL: -0.037809824627149734', 'Epoch Time (s): 163.8670754218474')
('Epoch 78', 'Objective: -0.012331875590206914', 'Train Acc: 0.9969166666666667', 'Test Acc: 0.9911', 'Train LL: -0.008567502851199477', 'Test LL: -0.03256113808326781', 'Epoch Time (s): 163.87085561989807')
('Epoch 79', 'Objective: -0.012132258516828726', 'Train Acc: 0.9971666666666666', 'Test Acc: 0.991', 'Train LL: -0.008402480708464558', 'Test LL: -0.03260833734278912', 'Epoch Time (s): 163.81936212279834')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.010245427064642508', 'Train Acc: 0.99785', 'Test Acc: 0.9913', 'Train LL: -0.006646925076378623', 'Test LL: -0.03205469040420924', 'Epoch Time (s): 163.7994316178374')
('Epoch 81', 'Objective: -0.009545308503351883', 'Train Acc: 0.9980166666666667', 'Test Acc: 0.9916', 'Train LL: -0.005997322031534147', 'Test LL: -0.030485623718885524', 'Epoch Time (s): 163.88572662393562')
('Epoch 82', 'Objective: -0.009154350700292618', 'Train Acc: 0.9982', 'Test Acc: 0.9916', 'Train LL: -0.005609652639823623', 'Test LL: -0.030374299609232373', 'Epoch Time (s): 163.87502900906838')
('Epoch 83', 'Objective: -0.008967513514973475', 'Train Acc: 0.9983', 'Test Acc: 0.991', 'Train LL: -0.005445372243547151', 'Test LL: -0.03248780776584248', 'Epoch Time (s): 163.8500073440373')
('Epoch 84', 'Objective: -0.009297227862615429', 'Train Acc: 0.9982833333333333', 'Test Acc: 0.9916', 'Train LL: -0.0057316583770252215', 'Test LL: -0.03149671444290499', 'Epoch Time (s): 163.86812045006081')
('Epoch 85', 'Objective: -0.008356440341385425', 'Train Acc: 0.9983666666666666', 'Test Acc: 0.9912', 'Train LL: -0.004853318360029838', 'Test LL: -0.03247750737042739', 'Epoch Time (s): 163.849486048799')
('Epoch 86', 'Objective: -0.008716518983456005', 'Train Acc: 0.9985', 'Test Acc: 0.9913', 'Train LL: -0.005193531896615919', 'Test LL: -0.03306719220217721', 'Epoch Time (s): 163.9572145009879')
('Epoch 87', 'Objective: -0.008450896193938856', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9911', 'Train LL: -0.0049351834595445085', 'Test LL: -0.034266774079391965', 'Epoch Time (s): 163.85187762207352')
('Epoch 88', 'Objective: -0.008370471035740784', 'Train Acc: 0.9984666666666666', 'Test Acc: 0.9917', 'Train LL: -0.004840394260041046', 'Test LL: -0.0332162622593653', 'Epoch Time (s): 163.85082897613756')
('Epoch 89', 'Objective: -0.008488791076867648', 'Train Acc: 0.9985166666666667', 'Test Acc: 0.9911', 'Train LL: -0.004945570010857703', 'Test LL: -0.03438060268644641', 'Epoch Time (s): 163.86853679595515')
('Epoch 90', 'Objective: -0.008750136760306648', 'Train Acc: 0.9985', 'Test Acc: 0.9913', 'Train LL: -0.005204773217263217', 'Test LL: -0.03413734463692001', 'Epoch Time (s): 163.881019663997')
('Epoch 91', 'Objective: -0.007953782071658942', 'Train Acc: 0.9986', 'Test Acc: 0.9918', 'Train LL: -0.004436718892072625', 'Test LL: -0.03223435481323437', 'Epoch Time (s): 163.8357902651187')
('Epoch 92', 'Objective: -0.008209682147222779', 'Train Acc: 0.99865', 'Test Acc: 0.9918', 'Train LL: -0.0046811258144836086', 'Test LL: -0.03359407201343507', 'Epoch Time (s): 163.87462875596248')
('Epoch 93', 'Objective: -0.008486446706055077', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.991', 'Train LL: -0.004916030414995941', 'Test LL: -0.03604901322918523', 'Epoch Time (s): 163.8905044279527')
('Epoch 94', 'Objective: -0.00813256369923954', 'Train Acc: 0.9984666666666666', 'Test Acc: 0.9916', 'Train LL: -0.004588496129078566', 'Test LL: -0.03499765417827592', 'Epoch Time (s): 163.88232032000087')
('Epoch 95', 'Objective: -0.008369106180737529', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9914', 'Train LL: -0.004793066768351906', 'Test LL: -0.0351042560775438', 'Epoch Time (s): 163.86399895488285')
('Epoch 96', 'Objective: -0.007598244944573407', 'Train Acc: 0.99855', 'Test Acc: 0.9913', 'Train LL: -0.004074835403116146', 'Test LL: -0.03490952092215769', 'Epoch Time (s): 163.8626421019435')
('Epoch 97', 'Objective: -0.007919758660169519', 'Train Acc: 0.9987166666666667', 'Test Acc: 0.9913', 'Train LL: -0.004394008494931921', 'Test LL: -0.03501499704004237', 'Epoch Time (s): 163.84816698590294')
('Epoch 98', 'Objective: -0.007822218819490504', 'Train Acc: 0.9988666666666667', 'Test Acc: 0.9911', 'Train LL: -0.004306649754194025', 'Test LL: -0.03728397723060281', 'Epoch Time (s): 163.86449703294784')
('Epoch 99', 'Objective: -0.008291906618354546', 'Train Acc: 0.9984666666666666', 'Test Acc: 0.9909', 'Train LL: -0.0047375045461379925', 'Test LL: -0.03713754453189761', 'Epoch Time (s): 163.87056411709636')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.00787653588621011
Final Train Accuracy: £0.9986333333333334
Final Train LL: £-0.004332297249095347
Final Test Accuracy: £0.9909
Final Test LL: £-0.037007793217097414
