dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: location
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3512805942360002', 'Train Acc: 0.5302333333333333', 'Test Acc: 0.7883', 'Train LL: -1.2961509785279424', 'Test LL: -0.6407180140433385', 'Epoch Time (s): 163.51395450904965')
('Epoch 1', 'Objective: -0.567565502532652', 'Train Acc: 0.8233333333333334', 'Test Acc: 0.8182', 'Train LL: -0.5132294458626887', 'Test LL: -0.5748744548058138', 'Epoch Time (s): 163.61913751182146')
('Epoch 2', 'Objective: -0.3814184080163474', 'Train Acc: 0.8922333333333333', 'Test Acc: 0.9208', 'Train LL: -0.3297113686131388', 'Test LL: -0.26279298373586224', 'Epoch Time (s): 163.644231621176')
('Epoch 3', 'Objective: -0.27734693677546157', 'Train Acc: 0.9281333333333334', 'Test Acc: 0.9505', 'Train LL: -0.2286289836407792', 'Test LL: -0.16258373875526108', 'Epoch Time (s): 163.5961073481012')
('Epoch 4', 'Objective: -0.22644774217919816', 'Train Acc: 0.9443', 'Test Acc: 0.9584', 'Train LL: -0.18130417472362803', 'Test LL: -0.13433576494983754', 'Epoch Time (s): 163.62204351997934')
('Epoch 5', 'Objective: -0.20196921833467643', 'Train Acc: 0.9502833333333334', 'Test Acc: 0.9487', 'Train LL: -0.15917713808786405', 'Test LL: -0.1480639160192978', 'Epoch Time (s): 163.59853285597637')
('Epoch 6', 'Objective: -0.18395483301980828', 'Train Acc: 0.9556166666666667', 'Test Acc: 0.9705', 'Train LL: -0.14282358680478524', 'Test LL: -0.09526567068530875', 'Epoch Time (s): 163.63369525386952')
('Epoch 7', 'Objective: -0.16690193712398851', 'Train Acc: 0.9603', 'Test Acc: 0.9562', 'Train LL: -0.12720527287797745', 'Test LL: -0.14072745261026598', 'Epoch Time (s): 163.51077566598542')
('Epoch 8', 'Objective: -0.15736771109778527', 'Train Acc: 0.9624333333333334', 'Test Acc: 0.9709', 'Train LL: -0.11843375311672506', 'Test LL: -0.09139575490447803', 'Epoch Time (s): 163.53831682889722')
('Epoch 9', 'Objective: -0.14730726373081607', 'Train Acc: 0.96535', 'Test Acc: 0.9708', 'Train LL: -0.10966674933916237', 'Test LL: -0.09807804342771846', 'Epoch Time (s): 163.52664709510282')
('Epoch 10', 'Objective: -0.13906710620934784', 'Train Acc: 0.96795', 'Test Acc: 0.9724', 'Train LL: -0.102003789804598', 'Test LL: -0.0893619867388494', 'Epoch Time (s): 163.51317576901056')
('Epoch 11', 'Objective: -0.13151506228194246', 'Train Acc: 0.9705', 'Test Acc: 0.9702', 'Train LL: -0.09551250953208323', 'Test LL: -0.09871987539022574', 'Epoch Time (s): 163.48822044301778')
('Epoch 12', 'Objective: -0.12660388678419904', 'Train Acc: 0.9718666666666667', 'Test Acc: 0.9681', 'Train LL: -0.09129305650957918', 'Test LL: -0.0962384108713772', 'Epoch Time (s): 163.51511237886734')
('Epoch 13', 'Objective: -0.1211563334179578', 'Train Acc: 0.9727833333333333', 'Test Acc: 0.9707', 'Train LL: -0.08667028030673368', 'Test LL: -0.09131416744517509', 'Epoch Time (s): 163.51644963608123')
('Epoch 14', 'Objective: -0.11875152693714619', 'Train Acc: 0.9735166666666667', 'Test Acc: 0.9746', 'Train LL: -0.08475916801598624', 'Test LL: -0.07906240668964169', 'Epoch Time (s): 163.49079288588837')
('Epoch 15', 'Objective: -0.11426255308248018', 'Train Acc: 0.9752833333333333', 'Test Acc: 0.9734', 'Train LL: -0.08096468387941935', 'Test LL: -0.08339898448242604', 'Epoch Time (s): 163.54479062184691')
('Epoch 16', 'Objective: -0.11252598977399757', 'Train Acc: 0.9746166666666667', 'Test Acc: 0.9804', 'Train LL: -0.0798394054864154', 'Test LL: -0.06406497602827865', 'Epoch Time (s): 163.54040021100082')
('Epoch 17', 'Objective: -0.10778707628847944', 'Train Acc: 0.9762833333333333', 'Test Acc: 0.9804', 'Train LL: -0.07535793168801494', 'Test LL: -0.06230216652841414', 'Epoch Time (s): 163.51741294004023')
('Epoch 18', 'Objective: -0.10635975184392248', 'Train Acc: 0.9759', 'Test Acc: 0.9758', 'Train LL: -0.07441097603339654', 'Test LL: -0.07740866643898707', 'Epoch Time (s): 163.54254655586556')
('Epoch 19', 'Objective: -0.10475720533394502', 'Train Acc: 0.9771666666666666', 'Test Acc: 0.9788', 'Train LL: -0.07311898531013394', 'Test LL: -0.06574829728962908', 'Epoch Time (s): 163.52461243397556')
('Epoch 20', 'Objective: -0.10131884823933837', 'Train Acc: 0.9778166666666667', 'Test Acc: 0.9781', 'Train LL: -0.07017151588327075', 'Test LL: -0.06722168912125681', 'Epoch Time (s): 163.5539020630531')
('Epoch 21', 'Objective: -0.09871365118739563', 'Train Acc: 0.9784166666666667', 'Test Acc: 0.9751', 'Train LL: -0.0675914509864547', 'Test LL: -0.07588514870141133', 'Epoch Time (s): 163.5414157800842')
('Epoch 22', 'Objective: -0.09770169605972692', 'Train Acc: 0.9783666666666667', 'Test Acc: 0.9805', 'Train LL: -0.06730868031819931', 'Test LL: -0.06186872230785389', 'Epoch Time (s): 163.54793500108644')
('Epoch 23', 'Objective: -0.0959450400632535', 'Train Acc: 0.9794833333333334', 'Test Acc: 0.9765', 'Train LL: -0.06563497476481346', 'Test LL: -0.06979065423638829', 'Epoch Time (s): 163.52578778611496')
('Epoch 24', 'Objective: -0.093571550740785', 'Train Acc: 0.97965', 'Test Acc: 0.9803', 'Train LL: -0.06369212643983327', 'Test LL: -0.057118114975199114', 'Epoch Time (s): 163.53774018888362')
('Epoch 25', 'Objective: -0.09178260242501579', 'Train Acc: 0.9798', 'Test Acc: 0.9811', 'Train LL: -0.06221562647788736', 'Test LL: -0.05684022934395107', 'Epoch Time (s): 163.5406509458553')
('Epoch 26', 'Objective: -0.09030913576505453', 'Train Acc: 0.9811833333333333', 'Test Acc: 0.9796', 'Train LL: -0.06100268298599585', 'Test LL: -0.064845392678807', 'Epoch Time (s): 163.52504126401618')
('Epoch 27', 'Objective: -0.09111604893998686', 'Train Acc: 0.9808166666666667', 'Test Acc: 0.9839', 'Train LL: -0.062066074163263284', 'Test LL: -0.04915719893186188', 'Epoch Time (s): 163.55840066401288')
('Epoch 28', 'Objective: -0.08979506897591086', 'Train Acc: 0.9803666666666667', 'Test Acc: 0.9743', 'Train LL: -0.06093685315320985', 'Test LL: -0.07571899205424036', 'Epoch Time (s): 163.53820564807393')
('Epoch 29', 'Objective: -0.09018663795731245', 'Train Acc: 0.9810666666666666', 'Test Acc: 0.9822', 'Train LL: -0.06141489925895678', 'Test LL: -0.05587051395524853', 'Epoch Time (s): 163.53531816997565')
('Epoch 30', 'Objective: -0.08657192230487888', 'Train Acc: 0.9821833333333333', 'Test Acc: 0.9837', 'Train LL: -0.0583571487232535', 'Test LL: -0.04735142932247236', 'Epoch Time (s): 163.52830853685737')
('Epoch 31', 'Objective: -0.08517958149647402', 'Train Acc: 0.98155', 'Test Acc: 0.9831', 'Train LL: -0.05693333211203948', 'Test LL: -0.053511568372146406', 'Epoch Time (s): 163.52931137708947')
('Epoch 32', 'Objective: -0.08358386843223509', 'Train Acc: 0.9825833333333334', 'Test Acc: 0.9855', 'Train LL: -0.05570938463677023', 'Test LL: -0.0487234557526227', 'Epoch Time (s): 163.55307583487593')
('Epoch 33', 'Objective: -0.08433052244007623', 'Train Acc: 0.9824166666666667', 'Test Acc: 0.974', 'Train LL: -0.05643003693944706', 'Test LL: -0.07663763185106737', 'Epoch Time (s): 163.56948294700123')
('Epoch 34', 'Objective: -0.08250049697959098', 'Train Acc: 0.9826166666666667', 'Test Acc: 0.9861', 'Train LL: -0.054808422505598815', 'Test LL: -0.04305023122655323', 'Epoch Time (s): 163.57843939610757')
('Epoch 35', 'Objective: -0.08296217522406633', 'Train Acc: 0.9830166666666666', 'Test Acc: 0.9857', 'Train LL: -0.05553928596498591', 'Test LL: -0.04442216061241526', 'Epoch Time (s): 163.52639277395792')
('Epoch 36', 'Objective: -0.08038740468815521', 'Train Acc: 0.9828', 'Test Acc: 0.9853', 'Train LL: -0.052863476249986587', 'Test LL: -0.04389865068738867', 'Epoch Time (s): 163.56465880805627')
('Epoch 37', 'Objective: -0.08163992955273741', 'Train Acc: 0.9827666666666667', 'Test Acc: 0.9838', 'Train LL: -0.054329935393351333', 'Test LL: -0.04672645012803838', 'Epoch Time (s): 163.51273368299007')
('Epoch 38', 'Objective: -0.08079036266862029', 'Train Acc: 0.9831333333333333', 'Test Acc: 0.982', 'Train LL: -0.053622302735091436', 'Test LL: -0.058159677542555424', 'Epoch Time (s): 163.48979766503908')
('Epoch 39', 'Objective: -0.07906787118542748', 'Train Acc: 0.98365', 'Test Acc: 0.9814', 'Train LL: -0.05223816277396827', 'Test LL: -0.05961916576434609', 'Epoch Time (s): 163.56451188703068')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.060046242104173544', 'Train Acc: 0.9886833333333334', 'Test Acc: 0.9897', 'Train LL: -0.03485935997250615', 'Test LL: -0.03203528496153905', 'Epoch Time (s): 163.5820199290756')
('Epoch 41', 'Objective: -0.05366334586855388', 'Train Acc: 0.9904333333333334', 'Test Acc: 0.9909', 'Train LL: -0.029397678904259487', 'Test LL: -0.030066817628772422', 'Epoch Time (s): 163.55337234283797')
('Epoch 42', 'Objective: -0.052581296976115036', 'Train Acc: 0.9905166666666667', 'Test Acc: 0.9895', 'Train LL: -0.028611372393168633', 'Test LL: -0.032162985441039106', 'Epoch Time (s): 163.56095188087784')
('Epoch 43', 'Objective: -0.05144326856922072', 'Train Acc: 0.9911166666666666', 'Test Acc: 0.9907', 'Train LL: -0.02773297784400393', 'Test LL: -0.030524951881488193', 'Epoch Time (s): 163.53374224388972')
('Epoch 44', 'Objective: -0.05103933077076751', 'Train Acc: 0.9913833333333333', 'Test Acc: 0.9901', 'Train LL: -0.027522133803949866', 'Test LL: -0.03232805200730861', 'Epoch Time (s): 163.54023804096505')
('Epoch 45', 'Objective: -0.05050688610961328', 'Train Acc: 0.9912', 'Test Acc: 0.9904', 'Train LL: -0.027089602387339165', 'Test LL: -0.03037160707910918', 'Epoch Time (s): 163.5241450939793')
('Epoch 46', 'Objective: -0.049701076084612224', 'Train Acc: 0.99135', 'Test Acc: 0.9897', 'Train LL: -0.026382195872076783', 'Test LL: -0.03096098852836924', 'Epoch Time (s): 163.52582108601928')
('Epoch 47', 'Objective: -0.049204508073803346', 'Train Acc: 0.99165', 'Test Acc: 0.9899', 'Train LL: -0.026051345100647244', 'Test LL: -0.030945747987846318', 'Epoch Time (s): 163.52985490113497')
('Epoch 48', 'Objective: -0.049141463727607824', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9911', 'Train LL: -0.025967485903877978', 'Test LL: -0.027976041373563253', 'Epoch Time (s): 163.5446057699155')
('Epoch 49', 'Objective: -0.047967225609835136', 'Train Acc: 0.9919833333333333', 'Test Acc: 0.9897', 'Train LL: -0.0249873993278199', 'Test LL: -0.03232596879094272', 'Epoch Time (s): 163.54926706803963')
('Epoch 50', 'Objective: -0.04811139292555988', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9913', 'Train LL: -0.025071481148941907', 'Test LL: -0.027136017194026703', 'Epoch Time (s): 163.587477222085')
('Epoch 51', 'Objective: -0.047980067831649285', 'Train Acc: 0.9918333333333333', 'Test Acc: 0.9905', 'Train LL: -0.025092283270112797', 'Test LL: -0.029297737506195024', 'Epoch Time (s): 163.5852331260685')
('Epoch 52', 'Objective: -0.047205275257821075', 'Train Acc: 0.9920833333333333', 'Test Acc: 0.9907', 'Train LL: -0.02437759529653174', 'Test LL: -0.029605653381220082', 'Epoch Time (s): 163.54666468990035')
('Epoch 53', 'Objective: -0.047511494486760654', 'Train Acc: 0.9919833333333333', 'Test Acc: 0.9907', 'Train LL: -0.024722123635355912', 'Test LL: -0.028069908695066856', 'Epoch Time (s): 163.5515708969906')
('Epoch 54', 'Objective: -0.0471891630003813', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.991', 'Train LL: -0.024485521940718215', 'Test LL: -0.02926180315835894', 'Epoch Time (s): 163.5764024099335')
('Epoch 55', 'Objective: -0.04710318098259423', 'Train Acc: 0.9921833333333333', 'Test Acc: 0.9906', 'Train LL: -0.024461423581167718', 'Test LL: -0.02943759098374647', 'Epoch Time (s): 163.55399699904956')
('Epoch 56', 'Objective: -0.04638861110204838', 'Train Acc: 0.9924', 'Test Acc: 0.9908', 'Train LL: -0.023875698895314396', 'Test LL: -0.027998793910384255', 'Epoch Time (s): 163.52244785707444')
('Epoch 57', 'Objective: -0.04641618656533095', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9908', 'Train LL: -0.023968024237031076', 'Test LL: -0.0292294633964914', 'Epoch Time (s): 163.54130133916624')
('Epoch 58', 'Objective: -0.04578536278763877', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9907', 'Train LL: -0.023384597689048398', 'Test LL: -0.02983561428956266', 'Epoch Time (s): 163.53370910696685')
('Epoch 59', 'Objective: -0.04544291802215427', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9918', 'Train LL: -0.023153548879016717', 'Test LL: -0.02670860346418354', 'Epoch Time (s): 163.5015297429636')
('Epoch 60', 'Objective: -0.04533366334318592', 'Train Acc: 0.99245', 'Test Acc: 0.9896', 'Train LL: -0.022978098067444424', 'Test LL: -0.03268858976657259', 'Epoch Time (s): 163.5603253520094')
('Epoch 61', 'Objective: -0.04494539729197167', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.99', 'Train LL: -0.022672368977197085', 'Test LL: -0.03229465346927935', 'Epoch Time (s): 163.5253646520432')
('Epoch 62', 'Objective: -0.044870875769869416', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9907', 'Train LL: -0.022577588385159636', 'Test LL: -0.03087397336275074', 'Epoch Time (s): 163.5725942919962')
('Epoch 63', 'Objective: -0.04495120348353778', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9902', 'Train LL: -0.022896847061184396', 'Test LL: -0.03364388958562753', 'Epoch Time (s): 163.55101220309734')
('Epoch 64', 'Objective: -0.04512520718316628', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9898', 'Train LL: -0.023117996938180903', 'Test LL: -0.030170756622039288', 'Epoch Time (s): 163.5783719329629')
('Epoch 65', 'Objective: -0.0451772447177283', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9912', 'Train LL: -0.02313004113955689', 'Test LL: -0.0271197622219088', 'Epoch Time (s): 163.56659953901544')
('Epoch 66', 'Objective: -0.043656777148798884', 'Train Acc: 0.9930333333333333', 'Test Acc: 0.9922', 'Train LL: -0.021681342820120613', 'Test LL: -0.02648961164125127', 'Epoch Time (s): 163.57051183306612')
('Epoch 67', 'Objective: -0.04448182610791056', 'Train Acc: 0.99245', 'Test Acc: 0.9888', 'Train LL: -0.022514861760532568', 'Test LL: -0.03367187457464609', 'Epoch Time (s): 163.5336489197798')
('Epoch 68', 'Objective: -0.044686853418399224', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9905', 'Train LL: -0.022774551432660446', 'Test LL: -0.02964937875602866', 'Epoch Time (s): 163.5519241541624')
('Epoch 69', 'Objective: -0.04427008150312949', 'Train Acc: 0.99285', 'Test Acc: 0.9909', 'Train LL: -0.022372252021153193', 'Test LL: -0.03130830481432165', 'Epoch Time (s): 163.55154590401798')
('Epoch 70', 'Objective: -0.04417224303064545', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9908', 'Train LL: -0.022395717048296186', 'Test LL: -0.02753605798489407', 'Epoch Time (s): 163.53830482903868')
('Epoch 71', 'Objective: -0.04322418389401657', 'Train Acc: 0.9934', 'Test Acc: 0.9888', 'Train LL: -0.021549404855666743', 'Test LL: -0.03353230762129701', 'Epoch Time (s): 163.5399438359309')
('Epoch 72', 'Objective: -0.04422993449758936', 'Train Acc: 0.99275', 'Test Acc: 0.991', 'Train LL: -0.022518635772238546', 'Test LL: -0.030282258759133242', 'Epoch Time (s): 163.56252756901085')
('Epoch 73', 'Objective: -0.04317274772353294', 'Train Acc: 0.99315', 'Test Acc: 0.9906', 'Train LL: -0.021430655022269176', 'Test LL: -0.02880080146732403', 'Epoch Time (s): 163.54991774610244')
('Epoch 74', 'Objective: -0.04362517727154817', 'Train Acc: 0.99335', 'Test Acc: 0.9904', 'Train LL: -0.02194225958569488', 'Test LL: -0.030855557383997784', 'Epoch Time (s): 163.56643134797923')
('Epoch 75', 'Objective: -0.04394655780023595', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9902', 'Train LL: -0.02218269198035551', 'Test LL: -0.0323645844354581', 'Epoch Time (s): 163.52128229709342')
('Epoch 76', 'Objective: -0.043535447319460296', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9885', 'Train LL: -0.021876492604619366', 'Test LL: -0.034082865909320526', 'Epoch Time (s): 163.7123199638445')
('Epoch 77', 'Objective: -0.04333585354169178', 'Train Acc: 0.99285', 'Test Acc: 0.9906', 'Train LL: -0.021776171461362806', 'Test LL: -0.030954815738894394', 'Epoch Time (s): 163.64473238401115')
('Epoch 78', 'Objective: -0.04391577345444975', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9898', 'Train LL: -0.022270241606610303', 'Test LL: -0.0317735325703341', 'Epoch Time (s): 163.67112518008798')
('Epoch 79', 'Objective: -0.043503468659295816', 'Train Acc: 0.99295', 'Test Acc: 0.9896', 'Train LL: -0.022088719322697212', 'Test LL: -0.03256394113297839', 'Epoch Time (s): 163.67107915389352')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04046133478914881', 'Train Acc: 0.99375', 'Test Acc: 0.9909', 'Train LL: -0.019199714230883357', 'Test LL: -0.02841615975735462', 'Epoch Time (s): 163.6552850799635')
('Epoch 81', 'Objective: -0.03994802459765734', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9915', 'Train LL: -0.01881978835357813', 'Test LL: -0.027717109799999935', 'Epoch Time (s): 163.70998178911395')
('Epoch 82', 'Objective: -0.03985577299535668', 'Train Acc: 0.9941', 'Test Acc: 0.9915', 'Train LL: -0.018731355891640312', 'Test LL: -0.02770344651159835', 'Epoch Time (s): 163.658300279174')
('Epoch 83', 'Objective: -0.040018044723861855', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9917', 'Train LL: -0.018899705409210786', 'Test LL: -0.027458854871265044', 'Epoch Time (s): 163.63599040498957')
('Epoch 84', 'Objective: -0.039711039530351766', 'Train Acc: 0.9944', 'Test Acc: 0.9917', 'Train LL: -0.01860381942468636', 'Test LL: -0.027370904720768887', 'Epoch Time (s): 163.70634326012805')
('Epoch 85', 'Objective: -0.03990547079384633', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9914', 'Train LL: -0.01879374162828339', 'Test LL: -0.027656795778927913', 'Epoch Time (s): 163.6796240499243')
('Epoch 86', 'Objective: -0.03953593743551181', 'Train Acc: 0.99415', 'Test Acc: 0.9916', 'Train LL: -0.018417614210270463', 'Test LL: -0.02777379749974554', 'Epoch Time (s): 163.754702815786')
('Epoch 87', 'Objective: -0.03932349736654852', 'Train Acc: 0.9942333333333333', 'Test Acc: 0.9907', 'Train LL: -0.018258598609641834', 'Test LL: -0.028090294108455476', 'Epoch Time (s): 163.67803107993677')
('Epoch 88', 'Objective: -0.03920700129334442', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9915', 'Train LL: -0.01816897058517305', 'Test LL: -0.027685181238502322', 'Epoch Time (s): 163.6772433638107')
('Epoch 89', 'Objective: -0.038774220024211034', 'Train Acc: 0.99445', 'Test Acc: 0.9905', 'Train LL: -0.017723010880862193', 'Test LL: -0.02902403440433784', 'Epoch Time (s): 163.690917306114')
('Epoch 90', 'Objective: -0.03884905201063888', 'Train Acc: 0.99425', 'Test Acc: 0.9917', 'Train LL: -0.017784944276654942', 'Test LL: -0.027679707052825103', 'Epoch Time (s): 163.68107928312384')
('Epoch 91', 'Objective: -0.03893800540017404', 'Train Acc: 0.99415', 'Test Acc: 0.9908', 'Train LL: -0.01785373005604105', 'Test LL: -0.028226780949708034', 'Epoch Time (s): 163.69987370399758')
('Epoch 92', 'Objective: -0.03922017531990145', 'Train Acc: 0.9943', 'Test Acc: 0.991', 'Train LL: -0.01812826772172341', 'Test LL: -0.028502170217728273', 'Epoch Time (s): 163.70837788493372')
('Epoch 93', 'Objective: -0.039068229605279205', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.991', 'Train LL: -0.018033011480520948', 'Test LL: -0.028102635297776624', 'Epoch Time (s): 163.7012712440919')
('Epoch 94', 'Objective: -0.039171342395817474', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9913', 'Train LL: -0.01814522896516255', 'Test LL: -0.028532739849508926', 'Epoch Time (s): 163.67867472488433')
('Epoch 95', 'Objective: -0.038626512328375086', 'Train Acc: 0.99415', 'Test Acc: 0.9911', 'Train LL: -0.017609192386115777', 'Test LL: -0.028843191527146927', 'Epoch Time (s): 163.70347543619573')
('Epoch 96', 'Objective: -0.03902611312312791', 'Train Acc: 0.99405', 'Test Acc: 0.9912', 'Train LL: -0.01795702351764087', 'Test LL: -0.027870962814852487', 'Epoch Time (s): 163.62645482691005')
('Epoch 97', 'Objective: -0.0388877882549264', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.9911', 'Train LL: -0.0178183429957616', 'Test LL: -0.028521458637917607', 'Epoch Time (s): 163.78932682308368')
('Epoch 98', 'Objective: -0.03826371717193638', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9906', 'Train LL: -0.01723878279024585', 'Test LL: -0.029086113073286707', 'Epoch Time (s): 163.67721002409235')
('Epoch 99', 'Objective: -0.03895281008513925', 'Train Acc: 0.99455', 'Test Acc: 0.9909', 'Train LL: -0.01789248433520465', 'Test LL: -0.027654900012571572', 'Epoch Time (s): 163.66047517303377')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03873965543944644
Final Train Accuracy: £0.9942666666666666
Final Train LL: £-0.017697191072786334
Final Test Accuracy: £0.9909
Final Test LL: £-0.02768716527126149
