dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: BFC
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.472305274613235', 'Train Acc: 0.495', 'Test Acc: 0.7803', 'Train LL: -1.371882453918836', 'Test LL: -0.6783313460176403', 'Epoch Time (s): 170.2180608427152')
('Epoch 1', 'Objective: -0.5872504511176359', 'Train Acc: 0.825', 'Test Acc: 0.8617', 'Train LL: -0.5090051634327634', 'Test LL: -0.41714432576596844', 'Epoch Time (s): 169.6032145190984')
('Epoch 2', 'Objective: -0.3790069444182745', 'Train Acc: 0.8993333333333333', 'Test Acc: 0.9279', 'Train LL: -0.30871255436348594', 'Test LL: -0.22926244897223932', 'Epoch Time (s): 169.5397295039147')
('Epoch 3', 'Objective: -0.273467955908957', 'Train Acc: 0.9353333333333333', 'Test Acc: 0.9538', 'Train LL: -0.20883107361229697', 'Test LL: -0.14793903016916835', 'Epoch Time (s): 169.5621553780511')
('Epoch 4', 'Objective: -0.23019310929172332', 'Train Acc: 0.94755', 'Test Acc: 0.948', 'Train LL: -0.17005933337401644', 'Test LL: -0.16596647952796706', 'Epoch Time (s): 169.58406524313614')
('Epoch 5', 'Objective: -0.20544367726088483', 'Train Acc: 0.95415', 'Test Acc: 0.9628', 'Train LL: -0.14898270519025927', 'Test LL: -0.11988989966430433', 'Epoch Time (s): 169.60939239058644')
('Epoch 6', 'Objective: -0.18715047332321086', 'Train Acc: 0.9586', 'Test Acc: 0.964', 'Train LL: -0.13369802945452927', 'Test LL: -0.10660314805577972', 'Epoch Time (s): 169.533719540108')
('Epoch 7', 'Objective: -0.1779868038890156', 'Train Acc: 0.96085', 'Test Acc: 0.965', 'Train LL: -0.12591697932140908', 'Test LL: -0.10800679189250456', 'Epoch Time (s): 169.5600485629402')
('Epoch 8', 'Objective: -0.1671139930173956', 'Train Acc: 0.9640666666666666', 'Test Acc: 0.9698', 'Train LL: -0.11661740554472291', 'Test LL: -0.09962295531787373', 'Epoch Time (s): 169.5576964020729')
('Epoch 9', 'Objective: -0.15994926915918528', 'Train Acc: 0.9653', 'Test Acc: 0.9637', 'Train LL: -0.11093848998536444', 'Test LL: -0.11604645834541011', 'Epoch Time (s): 169.59393886942416')
('Epoch 10', 'Objective: -0.15246692093870085', 'Train Acc: 0.9671', 'Test Acc: 0.9544', 'Train LL: -0.10447460370126613', 'Test LL: -0.1359728081829101', 'Epoch Time (s): 169.55863280082121')
('Epoch 11', 'Objective: -0.14527776015229185', 'Train Acc: 0.9687166666666667', 'Test Acc: 0.9719', 'Train LL: -0.09855453256517985', 'Test LL: -0.08845608449329377', 'Epoch Time (s): 169.55287799611688')
('Epoch 12', 'Objective: -0.1402946013915927', 'Train Acc: 0.9704833333333334', 'Test Acc: 0.9737', 'Train LL: -0.0942608523485072', 'Test LL: -0.08105916478951897', 'Epoch Time (s): 169.49849603697658')
('Epoch 13', 'Objective: -0.13844418882669626', 'Train Acc: 0.97075', 'Test Acc: 0.971', 'Train LL: -0.0926211374131085', 'Test LL: -0.09383982675753598', 'Epoch Time (s): 169.54200780112296')
('Epoch 14', 'Objective: -0.13161880815641033', 'Train Acc: 0.9723', 'Test Acc: 0.9746', 'Train LL: -0.08696070348267677', 'Test LL: -0.08298783337056112', 'Epoch Time (s): 169.53306797612458')
('Epoch 15', 'Objective: -0.12827598426071593', 'Train Acc: 0.97385', 'Test Acc: 0.9688', 'Train LL: -0.08412440776616295', 'Test LL: -0.09335122149185271', 'Epoch Time (s): 169.57215992175043')
('Epoch 16', 'Objective: -0.12698376428157462', 'Train Acc: 0.9741666666666666', 'Test Acc: 0.9753', 'Train LL: -0.0831912124094895', 'Test LL: -0.0730902560200053', 'Epoch Time (s): 169.57797711342573')
('Epoch 17', 'Objective: -0.12299738895615733', 'Train Acc: 0.9753166666666667', 'Test Acc: 0.9847', 'Train LL: -0.07946632274203026', 'Test LL: -0.05071199143708849', 'Epoch Time (s): 169.58813364896923')
('Epoch 18', 'Objective: -0.11876979625567306', 'Train Acc: 0.9760833333333333', 'Test Acc: 0.9777', 'Train LL: -0.07605734610730887', 'Test LL: -0.0680858628456766', 'Epoch Time (s): 169.53747114399448')
('Epoch 19', 'Objective: -0.11536739082448215', 'Train Acc: 0.9765166666666667', 'Test Acc: 0.9808', 'Train LL: -0.07326059285478029', 'Test LL: -0.05511935954766412', 'Epoch Time (s): 169.58760167704895')
('Epoch 20', 'Objective: -0.11416941539254301', 'Train Acc: 0.9774166666666667', 'Test Acc: 0.9792', 'Train LL: -0.07229538414273054', 'Test LL: -0.06196052351790665', 'Epoch Time (s): 169.54954644292593')
('Epoch 21', 'Objective: -0.10996077485679479', 'Train Acc: 0.9784333333333334', 'Test Acc: 0.9796', 'Train LL: -0.06882199101478123', 'Test LL: -0.06256131679444651', 'Epoch Time (s): 169.61396627686918')
('Epoch 22', 'Objective: -0.10869901940436084', 'Train Acc: 0.9792166666666666', 'Test Acc: 0.9769', 'Train LL: -0.0680696350236084', 'Test LL: -0.06886855708242091', 'Epoch Time (s): 169.5299307401292')
('Epoch 23', 'Objective: -0.10631125832340559', 'Train Acc: 0.9790666666666666', 'Test Acc: 0.9725', 'Train LL: -0.06591167910559052', 'Test LL: -0.08505204133857308', 'Epoch Time (s): 169.58002552809194')
('Epoch 24', 'Objective: -0.10525573697614253', 'Train Acc: 0.9793166666666666', 'Test Acc: 0.9829', 'Train LL: -0.06546574525006843', 'Test LL: -0.0525802663159227', 'Epoch Time (s): 169.56164463516325')
('Epoch 25', 'Objective: -0.10253331885253623', 'Train Acc: 0.97955', 'Test Acc: 0.9795', 'Train LL: -0.06322337668546878', 'Test LL: -0.06551345282311616', 'Epoch Time (s): 169.57801571907476')
('Epoch 26', 'Objective: -0.10208878435149377', 'Train Acc: 0.9803333333333333', 'Test Acc: 0.9815', 'Train LL: -0.06336854496783718', 'Test LL: -0.056243293073804886', 'Epoch Time (s): 169.56710242433473')
('Epoch 27', 'Objective: -0.1029914428020533', 'Train Acc: 0.9795833333333334', 'Test Acc: 0.9833', 'Train LL: -0.06435371705242435', 'Test LL: -0.051002975696253706', 'Epoch Time (s): 169.53118959721178')
('Epoch 28', 'Objective: -0.0994137076121321', 'Train Acc: 0.9804666666666667', 'Test Acc: 0.9806', 'Train LL: -0.06111698132364409', 'Test LL: -0.05524811395435763', 'Epoch Time (s): 169.55631709983572')
('Epoch 29', 'Objective: -0.09818918568923089', 'Train Acc: 0.9810666666666666', 'Test Acc: 0.9859', 'Train LL: -0.06058915996475608', 'Test LL: -0.04762727382488152', 'Epoch Time (s): 169.5725482259877')
('Epoch 30', 'Objective: -0.09526182603907188', 'Train Acc: 0.9818333333333333', 'Test Acc: 0.986', 'Train LL: -0.057870726445036935', 'Test LL: -0.04425787216546955', 'Epoch Time (s): 169.57189915888011')
('Epoch 31', 'Objective: -0.0956217839261787', 'Train Acc: 0.9815', 'Test Acc: 0.9817', 'Train LL: -0.05837305563145247', 'Test LL: -0.05718962871101388', 'Epoch Time (s): 169.60154301300645')
('Epoch 32', 'Objective: -0.09379286869030969', 'Train Acc: 0.9821833333333333', 'Test Acc: 0.9794', 'Train LL: -0.05682040973979542', 'Test LL: -0.05965551093030822', 'Epoch Time (s): 169.59381609922275')
('Epoch 33', 'Objective: -0.09280583265326282', 'Train Acc: 0.98265', 'Test Acc: 0.9826', 'Train LL: -0.056322008915736146', 'Test LL: -0.05305612371250378', 'Epoch Time (s): 169.59949466306716')
('Epoch 34', 'Objective: -0.09200021394613385', 'Train Acc: 0.98295', 'Test Acc: 0.9843', 'Train LL: -0.05574983203015428', 'Test LL: -0.04823090231882185', 'Epoch Time (s): 169.58989655598998')
('Epoch 35', 'Objective: -0.09166314545701121', 'Train Acc: 0.98255', 'Test Acc: 0.9837', 'Train LL: -0.05570814701324567', 'Test LL: -0.0477505597884493', 'Epoch Time (s): 169.52368611795828')
('Epoch 36', 'Objective: -0.08969781963526799', 'Train Acc: 0.9827166666666667', 'Test Acc: 0.9854', 'Train LL: -0.05390369378367223', 'Test LL: -0.047878749661172476', 'Epoch Time (s): 169.55758699402213')
('Epoch 37', 'Objective: -0.0898783412441405', 'Train Acc: 0.9830166666666666', 'Test Acc: 0.9824', 'Train LL: -0.054276441135057835', 'Test LL: -0.05337361810154108', 'Epoch Time (s): 169.57728605391458')
('Epoch 38', 'Objective: -0.08919563195826073', 'Train Acc: 0.9830166666666666', 'Test Acc: 0.9825', 'Train LL: -0.05404760433377249', 'Test LL: -0.05534708777631804', 'Epoch Time (s): 169.55873064417392')
('Epoch 39', 'Objective: -0.08742061263842772', 'Train Acc: 0.9838166666666667', 'Test Acc: 0.9836', 'Train LL: -0.05226401954423614', 'Test LL: -0.05144646651436119', 'Epoch Time (s): 169.5473030428402')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06730315523007328', 'Train Acc: 0.9887166666666667', 'Test Acc: 0.9907', 'Train LL: -0.03461048061539667', 'Test LL: -0.03026396350218812', 'Epoch Time (s): 169.56413167668507')
('Epoch 41', 'Objective: -0.06064583321587155', 'Train Acc: 0.9904833333333334', 'Test Acc: 0.9911', 'Train LL: -0.0293528425066121', 'Test LL: -0.02888645946769176', 'Epoch Time (s): 169.56839914107695')
('Epoch 42', 'Objective: -0.05895684091396854', 'Train Acc: 0.99075', 'Test Acc: 0.9903', 'Train LL: -0.028254210015079204', 'Test LL: -0.03006456090929772', 'Epoch Time (s): 169.5640736897476')
('Epoch 43', 'Objective: -0.057754283641482364', 'Train Acc: 0.9910166666666667', 'Test Acc: 0.9907', 'Train LL: -0.02734111592433011', 'Test LL: -0.029106159624629743', 'Epoch Time (s): 169.53289469098672')
('Epoch 44', 'Objective: -0.05710710454515702', 'Train Acc: 0.9913', 'Test Acc: 0.9904', 'Train LL: -0.027015343746035005', 'Test LL: -0.03066407616409906', 'Epoch Time (s): 169.54025673028082')
('Epoch 45', 'Objective: -0.05647471158387419', 'Train Acc: 0.9915', 'Test Acc: 0.9904', 'Train LL: -0.0266356099592642', 'Test LL: -0.029231906183833218', 'Epoch Time (s): 169.53407039074227')
('Epoch 46', 'Objective: -0.05522572331428053', 'Train Acc: 0.99195', 'Test Acc: 0.9897', 'Train LL: -0.02559219037845709', 'Test LL: -0.031354546886141185', 'Epoch Time (s): 169.53265517298132')
('Epoch 47', 'Objective: -0.05538319464947173', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9914', 'Train LL: -0.02598235151056807', 'Test LL: -0.02746586977618972', 'Epoch Time (s): 169.53961516031995')
('Epoch 48', 'Objective: -0.054949494174725624', 'Train Acc: 0.9916', 'Test Acc: 0.9906', 'Train LL: -0.02566657854978492', 'Test LL: -0.028531661844038235', 'Epoch Time (s): 169.52760525420308')
('Epoch 49', 'Objective: -0.0540491831494438', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9913', 'Train LL: -0.02504237737314688', 'Test LL: -0.029901358608533168', 'Epoch Time (s): 169.56173929804936')
('Epoch 50', 'Objective: -0.05368375600869014', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.9913', 'Train LL: -0.02486098392747816', 'Test LL: -0.0278133964834433', 'Epoch Time (s): 169.56845626374707')
('Epoch 51', 'Objective: -0.05360267143538309', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9912', 'Train LL: -0.024825535101601445', 'Test LL: -0.030208332685446856', 'Epoch Time (s): 169.53066875226796')
('Epoch 52', 'Objective: -0.0532100056296672', 'Train Acc: 0.99195', 'Test Acc: 0.9919', 'Train LL: -0.0245483701193675', 'Test LL: -0.02717191263121764', 'Epoch Time (s): 169.54736659303308')
('Epoch 53', 'Objective: -0.05302384497759788', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.9909', 'Train LL: -0.024455754143681604', 'Test LL: -0.029970716520303357', 'Epoch Time (s): 169.5465641352348')
('Epoch 54', 'Objective: -0.053130029335503114', 'Train Acc: 0.99225', 'Test Acc: 0.9909', 'Train LL: -0.02461604561582962', 'Test LL: -0.029425952414732195', 'Epoch Time (s): 169.55164439510554')
('Epoch 55', 'Objective: -0.05232137282072101', 'Train Acc: 0.9922', 'Test Acc: 0.9918', 'Train LL: -0.02399651203501968', 'Test LL: -0.027232640237891955', 'Epoch Time (s): 169.53140717279166')
('Epoch 56', 'Objective: -0.05179017773610803', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9912', 'Train LL: -0.023618310348165947', 'Test LL: -0.02819538707674078', 'Epoch Time (s): 169.51378028886393')
('Epoch 57', 'Objective: -0.05248578100976332', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9907', 'Train LL: -0.02441071187106711', 'Test LL: -0.029862548699736906', 'Epoch Time (s): 169.51943231420591')
('Epoch 58', 'Objective: -0.051160482680060765', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9914', 'Train LL: -0.023246196277299378', 'Test LL: -0.02870684228312125', 'Epoch Time (s): 169.55010268837214')
('Epoch 59', 'Objective: -0.051504799619881726', 'Train Acc: 0.99255', 'Test Acc: 0.9918', 'Train LL: -0.02353908996940003', 'Test LL: -0.02625960414955104', 'Epoch Time (s): 169.56124836811796')
('Epoch 60', 'Objective: -0.05142496779591039', 'Train Acc: 0.9920666666666667', 'Test Acc: 0.9908', 'Train LL: -0.023503634843644747', 'Test LL: -0.030805570366248754', 'Epoch Time (s): 169.54457244090736')
('Epoch 61', 'Objective: -0.05099644047640316', 'Train Acc: 0.99255', 'Test Acc: 0.9901', 'Train LL: -0.023300530936397196', 'Test LL: -0.03233952153945465', 'Epoch Time (s): 169.40355227608234')
('Epoch 62', 'Objective: -0.0509622002713688', 'Train Acc: 0.99205', 'Test Acc: 0.9912', 'Train LL: -0.02320669861222174', 'Test LL: -0.0305103300329822', 'Epoch Time (s): 169.53893120680004')
('Epoch 63', 'Objective: -0.05089403006307936', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9909', 'Train LL: -0.02340642829882663', 'Test LL: -0.031186406761854375', 'Epoch Time (s): 169.43867432512343')
('Epoch 64', 'Objective: -0.05056528282845242', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.9898', 'Train LL: -0.02309882653484149', 'Test LL: -0.031511764013062805', 'Epoch Time (s): 169.43355157971382')
('Epoch 65', 'Objective: -0.050329018109808395', 'Train Acc: 0.9925666666666667', 'Test Acc: 0.9918', 'Train LL: -0.022958163119841644', 'Test LL: -0.02768359616821341', 'Epoch Time (s): 169.38418131601065')
('Epoch 66', 'Objective: -0.04939890839976796', 'Train Acc: 0.99285', 'Test Acc: 0.9915', 'Train LL: -0.022178422464035064', 'Test LL: -0.027545381517452443', 'Epoch Time (s): 169.40343187190592')
('Epoch 67', 'Objective: -0.04976178741976372', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9894', 'Train LL: -0.022510642058802204', 'Test LL: -0.03454210742402351', 'Epoch Time (s): 169.38294874783605')
('Epoch 68', 'Objective: -0.050209018639643076', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9915', 'Train LL: -0.023124198923923086', 'Test LL: -0.026731715971939612', 'Epoch Time (s): 169.42216938501224')
('Epoch 69', 'Objective: -0.04950481627536929', 'Train Acc: 0.99255', 'Test Acc: 0.9915', 'Train LL: -0.022448337681852823', 'Test LL: -0.028157852930234754', 'Epoch Time (s): 169.41531750978902')
('Epoch 70', 'Objective: -0.0496661389807134', 'Train Acc: 0.993', 'Test Acc: 0.9914', 'Train LL: -0.022581587295413753', 'Test LL: -0.028424154239282098', 'Epoch Time (s): 169.43321901606396')
('Epoch 71', 'Objective: -0.048752420707430404', 'Train Acc: 0.99335', 'Test Acc: 0.9903', 'Train LL: -0.021869793188793903', 'Test LL: -0.031134477840435337', 'Epoch Time (s): 169.38421414932236')
('Epoch 72', 'Objective: -0.04961085130724824', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9916', 'Train LL: -0.02267668542107731', 'Test LL: -0.027326159332037647', 'Epoch Time (s): 169.48821515589952')
('Epoch 73', 'Objective: -0.0481394855349406', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9906', 'Train LL: -0.02124198820217028', 'Test LL: -0.03281028486333498', 'Epoch Time (s): 169.47081338521093')
('Epoch 74', 'Objective: -0.048707108949420694', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9912', 'Train LL: -0.021872353756922484', 'Test LL: -0.03080532112563044', 'Epoch Time (s): 169.46049566892907')
('Epoch 75', 'Objective: -0.04874481326471635', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9908', 'Train LL: -0.021920804922526144', 'Test LL: -0.03153710843083028', 'Epoch Time (s): 169.4756554053165')
('Epoch 76', 'Objective: -0.04792750227068771', 'Train Acc: 0.9928', 'Test Acc: 0.9901', 'Train LL: -0.021154503259778502', 'Test LL: -0.031518362578002224', 'Epoch Time (s): 169.41160014178604')
('Epoch 77', 'Objective: -0.04848680874837669', 'Train Acc: 0.99325', 'Test Acc: 0.9904', 'Train LL: -0.021823165677645494', 'Test LL: -0.031245926334581692', 'Epoch Time (s): 169.42758568096906')
('Epoch 78', 'Objective: -0.04845221553235398', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9904', 'Train LL: -0.021748034451927273', 'Test LL: -0.030628837909492834', 'Epoch Time (s): 169.47157621197402')
('Epoch 79', 'Objective: -0.04826422417897491', 'Train Acc: 0.99315', 'Test Acc: 0.9908', 'Train LL: -0.021755044075171842', 'Test LL: -0.03214751519482098', 'Epoch Time (s): 169.4093098170124')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.045411943169249847', 'Train Acc: 0.9936333333333334', 'Test Acc: 0.9914', 'Train LL: -0.019040806385871245', 'Test LL: -0.029533689930282287', 'Epoch Time (s): 169.4017574810423')
('Epoch 81', 'Objective: -0.04491122151714803', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.992', 'Train LL: -0.018754584526693936', 'Test LL: -0.027768441747913545', 'Epoch Time (s): 169.55880853021517')
('Epoch 82', 'Objective: -0.044631257072352146', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.9917', 'Train LL: -0.01849431298818282', 'Test LL: -0.028675456725329264', 'Epoch Time (s): 169.42886092094705')
('Epoch 83', 'Objective: -0.044496355344777694', 'Train Acc: 0.9941', 'Test Acc: 0.9921', 'Train LL: -0.01845251678711415', 'Test LL: -0.027507657278629465', 'Epoch Time (s): 169.41782913310453')
('Epoch 84', 'Objective: -0.043967966703647735', 'Train Acc: 0.99405', 'Test Acc: 0.9919', 'Train LL: -0.017894986705766322', 'Test LL: -0.027838483737681555', 'Epoch Time (s): 169.46395304612815')
('Epoch 85', 'Objective: -0.044098602092462066', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.992', 'Train LL: -0.018082014764404672', 'Test LL: -0.028231021532102364', 'Epoch Time (s): 169.37981081800535')
('Epoch 86', 'Objective: -0.0439693347871002', 'Train Acc: 0.9944833333333334', 'Test Acc: 0.9917', 'Train LL: -0.017946233442705115', 'Test LL: -0.027900299781364338', 'Epoch Time (s): 169.46909904899076')
('Epoch 87', 'Objective: -0.04453182148303018', 'Train Acc: 0.99405', 'Test Acc: 0.9915', 'Train LL: -0.018488558069768287', 'Test LL: -0.028155501537851978', 'Epoch Time (s): 169.4470263440162')
('Epoch 88', 'Objective: -0.04415871511029184', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.9922', 'Train LL: -0.018151592353845395', 'Test LL: -0.027863430316148033', 'Epoch Time (s): 169.46652883430943')
('Epoch 89', 'Objective: -0.044050247702065365', 'Train Acc: 0.99395', 'Test Acc: 0.9912', 'Train LL: -0.01800820217339213', 'Test LL: -0.02944152344297255', 'Epoch Time (s): 169.4226219812408')
('Epoch 90', 'Objective: -0.04383181585493359', 'Train Acc: 0.99435', 'Test Acc: 0.9918', 'Train LL: -0.017865655251092377', 'Test LL: -0.028204945440799996', 'Epoch Time (s): 169.43663581321016')
('Epoch 91', 'Objective: -0.043437406863517374', 'Train Acc: 0.9944166666666666', 'Test Acc: 0.9915', 'Train LL: -0.017445437246287433', 'Test LL: -0.02887526635413915', 'Epoch Time (s): 169.41568480012938')
('Epoch 92', 'Objective: -0.04389796901386719', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9914', 'Train LL: -0.01788205310087585', 'Test LL: -0.029009327622978903', 'Epoch Time (s): 169.45277270721272')
('Epoch 93', 'Objective: -0.04340605077034491', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9915', 'Train LL: -0.0174640822709063', 'Test LL: -0.028522677417349727', 'Epoch Time (s): 169.4493050207384')
('Epoch 94', 'Objective: -0.0440120372232183', 'Train Acc: 0.9942', 'Test Acc: 0.9917', 'Train LL: -0.017961836042524517', 'Test LL: -0.02823461564772823', 'Epoch Time (s): 169.4428283139132')
('Epoch 95', 'Objective: -0.043522124476936215', 'Train Acc: 0.9945666666666667', 'Test Acc: 0.9914', 'Train LL: -0.017557857625903724', 'Test LL: -0.028455006953263334', 'Epoch Time (s): 169.4650996592827')
('Epoch 96', 'Objective: -0.04422224412963173', 'Train Acc: 0.9942', 'Test Acc: 0.9917', 'Train LL: -0.018193958597802633', 'Test LL: -0.02818374199932128', 'Epoch Time (s): 169.44689350528643')
('Epoch 97', 'Objective: -0.043477894105683486', 'Train Acc: 0.9943', 'Test Acc: 0.9914', 'Train LL: -0.017529894651650415', 'Test LL: -0.028592451018945746', 'Epoch Time (s): 169.51728554582223')
('Epoch 98', 'Objective: -0.04320956177783439', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9916', 'Train LL: -0.017268434086684464', 'Test LL: -0.028902498708368803', 'Epoch Time (s): 169.4237143448554')
('Epoch 99', 'Objective: -0.04369700881744653', 'Train Acc: 0.99435', 'Test Acc: 0.9914', 'Train LL: -0.017720233740384863', 'Test LL: -0.028656871482686485', 'Epoch Time (s): 169.4441766999662')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.043380242850825305
Final Train Accuracy: £0.9945166666666667
Final Train LL: £-0.01743261195687237
Final Test Accuracy: £0.9914
Final Test LL: £-0.02872507015108526
