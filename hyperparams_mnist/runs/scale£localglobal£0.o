dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: local
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2937218963828614', 'Train Acc: 0.5524', 'Test Acc: 0.7939', 'Train LL: -1.2404915320995449', 'Test LL: -0.6379691506042966', 'Epoch Time (s): 162.81992118689232')
('Epoch 1', 'Objective: -0.5222670381681686', 'Train Acc: 0.8418666666666667', 'Test Acc: 0.911', 'Train LL: -0.4698817517313454', 'Test LL: -0.28907105119270826', 'Epoch Time (s): 162.96114810998552')
('Epoch 2', 'Objective: -0.30739564881607984', 'Train Acc: 0.91925', 'Test Acc: 0.9355', 'Train LL: -0.25738758001462203', 'Test LL: -0.20086240196706093', 'Epoch Time (s): 162.88532926491462')
('Epoch 3', 'Objective: -0.24461998662490056', 'Train Acc: 0.9392333333333334', 'Test Acc: 0.9243', 'Train LL: -0.19871342414761736', 'Test LL: -0.2565486463885365', 'Epoch Time (s): 162.944661692949')
('Epoch 4', 'Objective: -0.20931313434073884', 'Train Acc: 0.9482333333333334', 'Test Acc: 0.9512', 'Train LL: -0.16519967452562237', 'Test LL: -0.15608650815719466', 'Epoch Time (s): 162.9164927760139')
('Epoch 5', 'Objective: -0.1919329232539158', 'Train Acc: 0.9543', 'Test Acc: 0.9641', 'Train LL: -0.1494965711649115', 'Test LL: -0.11297547398333409', 'Epoch Time (s): 162.93105147895403')
('Epoch 6', 'Objective: -0.17370472613621496', 'Train Acc: 0.9584', 'Test Acc: 0.9635', 'Train LL: -0.13301741242767412', 'Test LL: -0.11159540180869931', 'Epoch Time (s): 162.94017720897682')
('Epoch 7', 'Objective: -0.16339481153609658', 'Train Acc: 0.9607333333333333', 'Test Acc: 0.9714', 'Train LL: -0.12354593525386151', 'Test LL: -0.09144884266918886', 'Epoch Time (s): 162.9014031321276')
('Epoch 8', 'Objective: -0.1522767714915974', 'Train Acc: 0.9641333333333333', 'Test Acc: 0.9696', 'Train LL: -0.11332793689919132', 'Test LL: -0.09407496795987884', 'Epoch Time (s): 162.9678274160251')
('Epoch 9', 'Objective: -0.14649512522046265', 'Train Acc: 0.9660333333333333', 'Test Acc: 0.9708', 'Train LL: -0.10814505467002852', 'Test LL: -0.08964548588683545', 'Epoch Time (s): 163.0030706760008')
('Epoch 10', 'Objective: -0.13937954807255193', 'Train Acc: 0.9676166666666667', 'Test Acc: 0.9566', 'Train LL: -0.10161395134113199', 'Test LL: -0.12770795994508807', 'Epoch Time (s): 163.01405463786796')
('Epoch 11', 'Objective: -0.13222553024097797', 'Train Acc: 0.97015', 'Test Acc: 0.9759', 'Train LL: -0.09489062842844496', 'Test LL: -0.07935956194864766', 'Epoch Time (s): 162.95114893000573')
('Epoch 12', 'Objective: -0.12684890071975818', 'Train Acc: 0.9713833333333334', 'Test Acc: 0.9778', 'Train LL: -0.09061595880734179', 'Test LL: -0.06947485505560326', 'Epoch Time (s): 162.95854010619223')
('Epoch 13', 'Objective: -0.12229396705347315', 'Train Acc: 0.9725833333333334', 'Test Acc: 0.9733', 'Train LL: -0.08653630582384526', 'Test LL: -0.07894218012210022', 'Epoch Time (s): 163.06010340503417')
('Epoch 14', 'Objective: -0.12037751963074766', 'Train Acc: 0.97275', 'Test Acc: 0.9685', 'Train LL: -0.08487688545097281', 'Test LL: -0.10171103006241444', 'Epoch Time (s): 163.01891286112368')
('Epoch 15', 'Objective: -0.1159204395352692', 'Train Acc: 0.9744', 'Test Acc: 0.9739', 'Train LL: -0.08090166856726022', 'Test LL: -0.07973284524610977', 'Epoch Time (s): 162.98577682906762')
('Epoch 16', 'Objective: -0.11368251364500516', 'Train Acc: 0.9750666666666666', 'Test Acc: 0.9819', 'Train LL: -0.07920366844422615', 'Test LL: -0.05734169242574467', 'Epoch Time (s): 163.02840292197652')
('Epoch 17', 'Objective: -0.1097659494718407', 'Train Acc: 0.97595', 'Test Acc: 0.9841', 'Train LL: -0.07565977253398358', 'Test LL: -0.05237712194390324', 'Epoch Time (s): 162.9624086660333')
('Epoch 18', 'Objective: -0.1080246543426521', 'Train Acc: 0.97655', 'Test Acc: 0.9779', 'Train LL: -0.07439319111619137', 'Test LL: -0.06537004968932801', 'Epoch Time (s): 162.9854210098274')
('Epoch 19', 'Objective: -0.1063137712620267', 'Train Acc: 0.9762666666666666', 'Test Acc: 0.9634', 'Train LL: -0.07301882628288352', 'Test LL: -0.10474708849809972', 'Epoch Time (s): 162.93537738313898')
('Epoch 20', 'Objective: -0.10189441156209822', 'Train Acc: 0.9782666666666666', 'Test Acc: 0.9779', 'Train LL: -0.06922445114595065', 'Test LL: -0.06872461769428502', 'Epoch Time (s): 162.89188709598966')
('Epoch 21', 'Objective: -0.10024103322733742', 'Train Acc: 0.9780166666666666', 'Test Acc: 0.9809', 'Train LL: -0.06795340936350076', 'Test LL: -0.05771184275703581', 'Epoch Time (s): 162.8980559699703')
('Epoch 22', 'Objective: -0.09869370831160486', 'Train Acc: 0.9782666666666666', 'Test Acc: 0.9763', 'Train LL: -0.06674653096361302', 'Test LL: -0.07718991922565423', 'Epoch Time (s): 162.91840942506678')
('Epoch 23', 'Objective: -0.09855426465780202', 'Train Acc: 0.9787166666666667', 'Test Acc: 0.9766', 'Train LL: -0.06671700749309334', 'Test LL: -0.06769002409736084', 'Epoch Time (s): 162.9242474399507')
('Epoch 24', 'Objective: -0.09639078656310225', 'Train Acc: 0.9788833333333333', 'Test Acc: 0.9785', 'Train LL: -0.0646602299629509', 'Test LL: -0.06426495252606701', 'Epoch Time (s): 162.98833826906048')
('Epoch 25', 'Objective: -0.09443810195410603', 'Train Acc: 0.9802666666666666', 'Test Acc: 0.9815', 'Train LL: -0.06317143255166192', 'Test LL: -0.05774990220116407', 'Epoch Time (s): 162.9511099869851')
('Epoch 26', 'Objective: -0.09428572917006377', 'Train Acc: 0.9800333333333333', 'Test Acc: 0.9839', 'Train LL: -0.06329702727891647', 'Test LL: -0.05130946315577828', 'Epoch Time (s): 162.9556788909249')
('Epoch 27', 'Objective: -0.09148585263193285', 'Train Acc: 0.9806', 'Test Acc: 0.9848', 'Train LL: -0.06100739151268882', 'Test LL: -0.04891272503229526', 'Epoch Time (s): 162.9305013869889')
('Epoch 28', 'Objective: -0.0920062932346772', 'Train Acc: 0.9801833333333333', 'Test Acc: 0.982', 'Train LL: -0.06176646426656913', 'Test LL: -0.05788664167059292', 'Epoch Time (s): 162.97309525683522')
('Epoch 29', 'Objective: -0.08968037467661488', 'Train Acc: 0.98105', 'Test Acc: 0.979', 'Train LL: -0.059744984276752816', 'Test LL: -0.06537594569334931', 'Epoch Time (s): 162.99756820104085')
('Epoch 30', 'Objective: -0.08981304460559457', 'Train Acc: 0.9813333333333333', 'Test Acc: 0.9833', 'Train LL: -0.060308633110484317', 'Test LL: -0.05343751999179948', 'Epoch Time (s): 162.92407698603347')
('Epoch 31', 'Objective: -0.08599239233770237', 'Train Acc: 0.9816166666666667', 'Test Acc: 0.9787', 'Train LL: -0.05665229231118334', 'Test LL: -0.06561816512625898', 'Epoch Time (s): 162.92975113494322')
('Epoch 32', 'Objective: -0.08720173611857213', 'Train Acc: 0.98115', 'Test Acc: 0.9832', 'Train LL: -0.058146148872153504', 'Test LL: -0.05318528307677036', 'Epoch Time (s): 162.94054209184833')
('Epoch 33', 'Objective: -0.08552896411561949', 'Train Acc: 0.9819833333333333', 'Test Acc: 0.9836', 'Train LL: -0.0568608478144672', 'Test LL: -0.05614801045562137', 'Epoch Time (s): 162.97705155285075')
('Epoch 34', 'Objective: -0.08456760967604134', 'Train Acc: 0.9823', 'Test Acc: 0.9849', 'Train LL: -0.05605626995046131', 'Test LL: -0.04822865083392498', 'Epoch Time (s): 162.9561482530553')
('Epoch 35', 'Objective: -0.08346667082309447', 'Train Acc: 0.9826166666666667', 'Test Acc: 0.9757', 'Train LL: -0.05519585783098279', 'Test LL: -0.07131130778682987', 'Epoch Time (s): 162.95030900789425')
('Epoch 36', 'Objective: -0.08210615824070451', 'Train Acc: 0.9828666666666667', 'Test Acc: 0.9846', 'Train LL: -0.054072944962771645', 'Test LL: -0.04968421967047433', 'Epoch Time (s): 162.97193311201409')
('Epoch 37', 'Objective: -0.08227367154223131', 'Train Acc: 0.98265', 'Test Acc: 0.9772', 'Train LL: -0.05435653023549532', 'Test LL: -0.07027737414218857', 'Epoch Time (s): 162.9758568929974')
('Epoch 38', 'Objective: -0.08147275656488526', 'Train Acc: 0.98295', 'Test Acc: 0.9894', 'Train LL: -0.05369851450501262', 'Test LL: -0.03204699390566394', 'Epoch Time (s): 163.00106907705776')
('Epoch 39', 'Objective: -0.07876343897152546', 'Train Acc: 0.98375', 'Test Acc: 0.9809', 'Train LL: -0.05144766425620884', 'Test LL: -0.05922374451423239', 'Epoch Time (s): 163.00899835000746')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.05951946524574528', 'Train Acc: 0.98945', 'Test Acc: 0.9912', 'Train LL: -0.033723792482561084', 'Test LL: -0.029405300715189736', 'Epoch Time (s): 162.99503212887794')
('Epoch 41', 'Objective: -0.05366983954356136', 'Train Acc: 0.9906', 'Test Acc: 0.9903', 'Train LL: -0.02901344086177439', 'Test LL: -0.028590294022424946', 'Epoch Time (s): 162.9405658170581')
('Epoch 42', 'Objective: -0.051424618298025505', 'Train Acc: 0.99135', 'Test Acc: 0.9903', 'Train LL: -0.02718300079131783', 'Test LL: -0.029792623189235947', 'Epoch Time (s): 162.99557103798725')
('Epoch 43', 'Objective: -0.05078562893508566', 'Train Acc: 0.99165', 'Test Acc: 0.9905', 'Train LL: -0.026737044032729418', 'Test LL: -0.02896543550531303', 'Epoch Time (s): 162.98140288493596')
('Epoch 44', 'Objective: -0.05009918808776753', 'Train Acc: 0.9915833333333334', 'Test Acc: 0.9903', 'Train LL: -0.02623683241364224', 'Test LL: -0.027928962488398202', 'Epoch Time (s): 162.99379806197248')
('Epoch 45', 'Objective: -0.048131330202659924', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9901', 'Train LL: -0.024589624409873567', 'Test LL: -0.028644578720281602', 'Epoch Time (s): 162.92920253705233')
('Epoch 46', 'Objective: -0.04813124203928145', 'Train Acc: 0.9918833333333333', 'Test Acc: 0.9904', 'Train LL: -0.024724353184188693', 'Test LL: -0.03110309517981013', 'Epoch Time (s): 162.92995058000088')
('Epoch 47', 'Objective: -0.04829646061613335', 'Train Acc: 0.9922', 'Test Acc: 0.9902', 'Train LL: -0.024990459868754405', 'Test LL: -0.03053331496026375', 'Epoch Time (s): 162.97774855489843')
('Epoch 48', 'Objective: -0.04762722475121605', 'Train Acc: 0.9919833333333333', 'Test Acc: 0.9905', 'Train LL: -0.02448438080022515', 'Test LL: -0.027637393524179096', 'Epoch Time (s): 162.95641746395268')
('Epoch 49', 'Objective: -0.047116037264338405', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9895', 'Train LL: -0.02414194884081666', 'Test LL: -0.03185827381292774', 'Epoch Time (s): 162.96319521497935')
('Epoch 50', 'Objective: -0.04745595841934249', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9916', 'Train LL: -0.024597191374599623', 'Test LL: -0.026723137689110422', 'Epoch Time (s): 163.0053275572136')
('Epoch 51', 'Objective: -0.04590736613630857', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9904', 'Train LL: -0.023190411546197817', 'Test LL: -0.029942673979356273', 'Epoch Time (s): 162.99849613010883')
('Epoch 52', 'Objective: -0.04614605542642643', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9906', 'Train LL: -0.023429024514598842', 'Test LL: -0.02798167836404436', 'Epoch Time (s): 162.95997228310443')
('Epoch 53', 'Objective: -0.045052890969940626', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9919', 'Train LL: -0.022632090746367975', 'Test LL: -0.025505164203096523', 'Epoch Time (s): 162.9433532699477')
('Epoch 54', 'Objective: -0.0454236896376064', 'Train Acc: 0.99245', 'Test Acc: 0.9913', 'Train LL: -0.023052972405532588', 'Test LL: -0.027668536614709298', 'Epoch Time (s): 162.95118191489018')
('Epoch 55', 'Objective: -0.04409974033051582', 'Train Acc: 0.99305', 'Test Acc: 0.9908', 'Train LL: -0.021773015394265568', 'Test LL: -0.02807969688939911', 'Epoch Time (s): 162.97308210493065')
('Epoch 56', 'Objective: -0.04439406553987399', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9907', 'Train LL: -0.022181105569752658', 'Test LL: -0.02884384638029373', 'Epoch Time (s): 162.9395525411237')
('Epoch 57', 'Objective: -0.04423098353063926', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9903', 'Train LL: -0.022068024456691433', 'Test LL: -0.029115268788022303', 'Epoch Time (s): 162.99447607109323')
('Epoch 58', 'Objective: -0.0442143931113211', 'Train Acc: 0.99295', 'Test Acc: 0.9909', 'Train LL: -0.022158997855616723', 'Test LL: -0.028893244286881666', 'Epoch Time (s): 162.9855061660055')
('Epoch 59', 'Objective: -0.04405582236326192', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9913', 'Train LL: -0.022017748069524435', 'Test LL: -0.027626948431966263', 'Epoch Time (s): 163.01257101190276')
('Epoch 60', 'Objective: -0.044538385536564064', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9901', 'Train LL: -0.022665541142880868', 'Test LL: -0.029598969536664015', 'Epoch Time (s): 162.98799848090857')
('Epoch 61', 'Objective: -0.0435648118189177', 'Train Acc: 0.9929833333333333', 'Test Acc: 0.9908', 'Train LL: -0.021734743359590893', 'Test LL: -0.0273923327373291', 'Epoch Time (s): 162.9990486369934')
('Epoch 62', 'Objective: -0.043633965802458055', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9906', 'Train LL: -0.021827767831291665', 'Test LL: -0.029396220771049114', 'Epoch Time (s): 162.97863587201573')
('Epoch 63', 'Objective: -0.04322831434782949', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9902', 'Train LL: -0.02155048387311721', 'Test LL: -0.02985713945136737', 'Epoch Time (s): 162.97926597716287')
('Epoch 64', 'Objective: -0.04230683358860178', 'Train Acc: 0.99315', 'Test Acc: 0.9911', 'Train LL: -0.020675418029518007', 'Test LL: -0.026816893728687837', 'Epoch Time (s): 162.945315470919')
('Epoch 65', 'Objective: -0.043563499016972554', 'Train Acc: 0.9926333333333334', 'Test Acc: 0.9917', 'Train LL: -0.021917511357313298', 'Test LL: -0.02464552375101158', 'Epoch Time (s): 162.9977804410737')
('Epoch 66', 'Objective: -0.04341254346941582', 'Train Acc: 0.9927', 'Test Acc: 0.9909', 'Train LL: -0.021791579027305524', 'Test LL: -0.0291001397832395', 'Epoch Time (s): 162.98297774815')
('Epoch 67', 'Objective: -0.042744430130729906', 'Train Acc: 0.9931', 'Test Acc: 0.9904', 'Train LL: -0.021252077815139412', 'Test LL: -0.028581257611453113', 'Epoch Time (s): 162.97131095500663')
('Epoch 68', 'Objective: -0.04235925219163428', 'Train Acc: 0.9930333333333333', 'Test Acc: 0.9915', 'Train LL: -0.02097280215460561', 'Test LL: -0.02643813778851561', 'Epoch Time (s): 162.98053455608897')
('Epoch 69', 'Objective: -0.04191099590646643', 'Train Acc: 0.99335', 'Test Acc: 0.992', 'Train LL: -0.02053077597326429', 'Test LL: -0.026071982545777736', 'Epoch Time (s): 163.01618735003285')
('Epoch 70', 'Objective: -0.041697437599007514', 'Train Acc: 0.9937166666666667', 'Test Acc: 0.9909', 'Train LL: -0.02044605027743528', 'Test LL: -0.02789621361100078', 'Epoch Time (s): 162.97848088783212')
('Epoch 71', 'Objective: -0.042691163161633544', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9901', 'Train LL: -0.02141723766992547', 'Test LL: -0.030274704113805388', 'Epoch Time (s): 162.94627602701075')
('Epoch 72', 'Objective: -0.04093560574356146', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.9898', 'Train LL: -0.019880116000589615', 'Test LL: -0.03461178232730429', 'Epoch Time (s): 162.95383295905776')
('Epoch 73', 'Objective: -0.041277750607395504', 'Train Acc: 0.9936166666666667', 'Test Acc: 0.9904', 'Train LL: -0.0201267989048364', 'Test LL: -0.030650099850848038', 'Epoch Time (s): 162.96231020987034')
('Epoch 74', 'Objective: -0.04127967733951293', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.991', 'Train LL: -0.020209502166897392', 'Test LL: -0.029040290629731378', 'Epoch Time (s): 162.96263210405596')
('Epoch 75', 'Objective: -0.04127131190843448', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9916', 'Train LL: -0.02017352297170033', 'Test LL: -0.02677236595047222', 'Epoch Time (s): 162.94166721310467')
('Epoch 76', 'Objective: -0.04111099979654029', 'Train Acc: 0.9934666666666667', 'Test Acc: 0.991', 'Train LL: -0.020051264306164218', 'Test LL: -0.028626341082512285', 'Epoch Time (s): 162.96706482511945')
('Epoch 77', 'Objective: -0.04124056415506653', 'Train Acc: 0.9933', 'Test Acc: 0.9898', 'Train LL: -0.02019095428117812', 'Test LL: -0.03193296033657712', 'Epoch Time (s): 162.96858891216107')
('Epoch 78', 'Objective: -0.041197682314411545', 'Train Acc: 0.9936833333333334', 'Test Acc: 0.9917', 'Train LL: -0.020229745414793793', 'Test LL: -0.027122553846259955', 'Epoch Time (s): 162.99493894795887')
('Epoch 79', 'Objective: -0.04120778353591149', 'Train Acc: 0.9935166666666667', 'Test Acc: 0.9912', 'Train LL: -0.020328941095108233', 'Test LL: -0.02772571535746781', 'Epoch Time (s): 163.02430593711324')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.03819777551096655', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9914', 'Train LL: -0.01762294344904187', 'Test LL: -0.028220516678728994', 'Epoch Time (s): 162.96259025484324')
('Epoch 81', 'Objective: -0.03694237966411415', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9909', 'Train LL: -0.016450756070099614', 'Test LL: -0.02838164055507122', 'Epoch Time (s): 162.99010635679588')
('Epoch 82', 'Objective: -0.03690119717228937', 'Train Acc: 0.9948', 'Test Acc: 0.9911', 'Train LL: -0.016359999063707508', 'Test LL: -0.027816699778729016', 'Epoch Time (s): 162.9891570881009')
('Epoch 83', 'Objective: -0.03731923107313192', 'Train Acc: 0.9947666666666667', 'Test Acc: 0.9911', 'Train LL: -0.01674898093397895', 'Test LL: -0.02764647057131973', 'Epoch Time (s): 163.0184295780491')
('Epoch 84', 'Objective: -0.03647870268195016', 'Train Acc: 0.99495', 'Test Acc: 0.9909', 'Train LL: -0.015967971437370873', 'Test LL: -0.029357464618907297', 'Epoch Time (s): 163.02414237800986')
('Epoch 85', 'Objective: -0.0367863133332296', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.991', 'Train LL: -0.016246774540141107', 'Test LL: -0.028490755034442008', 'Epoch Time (s): 162.9830057839863')
('Epoch 86', 'Objective: -0.03633064757575774', 'Train Acc: 0.9948833333333333', 'Test Acc: 0.9908', 'Train LL: -0.015816809531489652', 'Test LL: -0.029055794638623685', 'Epoch Time (s): 163.0109513301868')
('Epoch 87', 'Objective: -0.036597336286257054', 'Train Acc: 0.99515', 'Test Acc: 0.9912', 'Train LL: -0.016054089814431405', 'Test LL: -0.028006006723950587', 'Epoch Time (s): 162.96826917678118')
('Epoch 88', 'Objective: -0.03651765470277098', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9911', 'Train LL: -0.01600937015962913', 'Test LL: -0.028367843146496603', 'Epoch Time (s): 162.9678374400828')
('Epoch 89', 'Objective: -0.03656583962529912', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9911', 'Train LL: -0.016018761769992243', 'Test LL: -0.02833502998887891', 'Epoch Time (s): 162.96354238898493')
('Epoch 90', 'Objective: -0.03741131029462418', 'Train Acc: 0.9946166666666667', 'Test Acc: 0.991', 'Train LL: -0.01679383681398762', 'Test LL: -0.02726963251446214', 'Epoch Time (s): 162.98194543784484')
('Epoch 91', 'Objective: -0.036504676989687485', 'Train Acc: 0.9948', 'Test Acc: 0.9909', 'Train LL: -0.01598810604921026', 'Test LL: -0.027873139649990913', 'Epoch Time (s): 162.98446236597374')
('Epoch 92', 'Objective: -0.036112332746655325', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.9906', 'Train LL: -0.01563402199818922', 'Test LL: -0.02901775282116663', 'Epoch Time (s): 162.93145567690954')
('Epoch 93', 'Objective: -0.03633402627220863', 'Train Acc: 0.99515', 'Test Acc: 0.9904', 'Train LL: -0.01586389763726925', 'Test LL: -0.02873442971352151', 'Epoch Time (s): 162.9897291290108')
('Epoch 94', 'Objective: -0.03610469494195228', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9911', 'Train LL: -0.015620438091461785', 'Test LL: -0.028650301956278993', 'Epoch Time (s): 162.94747095997445')
('Epoch 95', 'Objective: -0.03618845551976623', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.9909', 'Train LL: -0.01568797988135819', 'Test LL: -0.028414137778823585', 'Epoch Time (s): 162.97809906606562')
('Epoch 96', 'Objective: -0.03548654566672103', 'Train Acc: 0.9953', 'Test Acc: 0.9906', 'Train LL: -0.01507383505254663', 'Test LL: -0.0298095986807038', 'Epoch Time (s): 162.98375556990504')
('Epoch 97', 'Objective: -0.035657451029444315', 'Train Acc: 0.9951166666666666', 'Test Acc: 0.9908', 'Train LL: -0.015183653470425558', 'Test LL: -0.02866730474756464', 'Epoch Time (s): 162.97926239692606')
('Epoch 98', 'Objective: -0.03611320716597927', 'Train Acc: 0.9954', 'Test Acc: 0.9913', 'Train LL: -0.01564608614608468', 'Test LL: -0.02734903968824089', 'Epoch Time (s): 162.98686641198583')
('Epoch 99', 'Objective: -0.03615951987202839', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9914', 'Train LL: -0.01565079420321191', 'Test LL: -0.02727784317464931', 'Epoch Time (s): 162.97095064609312')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03565173340462821
Final Train Accuracy: £0.9950833333333333
Final Train LL: £-0.01520216794911033
Final Test Accuracy: £0.9915
Final Test LL: £-0.02713348209675046
