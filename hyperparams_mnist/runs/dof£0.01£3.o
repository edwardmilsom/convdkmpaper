dataset: MNIST
dtype: float64
dof: 0.01
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2560569332444358', 'Train Acc: 0.5633833333333333', 'Test Acc: 0.7916', 'Train LL: -1.2214505511017106', 'Test LL: -0.6079657607091357', 'Epoch Time (s): 164.65177031001076')
('Epoch 1', 'Objective: -0.46305334954054245', 'Train Acc: 0.8487', 'Test Acc: 0.8403', 'Train LL: -0.4433017069509372', 'Test LL: -0.4703747098349666', 'Epoch Time (s): 164.7487010001205')
('Epoch 2', 'Objective: -0.24888842158133073', 'Train Acc: 0.9250666666666667', 'Test Acc: 0.9431', 'Train LL: -0.23257237475740458', 'Test LL: -0.18533761581255548', 'Epoch Time (s): 164.74862721003592')
('Epoch 3', 'Objective: -0.1896294941489405', 'Train Acc: 0.9451833333333334', 'Test Acc: 0.9669', 'Train LL: -0.17544153738207355', 'Test LL: -0.10849518221099906', 'Epoch Time (s): 164.74699459900148')
('Epoch 4', 'Objective: -0.15448035986924535', 'Train Acc: 0.9560333333333333', 'Test Acc: 0.9649', 'Train LL: -0.14153924763839312', 'Test LL: -0.11812247825106849', 'Epoch Time (s): 164.77727677905932')
('Epoch 5', 'Objective: -0.13545005179993438', 'Train Acc: 0.96195', 'Test Acc: 0.9534', 'Train LL: -0.12343928320630307', 'Test LL: -0.1413122721433633', 'Epoch Time (s): 164.7053567210678')
('Epoch 6', 'Objective: -0.12286525280971991', 'Train Acc: 0.9647666666666667', 'Test Acc: 0.966', 'Train LL: -0.11138333790773434', 'Test LL: -0.10704828658513124', 'Epoch Time (s): 164.72204490588047')
('Epoch 7', 'Objective: -0.11259254307466278', 'Train Acc: 0.968', 'Test Acc: 0.9749', 'Train LL: -0.10172842131091957', 'Test LL: -0.07354884087512015', 'Epoch Time (s): 164.28034178493544')
('Epoch 8', 'Objective: -0.10345671035266056', 'Train Acc: 0.9705', 'Test Acc: 0.9609', 'Train LL: -0.09309569532511575', 'Test LL: -0.1133993633140359', 'Epoch Time (s): 164.7710918840021')
('Epoch 9', 'Objective: -0.09666131353877208', 'Train Acc: 0.9725833333333334', 'Test Acc: 0.9558', 'Train LL: -0.0865420589490792', 'Test LL: -0.13038413606910693', 'Epoch Time (s): 164.76587189780548')
('Epoch 10', 'Objective: -0.0937794611610989', 'Train Acc: 0.9738333333333333', 'Test Acc: 0.9785', 'Train LL: -0.0841153038788366', 'Test LL: -0.06314677080812464', 'Epoch Time (s): 164.71523631713353')
('Epoch 11', 'Objective: -0.08800426135732034', 'Train Acc: 0.97485', 'Test Acc: 0.9738', 'Train LL: -0.0786761460949124', 'Test LL: -0.07921802409768622', 'Epoch Time (s): 164.75570210418664')
('Epoch 12', 'Objective: -0.0825739689876305', 'Train Acc: 0.97695', 'Test Acc: 0.979', 'Train LL: -0.07347797805391212', 'Test LL: -0.06335861676908755', 'Epoch Time (s): 164.81854765396565')
('Epoch 13', 'Objective: -0.08177155135234807', 'Train Acc: 0.97685', 'Test Acc: 0.9786', 'Train LL: -0.07285620561304683', 'Test LL: -0.06722596996503673', 'Epoch Time (s): 164.79750553099439')
('Epoch 14', 'Objective: -0.07804380880899829', 'Train Acc: 0.9783333333333334', 'Test Acc: 0.981', 'Train LL: -0.06938768913376278', 'Test LL: -0.0657677188611624', 'Epoch Time (s): 164.71424726606347')
('Epoch 15', 'Objective: -0.07579596729429468', 'Train Acc: 0.9785833333333334', 'Test Acc: 0.9765', 'Train LL: -0.06726807752709535', 'Test LL: -0.07375145760405391', 'Epoch Time (s): 164.73992376192473')
('Epoch 16', 'Objective: -0.07526981383303964', 'Train Acc: 0.9785', 'Test Acc: 0.981', 'Train LL: -0.06687672960124419', 'Test LL: -0.06252914515721553', 'Epoch Time (s): 164.8695529650431')
('Epoch 17', 'Objective: -0.07219475511883752', 'Train Acc: 0.9796666666666667', 'Test Acc: 0.9801', 'Train LL: -0.0640433217086671', 'Test LL: -0.05670264230668556', 'Epoch Time (s): 164.6105177870486')
('Epoch 18', 'Objective: -0.07094314155619483', 'Train Acc: 0.9796', 'Test Acc: 0.9827', 'Train LL: -0.06296600839483331', 'Test LL: -0.049823563927179196', 'Epoch Time (s): 164.68590448307805')
('Epoch 19', 'Objective: -0.06871037246685986', 'Train Acc: 0.9806333333333334', 'Test Acc: 0.9798', 'Train LL: -0.06093708088462661', 'Test LL: -0.05852764726170011', 'Epoch Time (s): 164.6360374749638')
('Epoch 20', 'Objective: -0.06640054206917592', 'Train Acc: 0.98095', 'Test Acc: 0.9799', 'Train LL: -0.058726344601877645', 'Test LL: -0.06021636221233366', 'Epoch Time (s): 164.64551728894003')
('Epoch 21', 'Objective: -0.06418372278786544', 'Train Acc: 0.9818666666666667', 'Test Acc: 0.9841', 'Train LL: -0.05670256003240229', 'Test LL: -0.04908176294118957', 'Epoch Time (s): 164.64332483010367')
('Epoch 22', 'Objective: -0.06335696332979086', 'Train Acc: 0.9824666666666667', 'Test Acc: 0.9864', 'Train LL: -0.056010124827679364', 'Test LL: -0.040330017942585825', 'Epoch Time (s): 164.46234009088948')
('Epoch 23', 'Objective: -0.06160462616406957', 'Train Acc: 0.9827833333333333', 'Test Acc: 0.984', 'Train LL: -0.05442215891663298', 'Test LL: -0.05267250364453447', 'Epoch Time (s): 164.4322422768455')
('Epoch 24', 'Objective: -0.06108205711016404', 'Train Acc: 0.9827666666666667', 'Test Acc: 0.9878', 'Train LL: -0.053957356487617375', 'Test LL: -0.04166065735127477', 'Epoch Time (s): 164.43199143582024')
('Epoch 25', 'Objective: -0.0584400076676934', 'Train Acc: 0.9833833333333334', 'Test Acc: 0.9846', 'Train LL: -0.0514328774962406', 'Test LL: -0.04893824765129511', 'Epoch Time (s): 164.43540253886022')
('Epoch 26', 'Objective: -0.058394249969927176', 'Train Acc: 0.9836', 'Test Acc: 0.9866', 'Train LL: -0.05144931094758851', 'Test LL: -0.040452328507147535', 'Epoch Time (s): 164.41777789988555')
('Epoch 27', 'Objective: -0.058460248763100804', 'Train Acc: 0.9829833333333333', 'Test Acc: 0.9843', 'Train LL: -0.051750902368574166', 'Test LL: -0.04886919462697289', 'Epoch Time (s): 164.44731459696777')
('Epoch 28', 'Objective: -0.05543491202292958', 'Train Acc: 0.9838333333333333', 'Test Acc: 0.9809', 'Train LL: -0.04868205126323482', 'Test LL: -0.058120402441309296', 'Epoch Time (s): 164.43164303479716')
('Epoch 29', 'Objective: -0.055914183902435285', 'Train Acc: 0.9842833333333333', 'Test Acc: 0.9797', 'Train LL: -0.04929403100419195', 'Test LL: -0.0644343301008155', 'Epoch Time (s): 164.45884920307435')
('Epoch 30', 'Objective: -0.05410009107499607', 'Train Acc: 0.9842666666666666', 'Test Acc: 0.9892', 'Train LL: -0.047620488815958095', 'Test LL: -0.03675567414040856', 'Epoch Time (s): 164.48155379784293')
('Epoch 31', 'Objective: -0.05413875002585839', 'Train Acc: 0.9848666666666667', 'Test Acc: 0.9886', 'Train LL: -0.047689747137834713', 'Test LL: -0.03620234640152974', 'Epoch Time (s): 164.48390665603802')
('Epoch 32', 'Objective: -0.05436528111502573', 'Train Acc: 0.9845166666666667', 'Test Acc: 0.9878', 'Train LL: -0.048037108444450936', 'Test LL: -0.03621043193289899', 'Epoch Time (s): 164.4785833179485')
('Epoch 33', 'Objective: -0.05236718041303839', 'Train Acc: 0.98545', 'Test Acc: 0.9857', 'Train LL: -0.046179659865825694', 'Test LL: -0.04292522595467559', 'Epoch Time (s): 164.4929318469949')
('Epoch 34', 'Objective: -0.053094555859456195', 'Train Acc: 0.9849333333333333', 'Test Acc: 0.9875', 'Train LL: -0.046855563667424355', 'Test LL: -0.038363612152340076', 'Epoch Time (s): 164.44855311117135')
('Epoch 35', 'Objective: -0.051617044749650454', 'Train Acc: 0.9853833333333334', 'Test Acc: 0.9857', 'Train LL: -0.045472906209760564', 'Test LL: -0.043920665935842804', 'Epoch Time (s): 164.20338164200075')
('Epoch 36', 'Objective: -0.050841486156138545', 'Train Acc: 0.9860666666666666', 'Test Acc: 0.9879', 'Train LL: -0.04476852347017071', 'Test LL: -0.037771338360276636', 'Epoch Time (s): 164.26725759007968')
('Epoch 37', 'Objective: -0.049785956196805974', 'Train Acc: 0.9858333333333333', 'Test Acc: 0.986', 'Train LL: -0.04377429341720911', 'Test LL: -0.042901086689496756', 'Epoch Time (s): 164.56575026200153')
('Epoch 38', 'Objective: -0.04839832643359405', 'Train Acc: 0.9861833333333333', 'Test Acc: 0.9848', 'Train LL: -0.04248748800314568', 'Test LL: -0.046078326270820966', 'Epoch Time (s): 164.34255067794584')
('Epoch 39', 'Objective: -0.048408440141655865', 'Train Acc: 0.9865333333333334', 'Test Acc: 0.9873', 'Train LL: -0.04254946205805755', 'Test LL: -0.039578992868113554', 'Epoch Time (s): 164.6098050510045')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.030989983126619935', 'Train Acc: 0.9918833333333333', 'Test Acc: 0.9909', 'Train LL: -0.025667081106268492', 'Test LL: -0.027611521289794983', 'Epoch Time (s): 164.55753489793278')
('Epoch 41', 'Objective: -0.02552507882095039', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9911', 'Train LL: -0.020553228438495368', 'Test LL: -0.026359447716754306', 'Epoch Time (s): 164.58967731706798')
('Epoch 42', 'Objective: -0.024494613995719377', 'Train Acc: 0.9937666666666667', 'Test Acc: 0.9921', 'Train LL: -0.0197142635857728', 'Test LL: -0.023503597102515202', 'Epoch Time (s): 164.56481814198196')
('Epoch 43', 'Objective: -0.022914707313381775', 'Train Acc: 0.9939166666666667', 'Test Acc: 0.9921', 'Train LL: -0.018260659412792035', 'Test LL: -0.02371340006007548', 'Epoch Time (s): 164.58438232308254')
('Epoch 44', 'Objective: -0.022210061475371287', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9924', 'Train LL: -0.017648296928497786', 'Test LL: -0.022983828680762708', 'Epoch Time (s): 164.52854066505097')
('Epoch 45', 'Objective: -0.021973214861462607', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9918', 'Train LL: -0.017460318170439325', 'Test LL: -0.02504665227142439', 'Epoch Time (s): 164.49704326712526')
('Epoch 46', 'Objective: -0.020952116726006265', 'Train Acc: 0.9947333333333334', 'Test Acc: 0.9915', 'Train LL: -0.016510748553078547', 'Test LL: -0.026404812559242076', 'Epoch Time (s): 164.4276197089348')
('Epoch 47', 'Objective: -0.01991000567230976', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.9909', 'Train LL: -0.015542890651054667', 'Test LL: -0.027207450410813686', 'Epoch Time (s): 164.42056251992472')
('Epoch 48', 'Objective: -0.020184049283158458', 'Train Acc: 0.9949', 'Test Acc: 0.9917', 'Train LL: -0.015815127679856426', 'Test LL: -0.025820025821741404', 'Epoch Time (s): 164.5178626270499')
('Epoch 49', 'Objective: -0.019218051581034557', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.9908', 'Train LL: -0.014944087485789922', 'Test LL: -0.028037136008060362', 'Epoch Time (s): 164.50685831415467')
('Epoch 50', 'Objective: -0.018869577902892603', 'Train Acc: 0.9952', 'Test Acc: 0.993', 'Train LL: -0.014608919361636748', 'Test LL: -0.02240088484220421', 'Epoch Time (s): 164.5150344108697')
('Epoch 51', 'Objective: -0.017942877860729366', 'Train Acc: 0.99535', 'Test Acc: 0.9912', 'Train LL: -0.013730555461981797', 'Test LL: -0.026638967305595167', 'Epoch Time (s): 164.4998470491264')
('Epoch 52', 'Objective: -0.018208983270206883', 'Train Acc: 0.99565', 'Test Acc: 0.9922', 'Train LL: -0.01398245158594772', 'Test LL: -0.025032853814374752', 'Epoch Time (s): 164.60603922698647')
('Epoch 53', 'Objective: -0.01850996401114339', 'Train Acc: 0.9954166666666666', 'Test Acc: 0.9916', 'Train LL: -0.01430846357202643', 'Test LL: -0.02454617321938163', 'Epoch Time (s): 164.43516424810514')
('Epoch 54', 'Objective: -0.01709420000074408', 'Train Acc: 0.9956333333333334', 'Test Acc: 0.9915', 'Train LL: -0.012955079409486153', 'Test LL: -0.025640727664159077', 'Epoch Time (s): 164.49960562679917')
('Epoch 55', 'Objective: -0.017315533393970812', 'Train Acc: 0.99555', 'Test Acc: 0.9897', 'Train LL: -0.013151763607170555', 'Test LL: -0.030409857265105034', 'Epoch Time (s): 164.53252383694053')
('Epoch 56', 'Objective: -0.016687248540698387', 'Train Acc: 0.9960833333333333', 'Test Acc: 0.99', 'Train LL: -0.012549791578075785', 'Test LL: -0.03187645834327635', 'Epoch Time (s): 164.56434426107444')
('Epoch 57', 'Objective: -0.017356878484288612', 'Train Acc: 0.9955166666666667', 'Test Acc: 0.991', 'Train LL: -0.013178238736520718', 'Test LL: -0.02750658670150417', 'Epoch Time (s): 164.47372277989052')
('Epoch 58', 'Objective: -0.015747745290595222', 'Train Acc: 0.9959833333333333', 'Test Acc: 0.992', 'Train LL: -0.011674523862321333', 'Test LL: -0.024828603298621764', 'Epoch Time (s): 164.53271052008495')
('Epoch 59', 'Objective: -0.0163530055752212', 'Train Acc: 0.9960666666666667', 'Test Acc: 0.9919', 'Train LL: -0.012279174861513616', 'Test LL: -0.026576911198398032', 'Epoch Time (s): 164.37459175591357')
('Epoch 60', 'Objective: -0.016113988233273188', 'Train Acc: 0.9960666666666667', 'Test Acc: 0.9902', 'Train LL: -0.012055754283145446', 'Test LL: -0.030531322589745582', 'Epoch Time (s): 164.43420487293042')
('Epoch 61', 'Objective: -0.015438800294355128', 'Train Acc: 0.9959333333333333', 'Test Acc: 0.9917', 'Train LL: -0.011400685999220221', 'Test LL: -0.02520897807474171', 'Epoch Time (s): 164.45682471292093')
('Epoch 62', 'Objective: -0.015137844890076512', 'Train Acc: 0.9960833333333333', 'Test Acc: 0.9912', 'Train LL: -0.011102325316744262', 'Test LL: -0.02842490336257283', 'Epoch Time (s): 164.4494686408434')
('Epoch 63', 'Objective: -0.015139671376453813', 'Train Acc: 0.99635', 'Test Acc: 0.9917', 'Train LL: -0.011141487828926152', 'Test LL: -0.025226839081296824', 'Epoch Time (s): 164.41904694307595')
('Epoch 64', 'Objective: -0.014930271049992127', 'Train Acc: 0.9964833333333334', 'Test Acc: 0.9914', 'Train LL: -0.010946278061749845', 'Test LL: -0.029535804468297344', 'Epoch Time (s): 164.48052414902486')
('Epoch 65', 'Objective: -0.014694699401675887', 'Train Acc: 0.9960833333333333', 'Test Acc: 0.9923', 'Train LL: -0.01073208321957036', 'Test LL: -0.0266940224991911', 'Epoch Time (s): 164.47436091513373')
('Epoch 66', 'Objective: -0.0151882395724807', 'Train Acc: 0.9961666666666666', 'Test Acc: 0.9913', 'Train LL: -0.01122004109125758', 'Test LL: -0.026899879859255144', 'Epoch Time (s): 164.47654894692823')
('Epoch 67', 'Objective: -0.014139299278987522', 'Train Acc: 0.9967166666666667', 'Test Acc: 0.9904', 'Train LL: -0.010223579308252767', 'Test LL: -0.030005407538726662', 'Epoch Time (s): 164.47327361395583')
('Epoch 68', 'Objective: -0.013581301095134711', 'Train Acc: 0.9968166666666667', 'Test Acc: 0.9915', 'Train LL: -0.009704215333184213', 'Test LL: -0.027446836417691783', 'Epoch Time (s): 164.46853346400894')
('Epoch 69', 'Objective: -0.01352742634000884', 'Train Acc: 0.9966833333333334', 'Test Acc: 0.9911', 'Train LL: -0.009618491558199287', 'Test LL: -0.028402056164643506', 'Epoch Time (s): 164.48562227911316')
('Epoch 70', 'Objective: -0.01427910792794101', 'Train Acc: 0.9966166666666667', 'Test Acc: 0.9918', 'Train LL: -0.010330861548975712', 'Test LL: -0.027629134698275687', 'Epoch Time (s): 164.4592575558927')
('Epoch 71', 'Objective: -0.013554322389697986', 'Train Acc: 0.9968666666666667', 'Test Acc: 0.9886', 'Train LL: -0.009670498519832281', 'Test LL: -0.036251206339983404', 'Epoch Time (s): 164.70026317192242')
('Epoch 72', 'Objective: -0.014062561688160332', 'Train Acc: 0.9965666666666667', 'Test Acc: 0.9917', 'Train LL: -0.010185210253476136', 'Test LL: -0.02696162063923677', 'Epoch Time (s): 164.409222060116')
('Epoch 73', 'Objective: -0.013470855367664283', 'Train Acc: 0.9968333333333333', 'Test Acc: 0.9894', 'Train LL: -0.009631106062450387', 'Test LL: -0.03774073349425732', 'Epoch Time (s): 164.8695776120294')
('Epoch 74', 'Objective: -0.013318048900302856', 'Train Acc: 0.9966666666666667', 'Test Acc: 0.9907', 'Train LL: -0.00944685412204202', 'Test LL: -0.03016833730844054', 'Epoch Time (s): 165.18486687191762')
('Epoch 75', 'Objective: -0.012477205230446074', 'Train Acc: 0.9969333333333333', 'Test Acc: 0.9907', 'Train LL: -0.008604207820483404', 'Test LL: -0.032769957834170645', 'Epoch Time (s): 165.23898302088492')
('Epoch 76', 'Objective: -0.012330606163044412', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9922', 'Train LL: -0.008495352325155458', 'Test LL: -0.02939604490771603', 'Epoch Time (s): 165.20294549292885')
('Epoch 77', 'Objective: -0.012704638624911654', 'Train Acc: 0.99705', 'Test Acc: 0.9906', 'Train LL: -0.008863523303865617', 'Test LL: -0.03220997849164997', 'Epoch Time (s): 164.98435620195232')
('Epoch 78', 'Objective: -0.011969710532719578', 'Train Acc: 0.9973833333333333', 'Test Acc: 0.9919', 'Train LL: -0.008158239026239307', 'Test LL: -0.028676353999376892', 'Epoch Time (s): 164.74617672688328')
('Epoch 79', 'Objective: -0.012477276366728027', 'Train Acc: 0.99715', 'Test Acc: 0.9909', 'Train LL: -0.008664478190001927', 'Test LL: -0.029445006339102537', 'Epoch Time (s): 164.6281135031022')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.010603831626209457', 'Train Acc: 0.9976666666666667', 'Test Acc: 0.9913', 'Train LL: -0.006920670475376454', 'Test LL: -0.029183542999909707', 'Epoch Time (s): 164.43847444397397')
('Epoch 81', 'Objective: -0.009704097814584933', 'Train Acc: 0.9981333333333333', 'Test Acc: 0.9915', 'Train LL: -0.0060867970190337795', 'Test LL: -0.02861273900480751', 'Epoch Time (s): 164.48038341896608')
('Epoch 82', 'Objective: -0.009673302051580953', 'Train Acc: 0.9980833333333333', 'Test Acc: 0.9912', 'Train LL: -0.006037491822778954', 'Test LL: -0.031127130863715047', 'Epoch Time (s): 164.50461290217936')
('Epoch 83', 'Objective: -0.009257104895919587', 'Train Acc: 0.9983333333333333', 'Test Acc: 0.9918', 'Train LL: -0.005651247475129336', 'Test LL: -0.03088076331767145', 'Epoch Time (s): 164.46964059001766')
('Epoch 84', 'Objective: -0.009433327664744105', 'Train Acc: 0.9981166666666667', 'Test Acc: 0.9908', 'Train LL: -0.005791416254185769', 'Test LL: -0.031551541480115304', 'Epoch Time (s): 164.53092548903078')
('Epoch 85', 'Objective: -0.009054080152393066', 'Train Acc: 0.9981666666666666', 'Test Acc: 0.9911', 'Train LL: -0.005435583145120837', 'Test LL: -0.031238893285143662', 'Epoch Time (s): 164.5510893089231')
('Epoch 86', 'Objective: -0.009091653343334756', 'Train Acc: 0.9983', 'Test Acc: 0.991', 'Train LL: -0.005444639352147349', 'Test LL: -0.03166397664816209', 'Epoch Time (s): 164.64055682113394')
('Epoch 87', 'Objective: -0.008478886485855942', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9911', 'Train LL: -0.00489569889310493', 'Test LL: -0.03225841136868046', 'Epoch Time (s): 164.43811053107493')
('Epoch 88', 'Objective: -0.008770839254572138', 'Train Acc: 0.9982333333333333', 'Test Acc: 0.9904', 'Train LL: -0.005134405120186175', 'Test LL: -0.03380590199610476', 'Epoch Time (s): 164.58811964606866')
('Epoch 89', 'Objective: -0.00830837482174562', 'Train Acc: 0.9985', 'Test Acc: 0.9913', 'Train LL: -0.004705382216024356', 'Test LL: -0.0321070806856118', 'Epoch Time (s): 164.7394073579926')
('Epoch 90', 'Objective: -0.00836649469404451', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9908', 'Train LL: -0.004749983317862829', 'Test LL: -0.03275663069810638', 'Epoch Time (s): 164.50607160897925')
('Epoch 91', 'Objective: -0.008475386328814921', 'Train Acc: 0.9983166666666666', 'Test Acc: 0.9905', 'Train LL: -0.004822969783946629', 'Test LL: -0.033412264612722065', 'Epoch Time (s): 164.62658024393022')
('Epoch 92', 'Objective: -0.008327081801304972', 'Train Acc: 0.9985', 'Test Acc: 0.9902', 'Train LL: -0.004695937298628891', 'Test LL: -0.035381193722184553', 'Epoch Time (s): 164.44830039795488')
('Epoch 93', 'Objective: -0.008292654826937763', 'Train Acc: 0.9985', 'Test Acc: 0.9901', 'Train LL: -0.004657715671207518', 'Test LL: -0.03396174263304718', 'Epoch Time (s): 164.47470631008036')
('Epoch 94', 'Objective: -0.008256838784719708', 'Train Acc: 0.9985', 'Test Acc: 0.9906', 'Train LL: -0.0046334758783272', 'Test LL: -0.03443436811316671', 'Epoch Time (s): 164.460001795087')
('Epoch 95', 'Objective: -0.008030376097905198', 'Train Acc: 0.9984666666666666', 'Test Acc: 0.9906', 'Train LL: -0.004410189039111889', 'Test LL: -0.0343438046624472', 'Epoch Time (s): 164.45525578712113')
('Epoch 96', 'Objective: -0.00828944175944023', 'Train Acc: 0.99835', 'Test Acc: 0.9908', 'Train LL: -0.004628328914158544', 'Test LL: -0.03480078658504507', 'Epoch Time (s): 164.4771346731577')
('Epoch 97', 'Objective: -0.008108857434574498', 'Train Acc: 0.99865', 'Test Acc: 0.9899', 'Train LL: -0.004466443178504683', 'Test LL: -0.03690091117307723', 'Epoch Time (s): 164.4834576989524')
('Epoch 98', 'Objective: -0.008400983125232141', 'Train Acc: 0.9984166666666666', 'Test Acc: 0.9902', 'Train LL: -0.00474556302847577', 'Test LL: -0.03689112428251176', 'Epoch Time (s): 164.48138929205015')
('Epoch 99', 'Objective: -0.007995720243691143', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9907', 'Train LL: -0.0043727154707179335', 'Test LL: -0.03552160651120381', 'Epoch Time (s): 164.43201055191457')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.0077195439058792645
Final Train Accuracy: £0.9986166666666667
Final Train LL: £-0.004093902292642752
Final Test Accuracy: £0.9907
Final Test LL: £-0.035676616927511694
