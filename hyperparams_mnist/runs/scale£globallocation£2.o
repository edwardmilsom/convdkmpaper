dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: location
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.274691480067656', 'Train Acc: 0.5526333333333333', 'Test Acc: 0.8429', 'Train LL: -1.2219428430107417', 'Test LL: -0.47149449136096766', 'Epoch Time (s): 171.1076362999156')
('Epoch 1', 'Objective: -0.48478284932368765', 'Train Acc: 0.8555666666666667', 'Test Acc: 0.8922', 'Train LL: -0.4338113323434978', 'Test LL: -0.34267217810534795', 'Epoch Time (s): 170.52197185065597')
('Epoch 2', 'Objective: -0.33665305480950364', 'Train Acc: 0.9066166666666666', 'Test Acc: 0.9369', 'Train LL: -0.288580651762595', 'Test LL: -0.20873771068188712', 'Epoch Time (s): 170.51265948591754')
('Epoch 3', 'Objective: -0.2567165704911872', 'Train Acc: 0.9337166666666666', 'Test Acc: 0.9445', 'Train LL: -0.21031500186601462', 'Test LL: -0.16373499924272364', 'Epoch Time (s): 170.46963064279407')
('Epoch 4', 'Objective: -0.21651514267038666', 'Train Acc: 0.94595', 'Test Acc: 0.9519', 'Train LL: -0.17213419021199525', 'Test LL: -0.15141983273302553', 'Epoch Time (s): 170.51961685391143')
('Epoch 5', 'Objective: -0.19459873041694103', 'Train Acc: 0.9517666666666666', 'Test Acc: 0.9612', 'Train LL: -0.15168245743707165', 'Test LL: -0.1234905862543391', 'Epoch Time (s): 170.50557259097695')
('Epoch 6', 'Objective: -0.17779656628134027', 'Train Acc: 0.9571', 'Test Acc: 0.963', 'Train LL: -0.13647259055627828', 'Test LL: -0.11811191773756752', 'Epoch Time (s): 170.51105317799374')
('Epoch 7', 'Objective: -0.1656012973649436', 'Train Acc: 0.96035', 'Test Acc: 0.9656', 'Train LL: -0.12560559256706968', 'Test LL: -0.11278311088602702', 'Epoch Time (s): 170.50883884588256')
('Epoch 8', 'Objective: -0.1538327200698563', 'Train Acc: 0.9637333333333333', 'Test Acc: 0.9749', 'Train LL: -0.11463980453541212', 'Test LL: -0.07739047831076744', 'Epoch Time (s): 170.5223849681206')
('Epoch 9', 'Objective: -0.1464230239057702', 'Train Acc: 0.9657166666666667', 'Test Acc: 0.9675', 'Train LL: -0.10843764003069144', 'Test LL: -0.1012317613120636', 'Epoch Time (s): 170.5238404753618')
('Epoch 10', 'Objective: -0.14010894968806678', 'Train Acc: 0.9681', 'Test Acc: 0.9719', 'Train LL: -0.10261831578364897', 'Test LL: -0.09250003715709267', 'Epoch Time (s): 170.48942163633183')
('Epoch 11', 'Objective: -0.13717542217966017', 'Train Acc: 0.9678166666666667', 'Test Acc: 0.9675', 'Train LL: -0.1002261307995536', 'Test LL: -0.09973605165788002', 'Epoch Time (s): 170.52189252898097')
('Epoch 12', 'Objective: -0.1309837460156486', 'Train Acc: 0.9697', 'Test Acc: 0.9733', 'Train LL: -0.09464584724274082', 'Test LL: -0.08390042598388614', 'Epoch Time (s): 170.50214359303936')
('Epoch 13', 'Objective: -0.12726499727865476', 'Train Acc: 0.9710333333333333', 'Test Acc: 0.9758', 'Train LL: -0.09131014068132579', 'Test LL: -0.07673658218187504', 'Epoch Time (s): 170.48605268634856')
('Epoch 14', 'Objective: -0.12190337797864327', 'Train Acc: 0.9723', 'Test Acc: 0.9767', 'Train LL: -0.08668800199658913', 'Test LL: -0.07182670519049571', 'Epoch Time (s): 170.49669219506904')
('Epoch 15', 'Objective: -0.11837536075879093', 'Train Acc: 0.97365', 'Test Acc: 0.9743', 'Train LL: -0.08362549312972878', 'Test LL: -0.07865726903711047', 'Epoch Time (s): 170.5070165619254')
('Epoch 16', 'Objective: -0.11731264566395827', 'Train Acc: 0.9735166666666667', 'Test Acc: 0.9802', 'Train LL: -0.08276264853763332', 'Test LL: -0.0622249965786044', 'Epoch Time (s): 170.52272824617103')
('Epoch 17', 'Objective: -0.11199318331581787', 'Train Acc: 0.9747833333333333', 'Test Acc: 0.9794', 'Train LL: -0.0779835791793916', 'Test LL: -0.059193283409380196', 'Epoch Time (s): 170.51162780169398')
('Epoch 18', 'Objective: -0.11072282412459072', 'Train Acc: 0.9758333333333333', 'Test Acc: 0.9827', 'Train LL: -0.07737214805628874', 'Test LL: -0.05916564560655961', 'Epoch Time (s): 170.52906646067277')
('Epoch 19', 'Objective: -0.1085414868892087', 'Train Acc: 0.9764', 'Test Acc: 0.981', 'Train LL: -0.0754349782379977', 'Test LL: -0.05798152462891932', 'Epoch Time (s): 170.53977434476838')
('Epoch 20', 'Objective: -0.105935679133449', 'Train Acc: 0.97655', 'Test Acc: 0.974', 'Train LL: -0.07309706738033722', 'Test LL: -0.07711036985010389', 'Epoch Time (s): 170.48453528620303')
('Epoch 21', 'Objective: -0.10275873130605322', 'Train Acc: 0.9780166666666666', 'Test Acc: 0.9731', 'Train LL: -0.07023216968448442', 'Test LL: -0.07999313795852611', 'Epoch Time (s): 170.49325538659468')
('Epoch 22', 'Objective: -0.1019481216078114', 'Train Acc: 0.9773', 'Test Acc: 0.9801', 'Train LL: -0.06992701239406564', 'Test LL: -0.06413995317343582', 'Epoch Time (s): 170.5424673021771')
('Epoch 23', 'Objective: -0.09913744892424281', 'Train Acc: 0.9783666666666667', 'Test Acc: 0.9818', 'Train LL: -0.06720044653975485', 'Test LL: -0.05919475505376416', 'Epoch Time (s): 170.50700461305678')
('Epoch 24', 'Objective: -0.10021573644130417', 'Train Acc: 0.9770333333333333', 'Test Acc: 0.9788', 'Train LL: -0.06841418101697598', 'Test LL: -0.060050766655530434', 'Epoch Time (s): 170.4820088809356')
('Epoch 25', 'Objective: -0.09740308117782294', 'Train Acc: 0.97905', 'Test Acc: 0.9794', 'Train LL: -0.0661594601384001', 'Test LL: -0.06391986428278551', 'Epoch Time (s): 170.4739169399254')
('Epoch 26', 'Objective: -0.09690685280901677', 'Train Acc: 0.9798333333333333', 'Test Acc: 0.9779', 'Train LL: -0.0659772924368015', 'Test LL: -0.06355010823118333', 'Epoch Time (s): 170.46955812675878')
('Epoch 27', 'Objective: -0.09519163452556793', 'Train Acc: 0.9792333333333333', 'Test Acc: 0.9865', 'Train LL: -0.06437844452473426', 'Test LL: -0.042044821341555905', 'Epoch Time (s): 170.4651177795604')
('Epoch 28', 'Objective: -0.09246614917625691', 'Train Acc: 0.97975', 'Test Acc: 0.9778', 'Train LL: -0.06200880053330197', 'Test LL: -0.06548483272397096', 'Epoch Time (s): 170.4583887718618')
('Epoch 29', 'Objective: -0.09374591353349077', 'Train Acc: 0.9797', 'Test Acc: 0.9818', 'Train LL: -0.06353989014871463', 'Test LL: -0.05340753281820103', 'Epoch Time (s): 170.459149798844')
('Epoch 30', 'Objective: -0.09097469874939051', 'Train Acc: 0.9810833333333333', 'Test Acc: 0.9779', 'Train LL: -0.06096942039274441', 'Test LL: -0.06252154631834309', 'Epoch Time (s): 170.47892741579562')
('Epoch 31', 'Objective: -0.08926505955897289', 'Train Acc: 0.9811166666666666', 'Test Acc: 0.9836', 'Train LL: -0.05959977141112381', 'Test LL: -0.047477508632162685', 'Epoch Time (s): 170.42661459278315')
('Epoch 32', 'Objective: -0.08916866888588243', 'Train Acc: 0.9812166666666666', 'Test Acc: 0.9835', 'Train LL: -0.059552028737120004', 'Test LL: -0.04979661274079672', 'Epoch Time (s): 170.44982103304937')
('Epoch 33', 'Objective: -0.08763267659987738', 'Train Acc: 0.9816833333333334', 'Test Acc: 0.9812', 'Train LL: -0.05833022666949046', 'Test LL: -0.0526486021725897', 'Epoch Time (s): 170.43764927471057')
('Epoch 34', 'Objective: -0.08789478045493355', 'Train Acc: 0.9815333333333334', 'Test Acc: 0.9878', 'Train LL: -0.05879893149192752', 'Test LL: -0.03632518744587906', 'Epoch Time (s): 170.41459224699065')
('Epoch 35', 'Objective: -0.0868901729073978', 'Train Acc: 0.9816166666666667', 'Test Acc: 0.9855', 'Train LL: -0.0582386636073206', 'Test LL: -0.04345332114653275', 'Epoch Time (s): 170.4514844128862')
('Epoch 36', 'Objective: -0.08516233289947595', 'Train Acc: 0.9815666666666667', 'Test Acc: 0.9863', 'Train LL: -0.05649514228816703', 'Test LL: -0.044917636568712144', 'Epoch Time (s): 170.4109310740605')
('Epoch 37', 'Objective: -0.08419204576057274', 'Train Acc: 0.9826666666666667', 'Test Acc: 0.9825', 'Train LL: -0.05576928761143188', 'Test LL: -0.05509741613755352', 'Epoch Time (s): 170.36588170425966')
('Epoch 38', 'Objective: -0.0836967482327713', 'Train Acc: 0.9822166666666666', 'Test Acc: 0.9845', 'Train LL: -0.05542889823836557', 'Test LL: -0.0508569408368272', 'Epoch Time (s): 170.40426791785285')
('Epoch 39', 'Objective: -0.08271052662472558', 'Train Acc: 0.98235', 'Test Acc: 0.9791', 'Train LL: -0.05458375654862985', 'Test LL: -0.06221109407426459', 'Epoch Time (s): 170.3618852412328')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06263774420814242', 'Train Acc: 0.98855', 'Test Acc: 0.9904', 'Train LL: -0.03612943385962556', 'Test LL: -0.029656896680396096', 'Epoch Time (s): 170.38249598490074')
('Epoch 41', 'Objective: -0.0562691582291202', 'Train Acc: 0.9902833333333333', 'Test Acc: 0.9901', 'Train LL: -0.030944110924809393', 'Test LL: -0.028114798038120586', 'Epoch Time (s): 170.38737941719592')
('Epoch 42', 'Objective: -0.054287261981587454', 'Train Acc: 0.99045', 'Test Acc: 0.9888', 'Train LL: -0.029411439095445465', 'Test LL: -0.029899574018030308', 'Epoch Time (s): 170.34685527300462')
('Epoch 43', 'Objective: -0.05277435041516367', 'Train Acc: 0.9908', 'Test Acc: 0.9889', 'Train LL: -0.02809782002913843', 'Test LL: -0.030678772095139594', 'Epoch Time (s): 170.30109931528568')
('Epoch 44', 'Objective: -0.0527192674969473', 'Train Acc: 0.9911333333333333', 'Test Acc: 0.9887', 'Train LL: -0.028275271863511715', 'Test LL: -0.03248523790444377', 'Epoch Time (s): 170.31330050015822')
('Epoch 45', 'Objective: -0.05227773632640212', 'Train Acc: 0.9911833333333333', 'Test Acc: 0.989', 'Train LL: -0.028100110176936706', 'Test LL: -0.03092830718645744', 'Epoch Time (s): 170.3023081771098')
('Epoch 46', 'Objective: -0.05115170584724374', 'Train Acc: 0.99145', 'Test Acc: 0.989', 'Train LL: -0.027158302101985502', 'Test LL: -0.03136222028439036', 'Epoch Time (s): 170.29895881889388')
('Epoch 47', 'Objective: -0.050839861747098675', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9896', 'Train LL: -0.027015534492555494', 'Test LL: -0.02885075904610435', 'Epoch Time (s): 170.33510982990265')
('Epoch 48', 'Objective: -0.0495280382594238', 'Train Acc: 0.9918', 'Test Acc: 0.9901', 'Train LL: -0.025806281294286117', 'Test LL: -0.028984812636113428', 'Epoch Time (s): 170.32451655808836')
('Epoch 49', 'Objective: -0.04978371141455965', 'Train Acc: 0.9914666666666667', 'Test Acc: 0.9896', 'Train LL: -0.026201302713322733', 'Test LL: -0.03025715464225541', 'Epoch Time (s): 170.33318775705993')
('Epoch 50', 'Objective: -0.049102419753676345', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9897', 'Train LL: -0.02565838046591502', 'Test LL: -0.028189268093743544', 'Epoch Time (s): 170.3329797759652')
('Epoch 51', 'Objective: -0.049101261953858506', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9895', 'Train LL: -0.02574423916441256', 'Test LL: -0.03154401538396155', 'Epoch Time (s): 170.30927744321525')
('Epoch 52', 'Objective: -0.04838774012051223', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.9905', 'Train LL: -0.025187571737470885', 'Test LL: -0.0288603559674466', 'Epoch Time (s): 170.29563759360462')
('Epoch 53', 'Objective: -0.04886973759084944', 'Train Acc: 0.99135', 'Test Acc: 0.9895', 'Train LL: -0.025636777112967336', 'Test LL: -0.029423193157165007', 'Epoch Time (s): 170.28748855600134')
('Epoch 54', 'Objective: -0.04823557167014548', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.989', 'Train LL: -0.025134865664474926', 'Test LL: -0.030945951154041584', 'Epoch Time (s): 170.3031499008648')
('Epoch 55', 'Objective: -0.04723371438250677', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.99', 'Train LL: -0.02419592567379824', 'Test LL: -0.028614192041795848', 'Epoch Time (s): 170.31026853388175')
('Epoch 56', 'Objective: -0.04758284802032917', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.9915', 'Train LL: -0.024627171143731728', 'Test LL: -0.026084693084794823', 'Epoch Time (s): 170.2884516948834')
('Epoch 57', 'Objective: -0.04782484786922335', 'Train Acc: 0.9921166666666666', 'Test Acc: 0.9899', 'Train LL: -0.02499040036728714', 'Test LL: -0.028211030393242863', 'Epoch Time (s): 170.28920438094065')
('Epoch 58', 'Objective: -0.046735586637293734', 'Train Acc: 0.9924', 'Test Acc: 0.989', 'Train LL: -0.0240281423570343', 'Test LL: -0.030424279236096426', 'Epoch Time (s): 170.29533267440274')
('Epoch 59', 'Objective: -0.04695434091983671', 'Train Acc: 0.9924', 'Test Acc: 0.9901', 'Train LL: -0.024324998241861528', 'Test LL: -0.02770021760270169', 'Epoch Time (s): 170.29946280783042')
('Epoch 60', 'Objective: -0.046692097681566375', 'Train Acc: 0.9921833333333333', 'Test Acc: 0.9883', 'Train LL: -0.02403198742155684', 'Test LL: -0.03481728844839087', 'Epoch Time (s): 170.2880906611681')
('Epoch 61', 'Objective: -0.04594496497741592', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9895', 'Train LL: -0.023364791056253095', 'Test LL: -0.030896638436864486', 'Epoch Time (s): 170.36275422992185')
('Epoch 62', 'Objective: -0.0467660715891411', 'Train Acc: 0.9922166666666666', 'Test Acc: 0.9895', 'Train LL: -0.024151145246692877', 'Test LL: -0.030117537436441546', 'Epoch Time (s): 170.37344381399453')
('Epoch 63', 'Objective: -0.046410742340110424', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9892', 'Train LL: -0.024038466530901498', 'Test LL: -0.02904555948475448', 'Epoch Time (s): 170.36567111499608')
('Epoch 64', 'Objective: -0.04589195327567455', 'Train Acc: 0.9926', 'Test Acc: 0.9888', 'Train LL: -0.02353943144687493', 'Test LL: -0.030278714116479886', 'Epoch Time (s): 170.35556537704542')
('Epoch 65', 'Objective: -0.046302895432961844', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.991', 'Train LL: -0.023952907471310587', 'Test LL: -0.02633450502224365', 'Epoch Time (s): 170.3884764718823')
('Epoch 66', 'Objective: -0.04597091287661246', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.991', 'Train LL: -0.02373962561167025', 'Test LL: -0.025890828913057624', 'Epoch Time (s): 170.3640240766108')
('Epoch 67', 'Objective: -0.045826926644362484', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.988', 'Train LL: -0.023596323694529863', 'Test LL: -0.032653770662135526', 'Epoch Time (s): 170.3767664898187')
('Epoch 68', 'Objective: -0.045080774918120375', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9902', 'Train LL: -0.022895704213987567', 'Test LL: -0.02920837985456451', 'Epoch Time (s): 170.40872063627467')
('Epoch 69', 'Objective: -0.04579149509872935', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9888', 'Train LL: -0.023684943812631264', 'Test LL: -0.030391458457575612', 'Epoch Time (s): 170.3490218752995')
('Epoch 70', 'Objective: -0.04600655054399393', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.9906', 'Train LL: -0.02393897442706211', 'Test LL: -0.027308167222829725', 'Epoch Time (s): 170.39221315598115')
('Epoch 71', 'Objective: -0.04470407658009791', 'Train Acc: 0.9928166666666667', 'Test Acc: 0.988', 'Train LL: -0.02274899745780699', 'Test LL: -0.033435247333104795', 'Epoch Time (s): 170.38356647174805')
('Epoch 72', 'Objective: -0.045213905491208475', 'Train Acc: 0.99245', 'Test Acc: 0.9899', 'Train LL: -0.023198522125870365', 'Test LL: -0.02845138448181655', 'Epoch Time (s): 170.41421799873933')
('Epoch 73', 'Objective: -0.04453723927239648', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9912', 'Train LL: -0.022594293205125064', 'Test LL: -0.026975882998395668', 'Epoch Time (s): 170.43179161287844')
('Epoch 74', 'Objective: -0.044080837999801545', 'Train Acc: 0.9929', 'Test Acc: 0.9896', 'Train LL: -0.022172641740150916', 'Test LL: -0.03126326033206785', 'Epoch Time (s): 170.34245100431144')
('Epoch 75', 'Objective: -0.044485197529189946', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9887', 'Train LL: -0.022626292280873015', 'Test LL: -0.03158248440854969', 'Epoch Time (s): 170.38784448616207')
('Epoch 76', 'Objective: -0.044446301947727154', 'Train Acc: 0.9925', 'Test Acc: 0.9895', 'Train LL: -0.022572321383653046', 'Test LL: -0.03183003437934776', 'Epoch Time (s): 170.3714630426839')
('Epoch 77', 'Objective: -0.044219045074424534', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9893', 'Train LL: -0.022405582685553798', 'Test LL: -0.029561442572313613', 'Epoch Time (s): 170.3794755055569')
('Epoch 78', 'Objective: -0.044208682683272174', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9895', 'Train LL: -0.022452480040457957', 'Test LL: -0.029109403227775728', 'Epoch Time (s): 170.40041754115373')
('Epoch 79', 'Objective: -0.04381871999820629', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9895', 'Train LL: -0.022094687412180854', 'Test LL: -0.03067532470086553', 'Epoch Time (s): 170.45957856904715')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.041841217747208774', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.9898', 'Train LL: -0.02025221308646211', 'Test LL: -0.0281011739295474', 'Epoch Time (s): 170.39794072508812')
('Epoch 81', 'Objective: -0.041121466782480694', 'Train Acc: 0.99375', 'Test Acc: 0.9908', 'Train LL: -0.019637247319734274', 'Test LL: -0.02719893274925297', 'Epoch Time (s): 170.3509510429576')
('Epoch 82', 'Objective: -0.04091634221514823', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.9902', 'Train LL: -0.01943792368833372', 'Test LL: -0.02779656784582686', 'Epoch Time (s): 170.35002772696316')
('Epoch 83', 'Objective: -0.04099113335990558', 'Train Acc: 0.9938333333333333', 'Test Acc: 0.9903', 'Train LL: -0.019532186395985685', 'Test LL: -0.026552573645018385', 'Epoch Time (s): 170.36611874122173')
('Epoch 84', 'Objective: -0.04027039637374334', 'Train Acc: 0.9939', 'Test Acc: 0.9904', 'Train LL: -0.018861800347512888', 'Test LL: -0.027063951177355057', 'Epoch Time (s): 170.3774274769239')
('Epoch 85', 'Objective: -0.04059961701495292', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.9905', 'Train LL: -0.01921466986178407', 'Test LL: -0.02763359747236317', 'Epoch Time (s): 170.38177062105387')
('Epoch 86', 'Objective: -0.03987632637087915', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9911', 'Train LL: -0.01854703931752917', 'Test LL: -0.026813180763369474', 'Epoch Time (s): 170.3723958893679')
('Epoch 87', 'Objective: -0.0403656360437009', 'Train Acc: 0.9939833333333333', 'Test Acc: 0.9908', 'Train LL: -0.018972213824094915', 'Test LL: -0.027499356939441295', 'Epoch Time (s): 170.37779091624543')
('Epoch 88', 'Objective: -0.03996258530910623', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.991', 'Train LL: -0.018629232599563908', 'Test LL: -0.026834205027779705', 'Epoch Time (s): 170.40498112514615')
('Epoch 89', 'Objective: -0.04000476510764929', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.9897', 'Train LL: -0.018621808511004166', 'Test LL: -0.028598438686765086', 'Epoch Time (s): 170.423137024045')
('Epoch 90', 'Objective: -0.039910867014946824', 'Train Acc: 0.994', 'Test Acc: 0.9907', 'Train LL: -0.01853237593626653', 'Test LL: -0.027302543664819524', 'Epoch Time (s): 170.36335687432438')
('Epoch 91', 'Objective: -0.03944354562372099', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9901', 'Train LL: -0.018120272054229575', 'Test LL: -0.027947659301347044', 'Epoch Time (s): 170.38886672491208')
('Epoch 92', 'Objective: -0.04017670175528424', 'Train Acc: 0.994', 'Test Acc: 0.9908', 'Train LL: -0.018787874677035767', 'Test LL: -0.027980572408403383', 'Epoch Time (s): 170.37473683524877')
('Epoch 93', 'Objective: -0.039704905105847656', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9912', 'Train LL: -0.018410314825430995', 'Test LL: -0.027383157698301245', 'Epoch Time (s): 170.32936898013577')
('Epoch 94', 'Objective: -0.039770669630169626', 'Train Acc: 0.9941333333333333', 'Test Acc: 0.9906', 'Train LL: -0.01839243921245029', 'Test LL: -0.028309150296576525', 'Epoch Time (s): 170.38363965088502')
('Epoch 95', 'Objective: -0.039509856211873126', 'Train Acc: 0.9943', 'Test Acc: 0.9908', 'Train LL: -0.018191367980208345', 'Test LL: -0.027750180203313823', 'Epoch Time (s): 170.39924360113218')
('Epoch 96', 'Objective: -0.04007614033835482', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9905', 'Train LL: -0.01868821637177301', 'Test LL: -0.028102499156699275', 'Epoch Time (s): 170.37125839898363')
('Epoch 97', 'Objective: -0.0400892710327823', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9906', 'Train LL: -0.018709185971386228', 'Test LL: -0.02757058847016217', 'Epoch Time (s): 170.35730955889449')
('Epoch 98', 'Objective: -0.03964172734715075', 'Train Acc: 0.9938166666666667', 'Test Acc: 0.9901', 'Train LL: -0.01830551224225478', 'Test LL: -0.028477827905559628', 'Epoch Time (s): 170.40275925816968')
('Epoch 99', 'Objective: -0.03965142524568017', 'Train Acc: 0.9941', 'Test Acc: 0.9907', 'Train LL: -0.018353530925536054', 'Test LL: -0.02727498212124151', 'Epoch Time (s): 170.37778088776395')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.039428886411063215
Final Train Accuracy: £0.9941166666666666
Final Train LL: £-0.01814336868246308
Final Test Accuracy: £0.9906
Final Test LL: £-0.027335295367594454
