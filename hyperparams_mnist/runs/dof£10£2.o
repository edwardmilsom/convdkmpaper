dataset: MNIST
dtype: float64
dof: 10.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.404962004918566', 'Train Acc: 0.5291333333333333', 'Test Acc: 0.7255', 'Train LL: -1.2985998587947074', 'Test LL: -0.7821151364234806', 'Epoch Time (s): 171.48410029010847')
('Epoch 1', 'Objective: -0.7570367863700367', 'Train Acc: 0.78025', 'Test Acc: 0.8273', 'Train LL: -0.6431046497818993', 'Test LL: -0.521760992187735', 'Epoch Time (s): 170.48140128562227')
('Epoch 2', 'Objective: -0.5101187299899287', 'Train Acc: 0.8735666666666667', 'Test Acc: 0.9222', 'Train LL: -0.3923388288761616', 'Test LL: -0.2593633444102471', 'Epoch Time (s): 170.51197124272585')
('Epoch 3', 'Objective: -0.40545821809193744', 'Train Acc: 0.9101166666666667', 'Test Acc: 0.9282', 'Train LL: -0.29014313587145657', 'Test LL: -0.23246724132587523', 'Epoch Time (s): 170.49793789209798')
('Epoch 4', 'Objective: -0.35222670588028376', 'Train Acc: 0.9261', 'Test Acc: 0.9204', 'Train LL: -0.23992481677699837', 'Test LL: -0.2521409739321395', 'Epoch Time (s): 170.5191978472285')
('Epoch 5', 'Objective: -0.31320479186922673', 'Train Acc: 0.9363333333333334', 'Test Acc: 0.9259', 'Train LL: -0.20565598081651792', 'Test LL: -0.23355058368225473', 'Epoch Time (s): 170.45531283970922')
('Epoch 6', 'Objective: -0.2881440841102312', 'Train Acc: 0.9430166666666666', 'Test Acc: 0.9601', 'Train LL: -0.18554721283150344', 'Test LL: -0.13531542607113506', 'Epoch Time (s): 170.45658132527024')
('Epoch 7', 'Objective: -0.27334335176062774', 'Train Acc: 0.9460333333333333', 'Test Acc: 0.9578', 'Train LL: -0.173903396147622', 'Test LL: -0.14248680567138025', 'Epoch Time (s): 170.43917120806873')
('Epoch 8', 'Objective: -0.25648737899051793', 'Train Acc: 0.9501333333333334', 'Test Acc: 0.9603', 'Train LL: -0.16016108480294144', 'Test LL: -0.12959958446277198', 'Epoch Time (s): 170.43869348894805')
('Epoch 9', 'Objective: -0.24833635075229038', 'Train Acc: 0.9521166666666666', 'Test Acc: 0.9531', 'Train LL: -0.15441462314594312', 'Test LL: -0.1465221030176062', 'Epoch Time (s): 170.48192453198135')
('Epoch 10', 'Objective: -0.24030292912057485', 'Train Acc: 0.95365', 'Test Acc: 0.9672', 'Train LL: -0.14821222248442786', 'Test LL: -0.11081543390983858', 'Epoch Time (s): 170.50280178384855')
('Epoch 11', 'Objective: -0.23133337114160246', 'Train Acc: 0.9567', 'Test Acc: 0.9596', 'Train LL: -0.14113817917639213', 'Test LL: -0.12608045421255953', 'Epoch Time (s): 170.45395604567602')
('Epoch 12', 'Objective: -0.22232719089265987', 'Train Acc: 0.95905', 'Test Acc: 0.9583', 'Train LL: -0.1335196271667353', 'Test LL: -0.13289718297982842', 'Epoch Time (s): 170.43407370103523')
('Epoch 13', 'Objective: -0.21837213717230597', 'Train Acc: 0.95865', 'Test Acc: 0.9659', 'Train LL: -0.13093275607518814', 'Test LL: -0.10705592138278452', 'Epoch Time (s): 170.449588985648')
('Epoch 14', 'Objective: -0.20978351570963732', 'Train Acc: 0.9609333333333333', 'Test Acc: 0.9637', 'Train LL: -0.12398310829945972', 'Test LL: -0.11612383861290664', 'Epoch Time (s): 170.39896111004055')
('Epoch 15', 'Objective: -0.205188751653328', 'Train Acc: 0.9626833333333333', 'Test Acc: 0.9524', 'Train LL: -0.11976090141536479', 'Test LL: -0.15140561886528503', 'Epoch Time (s): 170.4577736039646')
('Epoch 16', 'Objective: -0.20404454338214975', 'Train Acc: 0.9628833333333333', 'Test Acc: 0.9668', 'Train LL: -0.11999309085275246', 'Test LL: -0.11258957898225667', 'Epoch Time (s): 170.44553186604753')
('Epoch 17', 'Objective: -0.1985144336400178', 'Train Acc: 0.9645', 'Test Acc: 0.9723', 'Train LL: -0.11533524900869309', 'Test LL: -0.08292140472775446', 'Epoch Time (s): 170.40608827397227')
('Epoch 18', 'Objective: -0.19366662347390926', 'Train Acc: 0.9656', 'Test Acc: 0.9724', 'Train LL: -0.11125190049099157', 'Test LL: -0.09005742938070159', 'Epoch Time (s): 170.4223394826986')
('Epoch 19', 'Objective: -0.1884854125703179', 'Train Acc: 0.9663333333333334', 'Test Acc: 0.9704', 'Train LL: -0.10632592693803508', 'Test LL: -0.08900238917752006', 'Epoch Time (s): 170.42924178019166')
('Epoch 20', 'Objective: -0.18570438837122813', 'Train Acc: 0.96735', 'Test Acc: 0.9709', 'Train LL: -0.10464271778305761', 'Test LL: -0.08911784594449997', 'Epoch Time (s): 170.42414433090016')
('Epoch 21', 'Objective: -0.18190026417674962', 'Train Acc: 0.9681166666666666', 'Test Acc: 0.9682', 'Train LL: -0.10193521108432343', 'Test LL: -0.09398754579579281', 'Epoch Time (s): 170.46133719477803')
('Epoch 22', 'Objective: -0.18010120974517138', 'Train Acc: 0.9686', 'Test Acc: 0.9664', 'Train LL: -0.10143874985748204', 'Test LL: -0.10375475234177711', 'Epoch Time (s): 170.42761844675988')
('Epoch 23', 'Objective: -0.17747769911427153', 'Train Acc: 0.9691166666666666', 'Test Acc: 0.9712', 'Train LL: -0.09933435378290456', 'Test LL: -0.08699356958686838', 'Epoch Time (s): 170.44218582613394')
('Epoch 24', 'Objective: -0.17569639837829823', 'Train Acc: 0.9692', 'Test Acc: 0.9693', 'Train LL: -0.0982461628602071', 'Test LL: -0.09544359722866418', 'Epoch Time (s): 170.42016037274152')
('Epoch 25', 'Objective: -0.1732855601300531', 'Train Acc: 0.9703166666666667', 'Test Acc: 0.9654', 'Train LL: -0.09640938153665272', 'Test LL: -0.10492668051267297', 'Epoch Time (s): 170.42998614721')
('Epoch 26', 'Objective: -0.169247021198463', 'Train Acc: 0.9706166666666667', 'Test Acc: 0.9638', 'Train LL: -0.09315007799051175', 'Test LL: -0.10937941800695011', 'Epoch Time (s): 170.39656393183395')
('Epoch 27', 'Objective: -0.17036724188766977', 'Train Acc: 0.9697666666666667', 'Test Acc: 0.9793', 'Train LL: -0.09478925166357899', 'Test LL: -0.06035680786922818', 'Epoch Time (s): 170.42378631979227')
('Epoch 28', 'Objective: -0.16552459677205988', 'Train Acc: 0.9717833333333333', 'Test Acc: 0.9652', 'Train LL: -0.09061165206985654', 'Test LL: -0.10611153988124902', 'Epoch Time (s): 170.42486121878028')
('Epoch 29', 'Objective: -0.1640533503965091', 'Train Acc: 0.9717666666666667', 'Test Acc: 0.9728', 'Train LL: -0.0901597361532301', 'Test LL: -0.08391434847408526', 'Epoch Time (s): 170.44009110704064')
('Epoch 30', 'Objective: -0.16260365632540988', 'Train Acc: 0.9722166666666666', 'Test Acc: 0.9733', 'Train LL: -0.08893976200543548', 'Test LL: -0.08015615057581378', 'Epoch Time (s): 170.41083043487743')
('Epoch 31', 'Objective: -0.15942081070447547', 'Train Acc: 0.9732833333333333', 'Test Acc: 0.9822', 'Train LL: -0.08651856159270879', 'Test LL: -0.054168000885947205', 'Epoch Time (s): 170.4424296016805')
('Epoch 32', 'Objective: -0.15931375377589402', 'Train Acc: 0.9727833333333333', 'Test Acc: 0.9787', 'Train LL: -0.08663400449321174', 'Test LL: -0.06414080219476956', 'Epoch Time (s): 170.38549531903118')
('Epoch 33', 'Objective: -0.15612962545441864', 'Train Acc: 0.9734666666666667', 'Test Acc: 0.97', 'Train LL: -0.08407759563769296', 'Test LL: -0.09287877834775306', 'Epoch Time (s): 170.3906253222376')
('Epoch 34', 'Objective: -0.15542563029204395', 'Train Acc: 0.9742333333333333', 'Test Acc: 0.9778', 'Train LL: -0.08424107615373644', 'Test LL: -0.06355982677117412', 'Epoch Time (s): 170.3551390869543')
('Epoch 35', 'Objective: -0.1559963647901215', 'Train Acc: 0.9734333333333334', 'Test Acc: 0.9754', 'Train LL: -0.08477058851892334', 'Test LL: -0.07310448891131473', 'Epoch Time (s): 170.37060671159998')
('Epoch 36', 'Objective: -0.15184817947635212', 'Train Acc: 0.9743833333333334', 'Test Acc: 0.9794', 'Train LL: -0.08126881627387901', 'Test LL: -0.06681028628620163', 'Epoch Time (s): 170.3668557810597')
('Epoch 37', 'Objective: -0.15202750607633095', 'Train Acc: 0.9745666666666667', 'Test Acc: 0.9751', 'Train LL: -0.08130929834171861', 'Test LL: -0.07586456704782996', 'Epoch Time (s): 170.3368399660103')
('Epoch 38', 'Objective: -0.15101540045686387', 'Train Acc: 0.9741833333333333', 'Test Acc: 0.9715', 'Train LL: -0.08109526302690559', 'Test LL: -0.08815396045707874', 'Epoch Time (s): 170.35817377874628')
('Epoch 39', 'Objective: -0.15100479058545485', 'Train Acc: 0.97375', 'Test Acc: 0.9737', 'Train LL: -0.08128168810446298', 'Test LL: -0.08230010228562916', 'Epoch Time (s): 170.35603895504028')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.119702859086803', 'Train Acc: 0.9826', 'Test Acc: 0.9864', 'Train LL: -0.05506936916386104', 'Test LL: -0.04209401291538912', 'Epoch Time (s): 170.35526194423437')
('Epoch 41', 'Objective: -0.11166460516027549', 'Train Acc: 0.9848333333333333', 'Test Acc: 0.9868', 'Train LL: -0.04950497804686445', 'Test LL: -0.039935381034050865', 'Epoch Time (s): 170.36734528886154')
('Epoch 42', 'Objective: -0.10937754122024741', 'Train Acc: 0.9846833333333334', 'Test Acc: 0.9866', 'Train LL: -0.04824643597288614', 'Test LL: -0.03926462521266442', 'Epoch Time (s): 170.33582887798548')
('Epoch 43', 'Objective: -0.10741339133822841', 'Train Acc: 0.9851166666666666', 'Test Acc: 0.9867', 'Train LL: -0.04708184824990819', 'Test LL: -0.04008073618552428', 'Epoch Time (s): 170.39522999711335')
('Epoch 44', 'Objective: -0.1070715391955301', 'Train Acc: 0.9854166666666667', 'Test Acc: 0.9854', 'Train LL: -0.047400547240404226', 'Test LL: -0.04247009478102213', 'Epoch Time (s): 170.34900053683668')
('Epoch 45', 'Objective: -0.10594103818107772', 'Train Acc: 0.9851666666666666', 'Test Acc: 0.9856', 'Train LL: -0.046869618394805274', 'Test LL: -0.041959583010258324', 'Epoch Time (s): 170.35740113817155')
('Epoch 46', 'Objective: -0.10455763318569541', 'Train Acc: 0.9855166666666667', 'Test Acc: 0.986', 'Train LL: -0.045957973107840284', 'Test LL: -0.04020732325410632', 'Epoch Time (s): 170.38727883063257')
('Epoch 47', 'Objective: -0.10398403265761197', 'Train Acc: 0.9857166666666667', 'Test Acc: 0.9868', 'Train LL: -0.04579194346278591', 'Test LL: -0.03915091812871716', 'Epoch Time (s): 170.35263641225174')
('Epoch 48', 'Objective: -0.10473241088348866', 'Train Acc: 0.9851', 'Test Acc: 0.9875', 'Train LL: -0.04684562246294395', 'Test LL: -0.03778167283263833', 'Epoch Time (s): 170.3094413690269')
('Epoch 49', 'Objective: -0.10295822278807766', 'Train Acc: 0.9858833333333333', 'Test Acc: 0.9862', 'Train LL: -0.0455172239526449', 'Test LL: -0.04279826275526568', 'Epoch Time (s): 170.31777177471668')
('Epoch 50', 'Objective: -0.10332234354015894', 'Train Acc: 0.9855666666666667', 'Test Acc: 0.9873', 'Train LL: -0.045998809228254535', 'Test LL: -0.037749179836944896', 'Epoch Time (s): 170.34020303096622')
('Epoch 51', 'Objective: -0.1016982698782148', 'Train Acc: 0.9863', 'Test Acc: 0.9858', 'Train LL: -0.044700872194881586', 'Test LL: -0.04336500293349155', 'Epoch Time (s): 170.3669759570621')
('Epoch 52', 'Objective: -0.10246859771164893', 'Train Acc: 0.9852333333333333', 'Test Acc: 0.9869', 'Train LL: -0.04567931164804454', 'Test LL: -0.03931447538474404', 'Epoch Time (s): 170.36063838377595')
('Epoch 53', 'Objective: -0.10134811907552303', 'Train Acc: 0.9863333333333333', 'Test Acc: 0.9866', 'Train LL: -0.04479565717184954', 'Test LL: -0.0425499478320394', 'Epoch Time (s): 170.36685893731192')
('Epoch 54', 'Objective: -0.10171033311669207', 'Train Acc: 0.9860833333333333', 'Test Acc: 0.9862', 'Train LL: -0.04538786175845342', 'Test LL: -0.04052141310966966', 'Epoch Time (s): 170.34952265257016')
('Epoch 55', 'Objective: -0.1018145339488685', 'Train Acc: 0.9857833333333333', 'Test Acc: 0.9871', 'Train LL: -0.045805967108430816', 'Test LL: -0.039079275684943314', 'Epoch Time (s): 170.362798709888')
('Epoch 56', 'Objective: -0.10101664773310677', 'Train Acc: 0.9858166666666667', 'Test Acc: 0.9876', 'Train LL: -0.045285146121210526', 'Test LL: -0.03955677671222429', 'Epoch Time (s): 170.35283924872056')
('Epoch 57', 'Objective: -0.09992176019184242', 'Train Acc: 0.98625', 'Test Acc: 0.9875', 'Train LL: -0.044490499243195106', 'Test LL: -0.03902030109562184', 'Epoch Time (s): 170.36941006826237')
('Epoch 58', 'Objective: -0.09941564581636497', 'Train Acc: 0.9862666666666666', 'Test Acc: 0.9868', 'Train LL: -0.04416629761973622', 'Test LL: -0.038801505385867255', 'Epoch Time (s): 170.35466952901334')
('Epoch 59', 'Objective: -0.09950824333307767', 'Train Acc: 0.9860833333333333', 'Test Acc: 0.9888', 'Train LL: -0.044394343398035184', 'Test LL: -0.03701013732258311', 'Epoch Time (s): 170.3752747317776')
('Epoch 60', 'Objective: -0.10029229071030903', 'Train Acc: 0.9854833333333334', 'Test Acc: 0.9876', 'Train LL: -0.045151809396532405', 'Test LL: -0.03858856175290461', 'Epoch Time (s): 170.40037428587675')
('Epoch 61', 'Objective: -0.09894742811438423', 'Train Acc: 0.9858333333333333', 'Test Acc: 0.9857', 'Train LL: -0.044118835742466396', 'Test LL: -0.04306190271436418', 'Epoch Time (s): 170.3887814139016')
('Epoch 62', 'Objective: -0.09822959653936471', 'Train Acc: 0.9862', 'Test Acc: 0.9865', 'Train LL: -0.04364660942461942', 'Test LL: -0.04028279649184938', 'Epoch Time (s): 170.3921736110933')
('Epoch 63', 'Objective: -0.09806178897877499', 'Train Acc: 0.9863', 'Test Acc: 0.9852', 'Train LL: -0.04371890097209857', 'Test LL: -0.04195348426657447', 'Epoch Time (s): 170.35367654589936')
('Epoch 64', 'Objective: -0.09827656215543194', 'Train Acc: 0.9860333333333333', 'Test Acc: 0.987', 'Train LL: -0.04393717707891683', 'Test LL: -0.03966237096374214', 'Epoch Time (s): 170.35648265993223')
('Epoch 65', 'Objective: -0.09877078909267253', 'Train Acc: 0.9861666666666666', 'Test Acc: 0.9885', 'Train LL: -0.044707864108369334', 'Test LL: -0.03466425410864341', 'Epoch Time (s): 170.3322625970468')
('Epoch 66', 'Objective: -0.0973432534127539', 'Train Acc: 0.9860666666666666', 'Test Acc: 0.9874', 'Train LL: -0.043394061506727116', 'Test LL: -0.03692787696904875', 'Epoch Time (s): 170.34961414011195')
('Epoch 67', 'Objective: -0.09695953493244612', 'Train Acc: 0.9859833333333333', 'Test Acc: 0.9846', 'Train LL: -0.04323275934223616', 'Test LL: -0.043785302709079245', 'Epoch Time (s): 170.38048779498786')
('Epoch 68', 'Objective: -0.09714745162135666', 'Train Acc: 0.98625', 'Test Acc: 0.986', 'Train LL: -0.04352988778312254', 'Test LL: -0.04162572510891225', 'Epoch Time (s): 170.3147089369595')
('Epoch 69', 'Objective: -0.0974774679753934', 'Train Acc: 0.9858833333333333', 'Test Acc: 0.9868', 'Train LL: -0.04419066529708073', 'Test LL: -0.040357091178762954', 'Epoch Time (s): 170.35336190508679')
('Epoch 70', 'Objective: -0.09749319971450934', 'Train Acc: 0.9859666666666667', 'Test Acc: 0.9875', 'Train LL: -0.04416940456164089', 'Test LL: -0.03715059915543605', 'Epoch Time (s): 170.35289508663118')
('Epoch 71', 'Objective: -0.09669323817891742', 'Train Acc: 0.9870666666666666', 'Test Acc: 0.9843', 'Train LL: -0.043689171718781394', 'Test LL: -0.04445936922519713', 'Epoch Time (s): 170.39118791511282')
('Epoch 72', 'Objective: -0.09788864776810563', 'Train Acc: 0.9856166666666667', 'Test Acc: 0.9891', 'Train LL: -0.044874485280835784', 'Test LL: -0.036405756330219655', 'Epoch Time (s): 170.3450689688325')
('Epoch 73', 'Objective: -0.09657814679304015', 'Train Acc: 0.9861166666666666', 'Test Acc: 0.9883', 'Train LL: -0.043579964240758606', 'Test LL: -0.03706642542523788', 'Epoch Time (s): 170.38488008407876')
('Epoch 74', 'Objective: -0.09579897477852696', 'Train Acc: 0.9864333333333334', 'Test Acc: 0.9868', 'Train LL: -0.04303728761748816', 'Test LL: -0.04142847833691758', 'Epoch Time (s): 170.3943429128267')
('Epoch 75', 'Objective: -0.09588209218388444', 'Train Acc: 0.9864666666666667', 'Test Acc: 0.9851', 'Train LL: -0.04319252207804013', 'Test LL: -0.04425806608521071', 'Epoch Time (s): 170.33231129776686')
('Epoch 76', 'Objective: -0.09570223381364804', 'Train Acc: 0.9862833333333333', 'Test Acc: 0.9874', 'Train LL: -0.043122012219664066', 'Test LL: -0.03954769603145915', 'Epoch Time (s): 170.35957377497107')
('Epoch 77', 'Objective: -0.09556582763115071', 'Train Acc: 0.9864333333333334', 'Test Acc: 0.9879', 'Train LL: -0.04318144389153914', 'Test LL: -0.035833219134676485', 'Epoch Time (s): 170.39518551714718')
('Epoch 78', 'Objective: -0.09557250384033514', 'Train Acc: 0.9865833333333334', 'Test Acc: 0.9844', 'Train LL: -0.04321867629970614', 'Test LL: -0.04593307217803731', 'Epoch Time (s): 170.35438282741234')
('Epoch 79', 'Objective: -0.0947564239223933', 'Train Acc: 0.98675', 'Test Acc: 0.9869', 'Train LL: -0.04263780379120419', 'Test LL: -0.04051055949429508', 'Epoch Time (s): 170.37850261572748')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.09174335057428865', 'Train Acc: 0.9874833333333334', 'Test Acc: 0.9876', 'Train LL: -0.03995732024808548', 'Test LL: -0.03870165818150547', 'Epoch Time (s): 170.45082054659724')
('Epoch 81', 'Objective: -0.09097124640234723', 'Train Acc: 0.9873833333333333', 'Test Acc: 0.9885', 'Train LL: -0.03942095747632286', 'Test LL: -0.03512862517475745', 'Epoch Time (s): 170.3979446128942')
('Epoch 82', 'Objective: -0.0902041994969994', 'Train Acc: 0.9876833333333334', 'Test Acc: 0.9876', 'Train LL: -0.038738264622448865', 'Test LL: -0.03698564099614325', 'Epoch Time (s): 170.35674397600815')
('Epoch 83', 'Objective: -0.0900631198680193', 'Train Acc: 0.9878333333333333', 'Test Acc: 0.9886', 'Train LL: -0.03870635850113468', 'Test LL: -0.03497636743217122', 'Epoch Time (s): 170.3687786096707')
('Epoch 84', 'Objective: -0.09002383929054653', 'Train Acc: 0.98785', 'Test Acc: 0.9877', 'Train LL: -0.03856199716625305', 'Test LL: -0.035514096691359236', 'Epoch Time (s): 170.39762246795')
('Epoch 85', 'Objective: -0.08922023673647997', 'Train Acc: 0.9881666666666666', 'Test Acc: 0.9885', 'Train LL: -0.0379994158883973', 'Test LL: -0.034740329560221626', 'Epoch Time (s): 170.38101955875754')
('Epoch 86', 'Objective: -0.08937571300696935', 'Train Acc: 0.98845', 'Test Acc: 0.9881', 'Train LL: -0.03807603525545719', 'Test LL: -0.035007922879714014', 'Epoch Time (s): 170.37974257813767')
('Epoch 87', 'Objective: -0.08982396277319793', 'Train Acc: 0.988', 'Test Acc: 0.9887', 'Train LL: -0.03853216110800725', 'Test LL: -0.03622629980777004', 'Epoch Time (s): 170.3505335622467')
('Epoch 88', 'Objective: -0.09006789864499894', 'Train Acc: 0.9875333333333334', 'Test Acc: 0.9887', 'Train LL: -0.038809916798472406', 'Test LL: -0.03531755194185433', 'Epoch Time (s): 170.37121655093506')
('Epoch 89', 'Objective: -0.08958292439752667', 'Train Acc: 0.9877666666666667', 'Test Acc: 0.9878', 'Train LL: -0.03833700688707219', 'Test LL: -0.03778679544700292', 'Epoch Time (s): 170.34985714685172')
('Epoch 90', 'Objective: -0.08986769301954213', 'Train Acc: 0.9879', 'Test Acc: 0.988', 'Train LL: -0.038634553367652535', 'Test LL: -0.036758821290708545', 'Epoch Time (s): 170.3718571108766')
('Epoch 91', 'Objective: -0.08873423754783166', 'Train Acc: 0.9880666666666666', 'Test Acc: 0.9877', 'Train LL: -0.03762626786976718', 'Test LL: -0.037033163376581205', 'Epoch Time (s): 170.4562137722969')
('Epoch 92', 'Objective: -0.08923383151089519', 'Train Acc: 0.9881333333333333', 'Test Acc: 0.9882', 'Train LL: -0.03812533282982787', 'Test LL: -0.03580956597361846', 'Epoch Time (s): 170.38171235704795')
('Epoch 93', 'Objective: -0.08856529694856614', 'Train Acc: 0.9881166666666666', 'Test Acc: 0.9883', 'Train LL: -0.03754292398171602', 'Test LL: -0.03553729467489377', 'Epoch Time (s): 170.36329196207225')
('Epoch 94', 'Objective: -0.08963489567763624', 'Train Acc: 0.9876833333333334', 'Test Acc: 0.9883', 'Train LL: -0.03842430057363118', 'Test LL: -0.035362476619114486', 'Epoch Time (s): 170.35974047100171')
('Epoch 95', 'Objective: -0.08893834718738483', 'Train Acc: 0.98815', 'Test Acc: 0.9882', 'Train LL: -0.03791172548867996', 'Test LL: -0.03616998943508771', 'Epoch Time (s): 170.38159170513973')
('Epoch 96', 'Objective: -0.08954564662892134', 'Train Acc: 0.9879666666666667', 'Test Acc: 0.9886', 'Train LL: -0.03844833333788033', 'Test LL: -0.03508687870703842', 'Epoch Time (s): 170.3602999211289')
('Epoch 97', 'Objective: -0.08897441218314898', 'Train Acc: 0.9883666666666666', 'Test Acc: 0.9882', 'Train LL: -0.037955423750233724', 'Test LL: -0.035976467973790685', 'Epoch Time (s): 170.37558960169554')
('Epoch 98', 'Objective: -0.08852516517150437', 'Train Acc: 0.9881666666666666', 'Test Acc: 0.9884', 'Train LL: -0.03755574619928229', 'Test LL: -0.03568709371005284', 'Epoch Time (s): 170.4007602967322')
('Epoch 99', 'Objective: -0.0886576772082916', 'Train Acc: 0.9881166666666666', 'Test Acc: 0.9885', 'Train LL: -0.037753015340396524', 'Test LL: -0.03493849023449465', 'Epoch Time (s): 170.38183661503717')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.08830881117457628
Final Train Accuracy: £0.9882333333333333
Final Train LL: £-0.037380252192702586
Final Test Accuracy: £0.9886
Final Test LL: £-0.0350952954584464
