dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: none
bn_tscale: none
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3448669230763457', 'Train Acc: 0.5395666666666666', 'Test Acc: 0.7763', 'Train LL: -1.2916665011295583', 'Test LL: -0.6809981696856058', 'Epoch Time (s): 161.6185130670201')
('Epoch 1', 'Objective: -0.5643035732052974', 'Train Acc: 0.8258333333333333', 'Test Acc: 0.8776', 'Train LL: -0.5104961674070024', 'Test LL: -0.35475486962289293', 'Epoch Time (s): 161.71242119697854')
('Epoch 2', 'Objective: -0.35636649882360744', 'Train Acc: 0.90145', 'Test Acc: 0.9351', 'Train LL: -0.30383061240884673', 'Test LL: -0.21190895602995233', 'Epoch Time (s): 161.63500946294516')
('Epoch 3', 'Objective: -0.26348982254658293', 'Train Acc: 0.93395', 'Test Acc: 0.9473', 'Train LL: -0.21249224059243277', 'Test LL: -0.17817299993795876', 'Epoch Time (s): 161.7403743439354')
('Epoch 4', 'Objective: -0.2186273206472606', 'Train Acc: 0.9454666666666667', 'Test Acc: 0.952', 'Train LL: -0.17030775461851744', 'Test LL: -0.15739412380967255', 'Epoch Time (s): 161.64075525011867')
('Epoch 5', 'Objective: -0.19304628130226817', 'Train Acc: 0.9539333333333333', 'Test Acc: 0.9582', 'Train LL: -0.14637466822662737', 'Test LL: -0.13289427954811622', 'Epoch Time (s): 161.65358555293642')
('Epoch 6', 'Objective: -0.1777849038200644', 'Train Acc: 0.9591666666666666', 'Test Acc: 0.9577', 'Train LL: -0.13236761491835972', 'Test LL: -0.13805559811346338', 'Epoch Time (s): 161.63782147993334')
('Epoch 7', 'Objective: -0.16458699861670323', 'Train Acc: 0.9621166666666666', 'Test Acc: 0.9703', 'Train LL: -0.12061635706398782', 'Test LL: -0.0993941092999528', 'Epoch Time (s): 161.7219773309771')
('Epoch 8', 'Objective: -0.15807815128361533', 'Train Acc: 0.9643', 'Test Acc: 0.9633', 'Train LL: -0.11486270945491475', 'Test LL: -0.12195080130646124', 'Epoch Time (s): 161.65587566699833')
('Epoch 9', 'Objective: -0.14816909717021154', 'Train Acc: 0.9671166666666666', 'Test Acc: 0.9673', 'Train LL: -0.10623585375191157', 'Test LL: -0.10153045786506819', 'Epoch Time (s): 161.60944352997467')
('Epoch 10', 'Objective: -0.14248705730218655', 'Train Acc: 0.96885', 'Test Acc: 0.9806', 'Train LL: -0.10134799449445223', 'Test LL: -0.062092520123086685', 'Epoch Time (s): 161.59757199906744')
('Epoch 11', 'Objective: -0.1345209220536276', 'Train Acc: 0.9708', 'Test Acc: 0.9698', 'Train LL: -0.09385461347148168', 'Test LL: -0.09901993321395548', 'Epoch Time (s): 161.57455439702608')
('Epoch 12', 'Objective: -0.13020386575952506', 'Train Acc: 0.97155', 'Test Acc: 0.9707', 'Train LL: -0.09021748472449834', 'Test LL: -0.08897703389364245', 'Epoch Time (s): 161.60628553386778')
('Epoch 13', 'Objective: -0.1280023799604765', 'Train Acc: 0.9731166666666666', 'Test Acc: 0.978', 'Train LL: -0.08854753791853236', 'Test LL: -0.07083640050966938', 'Epoch Time (s): 161.6009720528964')
('Epoch 14', 'Objective: -0.12421168032528068', 'Train Acc: 0.97285', 'Test Acc: 0.9762', 'Train LL: -0.08515774639424853', 'Test LL: -0.07633740610737681', 'Epoch Time (s): 161.59679864905775')
('Epoch 15', 'Objective: -0.12136758824355011', 'Train Acc: 0.9739', 'Test Acc: 0.9658', 'Train LL: -0.08271624027534369', 'Test LL: -0.10270197299801803', 'Epoch Time (s): 161.57216337509453')
('Epoch 16', 'Objective: -0.11605601435861215', 'Train Acc: 0.9749666666666666', 'Test Acc: 0.967', 'Train LL: -0.07807883619350822', 'Test LL: -0.09781691926299843', 'Epoch Time (s): 161.60551710496657')
('Epoch 17', 'Objective: -0.11595683582685969', 'Train Acc: 0.9753', 'Test Acc: 0.9789', 'Train LL: -0.07838453273477691', 'Test LL: -0.06953008624969018', 'Epoch Time (s): 161.61946226796135')
('Epoch 18', 'Objective: -0.11062579493983395', 'Train Acc: 0.9767166666666667', 'Test Acc: 0.9821', 'Train LL: -0.07361661542722632', 'Test LL: -0.05608066437256716', 'Epoch Time (s): 161.61560810310766')
('Epoch 19', 'Objective: -0.10915981937753719', 'Train Acc: 0.9773666666666667', 'Test Acc: 0.9796', 'Train LL: -0.07227878674735715', 'Test LL: -0.06169677811305078', 'Epoch Time (s): 161.60782069386914')
('Epoch 20', 'Objective: -0.1055958349047871', 'Train Acc: 0.9781166666666666', 'Test Acc: 0.9827', 'Train LL: -0.069416147814402', 'Test LL: -0.05597803592873247', 'Epoch Time (s): 161.61458375211805')
('Epoch 21', 'Objective: -0.10556703688939839', 'Train Acc: 0.97855', 'Test Acc: 0.9744', 'Train LL: -0.06968585537618904', 'Test LL: -0.08017275145089105', 'Epoch Time (s): 161.62455691187643')
('Epoch 22', 'Objective: -0.10502724695422452', 'Train Acc: 0.9786333333333334', 'Test Acc: 0.9819', 'Train LL: -0.06928742035283007', 'Test LL: -0.0556904171779836', 'Epoch Time (s): 161.65277827903628')
('Epoch 23', 'Objective: -0.10145166365199329', 'Train Acc: 0.9790333333333333', 'Test Acc: 0.9825', 'Train LL: -0.06617063172994102', 'Test LL: -0.05359235307925132', 'Epoch Time (s): 161.67538362415507')
('Epoch 24', 'Objective: -0.10030591270165629', 'Train Acc: 0.9797833333333333', 'Test Acc: 0.9784', 'Train LL: -0.06531471082344517', 'Test LL: -0.07064049637677013', 'Epoch Time (s): 161.6225880938582')
('Epoch 25', 'Objective: -0.09919654105467905', 'Train Acc: 0.9802166666666666', 'Test Acc: 0.9807', 'Train LL: -0.0643983874450508', 'Test LL: -0.058479116504601074', 'Epoch Time (s): 161.62616010010242')
('Epoch 26', 'Objective: -0.09737284910353938', 'Train Acc: 0.9805166666666667', 'Test Acc: 0.9841', 'Train LL: -0.06282342835262944', 'Test LL: -0.05164827811628744', 'Epoch Time (s): 161.63521155994385')
('Epoch 27', 'Objective: -0.09585510480970291', 'Train Acc: 0.9804666666666667', 'Test Acc: 0.9761', 'Train LL: -0.06160339334675946', 'Test LL: -0.06619551653465892', 'Epoch Time (s): 161.59573552990332')
('Epoch 28', 'Objective: -0.09416933595090908', 'Train Acc: 0.9808', 'Test Acc: 0.9831', 'Train LL: -0.05998116970158203', 'Test LL: -0.055931588880266746', 'Epoch Time (s): 161.61093931808136')
('Epoch 29', 'Objective: -0.09497045220089258', 'Train Acc: 0.9809', 'Test Acc: 0.974', 'Train LL: -0.06096816547569758', 'Test LL: -0.08124836145160688', 'Epoch Time (s): 161.62998557207175')
('Epoch 30', 'Objective: -0.09149650836369214', 'Train Acc: 0.9815666666666667', 'Test Acc: 0.9861', 'Train LL: -0.05784545827824319', 'Test LL: -0.045739424047172045', 'Epoch Time (s): 161.57345679099672')
('Epoch 31', 'Objective: -0.0931129911751574', 'Train Acc: 0.9807833333333333', 'Test Acc: 0.9834', 'Train LL: -0.05956715528605781', 'Test LL: -0.05228611771668716', 'Epoch Time (s): 161.59317935397848')
('Epoch 32', 'Objective: -0.0903677365631058', 'Train Acc: 0.9821', 'Test Acc: 0.9782', 'Train LL: -0.05722316880195627', 'Test LL: -0.06700651744267247', 'Epoch Time (s): 161.64423575694673')
('Epoch 33', 'Objective: -0.08963645597208873', 'Train Acc: 0.9817333333333333', 'Test Acc: 0.9819', 'Train LL: -0.056412513345336056', 'Test LL: -0.05794036523374507', 'Epoch Time (s): 161.6343229468912')
('Epoch 34', 'Objective: -0.08823878235442176', 'Train Acc: 0.98265', 'Test Acc: 0.9806', 'Train LL: -0.055307518951635305', 'Test LL: -0.06278964258053663', 'Epoch Time (s): 161.61636806093156')
('Epoch 35', 'Objective: -0.08787368652196835', 'Train Acc: 0.98265', 'Test Acc: 0.9826', 'Train LL: -0.05485332729806521', 'Test LL: -0.057201378628194334', 'Epoch Time (s): 161.66331580490805')
('Epoch 36', 'Objective: -0.0861356672823352', 'Train Acc: 0.9824833333333334', 'Test Acc: 0.9872', 'Train LL: -0.05354481225571738', 'Test LL: -0.03969363849225454', 'Epoch Time (s): 161.64650752395391')
('Epoch 37', 'Objective: -0.08844522570919193', 'Train Acc: 0.9821666666666666', 'Test Acc: 0.9806', 'Train LL: -0.05569807932156355', 'Test LL: -0.0633255139912231', 'Epoch Time (s): 161.59986718581058')
('Epoch 38', 'Objective: -0.08628219517671717', 'Train Acc: 0.98285', 'Test Acc: 0.9867', 'Train LL: -0.05389363725714884', 'Test LL: -0.042000003984126684', 'Epoch Time (s): 161.67482922994532')
('Epoch 39', 'Objective: -0.08432327190332947', 'Train Acc: 0.98385', 'Test Acc: 0.9843', 'Train LL: -0.05197192275448846', 'Test LL: -0.0500272538745293', 'Epoch Time (s): 161.61027722316794')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06466707730564228', 'Train Acc: 0.9895', 'Test Acc: 0.9913', 'Train LL: -0.034320621472951264', 'Test LL: -0.027773744601085174', 'Epoch Time (s): 161.66733482899144')
('Epoch 41', 'Objective: -0.058625235922128746', 'Train Acc: 0.9905333333333334', 'Test Acc: 0.9902', 'Train LL: -0.029396491680845946', 'Test LL: -0.03090646671425768', 'Epoch Time (s): 161.61476506083272')
('Epoch 42', 'Objective: -0.05712135405123148', 'Train Acc: 0.9910333333333333', 'Test Acc: 0.9903', 'Train LL: -0.02833817139074305', 'Test LL: -0.029377476939374935', 'Epoch Time (s): 161.62624929193407')
('Epoch 43', 'Objective: -0.055688547071001154', 'Train Acc: 0.9914666666666667', 'Test Acc: 0.9884', 'Train LL: -0.027258025382465887', 'Test LL: -0.03346316777582874', 'Epoch Time (s): 161.65170301310718')
('Epoch 44', 'Objective: -0.05474676867023694', 'Train Acc: 0.9915833333333334', 'Test Acc: 0.9897', 'Train LL: -0.02662555130571894', 'Test LL: -0.029912849050671833', 'Epoch Time (s): 161.62226821901277')
('Epoch 45', 'Objective: -0.05406556585406315', 'Train Acc: 0.9915166666666667', 'Test Acc: 0.9885', 'Train LL: -0.026196795958661267', 'Test LL: -0.034210976360817734', 'Epoch Time (s): 161.62240713904612')
('Epoch 46', 'Objective: -0.054560005918227794', 'Train Acc: 0.9916666666666667', 'Test Acc: 0.9899', 'Train LL: -0.026840306542733467', 'Test LL: -0.029785233799930665', 'Epoch Time (s): 161.61123197618872')
('Epoch 47', 'Objective: -0.053299131696530305', 'Train Acc: 0.9919', 'Test Acc: 0.9903', 'Train LL: -0.02573117955514722', 'Test LL: -0.030816083123893417', 'Epoch Time (s): 161.6121934070252')
('Epoch 48', 'Objective: -0.052845815755092805', 'Train Acc: 0.9922166666666666', 'Test Acc: 0.9898', 'Train LL: -0.02546826484307684', 'Test LL: -0.03003924910077885', 'Epoch Time (s): 161.59750920906663')
('Epoch 49', 'Objective: -0.0522875360951632', 'Train Acc: 0.99225', 'Test Acc: 0.9894', 'Train LL: -0.02505447658626662', 'Test LL: -0.03298810324986575', 'Epoch Time (s): 161.6199713081587')
('Epoch 50', 'Objective: -0.052653938918063296', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9911', 'Train LL: -0.025503665316507957', 'Test LL: -0.025664940638788266', 'Epoch Time (s): 161.60759939416312')
('Epoch 51', 'Objective: -0.05160068354164824', 'Train Acc: 0.9920833333333333', 'Test Acc: 0.9896', 'Train LL: -0.02464696606405816', 'Test LL: -0.029043589963292385', 'Epoch Time (s): 161.59690459491685')
('Epoch 52', 'Objective: -0.05154806200203235', 'Train Acc: 0.9921', 'Test Acc: 0.9891', 'Train LL: -0.024698023132272793', 'Test LL: -0.031807025702063466', 'Epoch Time (s): 161.61013727379031')
('Epoch 53', 'Objective: -0.05123427840976676', 'Train Acc: 0.9923166666666666', 'Test Acc: 0.9907', 'Train LL: -0.024403700284008237', 'Test LL: -0.027240336838812176', 'Epoch Time (s): 161.59277843288146')
('Epoch 54', 'Objective: -0.05127865237591428', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9897', 'Train LL: -0.024561546653827263', 'Test LL: -0.02943630539029858', 'Epoch Time (s): 161.61143104196526')
('Epoch 55', 'Objective: -0.05058715910966313', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.991', 'Train LL: -0.024021157545606877', 'Test LL: -0.02946152715257139', 'Epoch Time (s): 161.61186046688817')
('Epoch 56', 'Objective: -0.05032102501841149', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9893', 'Train LL: -0.023813458009097985', 'Test LL: -0.032763506184099456', 'Epoch Time (s): 161.6046572329942')
('Epoch 57', 'Objective: -0.050333897851070196', 'Train Acc: 0.9924', 'Test Acc: 0.9917', 'Train LL: -0.02390180341212303', 'Test LL: -0.027245951452648152', 'Epoch Time (s): 161.58800800004974')
('Epoch 58', 'Objective: -0.04994656182400505', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9899', 'Train LL: -0.023484173645059028', 'Test LL: -0.03031473318343276', 'Epoch Time (s): 161.6043043769896')
('Epoch 59', 'Objective: -0.050067343806872125', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9899', 'Train LL: -0.023710966107519122', 'Test LL: -0.03022022219668279', 'Epoch Time (s): 161.6016093119979')
('Epoch 60', 'Objective: -0.05061468388916318', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9909', 'Train LL: -0.024373766910047976', 'Test LL: -0.02777956102663108', 'Epoch Time (s): 161.58570321905427')
('Epoch 61', 'Objective: -0.04943384386470134', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9907', 'Train LL: -0.02333128358891568', 'Test LL: -0.028212233127484602', 'Epoch Time (s): 161.57373241498135')
('Epoch 62', 'Objective: -0.048990717860770895', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9903', 'Train LL: -0.022890482675386126', 'Test LL: -0.032774336356012825', 'Epoch Time (s): 161.64564113807864')
('Epoch 63', 'Objective: -0.04933425277998051', 'Train Acc: 0.9928', 'Test Acc: 0.9906', 'Train LL: -0.02325411784373637', 'Test LL: -0.029866907164073062', 'Epoch Time (s): 161.62857186817564')
('Epoch 64', 'Objective: -0.04861695552732903', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9918', 'Train LL: -0.022712700306216898', 'Test LL: -0.027778452462409634', 'Epoch Time (s): 161.59168864507228')
('Epoch 65', 'Objective: -0.048791739269713266', 'Train Acc: 0.99245', 'Test Acc: 0.9914', 'Train LL: -0.022888807610044342', 'Test LL: -0.026919009228466996', 'Epoch Time (s): 161.62482244102284')
('Epoch 66', 'Objective: -0.04885548861080471', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9909', 'Train LL: -0.023031730881302094', 'Test LL: -0.02865881780033151', 'Epoch Time (s): 161.64238980598748')
('Epoch 67', 'Objective: -0.048268116126753774', 'Train Acc: 0.99295', 'Test Acc: 0.9905', 'Train LL: -0.02250101764093689', 'Test LL: -0.02956926185087895', 'Epoch Time (s): 161.6257504147943')
('Epoch 68', 'Objective: -0.04844874031208818', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9905', 'Train LL: -0.022732810373794793', 'Test LL: -0.02956091013512868', 'Epoch Time (s): 161.59623681404628')
('Epoch 69', 'Objective: -0.04766350333122396', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.9908', 'Train LL: -0.022026512684634337', 'Test LL: -0.031080942803762873', 'Epoch Time (s): 161.62202469003387')
('Epoch 70', 'Objective: -0.048160387467671595', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9907', 'Train LL: -0.022567775956683418', 'Test LL: -0.028528200935142457', 'Epoch Time (s): 161.59236296103336')
('Epoch 71', 'Objective: -0.047452306353952395', 'Train Acc: 0.9933333333333333', 'Test Acc: 0.9908', 'Train LL: -0.021946235045418115', 'Test LL: -0.030056274841416018', 'Epoch Time (s): 161.62887812615372')
('Epoch 72', 'Objective: -0.0475891915148779', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9906', 'Train LL: -0.022046481072760242', 'Test LL: -0.02808626025513877', 'Epoch Time (s): 161.623650114052')
('Epoch 73', 'Objective: -0.048285789116622284', 'Train Acc: 0.9925', 'Test Acc: 0.9902', 'Train LL: -0.022848277372099657', 'Test LL: -0.030649839719287208', 'Epoch Time (s): 161.65642556082457')
('Epoch 74', 'Objective: -0.047407002742660416', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9912', 'Train LL: -0.02204487123362952', 'Test LL: -0.029415812802509392', 'Epoch Time (s): 161.65876420820132')
('Epoch 75', 'Objective: -0.04644651427488252', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.9915', 'Train LL: -0.0211799002273636', 'Test LL: -0.027835582326239693', 'Epoch Time (s): 161.58592063491233')
('Epoch 76', 'Objective: -0.04708767961897073', 'Train Acc: 0.993', 'Test Acc: 0.9904', 'Train LL: -0.021796221904575058', 'Test LL: -0.03008753475388915', 'Epoch Time (s): 161.53400916885585')
('Epoch 77', 'Objective: -0.04677507570327523', 'Train Acc: 0.9928', 'Test Acc: 0.9916', 'Train LL: -0.021498397039289036', 'Test LL: -0.02830068629792911', 'Epoch Time (s): 161.49906199192628')
('Epoch 78', 'Objective: -0.047166439935707946', 'Train Acc: 0.9927', 'Test Acc: 0.9911', 'Train LL: -0.021970770437851905', 'Test LL: -0.02925932044701141', 'Epoch Time (s): 161.4914671550505')
('Epoch 79', 'Objective: -0.04659968457454566', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9913', 'Train LL: -0.02143178703451728', 'Test LL: -0.027979436924125724', 'Epoch Time (s): 161.502616598038')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.044224390676139216', 'Train Acc: 0.9941', 'Test Acc: 0.9911', 'Train LL: -0.019242707899029002', 'Test LL: -0.02832509644089855', 'Epoch Time (s): 161.51204474898987')
('Epoch 81', 'Objective: -0.04385168432965989', 'Train Acc: 0.994', 'Test Acc: 0.9911', 'Train LL: -0.01892908639764719', 'Test LL: -0.027845486743892162', 'Epoch Time (s): 161.51864434103481')
('Epoch 82', 'Objective: -0.043909761560606476', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9915', 'Train LL: -0.018964679032238307', 'Test LL: -0.026886877379843615', 'Epoch Time (s): 161.51158738019876')
('Epoch 83', 'Objective: -0.04308473660910339', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.9915', 'Train LL: -0.01825268614075669', 'Test LL: -0.027957500836671586', 'Epoch Time (s): 161.51649708882906')
('Epoch 84', 'Objective: -0.04351461515690419', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9916', 'Train LL: -0.018661115868729625', 'Test LL: -0.027932080126163227', 'Epoch Time (s): 161.50366588798352')
('Epoch 85', 'Objective: -0.04301535254218735', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9911', 'Train LL: -0.018188204308425847', 'Test LL: -0.029009050689973056', 'Epoch Time (s): 161.51517166919075')
('Epoch 86', 'Objective: -0.04318385627944253', 'Train Acc: 0.99405', 'Test Acc: 0.9912', 'Train LL: -0.018368170230799223', 'Test LL: -0.027841434347360642', 'Epoch Time (s): 161.5076621279586')
('Epoch 87', 'Objective: -0.04339863031381579', 'Train Acc: 0.9941', 'Test Acc: 0.9912', 'Train LL: -0.0185738972566974', 'Test LL: -0.027628366778485916', 'Epoch Time (s): 161.4974551431369')
('Epoch 88', 'Objective: -0.042571252099734606', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9916', 'Train LL: -0.01781885645824662', 'Test LL: -0.026496275001521945', 'Epoch Time (s): 161.51973668998107')
('Epoch 89', 'Objective: -0.042916669767024525', 'Train Acc: 0.9943', 'Test Acc: 0.9915', 'Train LL: -0.018158925779979133', 'Test LL: -0.028771385254245708', 'Epoch Time (s): 161.49092239211313')
('Epoch 90', 'Objective: -0.042641036184821915', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9918', 'Train LL: -0.01794364729480644', 'Test LL: -0.027626531501845353', 'Epoch Time (s): 161.49204371101223')
('Epoch 91', 'Objective: -0.04277306809867223', 'Train Acc: 0.9941', 'Test Acc: 0.9912', 'Train LL: -0.01804557184013711', 'Test LL: -0.0268404910612064', 'Epoch Time (s): 161.53031828720123')
('Epoch 92', 'Objective: -0.04286693528109041', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.9917', 'Train LL: -0.01816138188084413', 'Test LL: -0.026994173279782673', 'Epoch Time (s): 161.51423205900937')
('Epoch 93', 'Objective: -0.043365824287511', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9916', 'Train LL: -0.018604070573933474', 'Test LL: -0.027741327474047728', 'Epoch Time (s): 161.5021555311978')
('Epoch 94', 'Objective: -0.04248582790045749', 'Train Acc: 0.99445', 'Test Acc: 0.9912', 'Train LL: -0.017804763442129487', 'Test LL: -0.028214541622377333', 'Epoch Time (s): 161.4690391898621')
('Epoch 95', 'Objective: -0.04264300939784577', 'Train Acc: 0.99445', 'Test Acc: 0.9915', 'Train LL: -0.017951913092910825', 'Test LL: -0.02725163953289476', 'Epoch Time (s): 161.46969947800972')
('Epoch 96', 'Objective: -0.0424994971758584', 'Train Acc: 0.9944833333333334', 'Test Acc: 0.9911', 'Train LL: -0.017818356987185632', 'Test LL: -0.027492834059456128', 'Epoch Time (s): 161.4881941168569')
('Epoch 97', 'Objective: -0.04244589207347863', 'Train Acc: 0.99465', 'Test Acc: 0.9917', 'Train LL: -0.0177811435169291', 'Test LL: -0.02753266965398502', 'Epoch Time (s): 161.5092331559863')
('Epoch 98', 'Objective: -0.04210439399275649', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9914', 'Train LL: -0.017466259121750313', 'Test LL: -0.02877847247521059', 'Epoch Time (s): 161.51343708485365')
('Epoch 99', 'Objective: -0.04271362365523033', 'Train Acc: 0.99435', 'Test Acc: 0.9914', 'Train LL: -0.01803221876380779', 'Test LL: -0.028400045556722882', 'Epoch Time (s): 161.48498479602858')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04211736357965509
Final Train Accuracy: £0.99465
Final Train LL: £-0.01750977584795643
Final Test Accuracy: £0.9914
Final Test LL: £-0.028382901375052217
