dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 2
bn_indnorm: local
bn_tnorm: image
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3441332922454343', 'Train Acc: 0.5356666666666666', 'Test Acc: 0.7841', 'Train LL: -1.2933547906800043', 'Test LL: -0.6332073203591307', 'Epoch Time (s): 163.89023957098834')
('Epoch 1', 'Objective: -0.5042206641172764', 'Train Acc: 0.8470333333333333', 'Test Acc: 0.8688', 'Train LL: -0.45067791036248583', 'Test LL: -0.4069203634213086', 'Epoch Time (s): 163.8797460149508')
('Epoch 2', 'Objective: -0.34566099469105216', 'Train Acc: 0.9073166666666667', 'Test Acc: 0.9266', 'Train LL: -0.29379487352071326', 'Test LL: -0.2265466981664234', 'Epoch Time (s): 163.8368809320964')
('Epoch 3', 'Objective: -0.2740818470419337', 'Train Acc: 0.9295666666666667', 'Test Acc: 0.9524', 'Train LL: -0.22531992809826407', 'Test LL: -0.14611052952070017', 'Epoch Time (s): 163.80181418708526')
('Epoch 4', 'Objective: -0.22813154443470884', 'Train Acc: 0.9426833333333333', 'Test Acc: 0.9515', 'Train LL: -0.18104601141450966', 'Test LL: -0.15171302727231972', 'Epoch Time (s): 163.75563947996125')
('Epoch 5', 'Objective: -0.19709666680536675', 'Train Acc: 0.9526666666666667', 'Test Acc: 0.9605', 'Train LL: -0.15209624417530376', 'Test LL: -0.12041997496291411', 'Epoch Time (s): 163.67892621504143')
('Epoch 6', 'Objective: -0.17911922037393543', 'Train Acc: 0.9569166666666666', 'Test Acc: 0.971', 'Train LL: -0.13560254648930373', 'Test LL: -0.08976848393719081', 'Epoch Time (s): 163.68108832812868')
('Epoch 7', 'Objective: -0.1623507682902261', 'Train Acc: 0.9622666666666667', 'Test Acc: 0.9554', 'Train LL: -0.12046153059358686', 'Test LL: -0.13724118333252797', 'Epoch Time (s): 163.74591176002286')
('Epoch 8', 'Objective: -0.15114257539498774', 'Train Acc: 0.9652666666666667', 'Test Acc: 0.9669', 'Train LL: -0.1101330754660193', 'Test LL: -0.09999682460809473', 'Epoch Time (s): 163.78452962706797')
('Epoch 9', 'Objective: -0.14502543111811664', 'Train Acc: 0.9673666666666667', 'Test Acc: 0.9622', 'Train LL: -0.10478753653422333', 'Test LL: -0.12001754669225409', 'Epoch Time (s): 163.71371611091308')
('Epoch 10', 'Objective: -0.13750392682499668', 'Train Acc: 0.9696666666666667', 'Test Acc: 0.9729', 'Train LL: -0.09810822477979515', 'Test LL: -0.09007651861875957', 'Epoch Time (s): 163.67202917998657')
('Epoch 11', 'Objective: -0.12890545306321763', 'Train Acc: 0.97215', 'Test Acc: 0.9672', 'Train LL: -0.0905310450185118', 'Test LL: -0.10458823745846899', 'Epoch Time (s): 163.7064972249791')
('Epoch 12', 'Objective: -0.12712690152249495', 'Train Acc: 0.9720666666666666', 'Test Acc: 0.9759', 'Train LL: -0.0893774180193033', 'Test LL: -0.07672162506866068', 'Epoch Time (s): 163.76518577407114')
('Epoch 13', 'Objective: -0.12255348494468313', 'Train Acc: 0.9735666666666667', 'Test Acc: 0.9776', 'Train LL: -0.0853140188344462', 'Test LL: -0.0672807039554446', 'Epoch Time (s): 163.69400271913037')
('Epoch 14', 'Objective: -0.11878346573902837', 'Train Acc: 0.97555', 'Test Acc: 0.9754', 'Train LL: -0.08226882419913265', 'Test LL: -0.07432066387690547', 'Epoch Time (s): 163.66850004903972')
('Epoch 15', 'Objective: -0.11245888987693717', 'Train Acc: 0.9753333333333334', 'Test Acc: 0.9786', 'Train LL: -0.07643989752788105', 'Test LL: -0.06562488755290967', 'Epoch Time (s): 163.73161906911992')
('Epoch 16', 'Objective: -0.11350169695565107', 'Train Acc: 0.9753666666666667', 'Test Acc: 0.9833', 'Train LL: -0.0775635053172729', 'Test LL: -0.053762256042711364', 'Epoch Time (s): 163.77504867804237')
('Epoch 17', 'Objective: -0.11100803814367155', 'Train Acc: 0.9766', 'Test Acc: 0.9801', 'Train LL: -0.07563606310111609', 'Test LL: -0.061656733707284146', 'Epoch Time (s): 163.67482822784223')
('Epoch 18', 'Objective: -0.1081271134531051', 'Train Acc: 0.9768666666666667', 'Test Acc: 0.9814', 'Train LL: -0.07321885079533212', 'Test LL: -0.05965567966572442', 'Epoch Time (s): 163.7005704541225')
('Epoch 19', 'Objective: -0.10581035733990342', 'Train Acc: 0.9773166666666666', 'Test Acc: 0.9815', 'Train LL: -0.07136803165549403', 'Test LL: -0.05996216982915289', 'Epoch Time (s): 163.68386013200507')
('Epoch 20', 'Objective: -0.10441651293201476', 'Train Acc: 0.9775', 'Test Acc: 0.9671', 'Train LL: -0.07046788079749748', 'Test LL: -0.09882623443207203', 'Epoch Time (s): 163.77522237296216')
('Epoch 21', 'Objective: -0.10295795546216376', 'Train Acc: 0.9781333333333333', 'Test Acc: 0.9721', 'Train LL: -0.06938950037178486', 'Test LL: -0.08550366775092548', 'Epoch Time (s): 163.78027131804265')
('Epoch 22', 'Objective: -0.10094820497219348', 'Train Acc: 0.97825', 'Test Acc: 0.9716', 'Train LL: -0.06777360763168735', 'Test LL: -0.08593064692631863', 'Epoch Time (s): 163.69719553389587')
('Epoch 23', 'Objective: -0.09933806871277431', 'Train Acc: 0.9787333333333333', 'Test Acc: 0.9784', 'Train LL: -0.066540513047191', 'Test LL: -0.06757911525857155', 'Epoch Time (s): 163.68975035496987')
('Epoch 24', 'Objective: -0.09725333048631003', 'Train Acc: 0.9792666666666666', 'Test Acc: 0.9866', 'Train LL: -0.0645471787505851', 'Test LL: -0.04346229471244678', 'Epoch Time (s): 163.7451373829972')
('Epoch 25', 'Objective: -0.0957727033756532', 'Train Acc: 0.9800833333333333', 'Test Acc: 0.9829', 'Train LL: -0.06347472427051702', 'Test LL: -0.054817550882449974', 'Epoch Time (s): 163.76159348688088')
('Epoch 26', 'Objective: -0.09447794792378511', 'Train Acc: 0.9806666666666667', 'Test Acc: 0.9764', 'Train LL: -0.0623610207925924', 'Test LL: -0.0722856307111316', 'Epoch Time (s): 163.71561297099106')
('Epoch 27', 'Objective: -0.09541535319253937', 'Train Acc: 0.9799666666666667', 'Test Acc: 0.9841', 'Train LL: -0.06340617989808195', 'Test LL: -0.051895664327023895', 'Epoch Time (s): 163.69234009296633')
('Epoch 28', 'Objective: -0.09304489566664674', 'Train Acc: 0.98035', 'Test Acc: 0.9809', 'Train LL: -0.06139591327599083', 'Test LL: -0.055598258278937954', 'Epoch Time (s): 163.6906600529328')
('Epoch 29', 'Objective: -0.09072059098220535', 'Train Acc: 0.9815833333333334', 'Test Acc: 0.9818', 'Train LL: -0.05940705511299975', 'Test LL: -0.05506269739506822', 'Epoch Time (s): 163.76371721108444')
('Epoch 30', 'Objective: -0.08900517417550008', 'Train Acc: 0.9818833333333333', 'Test Acc: 0.9815', 'Train LL: -0.05805399259408149', 'Test LL: -0.05656192850567814', 'Epoch Time (s): 163.68051454098895')
('Epoch 31', 'Objective: -0.08938833175395335', 'Train Acc: 0.9813', 'Test Acc: 0.9867', 'Train LL: -0.05860563303103985', 'Test LL: -0.04194012886305079', 'Epoch Time (s): 163.69772164314054')
('Epoch 32', 'Objective: -0.08745875995738109', 'Train Acc: 0.9823166666666666', 'Test Acc: 0.9836', 'Train LL: -0.05701445005284909', 'Test LL: -0.04783006106599517', 'Epoch Time (s): 163.71566737396643')
('Epoch 33', 'Objective: -0.08603070590621446', 'Train Acc: 0.98235', 'Test Acc: 0.985', 'Train LL: -0.055775732193658466', 'Test LL: -0.0473540650505541', 'Epoch Time (s): 163.7675111249555')
('Epoch 34', 'Objective: -0.08518226822905163', 'Train Acc: 0.9825', 'Test Acc: 0.985', 'Train LL: -0.055087100045446785', 'Test LL: -0.04549293794894429', 'Epoch Time (s): 163.7512515601702')
('Epoch 35', 'Objective: -0.08427969842647075', 'Train Acc: 0.9826', 'Test Acc: 0.9875', 'Train LL: -0.05444713009232811', 'Test LL: -0.03888884818625099', 'Epoch Time (s): 163.6899006620515')
('Epoch 36', 'Objective: -0.083617036064425', 'Train Acc: 0.9834333333333334', 'Test Acc: 0.983', 'Train LL: -0.053667877188615626', 'Test LL: -0.05124623871192795', 'Epoch Time (s): 163.69890407286584')
('Epoch 37', 'Objective: -0.08434669149544798', 'Train Acc: 0.9824', 'Test Acc: 0.9855', 'Train LL: -0.05458642074306334', 'Test LL: -0.04734393889441923', 'Epoch Time (s): 163.7814743348863')
('Epoch 38', 'Objective: -0.08235748643219314', 'Train Acc: 0.9828333333333333', 'Test Acc: 0.9828', 'Train LL: -0.052745166108571925', 'Test LL: -0.055585833141698814', 'Epoch Time (s): 163.7855460359715')
('Epoch 39', 'Objective: -0.08209988811880384', 'Train Acc: 0.9833833333333334', 'Test Acc: 0.9777', 'Train LL: -0.05267397096225007', 'Test LL: -0.07175362597226781', 'Epoch Time (s): 163.77464576088823')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06129696742043089', 'Train Acc: 0.9889', 'Test Acc: 0.9909', 'Train LL: -0.033673316589488425', 'Test LL: -0.029585557758178147', 'Epoch Time (s): 163.68524219607934')
('Epoch 41', 'Objective: -0.05576381009428534', 'Train Acc: 0.9904666666666667', 'Test Acc: 0.9907', 'Train LL: -0.029098534977548364', 'Test LL: -0.02805577237712059', 'Epoch Time (s): 163.70435592299327')
('Epoch 42', 'Objective: -0.05386844932380832', 'Train Acc: 0.99145', 'Test Acc: 0.9907', 'Train LL: -0.027763615618045176', 'Test LL: -0.02643088599847549', 'Epoch Time (s): 163.7646009081509')
('Epoch 43', 'Objective: -0.052368685925612876', 'Train Acc: 0.99145', 'Test Acc: 0.9913', 'Train LL: -0.026581147320115975', 'Test LL: -0.025757076559566106', 'Epoch Time (s): 163.773603416048')
('Epoch 44', 'Objective: -0.05200326958540998', 'Train Acc: 0.9915666666666667', 'Test Acc: 0.9909', 'Train LL: -0.02648384323798121', 'Test LL: -0.02945617183601865', 'Epoch Time (s): 163.6906996150501')
('Epoch 45', 'Objective: -0.05205611747107015', 'Train Acc: 0.9914333333333334', 'Test Acc: 0.9915', 'Train LL: -0.026763731676578393', 'Test LL: -0.025465038926739122', 'Epoch Time (s): 163.683807563968')
('Epoch 46', 'Objective: -0.05020022697545486', 'Train Acc: 0.9923166666666666', 'Test Acc: 0.9912', 'Train LL: -0.025167178570379724', 'Test LL: -0.028471794252659662', 'Epoch Time (s): 163.70881721610203')
('Epoch 47', 'Objective: -0.05042998181613428', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9913', 'Train LL: -0.025631844672076975', 'Test LL: -0.027423054205511086', 'Epoch Time (s): 163.74678948079236')
('Epoch 48', 'Objective: -0.04955124162326506', 'Train Acc: 0.9917', 'Test Acc: 0.9921', 'Train LL: -0.02480057432296257', 'Test LL: -0.02609101344187791', 'Epoch Time (s): 163.7019330279436')
('Epoch 49', 'Objective: -0.04870748418240742', 'Train Acc: 0.9923166666666666', 'Test Acc: 0.9905', 'Train LL: -0.024136686068545736', 'Test LL: -0.027157039342794967', 'Epoch Time (s): 163.70513642393053')
('Epoch 50', 'Objective: -0.048247088130889036', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9914', 'Train LL: -0.02371665977935808', 'Test LL: -0.026768369326778747', 'Epoch Time (s): 163.70183278503828')
('Epoch 51', 'Objective: -0.0485884278235225', 'Train Acc: 0.9922', 'Test Acc: 0.991', 'Train LL: -0.024198975915304604', 'Test LL: -0.028200604327247386', 'Epoch Time (s): 163.75344793498516')
('Epoch 52', 'Objective: -0.048121632068699224', 'Train Acc: 0.9923', 'Test Acc: 0.992', 'Train LL: -0.023859084059753097', 'Test LL: -0.025252144879699165', 'Epoch Time (s): 163.68048892193474')
('Epoch 53', 'Objective: -0.047927223930903574', 'Train Acc: 0.9922666666666666', 'Test Acc: 0.9919', 'Train LL: -0.023770888105668242', 'Test LL: -0.027423736488565453', 'Epoch Time (s): 163.7027792048175')
('Epoch 54', 'Objective: -0.04770680692737632', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.9912', 'Train LL: -0.02346778347429691', 'Test LL: -0.02736180279310588', 'Epoch Time (s): 163.69755554082803')
('Epoch 55', 'Objective: -0.04709620046374018', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9918', 'Train LL: -0.022993861667233446', 'Test LL: -0.025913160128598407', 'Epoch Time (s): 163.804887911072')
('Epoch 56', 'Objective: -0.04734439494626232', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9919', 'Train LL: -0.02340937529534483', 'Test LL: -0.02557822115285237', 'Epoch Time (s): 163.80312977498397')
('Epoch 57', 'Objective: -0.046966880141425235', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9914', 'Train LL: -0.023104387100278356', 'Test LL: -0.026629041666082508', 'Epoch Time (s): 163.45583860995248')
('Epoch 58', 'Objective: -0.04583701336298607', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9914', 'Train LL: -0.022053152457541973', 'Test LL: -0.026837165652001782', 'Epoch Time (s): 163.42860539001413')
('Epoch 59', 'Objective: -0.04604636128313206', 'Train Acc: 0.99295', 'Test Acc: 0.9925', 'Train LL: -0.02240808709561849', 'Test LL: -0.02609666931283288', 'Epoch Time (s): 163.43307102215476')
('Epoch 60', 'Objective: -0.0463556640035987', 'Train Acc: 0.9926333333333334', 'Test Acc: 0.9905', 'Train LL: -0.022574998747449036', 'Test LL: -0.02917357893375837', 'Epoch Time (s): 163.42973531782627')
('Epoch 61', 'Objective: -0.04583212783840077', 'Train Acc: 0.99275', 'Test Acc: 0.9905', 'Train LL: -0.02217767797142592', 'Test LL: -0.030569854862071692', 'Epoch Time (s): 163.41625542379916')
('Epoch 62', 'Objective: -0.04562809401199995', 'Train Acc: 0.9926833333333334', 'Test Acc: 0.9913', 'Train LL: -0.022029413563210445', 'Test LL: -0.028760392437158718', 'Epoch Time (s): 163.43453608988784')
('Epoch 63', 'Objective: -0.04514252662570379', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9913', 'Train LL: -0.0218250099461396', 'Test LL: -0.027038979830044326', 'Epoch Time (s): 163.45905016106553')
('Epoch 64', 'Objective: -0.04539873717707299', 'Train Acc: 0.99295', 'Test Acc: 0.9907', 'Train LL: -0.02202158166838927', 'Test LL: -0.02649439968027491', 'Epoch Time (s): 163.42334966082126')
('Epoch 65', 'Objective: -0.04604418108339473', 'Train Acc: 0.99245', 'Test Acc: 0.9922', 'Train LL: -0.022668689261827885', 'Test LL: -0.026506258667708896', 'Epoch Time (s): 163.41863043303601')
('Epoch 66', 'Objective: -0.04465345042688773', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9922', 'Train LL: -0.02143448944294844', 'Test LL: -0.024174891978975502', 'Epoch Time (s): 163.43309814995155')
('Epoch 67', 'Objective: -0.045046559897538294', 'Train Acc: 0.99245', 'Test Acc: 0.9894', 'Train LL: -0.021776760727384607', 'Test LL: -0.03243917385823316', 'Epoch Time (s): 163.4353942850139')
('Epoch 68', 'Objective: -0.044556022239631767', 'Train Acc: 0.9931833333333333', 'Test Acc: 0.9907', 'Train LL: -0.021475931148677428', 'Test LL: -0.027787436500422973', 'Epoch Time (s): 163.43407343584113')
('Epoch 69', 'Objective: -0.0446548301264149', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9914', 'Train LL: -0.02154245805796664', 'Test LL: -0.026465861307913705', 'Epoch Time (s): 163.44128569494933')
('Epoch 70', 'Objective: -0.04498991240826186', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9927', 'Train LL: -0.021901667549759002', 'Test LL: -0.025084269187336215', 'Epoch Time (s): 163.41366906301118')
('Epoch 71', 'Objective: -0.04387847613662236', 'Train Acc: 0.9935166666666667', 'Test Acc: 0.9894', 'Train LL: -0.020902790613615517', 'Test LL: -0.03152645318993967', 'Epoch Time (s): 163.4361969931051')
('Epoch 72', 'Objective: -0.04442428008446437', 'Train Acc: 0.9931', 'Test Acc: 0.9913', 'Train LL: -0.02148142607242784', 'Test LL: -0.02816674054510247', 'Epoch Time (s): 163.4266752898693')
('Epoch 73', 'Objective: -0.043653277636814036', 'Train Acc: 0.9933833333333333', 'Test Acc: 0.9922', 'Train LL: -0.02076257138289781', 'Test LL: -0.02690416942382833', 'Epoch Time (s): 163.41710240999237')
('Epoch 74', 'Objective: -0.04357360883408276', 'Train Acc: 0.9935833333333334', 'Test Acc: 0.99', 'Train LL: -0.020639739197793817', 'Test LL: -0.03078908366715342', 'Epoch Time (s): 163.39134989399463')
('Epoch 75', 'Objective: -0.04420609723518597', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9913', 'Train LL: -0.021311231311226593', 'Test LL: -0.027416524432762275', 'Epoch Time (s): 163.34266957710497')
('Epoch 76', 'Objective: -0.04343277593396335', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9902', 'Train LL: -0.02066322944520329', 'Test LL: -0.030989191896051562', 'Epoch Time (s): 163.31092047691345')
('Epoch 77', 'Objective: -0.04324998347819209', 'Train Acc: 0.99335', 'Test Acc: 0.9917', 'Train LL: -0.020435140864819106', 'Test LL: -0.027060326713726403', 'Epoch Time (s): 163.24261052487418')
('Epoch 78', 'Objective: -0.04371988374520257', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9906', 'Train LL: -0.020858513683060437', 'Test LL: -0.02853707125704225', 'Epoch Time (s): 163.22609801404178')
('Epoch 79', 'Objective: -0.04331912112200511', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9897', 'Train LL: -0.02068007333072117', 'Test LL: -0.03102451132114794', 'Epoch Time (s): 163.2621010299772')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04078189616685262', 'Train Acc: 0.9942166666666666', 'Test Acc: 0.9909', 'Train LL: -0.018239323308043676', 'Test LL: -0.02735747550506153', 'Epoch Time (s): 163.24599027214572')
('Epoch 81', 'Objective: -0.04027346895824745', 'Train Acc: 0.9943833333333333', 'Test Acc: 0.9916', 'Train LL: -0.017902866334951265', 'Test LL: -0.026343083831327545', 'Epoch Time (s): 163.2502604459878')
('Epoch 82', 'Objective: -0.04027364199859303', 'Train Acc: 0.9939666666666667', 'Test Acc: 0.9914', 'Train LL: -0.017866832361523945', 'Test LL: -0.02643030413117861', 'Epoch Time (s): 163.2592751190532')
('Epoch 83', 'Objective: -0.039897915691813404', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9919', 'Train LL: -0.017550426693344737', 'Test LL: -0.02594481401691899', 'Epoch Time (s): 163.2498421720229')
('Epoch 84', 'Objective: -0.039164015692152575', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9917', 'Train LL: -0.0168305752656369', 'Test LL: -0.026304365274816194', 'Epoch Time (s): 163.22717432188801')
('Epoch 85', 'Objective: -0.03932892178964189', 'Train Acc: 0.9944333333333333', 'Test Acc: 0.9915', 'Train LL: -0.01702565147256388', 'Test LL: -0.02668716619880417', 'Epoch Time (s): 163.24040956585668')
('Epoch 86', 'Objective: -0.039084106751930275', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9918', 'Train LL: -0.016768752874099832', 'Test LL: -0.026062679670508918', 'Epoch Time (s): 163.26187280006707')
('Epoch 87', 'Objective: -0.03948374155775399', 'Train Acc: 0.99425', 'Test Acc: 0.9915', 'Train LL: -0.017147528466381744', 'Test LL: -0.026258000199829757', 'Epoch Time (s): 163.2696400450077')
('Epoch 88', 'Objective: -0.03937032291233133', 'Train Acc: 0.9946', 'Test Acc: 0.9919', 'Train LL: -0.01705021942831213', 'Test LL: -0.026169051163919228', 'Epoch Time (s): 163.21274729422294')
('Epoch 89', 'Objective: -0.03898871863047696', 'Train Acc: 0.9945', 'Test Acc: 0.9909', 'Train LL: -0.016667181118858603', 'Test LL: -0.027446148435411884', 'Epoch Time (s): 163.2394186409656')
('Epoch 90', 'Objective: -0.039602504088687276', 'Train Acc: 0.9945', 'Test Acc: 0.9918', 'Train LL: -0.01720280320707716', 'Test LL: -0.02584085183066017', 'Epoch Time (s): 163.241891376907')
('Epoch 91', 'Objective: -0.039024584858335515', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9915', 'Train LL: -0.01668559148474698', 'Test LL: -0.02692881317382432', 'Epoch Time (s): 163.24918381986208')
('Epoch 92', 'Objective: -0.039223236974313326', 'Train Acc: 0.9942', 'Test Acc: 0.9916', 'Train LL: -0.016896095945288642', 'Test LL: -0.02672744641068125', 'Epoch Time (s): 163.23359074397013')
('Epoch 93', 'Objective: -0.03839598268210657', 'Train Acc: 0.99485', 'Test Acc: 0.9917', 'Train LL: -0.016172379805106295', 'Test LL: -0.02637375258453622', 'Epoch Time (s): 163.25522009516135')
('Epoch 94', 'Objective: -0.03929424366517845', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9915', 'Train LL: -0.01693016321500451', 'Test LL: -0.027148849743205052', 'Epoch Time (s): 163.2462891000323')
('Epoch 95', 'Objective: -0.03851638191535665', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.992', 'Train LL: -0.016238811877086194', 'Test LL: -0.02613694365519235', 'Epoch Time (s): 163.2579272009898')
('Epoch 96', 'Objective: -0.0393261415117181', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9916', 'Train LL: -0.016973333254232014', 'Test LL: -0.026025942733942264', 'Epoch Time (s): 163.24023577105254')
('Epoch 97', 'Objective: -0.038752649763786506', 'Train Acc: 0.9944', 'Test Acc: 0.9916', 'Train LL: -0.016434265218240634', 'Test LL: -0.02629550213729988', 'Epoch Time (s): 163.22998374793679')
('Epoch 98', 'Objective: -0.038581180544863855', 'Train Acc: 0.9947', 'Test Acc: 0.9914', 'Train LL: -0.016344162687121133', 'Test LL: -0.0268581244436094', 'Epoch Time (s): 163.26211699703708')
('Epoch 99', 'Objective: -0.03885070620080879', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9916', 'Train LL: -0.016548841655859733', 'Test LL: -0.026135409580031698', 'Epoch Time (s): 163.25077192508616')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03853529478345341
Final Train Accuracy: £0.9950333333333333
Final Train LL: £-0.016288519890744507
Final Test Accuracy: £0.9916
Final Test LL: £-0.02619978264472416
