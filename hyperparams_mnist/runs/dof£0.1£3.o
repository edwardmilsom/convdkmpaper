dataset: MNIST
dtype: float64
dof: 0.1
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.261849350245947', 'Train Acc: 0.5612333333333334', 'Test Acc: 0.7846', 'Train LL: -1.2233446836461472', 'Test LL: -0.6397010920752866', 'Epoch Time (s): 164.70721699809656')
('Epoch 1', 'Objective: -0.49938761920168356', 'Train Acc: 0.8407666666666667', 'Test Acc: 0.8721', 'Train LL: -0.4682278207809592', 'Test LL: -0.4081560405414331', 'Epoch Time (s): 164.8107618249487')
('Epoch 2', 'Objective: -0.2905684748663362', 'Train Acc: 0.9173833333333333', 'Test Acc: 0.9377', 'Train LL: -0.26265288528389746', 'Test LL: -0.19481776098610926', 'Epoch Time (s): 164.78754990710877')
('Epoch 3', 'Objective: -0.2126095735454707', 'Train Acc: 0.9410833333333334', 'Test Acc: 0.9593', 'Train LL: -0.18753380826148536', 'Test LL: -0.1260462396658304', 'Epoch Time (s): 164.7769753751345')
('Epoch 4', 'Objective: -0.18178261773014284', 'Train Acc: 0.9502333333333334', 'Test Acc: 0.9515', 'Train LL: -0.15866423356335096', 'Test LL: -0.15018013240376235', 'Epoch Time (s): 164.78284563100897')
('Epoch 5', 'Objective: -0.15572536284832708', 'Train Acc: 0.9587833333333333', 'Test Acc: 0.9415', 'Train LL: -0.13406732829753662', 'Test LL: -0.1954208328928688', 'Epoch Time (s): 164.80413554399274')
('Epoch 6', 'Objective: -0.1408859320419366', 'Train Acc: 0.9619833333333333', 'Test Acc: 0.9662', 'Train LL: -0.12018203547478767', 'Test LL: -0.10358374101379464', 'Epoch Time (s): 164.52309796982445')
('Epoch 7', 'Objective: -0.13158688055085024', 'Train Acc: 0.965', 'Test Acc: 0.9707', 'Train LL: -0.11182685864530306', 'Test LL: -0.08894117374323855', 'Epoch Time (s): 164.4366042970214')
('Epoch 8', 'Objective: -0.11940244918413367', 'Train Acc: 0.96855', 'Test Acc: 0.9666', 'Train LL: -0.10045314681224239', 'Test LL: -0.10760624504065816', 'Epoch Time (s): 164.3312954888679')
('Epoch 9', 'Objective: -0.11266530055463467', 'Train Acc: 0.9704333333333334', 'Test Acc: 0.9752', 'Train LL: -0.09428593784109379', 'Test LL: -0.08029875719414926', 'Epoch Time (s): 164.36997519689612')
('Epoch 10', 'Objective: -0.10871863275186738', 'Train Acc: 0.9713666666666667', 'Test Acc: 0.9675', 'Train LL: -0.09084033362426992', 'Test LL: -0.09976534475117246', 'Epoch Time (s): 164.3837616420351')
('Epoch 11', 'Objective: -0.10473654833954732', 'Train Acc: 0.9719833333333333', 'Test Acc: 0.9726', 'Train LL: -0.08703657895497217', 'Test LL: -0.08371528912255569', 'Epoch Time (s): 164.38161838287488')
('Epoch 12', 'Objective: -0.09911226956801995', 'Train Acc: 0.9744833333333334', 'Test Acc: 0.9683', 'Train LL: -0.08201644393404552', 'Test LL: -0.0988553046196432', 'Epoch Time (s): 164.43429593904875')
('Epoch 13', 'Objective: -0.09359907047990476', 'Train Acc: 0.9750333333333333', 'Test Acc: 0.9772', 'Train LL: -0.07684891551426767', 'Test LL: -0.06951478056473585', 'Epoch Time (s): 164.47505750600249')
('Epoch 14', 'Objective: -0.09236734487062637', 'Train Acc: 0.9758333333333333', 'Test Acc: 0.9824', 'Train LL: -0.07629467432451904', 'Test LL: -0.05771250405277293', 'Epoch Time (s): 164.43418095307425')
('Epoch 15', 'Objective: -0.08731476045523161', 'Train Acc: 0.97725', 'Test Acc: 0.9769', 'Train LL: -0.07132982453267046', 'Test LL: -0.06686319279511937', 'Epoch Time (s): 164.44143004203215')
('Epoch 16', 'Objective: -0.08549536602194197', 'Train Acc: 0.97765', 'Test Acc: 0.9806', 'Train LL: -0.06989136199028187', 'Test LL: -0.05928242274116475', 'Epoch Time (s): 164.441155053908')
('Epoch 17', 'Objective: -0.08487704827149037', 'Train Acc: 0.9781', 'Test Acc: 0.9845', 'Train LL: -0.06953827672570925', 'Test LL: -0.05337468126023094', 'Epoch Time (s): 164.38016788079403')
('Epoch 18', 'Objective: -0.08074566961151278', 'Train Acc: 0.9789666666666667', 'Test Acc: 0.9845', 'Train LL: -0.06563908653311849', 'Test LL: -0.051340961101967786', 'Epoch Time (s): 164.25885354191996')
('Epoch 19', 'Objective: -0.07925813078140986', 'Train Acc: 0.97955', 'Test Acc: 0.9796', 'Train LL: -0.06446732037473388', 'Test LL: -0.05726561628707274', 'Epoch Time (s): 164.30762518499978')
('Epoch 20', 'Objective: -0.07731220519499232', 'Train Acc: 0.9796833333333334', 'Test Acc: 0.9603', 'Train LL: -0.06274017498487806', 'Test LL: -0.11989280396273061', 'Epoch Time (s): 164.26765879010782')
('Epoch 21', 'Objective: -0.07505181383791443', 'Train Acc: 0.9809666666666667', 'Test Acc: 0.9823', 'Train LL: -0.06084427299523336', 'Test LL: -0.05600817622236559', 'Epoch Time (s): 164.37507977103814')
('Epoch 22', 'Objective: -0.07339046656944179', 'Train Acc: 0.98095', 'Test Acc: 0.9821', 'Train LL: -0.05945822701020952', 'Test LL: -0.050291120458118344', 'Epoch Time (s): 164.36887204879895')
('Epoch 23', 'Objective: -0.07276901775866179', 'Train Acc: 0.9816166666666667', 'Test Acc: 0.9791', 'Train LL: -0.05902715206091968', 'Test LL: -0.06121603118371299', 'Epoch Time (s): 164.30183422588743')
('Epoch 24', 'Objective: -0.07081573690654303', 'Train Acc: 0.9816666666666667', 'Test Acc: 0.9838', 'Train LL: -0.05717669378858108', 'Test LL: -0.049949280688301206', 'Epoch Time (s): 164.278218974825')
('Epoch 25', 'Objective: -0.06938444291116613', 'Train Acc: 0.9815333333333334', 'Test Acc: 0.98', 'Train LL: -0.05601422515314357', 'Test LL: -0.05664888655885411', 'Epoch Time (s): 164.40086549590342')
('Epoch 26', 'Objective: -0.06748040668376694', 'Train Acc: 0.9828166666666667', 'Test Acc: 0.9837', 'Train LL: -0.05426448380166551', 'Test LL: -0.04923901019220769', 'Epoch Time (s): 164.31223441287875')
('Epoch 27', 'Objective: -0.0686982110528428', 'Train Acc: 0.982', 'Test Acc: 0.9854', 'Train LL: -0.055671794793837506', 'Test LL: -0.047863345421736876', 'Epoch Time (s): 164.25107603007928')
('Epoch 28', 'Objective: -0.0643413603585606', 'Train Acc: 0.98335', 'Test Acc: 0.9807', 'Train LL: -0.051375124639347805', 'Test LL: -0.06014032297692614', 'Epoch Time (s): 164.29924935195595')
('Epoch 29', 'Objective: -0.06521708467936596', 'Train Acc: 0.9823166666666666', 'Test Acc: 0.9809', 'Train LL: -0.05241882932216505', 'Test LL: -0.06012339732568633', 'Epoch Time (s): 164.4056844348088')
('Epoch 30', 'Objective: -0.06253871353357358', 'Train Acc: 0.9842', 'Test Acc: 0.9881', 'Train LL: -0.04987641870714906', 'Test LL: -0.04016835011238282', 'Epoch Time (s): 164.66658613504842')
('Epoch 31', 'Objective: -0.06257053195011568', 'Train Acc: 0.9843', 'Test Acc: 0.9859', 'Train LL: -0.050104607607554176', 'Test LL: -0.046201142636367605', 'Epoch Time (s): 164.8010378801264')
('Epoch 32', 'Objective: -0.06261744933243094', 'Train Acc: 0.9837333333333333', 'Test Acc: 0.985', 'Train LL: -0.050160830498804446', 'Test LL: -0.04595679313575599', 'Epoch Time (s): 164.7450748370029')
('Epoch 33', 'Objective: -0.06169491113638845', 'Train Acc: 0.9838166666666667', 'Test Acc: 0.9857', 'Train LL: -0.04948817554041826', 'Test LL: -0.04718824160980079', 'Epoch Time (s): 164.59629688994028')
('Epoch 34', 'Objective: -0.06024830829965424', 'Train Acc: 0.9845833333333334', 'Test Acc: 0.9855', 'Train LL: -0.048115065717140866', 'Test LL: -0.04637003189487625', 'Epoch Time (s): 164.5713316879701')
('Epoch 35', 'Objective: -0.060437391661828294', 'Train Acc: 0.9842166666666666', 'Test Acc: 0.986', 'Train LL: -0.04844886155876475', 'Test LL: -0.04053830674929435', 'Epoch Time (s): 164.55179234710522')
('Epoch 36', 'Objective: -0.059259458206251676', 'Train Acc: 0.9849333333333333', 'Test Acc: 0.9857', 'Train LL: -0.047444254097403764', 'Test LL: -0.044689245676404726', 'Epoch Time (s): 164.49698394699953')
('Epoch 37', 'Objective: -0.0587323175414811', 'Train Acc: 0.9846166666666667', 'Test Acc: 0.9825', 'Train LL: -0.04702307305143299', 'Test LL: -0.05535512240066446', 'Epoch Time (s): 164.44630931480788')
('Epoch 38', 'Objective: -0.05694681364268613', 'Train Acc: 0.9851166666666666', 'Test Acc: 0.9853', 'Train LL: -0.04531354720015197', 'Test LL: -0.048857257685417474', 'Epoch Time (s): 164.22521181008779')
('Epoch 39', 'Objective: -0.056946190767683764', 'Train Acc: 0.9855333333333334', 'Test Acc: 0.9848', 'Train LL: -0.045406206561692385', 'Test LL: -0.050037468163317694', 'Epoch Time (s): 164.4770201498177')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.03845113290906859', 'Train Acc: 0.9909166666666667', 'Test Acc: 0.9893', 'Train LL: -0.027688653772981724', 'Test LL: -0.030750837099253567', 'Epoch Time (s): 164.3825403789524')
('Epoch 41', 'Objective: -0.0329419673824852', 'Train Acc: 0.9927', 'Test Acc: 0.9898', 'Train LL: -0.022753244807274496', 'Test LL: -0.02933638551892436', 'Epoch Time (s): 164.2374292658642')
('Epoch 42', 'Objective: -0.031999398155372935', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9905', 'Train LL: -0.022052041481134627', 'Test LL: -0.02526314607570033', 'Epoch Time (s): 164.2401320540812')
('Epoch 43', 'Objective: -0.030083772092873554', 'Train Acc: 0.99355', 'Test Acc: 0.9913', 'Train LL: -0.020278327116393904', 'Test LL: -0.025668295961634856', 'Epoch Time (s): 164.2621326080989')
('Epoch 44', 'Objective: -0.030377649207191944', 'Train Acc: 0.9934333333333333', 'Test Acc: 0.9917', 'Train LL: -0.020641137417640856', 'Test LL: -0.02409472000230631', 'Epoch Time (s): 164.71728504286148')
('Epoch 45', 'Objective: -0.029451794041999834', 'Train Acc: 0.99365', 'Test Acc: 0.9916', 'Train LL: -0.019840509726605813', 'Test LL: -0.025790022662678876', 'Epoch Time (s): 164.8819967911113')
('Epoch 46', 'Objective: -0.02865560173829016', 'Train Acc: 0.9939333333333333', 'Test Acc: 0.9917', 'Train LL: -0.019064738448186413', 'Test LL: -0.02563719498822178', 'Epoch Time (s): 164.90739966905676')
('Epoch 47', 'Objective: -0.027336827349577417', 'Train Acc: 0.9940833333333333', 'Test Acc: 0.9914', 'Train LL: -0.017836170512368056', 'Test LL: -0.02671370245636773', 'Epoch Time (s): 164.89638785482384')
('Epoch 48', 'Objective: -0.027714850937989772', 'Train Acc: 0.9938', 'Test Acc: 0.9913', 'Train LL: -0.018202435171741103', 'Test LL: -0.026019665952936064', 'Epoch Time (s): 164.77640143386088')
('Epoch 49', 'Objective: -0.02660727787753117', 'Train Acc: 0.9944', 'Test Acc: 0.9912', 'Train LL: -0.017182341834268183', 'Test LL: -0.02764800482518532', 'Epoch Time (s): 163.8493253318593')
('Epoch 50', 'Objective: -0.02648851479654924', 'Train Acc: 0.9944166666666666', 'Test Acc: 0.9925', 'Train LL: -0.017104675269927906', 'Test LL: -0.02344745273592845', 'Epoch Time (s): 164.50403195992112')
('Epoch 51', 'Objective: -0.02586895962952984', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9916', 'Train LL: -0.016534527255853606', 'Test LL: -0.025804418266706382', 'Epoch Time (s): 164.3696894850582')
('Epoch 52', 'Objective: -0.02595770950705131', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9914', 'Train LL: -0.016661102585776015', 'Test LL: -0.02730631391224228', 'Epoch Time (s): 164.64901579287834')
('Epoch 53', 'Objective: -0.026069108478145895', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.9909', 'Train LL: -0.01682693108481165', 'Test LL: -0.02623771491843314', 'Epoch Time (s): 164.47931800503284')
('Epoch 54', 'Objective: -0.02475534032270852', 'Train Acc: 0.9950666666666667', 'Test Acc: 0.9914', 'Train LL: -0.015529234139441314', 'Test LL: -0.027499316537398625', 'Epoch Time (s): 164.44997520791367')
('Epoch 55', 'Objective: -0.024797516989588868', 'Train Acc: 0.99475', 'Test Acc: 0.9904', 'Train LL: -0.015564664869148212', 'Test LL: -0.030462456577832062', 'Epoch Time (s): 164.40445038396865')
('Epoch 56', 'Objective: -0.02439334982680103', 'Train Acc: 0.9950666666666667', 'Test Acc: 0.9901', 'Train LL: -0.015194215695279224', 'Test LL: -0.030760347052276437', 'Epoch Time (s): 164.42642760416493')
('Epoch 57', 'Objective: -0.024906685547054535', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9916', 'Train LL: -0.015712759389840004', 'Test LL: -0.026421919152501732', 'Epoch Time (s): 164.35540651413612')
('Epoch 58', 'Objective: -0.02390397865923441', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.992', 'Train LL: -0.014808602185660841', 'Test LL: -0.024951542365568055', 'Epoch Time (s): 164.51451950799674')
('Epoch 59', 'Objective: -0.023778610350273725', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9917', 'Train LL: -0.014663203877767317', 'Test LL: -0.026593924137372778', 'Epoch Time (s): 164.3855267839972')
('Epoch 60', 'Objective: -0.02438094486679348', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9908', 'Train LL: -0.015284072194695603', 'Test LL: -0.03140971810292229', 'Epoch Time (s): 164.5315571911633')
('Epoch 61', 'Objective: -0.024108434148249556', 'Train Acc: 0.9948666666666667', 'Test Acc: 0.9925', 'Train LL: -0.015081481511671263', 'Test LL: -0.023276119450799864', 'Epoch Time (s): 164.46606510598212')
('Epoch 62', 'Objective: -0.023485272318347104', 'Train Acc: 0.9951333333333333', 'Test Acc: 0.9914', 'Train LL: -0.014445938357499154', 'Test LL: -0.028012235143908663', 'Epoch Time (s): 164.4079548800364')
('Epoch 63', 'Objective: -0.023376540377768103', 'Train Acc: 0.9952833333333333', 'Test Acc: 0.9916', 'Train LL: -0.014398925333974664', 'Test LL: -0.02529081992603147', 'Epoch Time (s): 164.33832751214504')
('Epoch 64', 'Objective: -0.023216747224503946', 'Train Acc: 0.9953666666666666', 'Test Acc: 0.9914', 'Train LL: -0.01425840186944223', 'Test LL: -0.028178035509997146', 'Epoch Time (s): 164.12571169086732')
('Epoch 65', 'Objective: -0.022867817026830217', 'Train Acc: 0.9951666666666666', 'Test Acc: 0.9918', 'Train LL: -0.013887471718177878', 'Test LL: -0.025557659424188427', 'Epoch Time (s): 164.42513132002205')
('Epoch 66', 'Objective: -0.022472071278541974', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.9922', 'Train LL: -0.013521704056505688', 'Test LL: -0.026803083414274516', 'Epoch Time (s): 164.3886609878391')
('Epoch 67', 'Objective: -0.022346844413089706', 'Train Acc: 0.9954', 'Test Acc: 0.9918', 'Train LL: -0.013390288219884182', 'Test LL: -0.027415348633328916', 'Epoch Time (s): 164.68589872401208')
('Epoch 68', 'Objective: -0.02172315163443426', 'Train Acc: 0.9956166666666667', 'Test Acc: 0.9918', 'Train LL: -0.01284480072763307', 'Test LL: -0.02583422020293833', 'Epoch Time (s): 164.3319611621555')
('Epoch 69', 'Objective: -0.021759748851882987', 'Train Acc: 0.9957', 'Test Acc: 0.9919', 'Train LL: -0.01290099496809067', 'Test LL: -0.026650696007737805', 'Epoch Time (s): 164.35043822205625')
('Epoch 70', 'Objective: -0.022253761091321957', 'Train Acc: 0.9957666666666667', 'Test Acc: 0.9919', 'Train LL: -0.013365716506700794', 'Test LL: -0.02668188413607109', 'Epoch Time (s): 164.62176288990304')
('Epoch 71', 'Objective: -0.02172288346133972', 'Train Acc: 0.99595', 'Test Acc: 0.9906', 'Train LL: -0.01287204676533052', 'Test LL: -0.0288563407472501', 'Epoch Time (s): 164.40214431402273')
('Epoch 72', 'Objective: -0.02162313301609629', 'Train Acc: 0.9958166666666667', 'Test Acc: 0.9896', 'Train LL: -0.012752133044401141', 'Test LL: -0.03067000575061843', 'Epoch Time (s): 164.68990102689713')
('Epoch 73', 'Objective: -0.021812839815541187', 'Train Acc: 0.99555', 'Test Acc: 0.9906', 'Train LL: -0.012938158336041778', 'Test LL: -0.03100188893037809', 'Epoch Time (s): 164.34414293710142')
('Epoch 74', 'Objective: -0.02124791523559514', 'Train Acc: 0.99585', 'Test Acc: 0.9915', 'Train LL: -0.012406036099763524', 'Test LL: -0.026650848762603124', 'Epoch Time (s): 164.3501826499123')
('Epoch 75', 'Objective: -0.021026962704850525', 'Train Acc: 0.996', 'Test Acc: 0.9908', 'Train LL: -0.012174638319240687', 'Test LL: -0.030375452195107504', 'Epoch Time (s): 164.17221782519482')
('Epoch 76', 'Objective: -0.02089925173098177', 'Train Acc: 0.9959833333333333', 'Test Acc: 0.9918', 'Train LL: -0.012146890163007584', 'Test LL: -0.027500468219897396', 'Epoch Time (s): 164.37401695200242')
('Epoch 77', 'Objective: -0.020798817488286478', 'Train Acc: 0.99595', 'Test Acc: 0.9913', 'Train LL: -0.012052461863067339', 'Test LL: -0.027984007104932748', 'Epoch Time (s): 164.2891865449492')
('Epoch 78', 'Objective: -0.020663559732450258', 'Train Acc: 0.9961166666666667', 'Test Acc: 0.9919', 'Train LL: -0.011955536408155134', 'Test LL: -0.027626045244887917', 'Epoch Time (s): 164.5920243540313')
('Epoch 79', 'Objective: -0.019893672916207163', 'Train Acc: 0.9962', 'Test Acc: 0.9889', 'Train LL: -0.011224008535348315', 'Test LL: -0.032849289292715536', 'Epoch Time (s): 164.5130454369355')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.019094378536336835', 'Train Acc: 0.99635', 'Test Acc: 0.9909', 'Train LL: -0.010501362255439838', 'Test LL: -0.02894710112683189', 'Epoch Time (s): 165.2805452258326')
('Epoch 81', 'Objective: -0.017387575224159353', 'Train Acc: 0.9972833333333333', 'Test Acc: 0.9916', 'Train LL: -0.008917743802522422', 'Test LL: -0.027262938864785657', 'Epoch Time (s): 165.1606677151285')
('Epoch 82', 'Objective: -0.017314060961748364', 'Train Acc: 0.99725', 'Test Acc: 0.9913', 'Train LL: -0.008826457574372788', 'Test LL: -0.028792485929031397', 'Epoch Time (s): 165.15180404298007')
('Epoch 83', 'Objective: -0.017450293949364874', 'Train Acc: 0.9970833333333333', 'Test Acc: 0.9915', 'Train LL: -0.00891057774270766', 'Test LL: -0.028121473087937388', 'Epoch Time (s): 165.17174235195853')
('Epoch 84', 'Objective: -0.017102134565313724', 'Train Acc: 0.9970666666666667', 'Test Acc: 0.9912', 'Train LL: -0.008596247026426062', 'Test LL: -0.029087451357489375', 'Epoch Time (s): 164.41940718889236')
('Epoch 85', 'Objective: -0.01640917565391457', 'Train Acc: 0.99755', 'Test Acc: 0.9911', 'Train LL: -0.00795862067028057', 'Test LL: -0.028323099794508328', 'Epoch Time (s): 164.51990249287337')
('Epoch 86', 'Objective: -0.016953370450978215', 'Train Acc: 0.9972666666666666', 'Test Acc: 0.991', 'Train LL: -0.00843161235360671', 'Test LL: -0.029619815134280567', 'Epoch Time (s): 164.31177341099828')
('Epoch 87', 'Objective: -0.016438645511503307', 'Train Acc: 0.9975333333333334', 'Test Acc: 0.9913', 'Train LL: -0.007951108289028976', 'Test LL: -0.028724029297031894', 'Epoch Time (s): 164.23664508294314')
('Epoch 88', 'Objective: -0.016726613799768895', 'Train Acc: 0.9974', 'Test Acc: 0.9911', 'Train LL: -0.0081942872334285', 'Test LL: -0.029138656858361662', 'Epoch Time (s): 164.16134665813297')
('Epoch 89', 'Objective: -0.016541889533534717', 'Train Acc: 0.9973833333333333', 'Test Acc: 0.991', 'Train LL: -0.008015043391283028', 'Test LL: -0.029403003604894253', 'Epoch Time (s): 164.14369370299391')
('Epoch 90', 'Objective: -0.017034779513768538', 'Train Acc: 0.9973333333333333', 'Test Acc: 0.9915', 'Train LL: -0.00846911861196416', 'Test LL: -0.02880869210467668', 'Epoch Time (s): 164.26990672689863')
('Epoch 91', 'Objective: -0.01681219855169052', 'Train Acc: 0.9971666666666666', 'Test Acc: 0.9917', 'Train LL: -0.00822996472612342', 'Test LL: -0.028448505326042716', 'Epoch Time (s): 164.60877251485363')
('Epoch 92', 'Objective: -0.01651093096221214', 'Train Acc: 0.9973333333333333', 'Test Acc: 0.9908', 'Train LL: -0.007957947465130224', 'Test LL: -0.03037320508872598', 'Epoch Time (s): 164.63456195313483')
('Epoch 93', 'Objective: -0.01667656473643902', 'Train Acc: 0.99745', 'Test Acc: 0.9912', 'Train LL: -0.008107944832535503', 'Test LL: -0.029700390633643946', 'Epoch Time (s): 164.467996831052')
('Epoch 94', 'Objective: -0.016894647306364353', 'Train Acc: 0.9972333333333333', 'Test Acc: 0.9915', 'Train LL: -0.008306085158535386', 'Test LL: -0.02913936708155378', 'Epoch Time (s): 164.56069574784487')
('Epoch 95', 'Objective: -0.016563586236025777', 'Train Acc: 0.9974333333333333', 'Test Acc: 0.9916', 'Train LL: -0.00800155952671212', 'Test LL: -0.028706387983999413', 'Epoch Time (s): 164.4983902547974')
('Epoch 96', 'Objective: -0.016400241854128892', 'Train Acc: 0.99755', 'Test Acc: 0.9913', 'Train LL: -0.007865444793422627', 'Test LL: -0.029018999635882402', 'Epoch Time (s): 164.56135723693296')
('Epoch 97', 'Objective: -0.016060525029339176', 'Train Acc: 0.99765', 'Test Acc: 0.9912', 'Train LL: -0.007516756620591353', 'Test LL: -0.030070594459066586', 'Epoch Time (s): 164.50887781614438')
('Epoch 98', 'Objective: -0.016530349429764876', 'Train Acc: 0.99745', 'Test Acc: 0.9914', 'Train LL: -0.00794465424021667', 'Test LL: -0.02978445665646171', 'Epoch Time (s): 164.49600692698732')
('Epoch 99', 'Objective: -0.01622000077209732', 'Train Acc: 0.9974833333333334', 'Test Acc: 0.9913', 'Train LL: -0.007666922653331106', 'Test LL: -0.02923062901772589', 'Epoch Time (s): 164.32361589884385')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.015676426375629812
Final Train Accuracy: £0.99775
Final Train LL: £-0.00715744216490543
Final Test Accuracy: £0.9914
Final Test LL: £-0.029323376235488422
