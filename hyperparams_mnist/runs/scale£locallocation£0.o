dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: local
bn_tscale: location
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.410453507971147', 'Train Acc: 0.4948166666666667', 'Test Acc: 0.8022', 'Train LL: -1.3661719287920802', 'Test LL: -0.6131202682305485', 'Epoch Time (s): 171.01341171003878')
('Epoch 1', 'Objective: -0.5490833508509602', 'Train Acc: 0.8288', 'Test Acc: 0.8867', 'Train LL: -0.5041808768976344', 'Test LL: -0.33310952288742723', 'Epoch Time (s): 170.5972425811924')
('Epoch 2', 'Objective: -0.3318020169084931', 'Train Acc: 0.9086', 'Test Acc: 0.9143', 'Train LL: -0.28687865053982736', 'Test LL: -0.25540157980798195', 'Epoch Time (s): 170.55280119460076')
('Epoch 3', 'Objective: -0.2534419287186724', 'Train Acc: 0.9347166666666666', 'Test Acc: 0.9378', 'Train LL: -0.21108460568639373', 'Test LL: -0.19600325500520557', 'Epoch Time (s): 170.57972045475617')
('Epoch 4', 'Objective: -0.21278604742449675', 'Train Acc: 0.94535', 'Test Acc: 0.9349', 'Train LL: -0.17262737525729055', 'Test LL: -0.2009400094970722', 'Epoch Time (s): 170.6263103899546')
('Epoch 5', 'Objective: -0.19392055834772304', 'Train Acc: 0.9516166666666667', 'Test Acc: 0.9628', 'Train LL: -0.15514521969338244', 'Test LL: -0.109982456183283', 'Epoch Time (s): 170.561689352151')
('Epoch 6', 'Objective: -0.17807410074516292', 'Train Acc: 0.9562666666666667', 'Test Acc: 0.9539', 'Train LL: -0.1407166165427573', 'Test LL: -0.1371733227434017', 'Epoch Time (s): 170.60807829815894')
('Epoch 7', 'Objective: -0.16909175966605228', 'Train Acc: 0.9581333333333333', 'Test Acc: 0.9714', 'Train LL: -0.132463868869876', 'Test LL: -0.09435000295710488', 'Epoch Time (s): 170.61854303162545')
('Epoch 8', 'Objective: -0.1587459152744886', 'Train Acc: 0.9621833333333333', 'Test Acc: 0.967', 'Train LL: -0.12279634783032134', 'Test LL: -0.10494898769587058', 'Epoch Time (s): 170.6000421042554')
('Epoch 9', 'Objective: -0.15371710245353204', 'Train Acc: 0.9625166666666667', 'Test Acc: 0.9677', 'Train LL: -0.11875214146645657', 'Test LL: -0.09797996608718741', 'Epoch Time (s): 170.61132968077436')
('Epoch 10', 'Objective: -0.147688353438591', 'Train Acc: 0.96355', 'Test Acc: 0.9665', 'Train LL: -0.1131842898409143', 'Test LL: -0.10802706792891573', 'Epoch Time (s): 170.64471242018044')
('Epoch 11', 'Objective: -0.13997326593583775', 'Train Acc: 0.96595', 'Test Acc: 0.9701', 'Train LL: -0.10573737342473748', 'Test LL: -0.09510589167053053', 'Epoch Time (s): 170.64835749194026')
('Epoch 12', 'Objective: -0.13646070079358108', 'Train Acc: 0.9671', 'Test Acc: 0.9646', 'Train LL: -0.10248250866302425', 'Test LL: -0.11633837588543704', 'Epoch Time (s): 170.64418403804302')
('Epoch 13', 'Objective: -0.13153231944309637', 'Train Acc: 0.9684333333333334', 'Test Acc: 0.9761', 'Train LL: -0.09805298080993566', 'Test LL: -0.07790551786095432', 'Epoch Time (s): 170.58082419028506')
('Epoch 14', 'Objective: -0.1291228908021331', 'Train Acc: 0.9695833333333334', 'Test Acc: 0.9755', 'Train LL: -0.09604475623958296', 'Test LL: -0.08219720345399184', 'Epoch Time (s): 170.5971056809649')
('Epoch 15', 'Objective: -0.12281336741158456', 'Train Acc: 0.9715833333333334', 'Test Acc: 0.9731', 'Train LL: -0.0901750655540575', 'Test LL: -0.08194743655047303', 'Epoch Time (s): 170.60459496779367')
('Epoch 16', 'Objective: -0.12118251733767946', 'Train Acc: 0.97195', 'Test Acc: 0.9719', 'Train LL: -0.08892379737203322', 'Test LL: -0.08292346627203362', 'Epoch Time (s): 170.64211816014722')
('Epoch 17', 'Objective: -0.12062286939301035', 'Train Acc: 0.9719833333333333', 'Test Acc: 0.975', 'Train LL: -0.08875725649974066', 'Test LL: -0.08424842197725757', 'Epoch Time (s): 170.64623664179817')
('Epoch 18', 'Objective: -0.11739090706798913', 'Train Acc: 0.9730666666666666', 'Test Acc: 0.9758', 'Train LL: -0.0859522306703825', 'Test LL: -0.0775042702774155', 'Epoch Time (s): 170.9857652010396')
('Epoch 19', 'Objective: -0.11572138599378087', 'Train Acc: 0.9727333333333333', 'Test Acc: 0.9703', 'Train LL: -0.08429704549066944', 'Test LL: -0.09180668016212579', 'Epoch Time (s): 170.64635484293103')
('Epoch 20', 'Objective: -0.11212352342879323', 'Train Acc: 0.9741833333333333', 'Test Acc: 0.9757', 'Train LL: -0.08109773120312222', 'Test LL: -0.0754875167429367', 'Epoch Time (s): 170.54442252218723')
('Epoch 21', 'Objective: -0.11129315756748717', 'Train Acc: 0.9749', 'Test Acc: 0.9791', 'Train LL: -0.0801975164796303', 'Test LL: -0.06410734743689162', 'Epoch Time (s): 170.54217412602156')
('Epoch 22', 'Objective: -0.10769413092237493', 'Train Acc: 0.97525', 'Test Acc: 0.979', 'Train LL: -0.07703358193440324', 'Test LL: -0.06747436520470025', 'Epoch Time (s): 170.57052624924108')
('Epoch 23', 'Objective: -0.10430831556065621', 'Train Acc: 0.9762666666666666', 'Test Acc: 0.9746', 'Train LL: -0.0738670429476485', 'Test LL: -0.08009056975630315', 'Epoch Time (s): 170.58034753985703')
('Epoch 24', 'Objective: -0.10537536947215596', 'Train Acc: 0.97625', 'Test Acc: 0.9751', 'Train LL: -0.07506486113639489', 'Test LL: -0.07092702198097128', 'Epoch Time (s): 170.6293895202689')
('Epoch 25', 'Objective: -0.10253134738210237', 'Train Acc: 0.9769333333333333', 'Test Acc: 0.9737', 'Train LL: -0.07243974296414268', 'Test LL: -0.0806837772670736', 'Epoch Time (s): 170.55235111061484')
('Epoch 26', 'Objective: -0.10242196625978688', 'Train Acc: 0.977', 'Test Acc: 0.9821', 'Train LL: -0.0726066235715118', 'Test LL: -0.05756814564276118', 'Epoch Time (s): 170.55238118674606')
('Epoch 27', 'Objective: -0.09964108250503281', 'Train Acc: 0.9785666666666667', 'Test Acc: 0.9789', 'Train LL: -0.0701924745183647', 'Test LL: -0.06456130316851719', 'Epoch Time (s): 170.58407746627927')
('Epoch 28', 'Objective: -0.10138887638432621', 'Train Acc: 0.97755', 'Test Acc: 0.976', 'Train LL: -0.07195870365920379', 'Test LL: -0.07192045113506042', 'Epoch Time (s): 170.53445939999074')
('Epoch 29', 'Objective: -0.09918782293962465', 'Train Acc: 0.9781833333333333', 'Test Acc: 0.9806', 'Train LL: -0.06978321349027448', 'Test LL: -0.059467799835694016', 'Epoch Time (s): 170.54459970118478')
('Epoch 30', 'Objective: -0.09936730879966627', 'Train Acc: 0.9774833333333334', 'Test Acc: 0.979', 'Train LL: -0.06995927947445005', 'Test LL: -0.06624133817644724', 'Epoch Time (s): 170.60556159215048')
('Epoch 31', 'Objective: -0.0974420178271313', 'Train Acc: 0.97825', 'Test Acc: 0.9728', 'Train LL: -0.06845716672873738', 'Test LL: -0.08226156796605945', 'Epoch Time (s): 170.614290793892')
('Epoch 32', 'Objective: -0.09417491622660609', 'Train Acc: 0.9793333333333333', 'Test Acc: 0.9777', 'Train LL: -0.06544512449314299', 'Test LL: -0.0693527281379902', 'Epoch Time (s): 170.5847555566579')
('Epoch 33', 'Objective: -0.09335305336343336', 'Train Acc: 0.9792666666666666', 'Test Acc: 0.9808', 'Train LL: -0.06481513169397528', 'Test LL: -0.0593303608857783', 'Epoch Time (s): 170.5572357387282')
('Epoch 34', 'Objective: -0.09313853618016328', 'Train Acc: 0.979', 'Test Acc: 0.975', 'Train LL: -0.06466473185004867', 'Test LL: -0.07027687215225009', 'Epoch Time (s): 170.58397651277483')
('Epoch 35', 'Objective: -0.0914189157170079', 'Train Acc: 0.9793666666666667', 'Test Acc: 0.9718', 'Train LL: -0.06322641047275387', 'Test LL: -0.08699431450878438', 'Epoch Time (s): 170.48476725025102')
('Epoch 36', 'Objective: -0.09171344630614617', 'Train Acc: 0.9792833333333333', 'Test Acc: 0.9849', 'Train LL: -0.06357853940209318', 'Test LL: -0.043273694579222206', 'Epoch Time (s): 170.51140506519005')
('Epoch 37', 'Objective: -0.09185823624761796', 'Train Acc: 0.97945', 'Test Acc: 0.9808', 'Train LL: -0.06378821580224549', 'Test LL: -0.058553207559914326', 'Epoch Time (s): 170.47987177502364')
('Epoch 38', 'Objective: -0.0895297192787422', 'Train Acc: 0.9799', 'Test Acc: 0.9806', 'Train LL: -0.06137227334978815', 'Test LL: -0.06021153571967301', 'Epoch Time (s): 170.5376555500552')
('Epoch 39', 'Objective: -0.08820600634479851', 'Train Acc: 0.9807666666666667', 'Test Acc: 0.9791', 'Train LL: -0.06051967473372649', 'Test LL: -0.06333944962696757', 'Epoch Time (s): 170.48486777581275')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06567738996875044', 'Train Acc: 0.9876333333333334', 'Test Acc: 0.9881', 'Train LL: -0.039403714666712164', 'Test LL: -0.0386890990870829', 'Epoch Time (s): 170.45510879904032')
('Epoch 41', 'Objective: -0.05878814587152295', 'Train Acc: 0.9895666666666667', 'Test Acc: 0.9883', 'Train LL: -0.033669897971577434', 'Test LL: -0.034985689835986565', 'Epoch Time (s): 170.49010759592056')
('Epoch 42', 'Objective: -0.05744611918308491', 'Train Acc: 0.9895333333333334', 'Test Acc: 0.9862', 'Train LL: -0.0327098839799724', 'Test LL: -0.037529012985787265', 'Epoch Time (s): 170.5224817111157')
('Epoch 43', 'Objective: -0.056669062625464825', 'Train Acc: 0.9894833333333334', 'Test Acc: 0.9881', 'Train LL: -0.032121274916866775', 'Test LL: -0.0350362484294', 'Epoch Time (s): 170.4631598321721')
('Epoch 44', 'Objective: -0.05585977947804932', 'Train Acc: 0.9897666666666667', 'Test Acc: 0.988', 'Train LL: -0.03154606647647479', 'Test LL: -0.03476327417304024', 'Epoch Time (s): 170.55131484521553')
('Epoch 45', 'Objective: -0.0540001452276968', 'Train Acc: 0.9904333333333334', 'Test Acc: 0.9886', 'Train LL: -0.029999301132088072', 'Test LL: -0.0337009892209552', 'Epoch Time (s): 170.48472394561395')
('Epoch 46', 'Objective: -0.054305179172449994', 'Train Acc: 0.9902666666666666', 'Test Acc: 0.9878', 'Train LL: -0.030373055786814256', 'Test LL: -0.03757037175837761', 'Epoch Time (s): 170.49461632128805')
('Epoch 47', 'Objective: -0.05443965390619383', 'Train Acc: 0.99045', 'Test Acc: 0.9885', 'Train LL: -0.030599557225615474', 'Test LL: -0.0345238268361222', 'Epoch Time (s): 170.43840177170932')
('Epoch 48', 'Objective: -0.053071844927251935', 'Train Acc: 0.9904833333333334', 'Test Acc: 0.9896', 'Train LL: -0.029402385960733912', 'Test LL: -0.03305732889683294', 'Epoch Time (s): 170.46904442831874')
('Epoch 49', 'Objective: -0.05256906872063904', 'Train Acc: 0.9904', 'Test Acc: 0.9885', 'Train LL: -0.02897039339755235', 'Test LL: -0.03433628917260499', 'Epoch Time (s): 170.4877223256044')
('Epoch 50', 'Objective: -0.05320351866395765', 'Train Acc: 0.99055', 'Test Acc: 0.9897', 'Train LL: -0.02973104825317391', 'Test LL: -0.031814148653556744', 'Epoch Time (s): 170.50810054130852')
('Epoch 51', 'Objective: -0.051670678213886524', 'Train Acc: 0.9908333333333333', 'Test Acc: 0.989', 'Train LL: -0.02833282072251206', 'Test LL: -0.03327740744910854', 'Epoch Time (s): 170.50070770503953')
('Epoch 52', 'Objective: -0.05135118969180846', 'Train Acc: 0.9905833333333334', 'Test Acc: 0.9897', 'Train LL: -0.028056352857705736', 'Test LL: -0.03366999860193271', 'Epoch Time (s): 170.47214169986546')
('Epoch 53', 'Objective: -0.05078588098425654', 'Train Acc: 0.9911', 'Test Acc: 0.9904', 'Train LL: -0.027634967602422914', 'Test LL: -0.030235308030327552', 'Epoch Time (s): 170.5018081162125')
('Epoch 54', 'Objective: -0.05084682066943671', 'Train Acc: 0.9911333333333333', 'Test Acc: 0.9893', 'Train LL: -0.027740305472519603', 'Test LL: -0.03406865895919232', 'Epoch Time (s): 170.45428470196202')
('Epoch 55', 'Objective: -0.05009543483341744', 'Train Acc: 0.9911833333333333', 'Test Acc: 0.9887', 'Train LL: -0.02708124793388311', 'Test LL: -0.03326260055839927', 'Epoch Time (s): 170.46829530782998')
('Epoch 56', 'Objective: -0.050005179187025725', 'Train Acc: 0.9906833333333334', 'Test Acc: 0.9901', 'Train LL: -0.02709007507566425', 'Test LL: -0.030315657330796948', 'Epoch Time (s): 170.45915832277387')
('Epoch 57', 'Objective: -0.04948772993828539', 'Train Acc: 0.9912166666666666', 'Test Acc: 0.9881', 'Train LL: -0.02653962300965593', 'Test LL: -0.035368763236818715', 'Epoch Time (s): 170.4761627363041')
('Epoch 58', 'Objective: -0.04941200413567088', 'Train Acc: 0.9914833333333334', 'Test Acc: 0.9898', 'Train LL: -0.02654781557284375', 'Test LL: -0.03265212144424376', 'Epoch Time (s): 170.50943410489708')
('Epoch 59', 'Objective: -0.04962776269541945', 'Train Acc: 0.9911833333333333', 'Test Acc: 0.9878', 'Train LL: -0.02683664449503993', 'Test LL: -0.03625788058504559', 'Epoch Time (s): 170.50030091265216')
('Epoch 60', 'Objective: -0.05004166660381219', 'Train Acc: 0.9910666666666667', 'Test Acc: 0.9884', 'Train LL: -0.02729258713410427', 'Test LL: -0.033566762170982374', 'Epoch Time (s): 170.45566234411672')
('Epoch 61', 'Objective: -0.04938051195380835', 'Train Acc: 0.9913333333333333', 'Test Acc: 0.9874', 'Train LL: -0.026721594348882032', 'Test LL: -0.03646956684457916', 'Epoch Time (s): 170.43924837140366')
('Epoch 62', 'Objective: -0.04890254237253478', 'Train Acc: 0.9916166666666667', 'Test Acc: 0.9891', 'Train LL: -0.02637260156230672', 'Test LL: -0.032337075922172206', 'Epoch Time (s): 170.45729254791513')
('Epoch 63', 'Objective: -0.047892841436197334', 'Train Acc: 0.9917', 'Test Acc: 0.988', 'Train LL: -0.025465375054715734', 'Test LL: -0.03571659146513414', 'Epoch Time (s): 170.47186600230634')
('Epoch 64', 'Objective: -0.04775326060303868', 'Train Acc: 0.9918', 'Test Acc: 0.9899', 'Train LL: -0.025346702328199702', 'Test LL: -0.030522782789017936', 'Epoch Time (s): 170.46132400585338')
('Epoch 65', 'Objective: -0.048971815510576826', 'Train Acc: 0.99125', 'Test Acc: 0.9881', 'Train LL: -0.026563776562868558', 'Test LL: -0.03438757048935989', 'Epoch Time (s): 170.50006943242624')
('Epoch 66', 'Objective: -0.04810181289667222', 'Train Acc: 0.9913666666666666', 'Test Acc: 0.9887', 'Train LL: -0.025742917302603308', 'Test LL: -0.03689834623152614', 'Epoch Time (s): 170.4631712269038')
('Epoch 67', 'Objective: -0.048220022275080245', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9892', 'Train LL: -0.02593092286232358', 'Test LL: -0.031999526598735575', 'Epoch Time (s): 170.48658903501928')
('Epoch 68', 'Objective: -0.047542591821176754', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.989', 'Train LL: -0.025310245976296768', 'Test LL: -0.033688824663439566', 'Epoch Time (s): 170.51351641630754')
('Epoch 69', 'Objective: -0.04669269087002959', 'Train Acc: 0.99175', 'Test Acc: 0.988', 'Train LL: -0.024491773134065108', 'Test LL: -0.035313866123176406', 'Epoch Time (s): 170.48814141005278')
('Epoch 70', 'Objective: -0.04697938549044056', 'Train Acc: 0.9918166666666667', 'Test Acc: 0.9898', 'Train LL: -0.024802670944343738', 'Test LL: -0.030833376731943297', 'Epoch Time (s): 170.49005290167406')
('Epoch 71', 'Objective: -0.0475406052605703', 'Train Acc: 0.9919833333333333', 'Test Acc: 0.9892', 'Train LL: -0.025368377031182224', 'Test LL: -0.032875693545137426', 'Epoch Time (s): 170.51249710004777')
('Epoch 72', 'Objective: -0.04698532021271767', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.988', 'Train LL: -0.024958074560564897', 'Test LL: -0.03514129521290431', 'Epoch Time (s): 170.4741424061358')
('Epoch 73', 'Objective: -0.04721691518610449', 'Train Acc: 0.9919', 'Test Acc: 0.9881', 'Train LL: -0.025169914149423493', 'Test LL: -0.03365847168419173', 'Epoch Time (s): 170.4633466792293')
('Epoch 74', 'Objective: -0.04703393477700705', 'Train Acc: 0.99165', 'Test Acc: 0.9884', 'Train LL: -0.02506004947534161', 'Test LL: -0.03378409166636401', 'Epoch Time (s): 170.44397791894153')
('Epoch 75', 'Objective: -0.04648512203523825', 'Train Acc: 0.99155', 'Test Acc: 0.9884', 'Train LL: -0.024614535844139057', 'Test LL: -0.035879829936332895', 'Epoch Time (s): 170.4814634299837')
('Epoch 76', 'Objective: -0.046251826236243965', 'Train Acc: 0.99205', 'Test Acc: 0.9888', 'Train LL: -0.024415376925111348', 'Test LL: -0.03268993857275877', 'Epoch Time (s): 170.4709043931216')
('Epoch 77', 'Objective: -0.046368984145218756', 'Train Acc: 0.9917666666666667', 'Test Acc: 0.9875', 'Train LL: -0.024505669543385823', 'Test LL: -0.03571135624512623', 'Epoch Time (s): 170.47080791229382')
('Epoch 78', 'Objective: -0.046683103204967664', 'Train Acc: 0.99195', 'Test Acc: 0.9896', 'Train LL: -0.024915726426736416', 'Test LL: -0.031299290465750106', 'Epoch Time (s): 170.46740854205564')
('Epoch 79', 'Objective: -0.046368469327522914', 'Train Acc: 0.992', 'Test Acc: 0.9902', 'Train LL: -0.024572730349481875', 'Test LL: -0.02954414518490481', 'Epoch Time (s): 170.50596045795828')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04311855459844384', 'Train Acc: 0.99315', 'Test Acc: 0.9902', 'Train LL: -0.02161873655697235', 'Test LL: -0.03012524791639635', 'Epoch Time (s): 170.4539675428532')
('Epoch 81', 'Objective: -0.04296659853178715', 'Train Acc: 0.993', 'Test Acc: 0.9899', 'Train LL: -0.021458279133033897', 'Test LL: -0.030128881482848202', 'Epoch Time (s): 170.47364288615063')
('Epoch 82', 'Objective: -0.04253097409294376', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.9899', 'Train LL: -0.02104042082028253', 'Test LL: -0.029651638884918435', 'Epoch Time (s): 170.47880112193525')
('Epoch 83', 'Objective: -0.042482092401099375', 'Train Acc: 0.9929666666666667', 'Test Acc: 0.9898', 'Train LL: -0.020976793984300277', 'Test LL: -0.03058195202955452', 'Epoch Time (s): 170.43720467435196')
('Epoch 84', 'Objective: -0.0412801836629729', 'Train Acc: 0.9937166666666667', 'Test Acc: 0.9904', 'Train LL: -0.019875515116286768', 'Test LL: -0.030321899537818386', 'Epoch Time (s): 170.46245784126222')
('Epoch 85', 'Objective: -0.04159235625432718', 'Train Acc: 0.9933', 'Test Acc: 0.9903', 'Train LL: -0.020168392856575724', 'Test LL: -0.029950026380037603', 'Epoch Time (s): 170.49236178398132')
('Epoch 86', 'Objective: -0.041783760583843824', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9898', 'Train LL: -0.020298245404888223', 'Test LL: -0.03055680448476046', 'Epoch Time (s): 170.44996911101043')
('Epoch 87', 'Objective: -0.04191970821423703', 'Train Acc: 0.99325', 'Test Acc: 0.9902', 'Train LL: -0.020441751050449018', 'Test LL: -0.029960975329264346', 'Epoch Time (s): 170.50222111819312')
('Epoch 88', 'Objective: -0.04193716440157682', 'Train Acc: 0.99335', 'Test Acc: 0.9901', 'Train LL: -0.020471538256195305', 'Test LL: -0.030180438799966583', 'Epoch Time (s): 170.46388027910143')
('Epoch 89', 'Objective: -0.04186353641209483', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.9895', 'Train LL: -0.020386630624195694', 'Test LL: -0.03058634998349528', 'Epoch Time (s): 170.47155740996823')
('Epoch 90', 'Objective: -0.04205119809067617', 'Train Acc: 0.9933166666666666', 'Test Acc: 0.99', 'Train LL: -0.020569285937186696', 'Test LL: -0.030155110825449357', 'Epoch Time (s): 170.46476415125653')
('Epoch 91', 'Objective: -0.04186735210644914', 'Train Acc: 0.99335', 'Test Acc: 0.9905', 'Train LL: -0.020417468891889133', 'Test LL: -0.029205269557625105', 'Epoch Time (s): 170.41959186457098')
('Epoch 92', 'Objective: -0.04141186780153912', 'Train Acc: 0.99335', 'Test Acc: 0.9898', 'Train LL: -0.019979025188708307', 'Test LL: -0.030888043881327484', 'Epoch Time (s): 170.4955711737275')
('Epoch 93', 'Objective: -0.04163438872845041', 'Train Acc: 0.9934', 'Test Acc: 0.9895', 'Train LL: -0.020218691205895017', 'Test LL: -0.030602860598864436', 'Epoch Time (s): 170.44913590094075')
('Epoch 94', 'Objective: -0.0417078605105369', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.9902', 'Train LL: -0.020253586877628238', 'Test LL: -0.03085974070132054', 'Epoch Time (s): 170.4954992691055')
('Epoch 95', 'Objective: -0.0413704040667614', 'Train Acc: 0.99335', 'Test Acc: 0.9899', 'Train LL: -0.019938623496118992', 'Test LL: -0.03060656958912008', 'Epoch Time (s): 170.4852394941263')
('Epoch 96', 'Objective: -0.040769090171982436', 'Train Acc: 0.9936', 'Test Acc: 0.9893', 'Train LL: -0.01941839818042202', 'Test LL: -0.03186967442081729', 'Epoch Time (s): 170.45558681385592')
('Epoch 97', 'Objective: -0.04114381795211411', 'Train Acc: 0.9935333333333334', 'Test Acc: 0.9899', 'Train LL: -0.019704209269330142', 'Test LL: -0.03119528605442706', 'Epoch Time (s): 170.4916942329146')
('Epoch 98', 'Objective: -0.04158177971286769', 'Train Acc: 0.99365', 'Test Acc: 0.9903', 'Train LL: -0.020156199058881375', 'Test LL: -0.02974120125372333', 'Epoch Time (s): 170.4927102830261')
('Epoch 99', 'Objective: -0.04163312549645949', 'Train Acc: 0.9935833333333334', 'Test Acc: 0.9902', 'Train LL: -0.02020233516985013', 'Test LL: -0.029679429763217836', 'Epoch Time (s): 170.4818828110583')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04073337296782175
Final Train Accuracy: £0.9935666666666667
Final Train LL: £-0.0193840858608759
Final Test Accuracy: £0.9905
Final Test LL: £-0.029560855366601625
