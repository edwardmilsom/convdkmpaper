dataset: MNIST
dtype: float64
dof: 0.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.258738599948899', 'Train Acc: 0.5616833333333333', 'Test Acc: 0.7645', 'Train LL: -1.2246463696692762', 'Test LL: -0.678574541757288', 'Epoch Time (s): 164.02325239498168')
('Epoch 1', 'Objective: -0.475504757558711', 'Train Acc: 0.8449', 'Test Acc: 0.8612', 'Train LL: -0.45847296536565885', 'Test LL: -0.4408073303785296', 'Epoch Time (s): 164.13379297801293')
('Epoch 2', 'Objective: -0.24614126877972306', 'Train Acc: 0.92585', 'Test Acc: 0.9503', 'Train LL: -0.2347413057409346', 'Test LL: -0.15634814729421484', 'Epoch Time (s): 164.04885255591944')
('Epoch 3', 'Objective: -0.17947809872106182', 'Train Acc: 0.94615', 'Test Acc: 0.9644', 'Train LL: -0.17098336637732808', 'Test LL: -0.10959467512202109', 'Epoch Time (s): 164.0172651282046')
('Epoch 4', 'Objective: -0.14877937419745227', 'Train Acc: 0.95545', 'Test Acc: 0.9637', 'Train LL: -0.1415642521560308', 'Test LL: -0.12187863432785134', 'Epoch Time (s): 164.09356101509184')
('Epoch 5', 'Objective: -0.13163907296447613', 'Train Acc: 0.96095', 'Test Acc: 0.9587', 'Train LL: -0.12518656221727595', 'Test LL: -0.13418952407517945', 'Epoch Time (s): 164.08186630206183')
('Epoch 6', 'Objective: -0.11580049456921039', 'Train Acc: 0.96555', 'Test Acc: 0.9724', 'Train LL: -0.10991796380989077', 'Test LL: -0.08186286855739071', 'Epoch Time (s): 164.0839070980437')
('Epoch 7', 'Objective: -0.10718441719398594', 'Train Acc: 0.9683', 'Test Acc: 0.9766', 'Train LL: -0.10167692575705958', 'Test LL: -0.07122565988973367', 'Epoch Time (s): 164.04224589001387')
('Epoch 8', 'Objective: -0.09644720390977998', 'Train Acc: 0.9715166666666667', 'Test Acc: 0.9569', 'Train LL: -0.09145058471303547', 'Test LL: -0.12487888576008181', 'Epoch Time (s): 164.23800659598783')
('Epoch 9', 'Objective: -0.09033152100068632', 'Train Acc: 0.9731', 'Test Acc: 0.9763', 'Train LL: -0.08555329338236121', 'Test LL: -0.078797426024477', 'Epoch Time (s): 164.08957218006253')
('Epoch 10', 'Objective: -0.08757020052765287', 'Train Acc: 0.9738', 'Test Acc: 0.9774', 'Train LL: -0.08302993396751866', 'Test LL: -0.0709297382157559', 'Epoch Time (s): 164.08310051099397')
('Epoch 11', 'Objective: -0.08301900855849016', 'Train Acc: 0.9750333333333333', 'Test Acc: 0.9747', 'Train LL: -0.07873169001933729', 'Test LL: -0.08386638200472207', 'Epoch Time (s): 164.10314577189274')
('Epoch 12', 'Objective: -0.07854917865431245', 'Train Acc: 0.9769166666666667', 'Test Acc: 0.9721', 'Train LL: -0.07437736271282926', 'Test LL: -0.08679560793816624', 'Epoch Time (s): 164.06627612095326')
('Epoch 13', 'Objective: -0.07709092819247498', 'Train Acc: 0.977', 'Test Acc: 0.9762', 'Train LL: -0.07312928305463454', 'Test LL: -0.07208890758740492', 'Epoch Time (s): 164.0988144557923')
('Epoch 14', 'Objective: -0.0728627308275864', 'Train Acc: 0.9786333333333334', 'Test Acc: 0.9779', 'Train LL: -0.06912089432093695', 'Test LL: -0.07022436375564114', 'Epoch Time (s): 164.12230268795975')
('Epoch 15', 'Objective: -0.06971270111804595', 'Train Acc: 0.9789833333333333', 'Test Acc: 0.9793', 'Train LL: -0.06608045701271632', 'Test LL: -0.06347041522620155', 'Epoch Time (s): 164.1349492969457')
('Epoch 16', 'Objective: -0.06817877436786118', 'Train Acc: 0.9796333333333334', 'Test Acc: 0.9835', 'Train LL: -0.06461099671625369', 'Test LL: -0.05924066972826938', 'Epoch Time (s): 164.19860652601346')
('Epoch 17', 'Objective: -0.06697226032737204', 'Train Acc: 0.9799333333333333', 'Test Acc: 0.986', 'Train LL: -0.06353044292655262', 'Test LL: -0.04597198896935745', 'Epoch Time (s): 164.10173387592658')
('Epoch 18', 'Objective: -0.06483598541733966', 'Train Acc: 0.98', 'Test Acc: 0.9842', 'Train LL: -0.06151959788314921', 'Test LL: -0.051959916048744934', 'Epoch Time (s): 164.05150110204704')
('Epoch 19', 'Objective: -0.06253495996823263', 'Train Acc: 0.9807', 'Test Acc: 0.9833', 'Train LL: -0.0592552387448751', 'Test LL: -0.05273532028783287', 'Epoch Time (s): 164.09592556511052')
('Epoch 20', 'Objective: -0.06091469721706333', 'Train Acc: 0.9809833333333333', 'Test Acc: 0.9775', 'Train LL: -0.057746324385458125', 'Test LL: -0.07129608978846728', 'Epoch Time (s): 164.14388345205225')
('Epoch 21', 'Objective: -0.05850186191250272', 'Train Acc: 0.9821333333333333', 'Test Acc: 0.9868', 'Train LL: -0.055374601265716895', 'Test LL: -0.04107929939008345', 'Epoch Time (s): 164.07253817887977')
('Epoch 22', 'Objective: -0.0574856013294565', 'Train Acc: 0.98245', 'Test Acc: 0.9848', 'Train LL: -0.05449056934982418', 'Test LL: -0.04593255437648169', 'Epoch Time (s): 164.06505401898175')
('Epoch 23', 'Objective: -0.05700137367168541', 'Train Acc: 0.9826333333333334', 'Test Acc: 0.9852', 'Train LL: -0.05405070822205432', 'Test LL: -0.04844337115483776', 'Epoch Time (s): 164.15878328704275')
('Epoch 24', 'Objective: -0.055817800400213655', 'Train Acc: 0.9830333333333333', 'Test Acc: 0.9857', 'Train LL: -0.052955772700619026', 'Test LL: -0.044493410150827334', 'Epoch Time (s): 164.07936930796131')
('Epoch 25', 'Objective: -0.05370695256789839', 'Train Acc: 0.9831833333333333', 'Test Acc: 0.985', 'Train LL: -0.05087522535635721', 'Test LL: -0.04466400886954176', 'Epoch Time (s): 164.08545948099345')
('Epoch 26', 'Objective: -0.052029791790167354', 'Train Acc: 0.9839333333333333', 'Test Acc: 0.9865', 'Train LL: -0.049224438260874394', 'Test LL: -0.04125721984407079', 'Epoch Time (s): 164.12138464697637')
('Epoch 27', 'Objective: -0.05157120507825314', 'Train Acc: 0.9840666666666666', 'Test Acc: 0.9868', 'Train LL: -0.048880924998100164', 'Test LL: -0.0444403300648233', 'Epoch Time (s): 164.0830831520725')
('Epoch 28', 'Objective: -0.050974885912874385', 'Train Acc: 0.98375', 'Test Acc: 0.9815', 'Train LL: -0.0482640326110574', 'Test LL: -0.05372980101128307', 'Epoch Time (s): 164.11907094717026')
('Epoch 29', 'Objective: -0.049497448951476335', 'Train Acc: 0.9851', 'Test Acc: 0.9786', 'Train LL: -0.046857344373078334', 'Test LL: -0.06766144515768895', 'Epoch Time (s): 164.09443909185939')
('Epoch 30', 'Objective: -0.04979526921591079', 'Train Acc: 0.9854', 'Test Acc: 0.9887', 'Train LL: -0.04718577068128858', 'Test LL: -0.03571524548981639', 'Epoch Time (s): 164.11644557002')
('Epoch 31', 'Objective: -0.0493025988107946', 'Train Acc: 0.9848833333333333', 'Test Acc: 0.9882', 'Train LL: -0.046768305742981964', 'Test LL: -0.03600245441742456', 'Epoch Time (s): 164.1269459191244')
('Epoch 32', 'Objective: -0.048300707204051725', 'Train Acc: 0.9856333333333334', 'Test Acc: 0.9861', 'Train LL: -0.04578909446577335', 'Test LL: -0.04440647073521191', 'Epoch Time (s): 164.1829894860275')
('Epoch 33', 'Objective: -0.047780026969928995', 'Train Acc: 0.98575', 'Test Acc: 0.9868', 'Train LL: -0.045379959846309985', 'Test LL: -0.04183685793147111', 'Epoch Time (s): 164.20625526295044')
('Epoch 34', 'Objective: -0.04739681534691296', 'Train Acc: 0.9852166666666666', 'Test Acc: 0.987', 'Train LL: -0.04497119450623863', 'Test LL: -0.04247657203332685', 'Epoch Time (s): 164.1607934308704')
('Epoch 35', 'Objective: -0.04612614563729067', 'Train Acc: 0.98565', 'Test Acc: 0.9849', 'Train LL: -0.043723923061170934', 'Test LL: -0.047539507717123196', 'Epoch Time (s): 164.12171908887103')
('Epoch 36', 'Objective: -0.04582308748116535', 'Train Acc: 0.9859', 'Test Acc: 0.9886', 'Train LL: -0.04346883104742389', 'Test LL: -0.03553081065427352', 'Epoch Time (s): 164.06231145304628')
('Epoch 37', 'Objective: -0.04475202156436976', 'Train Acc: 0.9863833333333333', 'Test Acc: 0.9874', 'Train LL: -0.04241130338297414', 'Test LL: -0.03985955049768752', 'Epoch Time (s): 164.17739194398746')
('Epoch 38', 'Objective: -0.04325207076881185', 'Train Acc: 0.9868666666666667', 'Test Acc: 0.988', 'Train LL: -0.04097422302365303', 'Test LL: -0.04239137240096593', 'Epoch Time (s): 164.10345772700384')
('Epoch 39', 'Objective: -0.0431600270980296', 'Train Acc: 0.9870833333333333', 'Test Acc: 0.9868', 'Train LL: -0.04092480782180327', 'Test LL: -0.04117195240971822', 'Epoch Time (s): 164.1050774739124')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.027218292761582785', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9912', 'Train LL: -0.025389287615414452', 'Test LL: -0.02680409730193623', 'Epoch Time (s): 164.1756450170651')
('Epoch 41', 'Objective: -0.021615855845055945', 'Train Acc: 0.9933833333333333', 'Test Acc: 0.9913', 'Train LL: -0.01988651068778673', 'Test LL: -0.02686317232392435', 'Epoch Time (s): 164.09636393701658')
('Epoch 42', 'Objective: -0.020344602156967498', 'Train Acc: 0.9944', 'Test Acc: 0.9911', 'Train LL: -0.018674413325796217', 'Test LL: -0.024819372959665634', 'Epoch Time (s): 164.0626175799407')
('Epoch 43', 'Objective: -0.01899267559268994', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9914', 'Train LL: -0.01733650208093107', 'Test LL: -0.02489368050208235', 'Epoch Time (s): 163.9843591991812')
('Epoch 44', 'Objective: -0.01892324264204791', 'Train Acc: 0.9942', 'Test Acc: 0.9918', 'Train LL: -0.01729586240151062', 'Test LL: -0.0236649508264107', 'Epoch Time (s): 164.03770836722106')
('Epoch 45', 'Objective: -0.018114749478843273', 'Train Acc: 0.9946', 'Test Acc: 0.992', 'Train LL: -0.016501998844701465', 'Test LL: -0.025205967693704978', 'Epoch Time (s): 164.04290526011027')
('Epoch 46', 'Objective: -0.017067905026012603', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9928', 'Train LL: -0.015483816856737853', 'Test LL: -0.0232504419580467', 'Epoch Time (s): 164.04148490191437')
('Epoch 47', 'Objective: -0.016160383662293654', 'Train Acc: 0.9948833333333333', 'Test Acc: 0.9907', 'Train LL: -0.014609420036814548', 'Test LL: -0.028271447378529956', 'Epoch Time (s): 163.9952845890075')
('Epoch 48', 'Objective: -0.01631099106731185', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9908', 'Train LL: -0.01473991887748425', 'Test LL: -0.027863293714841232', 'Epoch Time (s): 164.07778492500074')
('Epoch 49', 'Objective: -0.015343367742002689', 'Train Acc: 0.9954333333333333', 'Test Acc: 0.9906', 'Train LL: -0.013802684611775626', 'Test LL: -0.0280585426353589', 'Epoch Time (s): 164.05678834300488')
('Epoch 50', 'Objective: -0.014819167041787517', 'Train Acc: 0.99545', 'Test Acc: 0.9924', 'Train LL: -0.013297341761210925', 'Test LL: -0.02393756424171426', 'Epoch Time (s): 164.04534814693034')
('Epoch 51', 'Objective: -0.014324380689706208', 'Train Acc: 0.9958166666666667', 'Test Acc: 0.9917', 'Train LL: -0.012821825432258219', 'Test LL: -0.02593984153155535', 'Epoch Time (s): 164.01737985596992')
('Epoch 52', 'Objective: -0.015023429350753525', 'Train Acc: 0.99565', 'Test Acc: 0.9917', 'Train LL: -0.013507927100812864', 'Test LL: -0.025096265914955153', 'Epoch Time (s): 164.04386951006018')
('Epoch 53', 'Objective: -0.013775971232977498', 'Train Acc: 0.9960666666666667', 'Test Acc: 0.9914', 'Train LL: -0.012300495557592031', 'Test LL: -0.026557437753736396', 'Epoch Time (s): 164.0735948102083')
('Epoch 54', 'Objective: -0.013795721489292454', 'Train Acc: 0.9959333333333333', 'Test Acc: 0.9927', 'Train LL: -0.012305157699895661', 'Test LL: -0.02419620948605053', 'Epoch Time (s): 164.0859911320731')
('Epoch 55', 'Objective: -0.013161491077694569', 'Train Acc: 0.9959333333333333', 'Test Acc: 0.9903', 'Train LL: -0.01168186694584615', 'Test LL: -0.030451160568864943', 'Epoch Time (s): 164.0901355710812')
('Epoch 56', 'Objective: -0.013262468797677063', 'Train Acc: 0.9960166666666667', 'Test Acc: 0.9893', 'Train LL: -0.011777183925306347', 'Test LL: -0.03220757322134406', 'Epoch Time (s): 163.9878749200143')
('Epoch 57', 'Objective: -0.013336384443816702', 'Train Acc: 0.99605', 'Test Acc: 0.9911', 'Train LL: -0.011847741870340352', 'Test LL: -0.02605399899622511', 'Epoch Time (s): 164.05788416415453')
('Epoch 58', 'Objective: -0.011755151124481082', 'Train Acc: 0.9965166666666667', 'Test Acc: 0.9904', 'Train LL: -0.010318130191879125', 'Test LL: -0.027257576759328803', 'Epoch Time (s): 164.06323742307723')
('Epoch 59', 'Objective: -0.012479395873678191', 'Train Acc: 0.9961833333333333', 'Test Acc: 0.9911', 'Train LL: -0.011022202637233063', 'Test LL: -0.02725653222407397', 'Epoch Time (s): 164.01157192210667')
('Epoch 60', 'Objective: -0.011902347371057503', 'Train Acc: 0.9967166666666667', 'Test Acc: 0.9897', 'Train LL: -0.010465749072484001', 'Test LL: -0.02880760094677882', 'Epoch Time (s): 164.02711836597882')
('Epoch 61', 'Objective: -0.011648833401618217', 'Train Acc: 0.9963333333333333', 'Test Acc: 0.9914', 'Train LL: -0.010224694322520942', 'Test LL: -0.027355935397584994', 'Epoch Time (s): 164.0116673950106')
('Epoch 62', 'Objective: -0.011660222423942903', 'Train Acc: 0.9963833333333333', 'Test Acc: 0.9907', 'Train LL: -0.010230941794863871', 'Test LL: -0.028045314772997664', 'Epoch Time (s): 164.08752075885423')
('Epoch 63', 'Objective: -0.01090974250930446', 'Train Acc: 0.9966666666666667', 'Test Acc: 0.9917', 'Train LL: -0.009493831140690892', 'Test LL: -0.02638704543304782', 'Epoch Time (s): 164.0483660150785')
('Epoch 64', 'Objective: -0.011186540739733405', 'Train Acc: 0.99645', 'Test Acc: 0.9908', 'Train LL: -0.009767489381212503', 'Test LL: -0.031352894926138575', 'Epoch Time (s): 164.0618968140334')
('Epoch 65', 'Objective: -0.010759003717546659', 'Train Acc: 0.9967666666666667', 'Test Acc: 0.9911', 'Train LL: -0.009368273755139506', 'Test LL: -0.028116349023127405', 'Epoch Time (s): 164.02337052696384')
('Epoch 66', 'Objective: -0.011078206994885867', 'Train Acc: 0.9965666666666667', 'Test Acc: 0.9928', 'Train LL: -0.009660412114110674', 'Test LL: -0.02599636066433619', 'Epoch Time (s): 164.09130184398964')
('Epoch 67', 'Objective: -0.010335633591034774', 'Train Acc: 0.9971666666666666', 'Test Acc: 0.9903', 'Train LL: -0.008970323463929734', 'Test LL: -0.0316200531579603', 'Epoch Time (s): 164.05144980712794')
('Epoch 68', 'Objective: -0.010201583888914354', 'Train Acc: 0.9970166666666667', 'Test Acc: 0.9913', 'Train LL: -0.008827904884390524', 'Test LL: -0.028511535528051718', 'Epoch Time (s): 164.02461261488497')
('Epoch 69', 'Objective: -0.010026968357765393', 'Train Acc: 0.9970833333333333', 'Test Acc: 0.9902', 'Train LL: -0.008660955810707697', 'Test LL: -0.03171977093252582', 'Epoch Time (s): 164.01576265413314')
('Epoch 70', 'Objective: -0.010733269701472899', 'Train Acc: 0.9966333333333334', 'Test Acc: 0.9913', 'Train LL: -0.009329912134274981', 'Test LL: -0.02807483988865813', 'Epoch Time (s): 164.03057143394835')
('Epoch 71', 'Objective: -0.010108667554416098', 'Train Acc: 0.9969166666666667', 'Test Acc: 0.99', 'Train LL: -0.008769621790072886', 'Test LL: -0.03407128426092698', 'Epoch Time (s): 164.04003086616285')
('Epoch 72', 'Objective: -0.009890356673382774', 'Train Acc: 0.99705', 'Test Acc: 0.9906', 'Train LL: -0.008544253252230039', 'Test LL: -0.029585362331131727', 'Epoch Time (s): 164.03665623907')
('Epoch 73', 'Objective: -0.009806091163967244', 'Train Acc: 0.9972', 'Test Acc: 0.9897', 'Train LL: -0.008468925034130851', 'Test LL: -0.03364352890517621', 'Epoch Time (s): 163.96083236602135')
('Epoch 74', 'Objective: -0.009821657003826607', 'Train Acc: 0.9969333333333333', 'Test Acc: 0.9908', 'Train LL: -0.008479915307148755', 'Test LL: -0.030646019438770895', 'Epoch Time (s): 163.95225362293422')
('Epoch 75', 'Objective: -0.00855681780190217', 'Train Acc: 0.9975833333333334', 'Test Acc: 0.9906', 'Train LL: -0.007253700182967642', 'Test LL: -0.03315151274399946', 'Epoch Time (s): 164.0009345910512')
('Epoch 76', 'Objective: -0.008887869069001396', 'Train Acc: 0.9975', 'Test Acc: 0.9917', 'Train LL: -0.00756890535756614', 'Test LL: -0.029367054076473345', 'Epoch Time (s): 164.00791442510672')
('Epoch 77', 'Objective: -0.008704500272883239', 'Train Acc: 0.9974333333333333', 'Test Acc: 0.9908', 'Train LL: -0.007389727894898637', 'Test LL: -0.029697110563262463', 'Epoch Time (s): 164.09554902208038')
('Epoch 78', 'Objective: -0.00853070046128369', 'Train Acc: 0.9974333333333333', 'Test Acc: 0.9904', 'Train LL: -0.0072114068259809625', 'Test LL: -0.03305671707138387', 'Epoch Time (s): 164.08402998908423')
('Epoch 79', 'Objective: -0.008662265414005603', 'Train Acc: 0.9975833333333334', 'Test Acc: 0.9901', 'Train LL: -0.007357993228516403', 'Test LL: -0.034178738048955846', 'Epoch Time (s): 164.05411375896074')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.00694863557743053', 'Train Acc: 0.9980166666666667', 'Test Acc: 0.9911', 'Train LL: -0.005713525499540202', 'Test LL: -0.032171708499123944', 'Epoch Time (s): 164.12164651602507')
('Epoch 81', 'Objective: -0.006254824428773503', 'Train Acc: 0.9985166666666667', 'Test Acc: 0.9911', 'Train LL: -0.0050599493625896426', 'Test LL: -0.031248750144780558', 'Epoch Time (s): 164.08111284999177')
('Epoch 82', 'Objective: -0.00613955166733336', 'Train Acc: 0.9984833333333333', 'Test Acc: 0.9907', 'Train LL: -0.004950539563458535', 'Test LL: -0.03211796760773807', 'Epoch Time (s): 163.99286956596188')
('Epoch 83', 'Objective: nan', 'Train Acc: 0.9986333333333334', 'Test Acc: 0.9906', 'Train LL: -0.0041221679920181225', 'Test LL: -0.03301136050436918', 'Epoch Time (s): 164.68113103485666')
('Epoch 84', 'Objective: -0.005420015555374335', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9901', 'Train LL: -0.0042390232574068204', 'Test LL: -0.03375485020375394', 'Epoch Time (s): 164.65763922594488')
('Epoch 85', 'Objective: -0.005376012102965646', 'Train Acc: 0.99855', 'Test Acc: 0.9906', 'Train LL: -0.004185802443723243', 'Test LL: -0.03317245409691841', 'Epoch Time (s): 164.61979504604824')
('Epoch 86', 'Objective: -0.005389148035298236', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.9911', 'Train LL: -0.00418750777264939', 'Test LL: -0.034140088009064706', 'Epoch Time (s): 164.64398155803792')
('Epoch 87', 'Objective: -0.00518092058053078', 'Train Acc: 0.99865', 'Test Acc: 0.9907', 'Train LL: -0.003992615349271368', 'Test LL: -0.034484450368097386', 'Epoch Time (s): 164.60321506601758')
('Epoch 88', 'Objective: -0.005167855151760641', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9903', 'Train LL: -0.00396326664143903', 'Test LL: -0.0347380498115373', 'Epoch Time (s): 164.6284822728485')
('Epoch 89', 'Objective: -0.004970499732875832', 'Train Acc: 0.9987', 'Test Acc: 0.991', 'Train LL: -0.0037748722057830324', 'Test LL: -0.03452983016717575', 'Epoch Time (s): 164.68875687615946')
('Epoch 90', 'Objective: -0.005231470423059263', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9906', 'Train LL: -0.0040217028505555134', 'Test LL: -0.035335216102720925', 'Epoch Time (s): 164.65839672205038')
('Epoch 91', 'Objective: -0.004678710737418493', 'Train Acc: 0.9988', 'Test Acc: 0.9905', 'Train LL: -0.003481894220972558', 'Test LL: -0.03525845393968044', 'Epoch Time (s): 164.63938546204008')
('Epoch 92', 'Objective: -0.004816320259316688', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9905', 'Train LL: -0.003622265813199138', 'Test LL: -0.03673588541085519', 'Epoch Time (s): 164.59690514579415')
('Epoch 93', 'Objective: -0.004604561134816951', 'Train Acc: 0.99885', 'Test Acc: 0.9898', 'Train LL: -0.0033913193508379805', 'Test LL: -0.03680668638328968', 'Epoch Time (s): 164.6028610020876')
('Epoch 94', 'Objective: -0.0047248453614721275', 'Train Acc: 0.9990166666666667', 'Test Acc: 0.9904', 'Train LL: -0.0035170397081172116', 'Test LL: -0.03709277842213431', 'Epoch Time (s): 164.6789721690584')
('Epoch 95', 'Objective: -0.004766966176417224', 'Train Acc: 0.9988333333333334', 'Test Acc: 0.9903', 'Train LL: -0.0035543345077006356', 'Test LL: -0.03550035661413315', 'Epoch Time (s): 164.62361392797902')
('Epoch 96', 'Objective: -0.004766969685913011', 'Train Acc: 0.9988666666666667', 'Test Acc: 0.9908', 'Train LL: -0.0035523193032664354', 'Test LL: -0.036236433734296004', 'Epoch Time (s): 164.61071679904126')
('Epoch 97', 'Objective: -0.004312806153897009', 'Train Acc: 0.9989333333333333', 'Test Acc: 0.9898', 'Train LL: -0.0031135535528682523', 'Test LL: -0.03930771227628347', 'Epoch Time (s): 164.55081227910705')
('Epoch 98', 'Objective: -0.004432643576323266', 'Train Acc: 0.99895', 'Test Acc: 0.9902', 'Train LL: -0.0032289034776934373', 'Test LL: -0.03762159669172069', 'Epoch Time (s): 164.55890440405346')
('Epoch 99', 'Objective: -0.004568279596482301', 'Train Acc: 0.9989666666666667', 'Test Acc: 0.9909', 'Train LL: -0.0033580921138828897', 'Test LL: -0.03582323246426999', 'Epoch Time (s): 164.58084811200388')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.003980017574001743
Final Train Accuracy: £0.9990666666666667
Final Train LL: £-0.0028008244755282465
Final Test Accuracy: £0.9907
Final Test LL: £-0.03593630453600679
