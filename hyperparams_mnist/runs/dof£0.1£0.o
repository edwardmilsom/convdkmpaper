dataset: MNIST
dtype: float64
dof: 0.1
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2443611431801425', 'Train Acc: 0.5698', 'Test Acc: 0.7915', 'Train LL: -1.2084449664212331', 'Test LL: -0.6434796107183238', 'Epoch Time (s): 172.44915944105014')
('Epoch 1', 'Objective: -0.40801660537223317', 'Train Acc: 0.8765833333333334', 'Test Acc: 0.9081', 'Train LL: -0.379497468610636', 'Test LL: -0.2886464116786341', 'Epoch Time (s): 171.38384202122688')
('Epoch 2', 'Objective: -0.2518281047442988', 'Train Acc: 0.9300666666666667', 'Test Acc: 0.9526', 'Train LL: -0.22689421241944305', 'Test LL: -0.14943005303771337', 'Epoch Time (s): 171.3627876751125')
('Epoch 3', 'Objective: -0.2043038640905558', 'Train Acc: 0.94455', 'Test Acc: 0.9475', 'Train LL: -0.18149165597155328', 'Test LL: -0.17143086921769238', 'Epoch Time (s): 171.39700628491119')
('Epoch 4', 'Objective: -0.17351701702854283', 'Train Acc: 0.9522333333333334', 'Test Acc: 0.951', 'Train LL: -0.1521151582682871', 'Test LL: -0.16024378917791215', 'Epoch Time (s): 171.42337698396295')
('Epoch 5', 'Objective: -0.15559919279236986', 'Train Acc: 0.9586166666666667', 'Test Acc: 0.9704', 'Train LL: -0.13540097201082835', 'Test LL: -0.09422925578248197', 'Epoch Time (s): 171.39668921986595')
('Epoch 6', 'Objective: -0.1377332498884937', 'Train Acc: 0.9623833333333334', 'Test Acc: 0.9576', 'Train LL: -0.1185435099862334', 'Test LL: -0.12882749849111602', 'Epoch Time (s): 171.33161010034382')
('Epoch 7', 'Objective: -0.13085827373975933', 'Train Acc: 0.9647', 'Test Acc: 0.9744', 'Train LL: -0.1124189202437271', 'Test LL: -0.08155256407230553', 'Epoch Time (s): 171.37593738827854')
('Epoch 8', 'Objective: -0.12065402364148074', 'Train Acc: 0.9681', 'Test Acc: 0.965', 'Train LL: -0.10309871038797294', 'Test LL: -0.11089448887564313', 'Epoch Time (s): 171.3976153349504')
('Epoch 9', 'Objective: -0.11231157741914148', 'Train Acc: 0.9703166666666667', 'Test Acc: 0.9767', 'Train LL: -0.0954414277695346', 'Test LL: -0.06843412241642029', 'Epoch Time (s): 171.40721940761432')
('Epoch 10', 'Objective: -0.1043663245944591', 'Train Acc: 0.97175', 'Test Acc: 0.9743', 'Train LL: -0.08815137304091442', 'Test LL: -0.0788834535839828', 'Epoch Time (s): 171.35497089615092')
('Epoch 11', 'Objective: -0.09805408171807209', 'Train Acc: 0.9733833333333334', 'Test Acc: 0.9779', 'Train LL: -0.08220039888317687', 'Test LL: -0.06644308671959559', 'Epoch Time (s): 171.3405891242437')
('Epoch 12', 'Objective: -0.09574596613551552', 'Train Acc: 0.97415', 'Test Acc: 0.9787', 'Train LL: -0.08056263833399377', 'Test LL: -0.06653385627032714', 'Epoch Time (s): 171.40792047418654')
('Epoch 13', 'Objective: -0.09059535179458504', 'Train Acc: 0.9760166666666666', 'Test Acc: 0.9742', 'Train LL: -0.07581217525720425', 'Test LL: -0.07406914117332296', 'Epoch Time (s): 171.36648492421955')
('Epoch 14', 'Objective: -0.09102674057689933', 'Train Acc: 0.9754333333333334', 'Test Acc: 0.9764', 'Train LL: -0.07645957016583618', 'Test LL: -0.07130250124561008', 'Epoch Time (s): 171.3779886472039')
('Epoch 15', 'Objective: -0.08315626562956992', 'Train Acc: 0.97795', 'Test Acc: 0.9784', 'Train LL: -0.06890225692952477', 'Test LL: -0.06606763507630355', 'Epoch Time (s): 171.40102471783757')
('Epoch 16', 'Objective: -0.08091604025456489', 'Train Acc: 0.9783333333333334', 'Test Acc: 0.9806', 'Train LL: -0.0670677931630452', 'Test LL: -0.057943761366776765', 'Epoch Time (s): 171.44089367892593')
('Epoch 17', 'Objective: -0.0815466419747892', 'Train Acc: 0.9785666666666667', 'Test Acc: 0.9871', 'Train LL: -0.06790701520762465', 'Test LL: -0.039880815999865205', 'Epoch Time (s): 171.41070325113833')
('Epoch 18', 'Objective: -0.07819702879482694', 'Train Acc: 0.9797', 'Test Acc: 0.9815', 'Train LL: -0.06495747683759624', 'Test LL: -0.055799022264582866', 'Epoch Time (s): 171.40748932911083')
('Epoch 19', 'Objective: -0.07624428428197073', 'Train Acc: 0.9797833333333333', 'Test Acc: 0.9759', 'Train LL: -0.06305106922286909', 'Test LL: -0.0705309537089427', 'Epoch Time (s): 171.3951082341373')
('Epoch 20', 'Objective: -0.07442374339926541', 'Train Acc: 0.9810833333333333', 'Test Acc: 0.9803', 'Train LL: -0.06148985494320362', 'Test LL: -0.06057261724823359', 'Epoch Time (s): 171.36634326493368')
('Epoch 21', 'Objective: -0.0750329217935455', 'Train Acc: 0.9799833333333333', 'Test Acc: 0.9861', 'Train LL: -0.06212727897119364', 'Test LL: -0.04586080054408868', 'Epoch Time (s): 171.36214432213455')
('Epoch 22', 'Objective: -0.07080107925523652', 'Train Acc: 0.9812', 'Test Acc: 0.9799', 'Train LL: -0.05817419511577712', 'Test LL: -0.06324417843640419', 'Epoch Time (s): 171.3862465559505')
('Epoch 23', 'Objective: -0.06996169913052615', 'Train Acc: 0.9816', 'Test Acc: 0.9837', 'Train LL: -0.05758300237111899', 'Test LL: -0.048956625500147406', 'Epoch Time (s): 171.3788644913584')
('Epoch 24', 'Objective: -0.06976111564546443', 'Train Acc: 0.9822', 'Test Acc: 0.9705', 'Train LL: -0.057385984909487674', 'Test LL: -0.09320143405742606', 'Epoch Time (s): 171.36626384966075')
('Epoch 25', 'Objective: -0.06832673566619382', 'Train Acc: 0.9822', 'Test Acc: 0.9826', 'Train LL: -0.056268723683581524', 'Test LL: -0.05163720576452636', 'Epoch Time (s): 171.3536543380469')
('Epoch 26', 'Objective: -0.0665037118403423', 'Train Acc: 0.9825666666666667', 'Test Acc: 0.986', 'Train LL: -0.05439258976518012', 'Test LL: -0.04324708140248297', 'Epoch Time (s): 171.37940075434744')
('Epoch 27', 'Objective: -0.06420108371071485', 'Train Acc: 0.9835166666666667', 'Test Acc: 0.9866', 'Train LL: -0.052399477052597995', 'Test LL: -0.040504695968127384', 'Epoch Time (s): 171.3629055568017')
('Epoch 28', 'Objective: -0.06403092705604652', 'Train Acc: 0.9828333333333333', 'Test Acc: 0.9778', 'Train LL: -0.052274545253805864', 'Test LL: -0.061947880008141956', 'Epoch Time (s): 171.32700012391433')
('Epoch 29', 'Objective: -0.06465524014622324', 'Train Acc: 0.9833666666666666', 'Test Acc: 0.9845', 'Train LL: -0.05287765138163188', 'Test LL: -0.053555096908405105', 'Epoch Time (s): 171.35127512086183')
('Epoch 30', 'Objective: -0.062079897079335776', 'Train Acc: 0.9836333333333334', 'Test Acc: 0.9873', 'Train LL: -0.05052701875494927', 'Test LL: -0.04322176660146802', 'Epoch Time (s): 171.36680439207703')
('Epoch 31', 'Objective: -0.06211721125263263', 'Train Acc: 0.9837333333333333', 'Test Acc: 0.9776', 'Train LL: -0.050605546072435045', 'Test LL: -0.06972763611970463', 'Epoch Time (s): 171.3876723172143')
('Epoch 32', 'Objective: -0.060926504206579996', 'Train Acc: 0.98425', 'Test Acc: 0.9832', 'Train LL: -0.049646732521665085', 'Test LL: -0.047243253419462346', 'Epoch Time (s): 171.48898665886372')
('Epoch 33', 'Objective: -0.06053428346678504', 'Train Acc: 0.9842', 'Test Acc: 0.9855', 'Train LL: -0.049293831213747016', 'Test LL: -0.04635993778452433', 'Epoch Time (s): 171.3613324961625')
('Epoch 34', 'Objective: -0.05822433372777392', 'Train Acc: 0.9852666666666666', 'Test Acc: 0.9857', 'Train LL: -0.047058660162709466', 'Test LL: -0.047081918274854466', 'Epoch Time (s): 171.35330110881478')
('Epoch 35', 'Objective: -0.05867389470386248', 'Train Acc: 0.9847833333333333', 'Test Acc: 0.98', 'Train LL: -0.047492763411843074', 'Test LL: -0.06184089348193876', 'Epoch Time (s): 171.3326680441387')
('Epoch 36', 'Objective: -0.057032523334440935', 'Train Acc: 0.98525', 'Test Acc: 0.9861', 'Train LL: -0.045982986653848534', 'Test LL: -0.04442374720965583', 'Epoch Time (s): 171.395665936172')
('Epoch 37', 'Objective: -0.05739265273291042', 'Train Acc: 0.9850833333333333', 'Test Acc: 0.9806', 'Train LL: -0.046344276027606976', 'Test LL: -0.061389085248064974', 'Epoch Time (s): 171.4398976317607')
('Epoch 38', 'Objective: -0.05626084446493578', 'Train Acc: 0.9850166666666667', 'Test Acc: 0.9874', 'Train LL: -0.045311210522039354', 'Test LL: -0.03978203679605045', 'Epoch Time (s): 171.39428292680532')
('Epoch 39', 'Objective: -0.054875640599425304', 'Train Acc: 0.9856833333333334', 'Test Acc: 0.9863', 'Train LL: -0.04408149948182737', 'Test LL: -0.04245916208532753', 'Epoch Time (s): 171.34979188395664')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.037865127548470504', 'Train Acc: 0.9909666666666667', 'Test Acc: 0.9907', 'Train LL: -0.027813230875198464', 'Test LL: -0.028803288395945502', 'Epoch Time (s): 171.35096377693117')
('Epoch 41', 'Objective: -0.03261957332913242', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9918', 'Train LL: -0.023104285285653153', 'Test LL: -0.02582424795937451', 'Epoch Time (s): 171.39352564839646')
('Epoch 42', 'Objective: -0.03150039579417996', 'Train Acc: 0.99295', 'Test Acc: 0.9906', 'Train LL: -0.022119418878293717', 'Test LL: -0.02769674487417344', 'Epoch Time (s): 171.38001687033102')
('Epoch 43', 'Objective: -0.03037456048846675', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9921', 'Train LL: -0.02107991326666949', 'Test LL: -0.025241970754485133', 'Epoch Time (s): 171.400942964945')
('Epoch 44', 'Objective: -0.030192801363796592', 'Train Acc: 0.9933166666666666', 'Test Acc: 0.9917', 'Train LL: -0.020910645113774117', 'Test LL: -0.026126234305838266', 'Epoch Time (s): 171.39302405994385')
('Epoch 45', 'Objective: -0.028652615122829808', 'Train Acc: 0.9935833333333334', 'Test Acc: 0.9911', 'Train LL: -0.019513352950840696', 'Test LL: -0.025467465469314714', 'Epoch Time (s): 171.33584462990984')
('Epoch 46', 'Objective: -0.028267663514148562', 'Train Acc: 0.99355', 'Test Acc: 0.9898', 'Train LL: -0.01918373527638893', 'Test LL: -0.031079048073787124', 'Epoch Time (s): 171.36516619613394')
('Epoch 47', 'Objective: -0.028572036017258582', 'Train Acc: 0.9937666666666667', 'Test Acc: 0.9916', 'Train LL: -0.019499724321325747', 'Test LL: -0.025057580178696887', 'Epoch Time (s): 171.44665331812575')
('Epoch 48', 'Objective: -0.028491285192662467', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.9913', 'Train LL: -0.01942807965060394', 'Test LL: -0.024794924032975695', 'Epoch Time (s): 171.39883858012035')
('Epoch 49', 'Objective: -0.02703621052248733', 'Train Acc: 0.99415', 'Test Acc: 0.9904', 'Train LL: -0.01808674090268398', 'Test LL: -0.028096699701144725', 'Epoch Time (s): 171.36366748809814')
('Epoch 50', 'Objective: -0.026694999085964784', 'Train Acc: 0.9942333333333333', 'Test Acc: 0.9923', 'Train LL: -0.01774930171349334', 'Test LL: -0.02455607529546221', 'Epoch Time (s): 171.33560780528933')
('Epoch 51', 'Objective: -0.026141166227935452', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9913', 'Train LL: -0.01721012317661757', 'Test LL: -0.028023866647819976', 'Epoch Time (s): 171.41786556504667')
('Epoch 52', 'Objective: -0.025958748366664158', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9916', 'Train LL: -0.01701456213170796', 'Test LL: -0.024970595410318364', 'Epoch Time (s): 171.40851895976812')
('Epoch 53', 'Objective: -0.02530195036921341', 'Train Acc: 0.99455', 'Test Acc: 0.9921', 'Train LL: -0.01646375785225156', 'Test LL: -0.02585180991847725', 'Epoch Time (s): 171.33468996733427')
('Epoch 54', 'Objective: -0.025759259097457382', 'Train Acc: 0.99465', 'Test Acc: 0.9928', 'Train LL: -0.016866511306746216', 'Test LL: -0.023869478309380934', 'Epoch Time (s): 171.39712651027367')
('Epoch 55', 'Objective: -0.024511420051865403', 'Train Acc: 0.99475', 'Test Acc: 0.9915', 'Train LL: -0.015679177806622212', 'Test LL: -0.02554031173662007', 'Epoch Time (s): 171.41844673687592')
('Epoch 56', 'Objective: -0.024438949554585733', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9915', 'Train LL: -0.01570239623300835', 'Test LL: -0.02676636095439669', 'Epoch Time (s): 171.36689470428973')
('Epoch 57', 'Objective: -0.024205396315232608', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9917', 'Train LL: -0.015415053165700427', 'Test LL: -0.02518501164437033', 'Epoch Time (s): 171.37501009786502')
('Epoch 58', 'Objective: -0.023673157314581018', 'Train Acc: 0.9951166666666666', 'Test Acc: 0.9915', 'Train LL: -0.014847926270907055', 'Test LL: -0.026789583490858103', 'Epoch Time (s): 171.34950124658644')
('Epoch 59', 'Objective: -0.024246242313209147', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9913', 'Train LL: -0.015462508398946844', 'Test LL: -0.027634081743982575', 'Epoch Time (s): 171.36567420698702')
('Epoch 60', 'Objective: -0.024032993740076048', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9912', 'Train LL: -0.015311319976980662', 'Test LL: -0.02714096503063723', 'Epoch Time (s): 171.37809327198192')
('Epoch 61', 'Objective: -0.02406701412618033', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9922', 'Train LL: -0.015305581990617446', 'Test LL: -0.02521091816795948', 'Epoch Time (s): 171.36315670609474')
('Epoch 62', 'Objective: -0.023345134878127203', 'Train Acc: 0.99495', 'Test Acc: 0.9909', 'Train LL: -0.014607701620469506', 'Test LL: -0.029898039288160233', 'Epoch Time (s): 171.36473015416414')
('Epoch 63', 'Objective: -0.022690930244488948', 'Train Acc: 0.9951333333333333', 'Test Acc: 0.9907', 'Train LL: -0.013989135167845449', 'Test LL: -0.028964687465038105', 'Epoch Time (s): 171.3455290910788')
('Epoch 64', 'Objective: -0.022679918767067677', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9919', 'Train LL: -0.013975756760826444', 'Test LL: -0.026145106753960083', 'Epoch Time (s): 171.3433990138583')
('Epoch 65', 'Objective: -0.023353657631524534', 'Train Acc: 0.9951333333333333', 'Test Acc: 0.9924', 'Train LL: -0.014651437058996415', 'Test LL: -0.024067716174898425', 'Epoch Time (s): 171.34395601507276')
('Epoch 66', 'Objective: -0.02274774613841384', 'Train Acc: 0.9953', 'Test Acc: 0.9926', 'Train LL: -0.014025182349448466', 'Test LL: -0.02699249206107937', 'Epoch Time (s): 171.3403045712039')
('Epoch 67', 'Objective: -0.022264961708062976', 'Train Acc: 0.99545', 'Test Acc: 0.9915', 'Train LL: -0.01356836667404508', 'Test LL: -0.026209461886828093', 'Epoch Time (s): 171.24096175376326')
('Epoch 68', 'Objective: -0.022541958152837074', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9926', 'Train LL: -0.013815549751934367', 'Test LL: -0.0252118225457196', 'Epoch Time (s): 171.2735824319534')
('Epoch 69', 'Objective: -0.021371632000214875', 'Train Acc: 0.9957333333333334', 'Test Acc: 0.9906', 'Train LL: -0.012693849350625645', 'Test LL: -0.02880445076658391', 'Epoch Time (s): 171.21914318110794')
('Epoch 70', 'Objective: -0.02146912243654934', 'Train Acc: 0.9958333333333333', 'Test Acc: 0.9919', 'Train LL: -0.012809812462458072', 'Test LL: -0.025090479822773334', 'Epoch Time (s): 171.27103106491268')
('Epoch 71', 'Objective: -0.022008053409114745', 'Train Acc: 0.9957166666666667', 'Test Acc: 0.9919', 'Train LL: -0.01335960442546743', 'Test LL: -0.02741142015782692', 'Epoch Time (s): 171.2632244983688')
('Epoch 72', 'Objective: -0.021026578356342123', 'Train Acc: 0.9955666666666667', 'Test Acc: 0.9904', 'Train LL: -0.012494654519763287', 'Test LL: -0.029421226290292538', 'Epoch Time (s): 171.3155018868856')
('Epoch 73', 'Objective: -0.02067865333734663', 'Train Acc: 0.996', 'Test Acc: 0.9907', 'Train LL: -0.01208155736976073', 'Test LL: -0.03022239480409388', 'Epoch Time (s): 171.27750066434965')
('Epoch 74', 'Objective: -0.020940173355723787', 'Train Acc: 0.9956666666666667', 'Test Acc: 0.9915', 'Train LL: -0.012322258858299346', 'Test LL: -0.027010691367819636', 'Epoch Time (s): 171.27056015701964')
('Epoch 75', 'Objective: -0.020257932255836632', 'Train Acc: 0.9961', 'Test Acc: 0.9917', 'Train LL: -0.011662729339514647', 'Test LL: -0.027731737839325206', 'Epoch Time (s): 171.23345653619617')
('Epoch 76', 'Objective: -0.02033162084454395', 'Train Acc: 0.99605', 'Test Acc: 0.9909', 'Train LL: -0.01174934970101148', 'Test LL: -0.028860551095025198', 'Epoch Time (s): 171.2349375099875')
('Epoch 77', 'Objective: -0.020589835797563315', 'Train Acc: 0.9961166666666667', 'Test Acc: 0.9913', 'Train LL: -0.011963670214776052', 'Test LL: -0.030969636746850437', 'Epoch Time (s): 171.24611704517156')
('Epoch 78', 'Objective: -0.020920117857050533', 'Train Acc: 0.99595', 'Test Acc: 0.9932', 'Train LL: -0.012314917433989879', 'Test LL: -0.023947594760137657', 'Epoch Time (s): 171.25758599396795')
('Epoch 79', 'Objective: -0.020307782447703135', 'Train Acc: 0.9961', 'Test Acc: 0.9924', 'Train LL: -0.011768911705921474', 'Test LL: -0.024842081795923163', 'Epoch Time (s): 171.25021770223975')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.017990294125472307', 'Train Acc: 0.9966333333333334', 'Test Acc: 0.9925', 'Train LL: -0.009609764206681443', 'Test LL: -0.025439599873811763', 'Epoch Time (s): 171.2423528889194')
('Epoch 81', 'Objective: -0.017423936410065073', 'Train Acc: 0.9971', 'Test Acc: 0.9927', 'Train LL: -0.009065716261307631', 'Test LL: -0.025359003734421584', 'Epoch Time (s): 171.21805481659248')
('Epoch 82', 'Objective: -0.017166366128602128', 'Train Acc: 0.9971333333333333', 'Test Acc: 0.9926', 'Train LL: -0.008813663823277904', 'Test LL: -0.025322572335122764', 'Epoch Time (s): 171.2680018520914')
('Epoch 83', 'Objective: -0.017328069940066734', 'Train Acc: 0.9969166666666667', 'Test Acc: 0.9926', 'Train LL: -0.008942952310695978', 'Test LL: -0.025530444122706813', 'Epoch Time (s): 171.26432601222768')
('Epoch 84', 'Objective: -0.016853114627662754', 'Train Acc: 0.9973', 'Test Acc: 0.9925', 'Train LL: -0.008500267753754901', 'Test LL: -0.026247483463740978', 'Epoch Time (s): 171.36646828101948')
('Epoch 85', 'Objective: -0.01680131664102132', 'Train Acc: 0.9972166666666666', 'Test Acc: 0.9924', 'Train LL: -0.00841786533825048', 'Test LL: -0.025925360378303407', 'Epoch Time (s): 171.26635277224705')
('Epoch 86', 'Objective: -0.016717378723264842', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9924', 'Train LL: -0.008364829877064033', 'Test LL: -0.026256741007539296', 'Epoch Time (s): 171.29787310166284')
('Epoch 87', 'Objective: -0.016963360948533904', 'Train Acc: 0.9972833333333333', 'Test Acc: 0.9925', 'Train LL: -0.008564671758227583', 'Test LL: -0.025831240029699352', 'Epoch Time (s): 171.33739691926166')
('Epoch 88', 'Objective: -0.01645811788471832', 'Train Acc: 0.9972333333333333', 'Test Acc: 0.9927', 'Train LL: -0.00810310618843726', 'Test LL: -0.02611947715558875', 'Epoch Time (s): 171.2912332257256')
('Epoch 89', 'Objective: -0.016202913690377015', 'Train Acc: 0.9971666666666666', 'Test Acc: 0.9928', 'Train LL: -0.007811571951775496', 'Test LL: -0.02655337354519944', 'Epoch Time (s): 171.27207544492558')
('Epoch 90', 'Objective: -0.01652846366288289', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9926', 'Train LL: -0.008115604269041987', 'Test LL: -0.026019685377639233', 'Epoch Time (s): 171.23329636175185')
('Epoch 91', 'Objective: -0.016278187898748967', 'Train Acc: 0.9973833333333333', 'Test Acc: 0.993', 'Train LL: -0.007884605398180979', 'Test LL: -0.025896202516090375', 'Epoch Time (s): 171.2267685108818')
('Epoch 92', 'Objective: -0.01625186739891306', 'Train Acc: 0.9973666666666666', 'Test Acc: 0.9924', 'Train LL: -0.00784590787417075', 'Test LL: -0.027480583142673043', 'Epoch Time (s): 171.24666333803907')
('Epoch 93', 'Objective: -0.016062411752346736', 'Train Acc: 0.99755', 'Test Acc: 0.9925', 'Train LL: -0.00770479265825961', 'Test LL: -0.02727703012249018', 'Epoch Time (s): 171.2135559571907')
('Epoch 94', 'Objective: -0.016043555618352245', 'Train Acc: 0.9974', 'Test Acc: 0.9923', 'Train LL: -0.007650682029096493', 'Test LL: -0.027323836396611314', 'Epoch Time (s): 171.30232434300706')
('Epoch 95', 'Objective: -0.01564582575631115', 'Train Acc: 0.99755', 'Test Acc: 0.9925', 'Train LL: -0.0072858344698562075', 'Test LL: -0.02702983379548371', 'Epoch Time (s): 171.28439246723428')
('Epoch 96', 'Objective: -0.016116017533061702', 'Train Acc: 0.9975', 'Test Acc: 0.9915', 'Train LL: -0.007699551507733719', 'Test LL: -0.029017226788212145', 'Epoch Time (s): 171.25595710705966')
('Epoch 97', 'Objective: -0.01563926937386043', 'Train Acc: 0.9974333333333333', 'Test Acc: 0.9927', 'Train LL: -0.00726607593123563', 'Test LL: -0.027459044015304482', 'Epoch Time (s): 171.2149426410906')
('Epoch 98', 'Objective: -0.016265500167359597', 'Train Acc: 0.9975666666666667', 'Test Acc: 0.9925', 'Train LL: -0.007830383838106969', 'Test LL: -0.02674838236200647', 'Epoch Time (s): 171.25863185385242')
('Epoch 99', 'Objective: -0.0157341911115998', 'Train Acc: 0.9977', 'Test Acc: 0.9929', 'Train LL: -0.007342875265523197', 'Test LL: -0.026485466530750335', 'Epoch Time (s): 171.2748002591543')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.015614651937223235
Final Train Accuracy: £0.9977666666666667
Final Train LL: £-0.007247476227345803
Final Test Accuracy: £0.9931
Final Test LL: £-0.026410917682266558
