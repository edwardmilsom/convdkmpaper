dataset: MNIST
dtype: float64
dof: 0.0001
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2525485615518925', 'Train Acc: 0.5644166666666667', 'Test Acc: 0.8217', 'Train LL: -1.2184597399782335', 'Test LL: -0.5521742108104674', 'Epoch Time (s): 163.67723081097938')
('Epoch 1', 'Objective: -0.4708854079013161', 'Train Acc: 0.8464666666666667', 'Test Acc: 0.8914', 'Train LL: -0.45364939684696676', 'Test LL: -0.33813936821214063', 'Epoch Time (s): 163.70786178600974')
('Epoch 2', 'Objective: -0.2449826027795201', 'Train Acc: 0.9257833333333333', 'Test Acc: 0.9527', 'Train LL: -0.23333681166149753', 'Test LL: -0.14920775272240822', 'Epoch Time (s): 163.7682637819089')
('Epoch 3', 'Objective: -0.17853240121152733', 'Train Acc: 0.9472', 'Test Acc: 0.9642', 'Train LL: -0.16953419772278364', 'Test LL: -0.10785935328567052', 'Epoch Time (s): 163.6718400400132')
('Epoch 4', 'Objective: -0.14962004699420337', 'Train Acc: 0.9554', 'Test Acc: 0.9591', 'Train LL: -0.14176299021806874', 'Test LL: -0.12766872776094315', 'Epoch Time (s): 163.67754075699486')
('Epoch 5', 'Objective: -0.1306485028232332', 'Train Acc: 0.96165', 'Test Acc: 0.9643', 'Train LL: -0.12372843234802298', 'Test LL: -0.11333183859582141', 'Epoch Time (s): 163.69472137605771')
('Epoch 6', 'Objective: -0.11796313539309801', 'Train Acc: 0.9647333333333333', 'Test Acc: 0.9722', 'Train LL: -0.11159170968687544', 'Test LL: -0.0815705434825563', 'Epoch Time (s): 163.68044827808626')
('Epoch 7', 'Objective: -0.10649709257586498', 'Train Acc: 0.9687', 'Test Acc: 0.9739', 'Train LL: -0.1005772946861682', 'Test LL: -0.07781399527275205', 'Epoch Time (s): 163.66892884206027')
('Epoch 8', 'Objective: -0.09749716590424093', 'Train Acc: 0.9704833333333334', 'Test Acc: 0.9716', 'Train LL: -0.09189046027444635', 'Test LL: -0.08715531884190125', 'Epoch Time (s): 163.6627658389043')
('Epoch 9', 'Objective: -0.09020788869892546', 'Train Acc: 0.9731', 'Test Acc: 0.9729', 'Train LL: -0.08483742929844401', 'Test LL: -0.0845406853946084', 'Epoch Time (s): 163.64688551798463')
('Epoch 10', 'Objective: -0.0862583712994921', 'Train Acc: 0.9739666666666666', 'Test Acc: 0.9766', 'Train LL: -0.0811065050550198', 'Test LL: -0.07374530052704713', 'Epoch Time (s): 163.6423007629346')
('Epoch 11', 'Objective: -0.08259661940409062', 'Train Acc: 0.9753833333333334', 'Test Acc: 0.9762', 'Train LL: -0.07767464160083803', 'Test LL: -0.07328422536534739', 'Epoch Time (s): 163.6167969838716')
('Epoch 12', 'Objective: -0.07936108721155276', 'Train Acc: 0.9761833333333333', 'Test Acc: 0.9774', 'Train LL: -0.07464422389219821', 'Test LL: -0.06808944856626317', 'Epoch Time (s): 163.64285242790356')
('Epoch 13', 'Objective: -0.07602372403785976', 'Train Acc: 0.97725', 'Test Acc: 0.9775', 'Train LL: -0.07149046821150969', 'Test LL: -0.0661498238311995', 'Epoch Time (s): 163.66953373514116')
('Epoch 14', 'Objective: -0.0721407676822106', 'Train Acc: 0.9782666666666666', 'Test Acc: 0.98', 'Train LL: -0.06777516097179684', 'Test LL: -0.0627136061889036', 'Epoch Time (s): 163.66213235002942')
('Epoch 15', 'Objective: -0.06973744430142019', 'Train Acc: 0.9784666666666667', 'Test Acc: 0.9827', 'Train LL: -0.0654396562992621', 'Test LL: -0.056251894151840474', 'Epoch Time (s): 163.64302556519397')
('Epoch 16', 'Objective: -0.06843521998463525', 'Train Acc: 0.9793833333333334', 'Test Acc: 0.9811', 'Train LL: -0.06421224779529631', 'Test LL: -0.06301764241866743', 'Epoch Time (s): 163.66494145290926')
('Epoch 17', 'Objective: -0.06591717919016063', 'Train Acc: 0.98055', 'Test Acc: 0.984', 'Train LL: -0.06180138979304708', 'Test LL: -0.05147001872180652', 'Epoch Time (s): 163.6421979968436')
('Epoch 18', 'Objective: -0.06445480499500654', 'Train Acc: 0.98085', 'Test Acc: 0.981', 'Train LL: -0.060440142399305764', 'Test LL: -0.05913753511559311', 'Epoch Time (s): 163.68244773196056')
('Epoch 19', 'Objective: -0.06281986847127073', 'Train Acc: 0.9814666666666667', 'Test Acc: 0.9825', 'Train LL: -0.05891328090725237', 'Test LL: -0.050800471983743094', 'Epoch Time (s): 163.67370056407526')
('Epoch 20', 'Objective: -0.062227150830287924', 'Train Acc: 0.9812166666666666', 'Test Acc: 0.9793', 'Train LL: -0.05837576605574222', 'Test LL: -0.0695886644758998', 'Epoch Time (s): 163.67992975190282')
('Epoch 21', 'Objective: -0.05810394864789721', 'Train Acc: 0.98195', 'Test Acc: 0.9863', 'Train LL: -0.054338326207483065', 'Test LL: -0.045225547412420075', 'Epoch Time (s): 163.69258403917775')
('Epoch 22', 'Objective: -0.05672488025212561', 'Train Acc: 0.9829666666666667', 'Test Acc: 0.985', 'Train LL: -0.05313049959532842', 'Test LL: -0.04597784267242839', 'Epoch Time (s): 163.70252371300012')
('Epoch 23', 'Objective: -0.058012065837816436', 'Train Acc: 0.9835', 'Test Acc: 0.9818', 'Train LL: -0.05449983585591334', 'Test LL: -0.057177333594531386', 'Epoch Time (s): 163.67988187703304')
('Epoch 24', 'Objective: -0.05645559498531882', 'Train Acc: 0.9830833333333333', 'Test Acc: 0.9852', 'Train LL: -0.05294651193272882', 'Test LL: -0.04763177712434482', 'Epoch Time (s): 163.67614787677303')
('Epoch 25', 'Objective: -0.05438608037834422', 'Train Acc: 0.9834833333333334', 'Test Acc: 0.9819', 'Train LL: -0.05090416318442676', 'Test LL: -0.05380566385402035', 'Epoch Time (s): 163.6762456500437')
('Epoch 26', 'Objective: -0.053543822964704904', 'Train Acc: 0.9839666666666667', 'Test Acc: 0.9862', 'Train LL: -0.05012084841408615', 'Test LL: -0.041679367474602824', 'Epoch Time (s): 163.65477706305683')
('Epoch 27', 'Objective: -0.05319046026174572', 'Train Acc: 0.9841166666666666', 'Test Acc: 0.9827', 'Train LL: -0.049899204269548865', 'Test LL: -0.05464068210445455', 'Epoch Time (s): 163.68476740899496')
('Epoch 28', 'Objective: -0.05106312119295216', 'Train Acc: 0.9846333333333334', 'Test Acc: 0.9815', 'Train LL: -0.047789321515446744', 'Test LL: -0.05367206911407957', 'Epoch Time (s): 163.6933303209953')
('Epoch 29', 'Objective: -0.04982361072736792', 'Train Acc: 0.98505', 'Test Acc: 0.9805', 'Train LL: -0.04661769181633347', 'Test LL: -0.06504795281444331', 'Epoch Time (s): 163.68343722284772')
('Epoch 30', 'Objective: -0.05015753518130766', 'Train Acc: 0.98405', 'Test Acc: 0.9897', 'Train LL: -0.04696986740313581', 'Test LL: -0.034440823527909226', 'Epoch Time (s): 163.70619032206014')
('Epoch 31', 'Objective: -0.049787922148350754', 'Train Acc: 0.9850333333333333', 'Test Acc: 0.9891', 'Train LL: -0.04665645607646914', 'Test LL: -0.03660254673371004', 'Epoch Time (s): 163.69798760395497')
('Epoch 32', 'Objective: -0.048527672682130756', 'Train Acc: 0.9852166666666666', 'Test Acc: 0.9862', 'Train LL: -0.045410993015351286', 'Test LL: -0.038647647218593054', 'Epoch Time (s): 163.67872942914255')
('Epoch 33', 'Objective: -0.04765495285525464', 'Train Acc: 0.9858166666666667', 'Test Acc: 0.985', 'Train LL: -0.04460725387551084', 'Test LL: -0.0474861634760145', 'Epoch Time (s): 163.70121003198437')
('Epoch 34', 'Objective: -0.04822533675045517', 'Train Acc: 0.9852', 'Test Acc: 0.9867', 'Train LL: -0.04521022297196008', 'Test LL: -0.0417014493392334', 'Epoch Time (s): 163.71294435719028')
('Epoch 35', 'Objective: -0.04585114336837293', 'Train Acc: 0.9855', 'Test Acc: 0.9865', 'Train LL: -0.042859572404040425', 'Test LL: -0.042046150776587105', 'Epoch Time (s): 163.69489771593362')
('Epoch 36', 'Objective: -0.046484397341341396', 'Train Acc: 0.98605', 'Test Acc: 0.9881', 'Train LL: -0.04352106192503678', 'Test LL: -0.0373667893560158', 'Epoch Time (s): 163.67639795388095')
('Epoch 37', 'Objective: -0.0452753100519493', 'Train Acc: 0.9871333333333333', 'Test Acc: 0.9873', 'Train LL: -0.04239137882745972', 'Test LL: -0.04093625485507867', 'Epoch Time (s): 163.69625769509003')
('Epoch 38', 'Objective: -0.043396401902229716', 'Train Acc: 0.987', 'Test Acc: 0.9861', 'Train LL: -0.04055990615251341', 'Test LL: -0.044397095529676155', 'Epoch Time (s): 163.62152689811774')
('Epoch 39', 'Objective: -0.04449586385018861', 'Train Acc: 0.9868333333333333', 'Test Acc: 0.9866', 'Train LL: -0.04168091605854867', 'Test LL: -0.04028677846340373', 'Epoch Time (s): 163.7334598370362')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.02737549046992252', 'Train Acc: 0.9919833333333333', 'Test Acc: 0.9908', 'Train LL: -0.025015544923196423', 'Test LL: -0.026194492398756', 'Epoch Time (s): 163.65205871500075')
('Epoch 41', 'Objective: -0.022600455760762164', 'Train Acc: 0.99325', 'Test Acc: 0.9904', 'Train LL: -0.020360019449219703', 'Test LL: -0.027124972988551294', 'Epoch Time (s): 163.66879969998263')
('Epoch 42', 'Objective: -0.02141605463284366', 'Train Acc: 0.99385', 'Test Acc: 0.9916', 'Train LL: -0.019248294207181705', 'Test LL: -0.024501706717634374', 'Epoch Time (s): 163.67382183508016')
('Epoch 43', 'Objective: -0.019593328880527266', 'Train Acc: 0.9944', 'Test Acc: 0.9924', 'Train LL: -0.01745608493858902', 'Test LL: -0.02393904828377211', 'Epoch Time (s): 163.71179736917838')
('Epoch 44', 'Objective: -0.019537314935365653', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9926', 'Train LL: -0.017427170918364047', 'Test LL: -0.0231989742960096', 'Epoch Time (s): 163.70017687394284')
('Epoch 45', 'Objective: -0.01905012190145297', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9922', 'Train LL: -0.01697150442191377', 'Test LL: -0.024970631843849282', 'Epoch Time (s): 163.69956510793418')
('Epoch 46', 'Objective: -0.017855020920931018', 'Train Acc: 0.99495', 'Test Acc: 0.9935', 'Train LL: -0.01581621915809283', 'Test LL: -0.023210935128857916', 'Epoch Time (s): 163.69981820695102')
('Epoch 47', 'Objective: -0.016878769085174588', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.9918', 'Train LL: -0.014883032069806556', 'Test LL: -0.0279547921631018', 'Epoch Time (s): 163.7084873081185')
('Epoch 48', 'Objective: -0.017148412655180897', 'Train Acc: 0.9950166666666667', 'Test Acc: 0.9917', 'Train LL: -0.015141934125398628', 'Test LL: -0.027360497165292277', 'Epoch Time (s): 163.70372270606458')
('Epoch 49', 'Objective: -0.016239001783282615', 'Train Acc: 0.9953', 'Test Acc: 0.9914', 'Train LL: -0.014276167064574833', 'Test LL: -0.0280470638552031', 'Epoch Time (s): 163.67919101682492')
('Epoch 50', 'Objective: -0.01581763428145152', 'Train Acc: 0.9954', 'Test Acc: 0.9932', 'Train LL: -0.013878013950182622', 'Test LL: -0.02218875500788944', 'Epoch Time (s): 163.68892126809806')
('Epoch 51', 'Objective: -0.015244829135913034', 'Train Acc: 0.9955166666666667', 'Test Acc: 0.9921', 'Train LL: -0.013311031801589957', 'Test LL: -0.026087647110405', 'Epoch Time (s): 163.67796429013833')
('Epoch 52', 'Objective: -0.015621422088822437', 'Train Acc: 0.99565', 'Test Acc: 0.9926', 'Train LL: -0.013686426206071746', 'Test LL: -0.02427917470231841', 'Epoch Time (s): 163.70750562194735')
('Epoch 53', 'Objective: -0.014498990356315945', 'Train Acc: 0.996', 'Test Acc: 0.9922', 'Train LL: -0.012606806742743538', 'Test LL: -0.026222669946436496', 'Epoch Time (s): 163.709337125998')
('Epoch 54', 'Objective: -0.013776465961332784', 'Train Acc: 0.9960666666666667', 'Test Acc: 0.992', 'Train LL: -0.011884125802365498', 'Test LL: -0.02765967549122061', 'Epoch Time (s): 163.68601036514156')
('Epoch 55', 'Objective: -0.013767540233144755', 'Train Acc: 0.9961', 'Test Acc: 0.9895', 'Train LL: -0.011868785760916323', 'Test LL: -0.03198084896382267', 'Epoch Time (s): 163.67137025902048')
('Epoch 56', 'Objective: -0.014353054573166888', 'Train Acc: 0.9959666666666667', 'Test Acc: 0.9898', 'Train LL: -0.012436564185260627', 'Test LL: -0.03304430537006171', 'Epoch Time (s): 163.68290662695654')
('Epoch 57', 'Objective: -0.014177776658166129', 'Train Acc: 0.99585', 'Test Acc: 0.9911', 'Train LL: -0.012302245941211614', 'Test LL: -0.027123999447284962', 'Epoch Time (s): 163.64622988691553')
('Epoch 58', 'Objective: -0.012596177204977623', 'Train Acc: 0.9964166666666666', 'Test Acc: 0.992', 'Train LL: -0.010769117820857673', 'Test LL: -0.025608414780272187', 'Epoch Time (s): 163.6965536181815')
('Epoch 59', 'Objective: -0.013194067037144985', 'Train Acc: 0.9960666666666667', 'Test Acc: 0.9919', 'Train LL: -0.011355042281893634', 'Test LL: -0.027623557524261367', 'Epoch Time (s): 163.68270558910444')
('Epoch 60', 'Objective: -0.012798917190733632', 'Train Acc: 0.99655', 'Test Acc: 0.99', 'Train LL: -0.010971224706857808', 'Test LL: -0.03188853214418105', 'Epoch Time (s): 163.66211668215692')
('Epoch 61', 'Objective: -0.012411694978473532', 'Train Acc: 0.9962833333333333', 'Test Acc: 0.9915', 'Train LL: -0.010581464379881828', 'Test LL: -0.026234523381794658', 'Epoch Time (s): 163.65361519507132')
('Epoch 62', 'Objective: -0.01224356713499799', 'Train Acc: 0.9963833333333333', 'Test Acc: 0.9915', 'Train LL: -0.010423734147490567', 'Test LL: -0.027940372456260798', 'Epoch Time (s): 163.70601932308637')
('Epoch 63', 'Objective: -0.011701625043770205', 'Train Acc: 0.9965666666666667', 'Test Acc: 0.9929', 'Train LL: -0.009898016413833179', 'Test LL: -0.025085829033922574', 'Epoch Time (s): 163.6314296608325')
('Epoch 64', 'Objective: -0.01195900657072449', 'Train Acc: 0.9965666666666667', 'Test Acc: 0.9916', 'Train LL: -0.010165612634359866', 'Test LL: -0.028589566367958157', 'Epoch Time (s): 163.64874445088208')
('Epoch 65', 'Objective: -0.01114534147305292', 'Train Acc: 0.9969', 'Test Acc: 0.9921', 'Train LL: -0.009374042578987172', 'Test LL: -0.026276039095614784', 'Epoch Time (s): 163.66761249210685')
('Epoch 66', 'Objective: -0.011815413373811829', 'Train Acc: 0.9964833333333334', 'Test Acc: 0.9927', 'Train LL: -0.009999250436558816', 'Test LL: -0.025668633177201066', 'Epoch Time (s): 163.65130758588202')
('Epoch 67', 'Objective: -0.010732855719474618', 'Train Acc: 0.9968833333333333', 'Test Acc: 0.9906', 'Train LL: -0.008948009290805758', 'Test LL: -0.031037435535111412', 'Epoch Time (s): 163.65819855500013')
('Epoch 68', 'Objective: -0.010801742708277677', 'Train Acc: 0.9967666666666667', 'Test Acc: 0.992', 'Train LL: -0.00903700856844531', 'Test LL: -0.02574881335492709', 'Epoch Time (s): 163.67554227705114')
('Epoch 69', 'Objective: -0.010383734426793067', 'Train Acc: 0.99705', 'Test Acc: 0.9917', 'Train LL: -0.00862990709691267', 'Test LL: -0.02912101559682021', 'Epoch Time (s): 163.66147491009906')
('Epoch 70', 'Objective: -0.011156440815814324', 'Train Acc: 0.9967333333333334', 'Test Acc: 0.9914', 'Train LL: -0.009380505482102838', 'Test LL: -0.028619670877533143', 'Epoch Time (s): 163.65672372607514')
('Epoch 71', 'Objective: -0.010712734338123456', 'Train Acc: 0.99695', 'Test Acc: 0.9895', 'Train LL: -0.008979504383099546', 'Test LL: -0.03332910846934064', 'Epoch Time (s): 163.67051393701695')
('Epoch 72', 'Objective: -0.01042492268949796', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9916', 'Train LL: -0.008717631238273647', 'Test LL: -0.027022615467131503', 'Epoch Time (s): 163.65964049310423')
('Epoch 73', 'Objective: -0.01038266486225293', 'Train Acc: 0.9968333333333333', 'Test Acc: 0.99', 'Train LL: -0.008646259854721396', 'Test LL: -0.03377158092827502', 'Epoch Time (s): 163.77473322488368')
('Epoch 74', 'Objective: -0.010203273465954165', 'Train Acc: 0.9969833333333333', 'Test Acc: 0.9908', 'Train LL: -0.008468748752211472', 'Test LL: -0.03120410189693648', 'Epoch Time (s): 163.636852926109')
('Epoch 75', 'Objective: -0.009762126154948843', 'Train Acc: 0.9970833333333333', 'Test Acc: 0.9908', 'Train LL: -0.008021345729382639', 'Test LL: -0.0337200222985407', 'Epoch Time (s): 163.60547792888246')
('Epoch 76', 'Objective: -0.01003374458985147', 'Train Acc: 0.9974333333333333', 'Test Acc: 0.9919', 'Train LL: -0.008304234903164889', 'Test LL: -0.02823518584649796', 'Epoch Time (s): 163.58481148211285')
('Epoch 77', 'Objective: -0.009560362822202927', 'Train Acc: 0.9973666666666666', 'Test Acc: 0.9905', 'Train LL: -0.007846281906928095', 'Test LL: -0.028682561905919824', 'Epoch Time (s): 163.59819967090152')
('Epoch 78', 'Objective: -0.009406624106406055', 'Train Acc: 0.9974', 'Test Acc: 0.9903', 'Train LL: -0.007717657150075772', 'Test LL: -0.0313037608579749', 'Epoch Time (s): 163.6169728441164')
('Epoch 79', 'Objective: -0.009280592723244562', 'Train Acc: 0.9974166666666666', 'Test Acc: 0.9892', 'Train LL: -0.007606824120109513', 'Test LL: -0.037340188639905056', 'Epoch Time (s): 163.62260200711899')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.007781232113069595', 'Train Acc: 0.9979166666666667', 'Test Acc: 0.9909', 'Train LL: -0.006191453592155795', 'Test LL: -0.03155900263599659', 'Epoch Time (s): 163.620365814073')
('Epoch 81', 'Objective: -0.006534938130783951', 'Train Acc: 0.9983666666666666', 'Test Acc: 0.9914', 'Train LL: -0.005003868936747619', 'Test LL: -0.030582148188646137', 'Epoch Time (s): 163.71594606805593')
('Epoch 82', 'Objective: -0.006560217625668308', 'Train Acc: 0.99835', 'Test Acc: 0.9913', 'Train LL: -0.005025796327635369', 'Test LL: -0.03158815857848', 'Epoch Time (s): 163.64398712594993')
('Epoch 83', 'Objective: -0.0059372739010226175', 'Train Acc: 0.9985833333333334', 'Test Acc: 0.9912', 'Train LL: -0.004420227072876128', 'Test LL: -0.03244112514159403', 'Epoch Time (s): 163.5998709530104')
('Epoch 84', 'Objective: -0.005726931327001849', 'Train Acc: 0.9986333333333334', 'Test Acc: 0.9911', 'Train LL: -0.004204433891198295', 'Test LL: -0.03396672846630862', 'Epoch Time (s): 163.5993393061217')
('Epoch 85', 'Objective: -0.006125041719837677', 'Train Acc: 0.9984666666666666', 'Test Acc: 0.9911', 'Train LL: -0.004564310884320831', 'Test LL: -0.032818429180689876', 'Epoch Time (s): 163.633617276093')
('Epoch 86', 'Objective: -0.005879821348713633', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9911', 'Train LL: -0.004330392813381805', 'Test LL: -0.03288483307237833', 'Epoch Time (s): 163.63107707398012')
('Epoch 87', 'Objective: -0.0055314951224579665', 'Train Acc: 0.9988', 'Test Acc: 0.9912', 'Train LL: -0.003997921465463977', 'Test LL: -0.03386802236428925', 'Epoch Time (s): 163.61589410784654')
('Epoch 88', 'Objective: -0.00581022338379328', 'Train Acc: 0.9985666666666667', 'Test Acc: 0.9914', 'Train LL: -0.0042463005254692165', 'Test LL: -0.03476953480826248', 'Epoch Time (s): 163.6196815900039')
('Epoch 89', 'Objective: -0.005327874572200442', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9911', 'Train LL: -0.0037946324673609356', 'Test LL: -0.03436043156047319', 'Epoch Time (s): 163.63447681581602')
('Epoch 90', 'Objective: -0.005552885485282258', 'Train Acc: 0.9987', 'Test Acc: 0.991', 'Train LL: -0.003992507367862709', 'Test LL: -0.034974971045459415', 'Epoch Time (s): 163.58713596500456')
('Epoch 91', 'Objective: -0.005362016096280784', 'Train Acc: 0.9986', 'Test Acc: 0.9906', 'Train LL: -0.0037871740009855705', 'Test LL: -0.0344970029095198', 'Epoch Time (s): 163.64393761288375')
('Epoch 92', 'Objective: -0.005506674695462496', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.991', 'Train LL: -0.003946917559804788', 'Test LL: -0.03547344752411464', 'Epoch Time (s): 163.6573209729977')
('Epoch 93', 'Objective: -0.005213355832023154', 'Train Acc: 0.9988166666666667', 'Test Acc: 0.9905', 'Train LL: -0.003649179017796169', 'Test LL: -0.03546426711700435', 'Epoch Time (s): 163.62316491105594')
('Epoch 94', 'Objective: -0.005474265688533486', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9907', 'Train LL: -0.003910385107479339', 'Test LL: -0.03565382667629297', 'Epoch Time (s): 163.6426481429953')
('Epoch 95', 'Objective: -0.005198787227103563', 'Train Acc: 0.9988833333333333', 'Test Acc: 0.9911', 'Train LL: -0.003643058532990598', 'Test LL: -0.03516099570423165', 'Epoch Time (s): 163.61348487995565')
('Epoch 96', 'Objective: -0.005316213635974401', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9916', 'Train LL: -0.0037427745562274555', 'Test LL: -0.035434414297021447', 'Epoch Time (s): 163.63069624593481')
('Epoch 97', 'Objective: -0.0051215140608738005', 'Train Acc: 0.9989', 'Test Acc: 0.99', 'Train LL: -0.003549474061548656', 'Test LL: -0.039236425108233455', 'Epoch Time (s): 163.58737855986692')
('Epoch 98', 'Objective: -0.005694546246137269', 'Train Acc: 0.9986666666666667', 'Test Acc: 0.9907', 'Train LL: -0.004092353496966433', 'Test LL: -0.0375997301043082', 'Epoch Time (s): 163.63194565894082')
('Epoch 99', 'Objective: -0.005180636225236596', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.991', 'Train LL: -0.0036188568395826883', 'Test LL: -0.03690047495532569', 'Epoch Time (s): 163.64715816802345')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.004643676291799355
Final Train Accuracy: £0.9988666666666667
Final Train LL: £-0.003099025652830242
Final Test Accuracy: £0.9912
Final Test LL: £-0.036884802468612324
