dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 1
bn_indnorm: local
bn_tnorm: image
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.3557563164175328', 'Train Acc: 0.5306', 'Test Acc: 0.7751', 'Train LL: -1.3054515327960792', 'Test LL: -0.6565901824372068', 'Epoch Time (s): 164.15831482689828')
('Epoch 1', 'Objective: -0.5306167669985917', 'Train Acc: 0.8360666666666666', 'Test Acc: 0.8862', 'Train LL: -0.47677845360819376', 'Test LL: -0.3308620492019385', 'Epoch Time (s): 164.1591915502213')
('Epoch 2', 'Objective: -0.355559013993929', 'Train Acc: 0.9028166666666667', 'Test Acc: 0.9343', 'Train LL: -0.30328578807936285', 'Test LL: -0.19871075202560878', 'Epoch Time (s): 164.15948518784717')
('Epoch 3', 'Objective: -0.26894406346175953', 'Train Acc: 0.9304833333333333', 'Test Acc: 0.9406', 'Train LL: -0.22018799036447909', 'Test LL: -0.1819250061361094', 'Epoch Time (s): 164.08595595601946')
('Epoch 4', 'Objective: -0.22564581451286014', 'Train Acc: 0.9427166666666666', 'Test Acc: 0.9462', 'Train LL: -0.17938887155517805', 'Test LL: -0.16340942071676295', 'Epoch Time (s): 164.0557367641013')
('Epoch 5', 'Objective: -0.19855965991430985', 'Train Acc: 0.9517333333333333', 'Test Acc: 0.9638', 'Train LL: -0.15458832698448857', 'Test LL: -0.11122061389043149', 'Epoch Time (s): 163.97436081711203')
('Epoch 6', 'Objective: -0.17892218530113657', 'Train Acc: 0.95715', 'Test Acc: 0.9589', 'Train LL: -0.13612833139711963', 'Test LL: -0.12984761790887506', 'Epoch Time (s): 164.01296946709044')
('Epoch 7', 'Objective: -0.16350485789831445', 'Train Acc: 0.9619166666666666', 'Test Acc: 0.9734', 'Train LL: -0.12250868187313696', 'Test LL: -0.08450879734544042', 'Epoch Time (s): 164.02083406108432')
('Epoch 8', 'Objective: -0.15294323668390622', 'Train Acc: 0.9639833333333333', 'Test Acc: 0.9708', 'Train LL: -0.11275132154058247', 'Test LL: -0.09038787328311794', 'Epoch Time (s): 164.04851143690757')
('Epoch 9', 'Objective: -0.1448522777395886', 'Train Acc: 0.968', 'Test Acc: 0.9561', 'Train LL: -0.10585440025532764', 'Test LL: -0.12972400123339534', 'Epoch Time (s): 163.91059581097215')
('Epoch 10', 'Objective: -0.13877676457429106', 'Train Acc: 0.9685333333333334', 'Test Acc: 0.9743', 'Train LL: -0.10070782197259073', 'Test LL: -0.08227519667956824', 'Epoch Time (s): 163.9742044680752')
('Epoch 11', 'Objective: -0.1296575618215962', 'Train Acc: 0.9709666666666666', 'Test Acc: 0.9768', 'Train LL: -0.09257758800826955', 'Test LL: -0.07620059243067945', 'Epoch Time (s): 164.1163241600152')
('Epoch 12', 'Objective: -0.1259074398686819', 'Train Acc: 0.9716833333333333', 'Test Acc: 0.9709', 'Train LL: -0.08934144848589151', 'Test LL: -0.0909612934779966', 'Epoch Time (s): 164.00395172601566')
('Epoch 13', 'Objective: -0.12348084918860863', 'Train Acc: 0.9724333333333334', 'Test Acc: 0.9674', 'Train LL: -0.08777556168493589', 'Test LL: -0.107451753707644', 'Epoch Time (s): 163.88825559895486')
('Epoch 14', 'Objective: -0.12012697419433299', 'Train Acc: 0.9738666666666667', 'Test Acc: 0.9783', 'Train LL: -0.08504826992933218', 'Test LL: -0.06159300981552055', 'Epoch Time (s): 164.04635491082445')
('Epoch 15', 'Objective: -0.1142698940567817', 'Train Acc: 0.9746833333333333', 'Test Acc: 0.975', 'Train LL: -0.07967621713255825', 'Test LL: -0.07464147984048815', 'Epoch Time (s): 164.05222481512465')
('Epoch 16', 'Objective: -0.11175927114614863', 'Train Acc: 0.9755333333333334', 'Test Acc: 0.971', 'Train LL: -0.07767431905603729', 'Test LL: -0.08969300574613867', 'Epoch Time (s): 164.08619045093656')
('Epoch 17', 'Objective: -0.11202140412156969', 'Train Acc: 0.9754', 'Test Acc: 0.9828', 'Train LL: -0.07843624394967247', 'Test LL: -0.05699134549702777', 'Epoch Time (s): 163.88821429689415')
('Epoch 18', 'Objective: -0.10820692042293698', 'Train Acc: 0.9762', 'Test Acc: 0.9766', 'Train LL: -0.0749524207092791', 'Test LL: -0.06963343745772983', 'Epoch Time (s): 164.3866065959446')
('Epoch 19', 'Objective: -0.10412364805609588', 'Train Acc: 0.9774', 'Test Acc: 0.9727', 'Train LL: -0.07123444562501563', 'Test LL: -0.08046229626807042', 'Epoch Time (s): 164.81926370295696')
('Epoch 20', 'Objective: -0.10242729104538513', 'Train Acc: 0.9780833333333333', 'Test Acc: 0.9731', 'Train LL: -0.06976870025277515', 'Test LL: -0.07972346989361265', 'Epoch Time (s): 164.71235881606117')
('Epoch 21', 'Objective: -0.09933790247674744', 'Train Acc: 0.9792166666666666', 'Test Acc: 0.9775', 'Train LL: -0.06727020529491572', 'Test LL: -0.06322456495443386', 'Epoch Time (s): 164.77392712398432')
('Epoch 22', 'Objective: -0.09773255811727648', 'Train Acc: 0.9798', 'Test Acc: 0.9843', 'Train LL: -0.06612028283256134', 'Test LL: -0.04887179808245038', 'Epoch Time (s): 164.6855508061126')
('Epoch 23', 'Objective: -0.09767569919451669', 'Train Acc: 0.97915', 'Test Acc: 0.9802', 'Train LL: -0.06616578494031379', 'Test LL: -0.06193483369763937', 'Epoch Time (s): 163.90869321115315')
('Epoch 24', 'Objective: -0.09457395485807864', 'Train Acc: 0.9802333333333333', 'Test Acc: 0.9842', 'Train LL: -0.0634734141163004', 'Test LL: -0.05462175430311675', 'Epoch Time (s): 163.9264925289899')
('Epoch 25', 'Objective: -0.09349903293708822', 'Train Acc: 0.9805666666666667', 'Test Acc: 0.9781', 'Train LL: -0.06248825023550853', 'Test LL: -0.06670357094303449', 'Epoch Time (s): 163.97765460214578')
('Epoch 26', 'Objective: -0.09303990971583256', 'Train Acc: 0.9802166666666666', 'Test Acc: 0.9834', 'Train LL: -0.062267871683660964', 'Test LL: -0.052149825995680556', 'Epoch Time (s): 163.79730472178198')
('Epoch 27', 'Objective: -0.09014524576844574', 'Train Acc: 0.9807666666666667', 'Test Acc: 0.9816', 'Train LL: -0.059423033936034035', 'Test LL: -0.05328205089932428', 'Epoch Time (s): 163.7877870600205')
('Epoch 28', 'Objective: -0.09017608899677555', 'Train Acc: 0.9805166666666667', 'Test Acc: 0.9827', 'Train LL: -0.0595548399849477', 'Test LL: -0.051270283557649315', 'Epoch Time (s): 163.79843339906074')
('Epoch 29', 'Objective: -0.08923815798470008', 'Train Acc: 0.9816166666666667', 'Test Acc: 0.9815', 'Train LL: -0.059055879879568784', 'Test LL: -0.056749449599248325', 'Epoch Time (s): 163.8023914990481')
('Epoch 30', 'Objective: -0.08708205696953732', 'Train Acc: 0.9815833333333334', 'Test Acc: 0.9891', 'Train LL: -0.05758531644845576', 'Test LL: -0.03620585132042696', 'Epoch Time (s): 163.86696817097254')
('Epoch 31', 'Objective: -0.08645585587898634', 'Train Acc: 0.9817333333333333', 'Test Acc: 0.9854', 'Train LL: -0.05684889650259045', 'Test LL: -0.04647589505486853', 'Epoch Time (s): 163.91159769892693')
('Epoch 32', 'Objective: -0.08562227882093343', 'Train Acc: 0.9823166666666666', 'Test Acc: 0.9844', 'Train LL: -0.05647065834776611', 'Test LL: -0.049061752364631374', 'Epoch Time (s): 163.9504610109143')
('Epoch 33', 'Objective: -0.08393010039721835', 'Train Acc: 0.9826', 'Test Acc: 0.9842', 'Train LL: -0.054512093187099195', 'Test LL: -0.054312077816689654', 'Epoch Time (s): 163.91045979014598')
('Epoch 34', 'Objective: -0.08379532887689126', 'Train Acc: 0.98265', 'Test Acc: 0.9779', 'Train LL: -0.05496218491802006', 'Test LL: -0.07118785006968996', 'Epoch Time (s): 163.89207195909694')
('Epoch 35', 'Objective: -0.08330334438476175', 'Train Acc: 0.9832333333333333', 'Test Acc: 0.9853', 'Train LL: -0.0544337560071113', 'Test LL: -0.047902241636232606', 'Epoch Time (s): 163.78940998809412')
('Epoch 36', 'Objective: -0.08157799094178617', 'Train Acc: 0.9836166666666667', 'Test Acc: 0.9853', 'Train LL: -0.052828455660909816', 'Test LL: -0.04438744366827627', 'Epoch Time (s): 163.83745659096166')
('Epoch 37', 'Objective: -0.08165661159315935', 'Train Acc: 0.98335', 'Test Acc: 0.9849', 'Train LL: -0.052958147269113486', 'Test LL: -0.049721011059929314', 'Epoch Time (s): 163.99038174096495')
('Epoch 38', 'Objective: -0.08078761412602355', 'Train Acc: 0.9834833333333334', 'Test Acc: 0.9856', 'Train LL: -0.05223198643238959', 'Test LL: -0.04479557950894842', 'Epoch Time (s): 163.91121943295002')
('Epoch 39', 'Objective: -0.07900958169014283', 'Train Acc: 0.9840166666666667', 'Test Acc: 0.9849', 'Train LL: -0.05068867934738092', 'Test LL: -0.049569029747351424', 'Epoch Time (s): 163.93605849100277')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.060055614338634135', 'Train Acc: 0.9895666666666667', 'Test Acc: 0.9909', 'Train LL: -0.03363249396231756', 'Test LL: -0.028991077083060236', 'Epoch Time (s): 163.93887367891148')
('Epoch 41', 'Objective: -0.05468021562009184', 'Train Acc: 0.9908666666666667', 'Test Acc: 0.9908', 'Train LL: -0.029058680144389885', 'Test LL: -0.028949060908807597', 'Epoch Time (s): 163.91319064120762')
('Epoch 42', 'Objective: -0.052392629259255134', 'Train Acc: 0.9912166666666666', 'Test Acc: 0.9904', 'Train LL: -0.02718362740560816', 'Test LL: -0.028712207402751842', 'Epoch Time (s): 163.9219798881095')
('Epoch 43', 'Objective: -0.05059886025870321', 'Train Acc: 0.99185', 'Test Acc: 0.9904', 'Train LL: -0.0257348796914722', 'Test LL: -0.02994461333296785', 'Epoch Time (s): 163.90723559609614')
('Epoch 44', 'Objective: -0.04948514408016111', 'Train Acc: 0.9922333333333333', 'Test Acc: 0.9914', 'Train LL: -0.024937982841717644', 'Test LL: -0.02821591379447924', 'Epoch Time (s): 163.89955556904897')
('Epoch 45', 'Objective: -0.049274807202873964', 'Train Acc: 0.99205', 'Test Acc: 0.989', 'Train LL: -0.02483749990667634', 'Test LL: -0.03247940912185538', 'Epoch Time (s): 163.84689696598798')
('Epoch 46', 'Objective: -0.04953809511636047', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9903', 'Train LL: -0.02529489036876796', 'Test LL: -0.028255136573997457', 'Epoch Time (s): 163.92971846205182')
('Epoch 47', 'Objective: -0.048718094439064656', 'Train Acc: 0.99235', 'Test Acc: 0.9903', 'Train LL: -0.02462139731728333', 'Test LL: -0.02904108271676498', 'Epoch Time (s): 163.7027189740911')
('Epoch 48', 'Objective: -0.047976394864316485', 'Train Acc: 0.9922', 'Test Acc: 0.9905', 'Train LL: -0.02412901116265141', 'Test LL: -0.029405519776341957', 'Epoch Time (s): 163.92434865492396')
('Epoch 49', 'Objective: -0.04728840515871596', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9912', 'Train LL: -0.023509478909570936', 'Test LL: -0.03170911987100552', 'Epoch Time (s): 163.93509676493704')
('Epoch 50', 'Objective: -0.0475345872865533', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.992', 'Train LL: -0.023804549990147115', 'Test LL: -0.02602868298457301', 'Epoch Time (s): 163.91842711996287')
('Epoch 51', 'Objective: -0.04640505530104984', 'Train Acc: 0.9926', 'Test Acc: 0.9921', 'Train LL: -0.02284956065751146', 'Test LL: -0.02546305507341505', 'Epoch Time (s): 163.93131822091527')
('Epoch 52', 'Objective: -0.04674962051133843', 'Train Acc: 0.9926', 'Test Acc: 0.9912', 'Train LL: -0.023305486084603307', 'Test LL: -0.029444004406619366', 'Epoch Time (s): 163.8746962309815')
('Epoch 53', 'Objective: -0.046274414873385426', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9913', 'Train LL: -0.02289500969024297', 'Test LL: -0.027973813632893064', 'Epoch Time (s): 163.90311019914225')
('Epoch 54', 'Objective: -0.046494543550264916', 'Train Acc: 0.99235', 'Test Acc: 0.9905', 'Train LL: -0.023138551546719965', 'Test LL: -0.029577989973747474', 'Epoch Time (s): 163.92130641289987')
('Epoch 55', 'Objective: -0.04549094252546824', 'Train Acc: 0.99295', 'Test Acc: 0.9911', 'Train LL: -0.022273610850089085', 'Test LL: -0.02955055613394405', 'Epoch Time (s): 164.19336792104878')
('Epoch 56', 'Objective: -0.04570147911648007', 'Train Acc: 0.99275', 'Test Acc: 0.9897', 'Train LL: -0.02255910399056222', 'Test LL: -0.03140171364892047', 'Epoch Time (s): 164.78527873917483')
('Epoch 57', 'Objective: -0.04528001638164627', 'Train Acc: 0.9926666666666667', 'Test Acc: 0.9916', 'Train LL: -0.02223222821734719', 'Test LL: -0.028579199578897017', 'Epoch Time (s): 164.74828208494')
('Epoch 58', 'Objective: -0.044572754989305664', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.9905', 'Train LL: -0.021535243277303898', 'Test LL: -0.029633284924346748', 'Epoch Time (s): 164.81188610498793')
('Epoch 59', 'Objective: -0.04502753552969188', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9909', 'Train LL: -0.022098682254940393', 'Test LL: -0.029093190332119257', 'Epoch Time (s): 164.71947443881072')
('Epoch 60', 'Objective: -0.04534455436723166', 'Train Acc: 0.9924', 'Test Acc: 0.9901', 'Train LL: -0.02239191417477108', 'Test LL: -0.0314249319893596', 'Epoch Time (s): 163.99542973702773')
('Epoch 61', 'Objective: -0.044222115103373885', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9906', 'Train LL: -0.021442624232764065', 'Test LL: -0.02967519948012321', 'Epoch Time (s): 163.94779631798156')
('Epoch 62', 'Objective: -0.043686190125247625', 'Train Acc: 0.9932833333333333', 'Test Acc: 0.9902', 'Train LL: -0.020940105996326695', 'Test LL: -0.03156772065937674', 'Epoch Time (s): 164.02520867995918')
('Epoch 63', 'Objective: -0.04421905186021815', 'Train Acc: 0.9931', 'Test Acc: 0.9905', 'Train LL: -0.02146090369309387', 'Test LL: -0.03124277956754726', 'Epoch Time (s): 164.13169223908335')
('Epoch 64', 'Objective: -0.04426158577138273', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9913', 'Train LL: -0.021540834289561515', 'Test LL: -0.028522858076983317', 'Epoch Time (s): 164.056689910125')
('Epoch 65', 'Objective: -0.04369788057766765', 'Train Acc: 0.99335', 'Test Acc: 0.9917', 'Train LL: -0.02108539552213683', 'Test LL: -0.025860040206755103', 'Epoch Time (s): 164.0626448839903')
('Epoch 66', 'Objective: -0.043778789413253597', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9896', 'Train LL: -0.021231299990638778', 'Test LL: -0.02958655170992475', 'Epoch Time (s): 164.01716223708354')
('Epoch 67', 'Objective: -0.04366234918916293', 'Train Acc: 0.9933166666666666', 'Test Acc: 0.9906', 'Train LL: -0.021158316543101605', 'Test LL: -0.028885481664202354', 'Epoch Time (s): 164.06732590007596')
('Epoch 68', 'Objective: -0.043321179337421224', 'Train Acc: 0.99355', 'Test Acc: 0.9909', 'Train LL: -0.020918450847568444', 'Test LL: -0.02796315236725121', 'Epoch Time (s): 164.07123716687784')
('Epoch 69', 'Objective: -0.042968344341957045', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9898', 'Train LL: -0.0204758080484669', 'Test LL: -0.03049324283313696', 'Epoch Time (s): 164.014107496012')
('Epoch 70', 'Objective: -0.043432021403481263', 'Train Acc: 0.9930833333333333', 'Test Acc: 0.991', 'Train LL: -0.021032612906458963', 'Test LL: -0.028110243064681798', 'Epoch Time (s): 164.01614900399')
('Epoch 71', 'Objective: -0.04268806125845536', 'Train Acc: 0.9935', 'Test Acc: 0.9916', 'Train LL: -0.020367197053615838', 'Test LL: -0.0291736700296788', 'Epoch Time (s): 164.04614336485974')
('Epoch 72', 'Objective: -0.0426710600158226', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.9913', 'Train LL: -0.02040205297671938', 'Test LL: -0.030880202288119354', 'Epoch Time (s): 164.0078902109526')
('Epoch 73', 'Objective: -0.04321458017183207', 'Train Acc: 0.9933', 'Test Acc: 0.9896', 'Train LL: -0.021003552062765274', 'Test LL: -0.02911271694742904', 'Epoch Time (s): 164.03011440509')
('Epoch 74', 'Objective: -0.04284035950704358', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.9906', 'Train LL: -0.020612219566406232', 'Test LL: -0.029187843751388557', 'Epoch Time (s): 164.00887015089393')
('Epoch 75', 'Objective: -0.04193014622576935', 'Train Acc: 0.9936', 'Test Acc: 0.9908', 'Train LL: -0.019805012059737854', 'Test LL: -0.02870655876407776', 'Epoch Time (s): 163.95466773118824')
('Epoch 76', 'Objective: -0.04221240435720556', 'Train Acc: 0.9936666666666667', 'Test Acc: 0.9899', 'Train LL: -0.020047534697358083', 'Test LL: -0.02777778720047848', 'Epoch Time (s): 163.9845615029335')
('Epoch 77', 'Objective: -0.042376492268467035', 'Train Acc: 0.9935833333333334', 'Test Acc: 0.9909', 'Train LL: -0.020276680853857625', 'Test LL: -0.028004676082830308', 'Epoch Time (s): 164.01105503202416')
('Epoch 78', 'Objective: -0.0421493109297867', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.991', 'Train LL: -0.020142241979056803', 'Test LL: -0.028568394017345428', 'Epoch Time (s): 163.91891558491625')
('Epoch 79', 'Objective: -0.041394457930401723', 'Train Acc: 0.99375', 'Test Acc: 0.9918', 'Train LL: -0.01946124981701414', 'Test LL: -0.026466595845585455', 'Epoch Time (s): 163.93149475799873')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.039311372131575754', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9915', 'Train LL: -0.01761629531419636', 'Test LL: -0.026764262516993022', 'Epoch Time (s): 163.88342872005887')
('Epoch 81', 'Objective: -0.03858623484809588', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.9914', 'Train LL: -0.016939099478426214', 'Test LL: -0.026063115396151137', 'Epoch Time (s): 163.8381278810557')
('Epoch 82', 'Objective: -0.03859090288615552', 'Train Acc: 0.9947', 'Test Acc: 0.9921', 'Train LL: -0.016887045908173123', 'Test LL: -0.026076036114538573', 'Epoch Time (s): 163.905076763127')
('Epoch 83', 'Objective: -0.03846888716551381', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9912', 'Train LL: -0.01680791124935486', 'Test LL: -0.027483877931363507', 'Epoch Time (s): 163.87572914385237')
('Epoch 84', 'Objective: -0.03863212517248822', 'Train Acc: 0.99455', 'Test Acc: 0.9912', 'Train LL: -0.01692649011201198', 'Test LL: -0.02711005211473482', 'Epoch Time (s): 163.87039391184226')
('Epoch 85', 'Objective: -0.038075288489669415', 'Train Acc: 0.99475', 'Test Acc: 0.9916', 'Train LL: -0.016429687875124107', 'Test LL: -0.02647164410987051', 'Epoch Time (s): 163.9266726388596')
('Epoch 86', 'Objective: -0.038565526889388836', 'Train Acc: 0.9946', 'Test Acc: 0.9915', 'Train LL: -0.016882062739434763', 'Test LL: -0.026261450111027807', 'Epoch Time (s): 163.93997783004306')
('Epoch 87', 'Objective: -0.03801446471160306', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9915', 'Train LL: -0.016381617378178774', 'Test LL: -0.02651334395064145', 'Epoch Time (s): 163.8771233430598')
('Epoch 88', 'Objective: -0.03752420599540227', 'Train Acc: 0.9945333333333334', 'Test Acc: 0.9916', 'Train LL: -0.015913833897824373', 'Test LL: -0.026552163984115498', 'Epoch Time (s): 163.9113161759451')
('Epoch 89', 'Objective: -0.03805111107338369', 'Train Acc: 0.99475', 'Test Acc: 0.9912', 'Train LL: -0.01639752786256336', 'Test LL: -0.028017067797863702', 'Epoch Time (s): 163.89778260397725')
('Epoch 90', 'Objective: -0.03774805544059275', 'Train Acc: 0.99485', 'Test Acc: 0.9917', 'Train LL: -0.016157145061718302', 'Test LL: -0.026533870333301707', 'Epoch Time (s): 163.82261878205463')
('Epoch 91', 'Objective: -0.0377874448869673', 'Train Acc: 0.9949833333333333', 'Test Acc: 0.9917', 'Train LL: -0.01616793924003699', 'Test LL: -0.026658629339119243', 'Epoch Time (s): 163.98874998488463')
('Epoch 92', 'Objective: -0.03813737141115655', 'Train Acc: 0.99485', 'Test Acc: 0.9917', 'Train LL: -0.01653370148353422', 'Test LL: -0.026630496500233646', 'Epoch Time (s): 163.9797055190429')
('Epoch 93', 'Objective: -0.038434226962551374', 'Train Acc: 0.99495', 'Test Acc: 0.9913', 'Train LL: -0.016781065716840432', 'Test LL: -0.027442477577786395', 'Epoch Time (s): 163.91789696388878')
('Epoch 94', 'Objective: -0.0373990104707274', 'Train Acc: 0.9947333333333334', 'Test Acc: 0.9914', 'Train LL: -0.015811598244144985', 'Test LL: -0.027125931940727856', 'Epoch Time (s): 164.01298718783073')
('Epoch 95', 'Objective: -0.03788972578782139', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9914', 'Train LL: -0.016242753916598084', 'Test LL: -0.0268005687475427', 'Epoch Time (s): 163.92701589991339')
('Epoch 96', 'Objective: -0.037578463764395977', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9913', 'Train LL: -0.015971396378701055', 'Test LL: -0.027522849595460714', 'Epoch Time (s): 164.08247629390098')
('Epoch 97', 'Objective: -0.03779382668347364', 'Train Acc: 0.99495', 'Test Acc: 0.9912', 'Train LL: -0.016121961727702337', 'Test LL: -0.027234721886430793', 'Epoch Time (s): 163.88194305892102')
('Epoch 98', 'Objective: -0.03734011478056904', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.9911', 'Train LL: -0.015753582460203926', 'Test LL: -0.027660823114637453', 'Epoch Time (s): 164.09753939299844')
('Epoch 99', 'Objective: -0.03757979806666974', 'Train Acc: 0.9951833333333333', 'Test Acc: 0.9912', 'Train LL: -0.016004315014964937', 'Test LL: -0.02736427798348213', 'Epoch Time (s): 164.2409652080387')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.0373509823600387
Final Train Accuracy: £0.995
Final Train LL: £-0.015809262651690224
Final Test Accuracy: £0.9912
Final Test LL: £-0.027324548495947096
