dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: BFCMixup
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.1915879808288705', 'Train Acc: 0.6179333333333333', 'Test Acc: 0.8366', 'Train LL: -1.0859731364995282', 'Test LL: -0.49445885493355735', 'Epoch Time (s): 171.38969460921362')
('Epoch 1', 'Objective: -0.448259996148016', 'Train Acc: 0.87765', 'Test Acc: 0.9268', 'Train LL: -0.37547365533410576', 'Test LL: -0.23330760833515574', 'Epoch Time (s): 171.02344492496923')
('Epoch 2', 'Objective: -0.3121791976582472', 'Train Acc: 0.9235', 'Test Acc: 0.9417', 'Train LL: -0.2452615336884291', 'Test LL: -0.17888663137901278', 'Epoch Time (s): 171.02118530776352')
('Epoch 3', 'Objective: -0.25676960719791736', 'Train Acc: 0.94015', 'Test Acc: 0.9475', 'Train LL: -0.1943040300342899', 'Test LL: -0.15994179133790154', 'Epoch Time (s): 171.05458268895745')
('Epoch 4', 'Objective: -0.21857027230710033', 'Train Acc: 0.9499166666666666', 'Test Acc: 0.9504', 'Train LL: -0.1598843226362708', 'Test LL: -0.15440562592456347', 'Epoch Time (s): 171.03716705739498')
('Epoch 5', 'Objective: -0.1998844494907216', 'Train Acc: 0.9558166666666666', 'Test Acc: 0.9561', 'Train LL: -0.1438347756827611', 'Test LL: -0.13144543069715142', 'Epoch Time (s): 170.99546216335148')
('Epoch 6', 'Objective: -0.18470536296299048', 'Train Acc: 0.9581333333333333', 'Test Acc: 0.9611', 'Train LL: -0.13047196849048068', 'Test LL: -0.11651412601196498', 'Epoch Time (s): 171.03130250284448')
('Epoch 7', 'Objective: -0.17120280112617672', 'Train Acc: 0.96305', 'Test Acc: 0.9678', 'Train LL: -0.11997005688347794', 'Test LL: -0.1035802227091033', 'Epoch Time (s): 171.01222423138097')
('Epoch 8', 'Objective: -0.1618681615906956', 'Train Acc: 0.9652333333333334', 'Test Acc: 0.9811', 'Train LL: -0.1126030692626195', 'Test LL: -0.060425808053445496', 'Epoch Time (s): 171.03845191234723')
('Epoch 9', 'Objective: -0.15149691846571467', 'Train Acc: 0.9676', 'Test Acc: 0.9774', 'Train LL: -0.10392816028907557', 'Test LL: -0.07085437739988772', 'Epoch Time (s): 171.01527101313695')
('Epoch 10', 'Objective: -0.14601996499187223', 'Train Acc: 0.9685166666666667', 'Test Acc: 0.9827', 'Train LL: -0.09967995119576478', 'Test LL: -0.05617302241798968', 'Epoch Time (s): 171.03221833566204')
('Epoch 11', 'Objective: -0.14072006490041747', 'Train Acc: 0.97015', 'Test Acc: 0.9815', 'Train LL: -0.0958664908833493', 'Test LL: -0.05333651077984326', 'Epoch Time (s): 171.04247619817033')
('Epoch 12', 'Objective: -0.13533199689854766', 'Train Acc: 0.9707333333333333', 'Test Acc: 0.9795', 'Train LL: -0.0918030209152467', 'Test LL: -0.06398176412614195', 'Epoch Time (s): 170.98705401923507')
('Epoch 13', 'Objective: -0.12978683367970434', 'Train Acc: 0.9727833333333333', 'Test Acc: 0.9808', 'Train LL: -0.0876384848175132', 'Test LL: -0.060949070589904876', 'Epoch Time (s): 171.04144054092467')
('Epoch 14', 'Objective: -0.12693934210003455', 'Train Acc: 0.97285', 'Test Acc: 0.9789', 'Train LL: -0.08577679513785604', 'Test LL: -0.0661013593655031', 'Epoch Time (s): 171.02529562311247')
('Epoch 15', 'Objective: -0.12205234046364583', 'Train Acc: 0.9750333333333333', 'Test Acc: 0.9779', 'Train LL: -0.08193979298303332', 'Test LL: -0.0697489408073115', 'Epoch Time (s): 171.06348704686388')
('Epoch 16', 'Objective: -0.11894523106735266', 'Train Acc: 0.97475', 'Test Acc: 0.9754', 'Train LL: -0.07990634617424332', 'Test LL: -0.07567728191268036', 'Epoch Time (s): 171.03378548007458')
('Epoch 17', 'Objective: -0.11564537521149265', 'Train Acc: 0.9764833333333334', 'Test Acc: 0.983', 'Train LL: -0.07712885603883236', 'Test LL: -0.05474364315575708', 'Epoch Time (s): 170.99489223118871')
('Epoch 18', 'Objective: -0.11067510488489445', 'Train Acc: 0.9776833333333333', 'Test Acc: 0.9798', 'Train LL: -0.07252829756648675', 'Test LL: -0.06260847871040195', 'Epoch Time (s): 171.07767770672217')
('Epoch 19', 'Objective: -0.11075019921071785', 'Train Acc: 0.9774666666666667', 'Test Acc: 0.9805', 'Train LL: -0.07331205872275591', 'Test LL: -0.06051767728090991', 'Epoch Time (s): 170.98637351905927')
('Epoch 20', 'Objective: -0.10859143675217622', 'Train Acc: 0.97795', 'Test Acc: 0.9814', 'Train LL: -0.07160223864399244', 'Test LL: -0.05645887672009599', 'Epoch Time (s): 171.03485943889245')
('Epoch 21', 'Objective: -0.10420624927507412', 'Train Acc: 0.9784', 'Test Acc: 0.9836', 'Train LL: -0.06788609920938286', 'Test LL: -0.056602168298393624', 'Epoch Time (s): 171.03050867980346')
('Epoch 22', 'Objective: -0.10335965776990613', 'Train Acc: 0.9791166666666666', 'Test Acc: 0.9768', 'Train LL: -0.0674536340948359', 'Test LL: -0.07376089245542183', 'Epoch Time (s): 171.02342659700662')
('Epoch 23', 'Objective: -0.0999823547778946', 'Train Acc: 0.9797166666666667', 'Test Acc: 0.9791', 'Train LL: -0.06482736096872475', 'Test LL: -0.06052717280205934', 'Epoch Time (s): 171.06036485172808')
('Epoch 24', 'Objective: -0.10103629235340761', 'Train Acc: 0.9788166666666667', 'Test Acc: 0.9814', 'Train LL: -0.06598038472242322', 'Test LL: -0.05569271164984324', 'Epoch Time (s): 171.04491381766275')
('Epoch 25', 'Objective: -0.09851765568901844', 'Train Acc: 0.9798333333333333', 'Test Acc: 0.9717', 'Train LL: -0.06396091860468824', 'Test LL: -0.087694437610055', 'Epoch Time (s): 171.01512884022668')
('Epoch 26', 'Objective: -0.09544199932686674', 'Train Acc: 0.981', 'Test Acc: 0.9781', 'Train LL: -0.06182326391610147', 'Test LL: -0.06514932259727606', 'Epoch Time (s): 170.98884589970112')
('Epoch 27', 'Objective: -0.09419901297241909', 'Train Acc: 0.98085', 'Test Acc: 0.9825', 'Train LL: -0.06029718307153463', 'Test LL: -0.05442796310195324', 'Epoch Time (s): 171.0541189275682')
('Epoch 28', 'Objective: -0.09298293416568991', 'Train Acc: 0.9815333333333334', 'Test Acc: 0.983', 'Train LL: -0.05952126912783564', 'Test LL: -0.052719305343024755', 'Epoch Time (s): 171.02945298328996')
('Epoch 29', 'Objective: -0.09125176317040319', 'Train Acc: 0.9815666666666667', 'Test Acc: 0.9812', 'Train LL: -0.05806050848055256', 'Test LL: -0.06028315998815093', 'Epoch Time (s): 170.98791457200423')
('Epoch 30', 'Objective: -0.09022303733776961', 'Train Acc: 0.9820333333333333', 'Test Acc: 0.9785', 'Train LL: -0.057528022378626496', 'Test LL: -0.06790987410033264', 'Epoch Time (s): 170.97930002771318')
('Epoch 31', 'Objective: -0.08991518701413394', 'Train Acc: 0.9819', 'Test Acc: 0.984', 'Train LL: -0.05751511062951139', 'Test LL: -0.053814883695507035', 'Epoch Time (s): 171.03161444608122')
('Epoch 32', 'Objective: -0.08896752935448332', 'Train Acc: 0.9817333333333333', 'Test Acc: 0.9842', 'Train LL: -0.05700972182616726', 'Test LL: -0.05140780628275171', 'Epoch Time (s): 171.07105544721708')
('Epoch 33', 'Objective: -0.08780120811132794', 'Train Acc: 0.9821833333333333', 'Test Acc: 0.9834', 'Train LL: -0.05613036488502469', 'Test LL: -0.0513818086156247', 'Epoch Time (s): 171.0368306050077')
('Epoch 34', 'Objective: -0.08690870732411506', 'Train Acc: 0.98335', 'Test Acc: 0.9821', 'Train LL: -0.05558182709574265', 'Test LL: -0.0554164671666696', 'Epoch Time (s): 171.04961491795257')
('Epoch 35', 'Objective: -0.08619872728597322', 'Train Acc: 0.9831666666666666', 'Test Acc: 0.9838', 'Train LL: -0.055141602531245074', 'Test LL: -0.05420108457242434', 'Epoch Time (s): 171.04196725180373')
('Epoch 36', 'Objective: -0.08280570294640285', 'Train Acc: 0.98345', 'Test Acc: 0.984', 'Train LL: -0.05220445386814733', 'Test LL: -0.05072972942418896', 'Epoch Time (s): 171.02203030372038')
('Epoch 37', 'Objective: -0.08464441179208293', 'Train Acc: 0.9831166666666666', 'Test Acc: 0.9832', 'Train LL: -0.05385668046960756', 'Test LL: -0.04942717971576476', 'Epoch Time (s): 171.01162048615515')
('Epoch 38', 'Objective: -0.08329868478877021', 'Train Acc: 0.9835', 'Test Acc: 0.9846', 'Train LL: -0.05293840315107024', 'Test LL: -0.04648809744648238', 'Epoch Time (s): 171.00212165759876')
('Epoch 39', 'Objective: -0.08118364901248826', 'Train Acc: 0.9841166666666666', 'Test Acc: 0.9862', 'Train LL: -0.051208576544519865', 'Test LL: -0.04382192079990371', 'Epoch Time (s): 171.04517292277887')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06021130341070466', 'Train Acc: 0.9898', 'Test Acc: 0.9885', 'Train LL: -0.03234535427736283', 'Test LL: -0.03518314941645835', 'Epoch Time (s): 171.0177242970094')
('Epoch 41', 'Objective: -0.055712139494097423', 'Train Acc: 0.9908666666666667', 'Test Acc: 0.99', 'Train LL: -0.02888284191324778', 'Test LL: -0.03114504113613738', 'Epoch Time (s): 171.01348936604336')
('Epoch 42', 'Objective: -0.05415351157483948', 'Train Acc: 0.9910666666666667', 'Test Acc: 0.9907', 'Train LL: -0.027686929252874668', 'Test LL: -0.02848755223094272', 'Epoch Time (s): 171.0118738990277')
('Epoch 43', 'Objective: -0.052237013915310104', 'Train Acc: 0.99165', 'Test Acc: 0.9902', 'Train LL: -0.026130976013400822', 'Test LL: -0.030474072258364782', 'Epoch Time (s): 171.16485637705773')
('Epoch 44', 'Objective: -0.05157820220145435', 'Train Acc: 0.99175', 'Test Acc: 0.9906', 'Train LL: -0.025687070562951646', 'Test LL: -0.029854542442013007', 'Epoch Time (s): 171.02058756211773')
('Epoch 45', 'Objective: -0.05151023043406789', 'Train Acc: 0.9916166666666667', 'Test Acc: 0.9894', 'Train LL: -0.025758361490563847', 'Test LL: -0.03269413854888241', 'Epoch Time (s): 170.9600895503536')
('Epoch 46', 'Objective: -0.05098633927275756', 'Train Acc: 0.9921', 'Test Acc: 0.9897', 'Train LL: -0.025379311636701832', 'Test LL: -0.03161355556836439', 'Epoch Time (s): 171.0224580182694')
('Epoch 47', 'Objective: -0.050648756257852694', 'Train Acc: 0.9919', 'Test Acc: 0.9909', 'Train LL: -0.025140726130017492', 'Test LL: -0.028416561209845054', 'Epoch Time (s): 170.9940692037344')
('Epoch 48', 'Objective: -0.05001392495824793', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9909', 'Train LL: -0.02480117721129223', 'Test LL: -0.027411882140127835', 'Epoch Time (s): 171.00155598670244')
('Epoch 49', 'Objective: -0.0496876857674287', 'Train Acc: 0.99235', 'Test Acc: 0.9904', 'Train LL: -0.024525177802326537', 'Test LL: -0.02981758272835118', 'Epoch Time (s): 171.03260031389073')
('Epoch 50', 'Objective: -0.04917625630168337', 'Train Acc: 0.99245', 'Test Acc: 0.9911', 'Train LL: -0.02413445906986203', 'Test LL: -0.02924711683198789', 'Epoch Time (s): 171.00606258725747')
('Epoch 51', 'Objective: -0.04917255801152926', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.9895', 'Train LL: -0.0242010476979079', 'Test LL: -0.03284115415940981', 'Epoch Time (s): 171.0120709007606')
('Epoch 52', 'Objective: -0.048183075342912836', 'Train Acc: 0.9925666666666667', 'Test Acc: 0.9903', 'Train LL: -0.023302345218980836', 'Test LL: -0.029053817793339737', 'Epoch Time (s): 170.98475881991908')
('Epoch 53', 'Objective: -0.04797301972915925', 'Train Acc: 0.99255', 'Test Acc: 0.9903', 'Train LL: -0.02321623544568088', 'Test LL: -0.029018633545675233', 'Epoch Time (s): 170.99112715106457')
('Epoch 54', 'Objective: -0.0476975508552313', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9903', 'Train LL: -0.023076496558241212', 'Test LL: -0.03016261751423001', 'Epoch Time (s): 171.00136613100767')
('Epoch 55', 'Objective: -0.04807333164842203', 'Train Acc: 0.9929166666666667', 'Test Acc: 0.9914', 'Train LL: -0.023453995427494292', 'Test LL: -0.02844759834072381', 'Epoch Time (s): 170.99737859563902')
('Epoch 56', 'Objective: -0.047463131354052106', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9901', 'Train LL: -0.02294078970294364', 'Test LL: -0.030291445672447292', 'Epoch Time (s): 171.034476746805')
('Epoch 57', 'Objective: -0.04679909010578481', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9914', 'Train LL: -0.022398566682048572', 'Test LL: -0.027824125092839273', 'Epoch Time (s): 170.97110733902082')
('Epoch 58', 'Objective: -0.047340188446471976', 'Train Acc: 0.9927', 'Test Acc: 0.9907', 'Train LL: -0.02292309745479447', 'Test LL: -0.029511845702051107', 'Epoch Time (s): 171.0350884469226')
('Epoch 59', 'Objective: -0.04721569211887955', 'Train Acc: 0.9930333333333333', 'Test Acc: 0.9908', 'Train LL: -0.02297838517414468', 'Test LL: -0.031060243248150807', 'Epoch Time (s): 170.98438417632133')
('Epoch 60', 'Objective: -0.046221766437947016', 'Train Acc: 0.9931166666666666', 'Test Acc: 0.9907', 'Train LL: -0.021999660162230213', 'Test LL: -0.026953902130474366', 'Epoch Time (s): 170.90400458080694')
('Epoch 61', 'Objective: -0.046238200276168526', 'Train Acc: 0.9931', 'Test Acc: 0.9914', 'Train LL: -0.02198840314926346', 'Test LL: -0.02863424965525245', 'Epoch Time (s): 170.90886767301708')
('Epoch 62', 'Objective: -0.04626762009021666', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9893', 'Train LL: -0.022170955069388078', 'Test LL: -0.0314362929296842', 'Epoch Time (s): 170.93919306015596')
('Epoch 63', 'Objective: -0.04606389075092344', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9914', 'Train LL: -0.02191593680452128', 'Test LL: -0.027007738663427528', 'Epoch Time (s): 170.9186696712859')
('Epoch 64', 'Objective: -0.04560235957745644', 'Train Acc: 0.99285', 'Test Acc: 0.9913', 'Train LL: -0.02154162145714707', 'Test LL: -0.028998860946947345', 'Epoch Time (s): 170.92236634995788')
('Epoch 65', 'Objective: -0.0455775190909498', 'Train Acc: 0.9931', 'Test Acc: 0.9903', 'Train LL: -0.021573348873520054', 'Test LL: -0.029626864649533336', 'Epoch Time (s): 170.9016989809461')
('Epoch 66', 'Objective: -0.04585060437890603', 'Train Acc: 0.9931666666666666', 'Test Acc: 0.9897', 'Train LL: -0.02185256278463741', 'Test LL: -0.03210944139599277', 'Epoch Time (s): 170.87410503113642')
('Epoch 67', 'Objective: -0.0451586015871348', 'Train Acc: 0.9932', 'Test Acc: 0.991', 'Train LL: -0.021266899799762665', 'Test LL: -0.029265539295798608', 'Epoch Time (s): 170.8800645582378')
('Epoch 68', 'Objective: -0.04552709794161867', 'Train Acc: 0.99325', 'Test Acc: 0.989', 'Train LL: -0.021690961395345928', 'Test LL: -0.03343405563777121', 'Epoch Time (s): 170.94849395519122')
('Epoch 69', 'Objective: -0.0451704561600841', 'Train Acc: 0.9932666666666666', 'Test Acc: 0.9897', 'Train LL: -0.021311488403196903', 'Test LL: -0.03145550008101228', 'Epoch Time (s): 170.9418419310823')
('Epoch 70', 'Objective: -0.04501488242530968', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9877', 'Train LL: -0.021184684180633857', 'Test LL: -0.034682520148481534', 'Epoch Time (s): 170.86775736976415')
('Epoch 71', 'Objective: -0.04406236293444928', 'Train Acc: 0.99345', 'Test Acc: 0.9912', 'Train LL: -0.020345629334805236', 'Test LL: -0.027129467330289606', 'Epoch Time (s): 170.86786675499752')
('Epoch 72', 'Objective: -0.04448557602783774', 'Train Acc: 0.9932166666666666', 'Test Acc: 0.9908', 'Train LL: -0.02066173952935697', 'Test LL: -0.02759986334461003', 'Epoch Time (s): 170.8787233242765')
('Epoch 73', 'Objective: -0.044011438862166234', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.9901', 'Train LL: -0.020314399365610917', 'Test LL: -0.031122127823066337', 'Epoch Time (s): 170.90767623716965')
('Epoch 74', 'Objective: -0.04443063911381441', 'Train Acc: 0.99365', 'Test Acc: 0.9897', 'Train LL: -0.02078398236829697', 'Test LL: -0.030821233014439453', 'Epoch Time (s): 170.9825234231539')
('Epoch 75', 'Objective: -0.04453798563007122', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.9903', 'Train LL: -0.020861030528654654', 'Test LL: -0.03091270863231631', 'Epoch Time (s): 170.9376250547357')
('Epoch 76', 'Objective: -0.043854666785336296', 'Train Acc: 0.9937166666666667', 'Test Acc: 0.9908', 'Train LL: -0.020275232908829988', 'Test LL: -0.027665778651797736', 'Epoch Time (s): 170.93813583487645')
('Epoch 77', 'Objective: -0.04392667447407005', 'Train Acc: 0.9934166666666666', 'Test Acc: 0.9894', 'Train LL: -0.020341710655092077', 'Test LL: -0.030661876399365406', 'Epoch Time (s): 170.92676000110805')
('Epoch 78', 'Objective: -0.04455589960956254', 'Train Acc: 0.99335', 'Test Acc: 0.9913', 'Train LL: -0.020999304663681065', 'Test LL: -0.02949123421022267', 'Epoch Time (s): 170.9012438398786')
('Epoch 79', 'Objective: -0.04368299776083023', 'Train Acc: 0.9936', 'Test Acc: 0.9904', 'Train LL: -0.020113233853557427', 'Test LL: -0.029703006846738385', 'Epoch Time (s): 170.977363885846')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.04142997902682502', 'Train Acc: 0.99435', 'Test Acc: 0.9913', 'Train LL: -0.018202335672366423', 'Test LL: -0.027593903155507974', 'Epoch Time (s): 170.92353834584355')
('Epoch 81', 'Objective: -0.040957713904136675', 'Train Acc: 0.9946666666666667', 'Test Acc: 0.991', 'Train LL: -0.017758056746978813', 'Test LL: -0.027567855866407764', 'Epoch Time (s): 170.92679297365248')
('Epoch 82', 'Objective: -0.040400515600828746', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9912', 'Train LL: -0.01725154518799066', 'Test LL: -0.02751134407340639', 'Epoch Time (s): 170.89485524827614')
('Epoch 83', 'Objective: -0.04008231878942488', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9918', 'Train LL: -0.016933030153137414', 'Test LL: -0.027103364765385766', 'Epoch Time (s): 170.9287769938819')
('Epoch 84', 'Objective: -0.039686868400404', 'Train Acc: 0.9949166666666667', 'Test Acc: 0.9914', 'Train LL: -0.016601013380852205', 'Test LL: -0.026729194906739157', 'Epoch Time (s): 170.88631054991856')
('Epoch 85', 'Objective: -0.04017741329614683', 'Train Acc: 0.99465', 'Test Acc: 0.9914', 'Train LL: -0.01700703567346046', 'Test LL: -0.027768826061485372', 'Epoch Time (s): 170.88879397092387')
('Epoch 86', 'Objective: -0.039940214727934645', 'Train Acc: 0.99475', 'Test Acc: 0.9914', 'Train LL: -0.016824926907400724', 'Test LL: -0.026905101116699973', 'Epoch Time (s): 170.9259202699177')
('Epoch 87', 'Objective: -0.039847672452729084', 'Train Acc: 0.9949', 'Test Acc: 0.9914', 'Train LL: -0.016784934299316667', 'Test LL: -0.027428430186977982', 'Epoch Time (s): 170.88874737313017')
('Epoch 88', 'Objective: -0.03991232517503688', 'Train Acc: 0.9945166666666667', 'Test Acc: 0.9912', 'Train LL: -0.01683959498580059', 'Test LL: -0.026863170222332037', 'Epoch Time (s): 170.86140219075605')
('Epoch 89', 'Objective: -0.040268418648256726', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9908', 'Train LL: -0.01714486278564152', 'Test LL: -0.02922355603381244', 'Epoch Time (s): 170.8657971220091')
('Epoch 90', 'Objective: -0.039814087624599113', 'Train Acc: 0.9949833333333333', 'Test Acc: 0.9915', 'Train LL: -0.016723319100844836', 'Test LL: -0.027881950394488313', 'Epoch Time (s): 170.94019828969613')
('Epoch 91', 'Objective: -0.039336164392859495', 'Train Acc: 0.9951166666666666', 'Test Acc: 0.9912', 'Train LL: -0.01629683177891191', 'Test LL: -0.02839060143592481', 'Epoch Time (s): 170.90174733288586')
('Epoch 92', 'Objective: -0.03935841045463889', 'Train Acc: 0.995', 'Test Acc: 0.9912', 'Train LL: -0.0163498798950863', 'Test LL: -0.029167225835090058', 'Epoch Time (s): 170.85321859968826')
('Epoch 93', 'Objective: -0.03933370603553995', 'Train Acc: 0.9948', 'Test Acc: 0.9913', 'Train LL: -0.01629302210762017', 'Test LL: -0.02839467415174614', 'Epoch Time (s): 170.91456798324361')
('Epoch 94', 'Objective: -0.03992531865904645', 'Train Acc: 0.9946833333333334', 'Test Acc: 0.9911', 'Train LL: -0.016811234406239283', 'Test LL: -0.02850505428654763', 'Epoch Time (s): 170.9200910748914')
('Epoch 95', 'Objective: -0.03923832428733069', 'Train Acc: 0.9948166666666667', 'Test Acc: 0.9914', 'Train LL: -0.01619041110314677', 'Test LL: -0.028738575472161007', 'Epoch Time (s): 170.91975806932896')
('Epoch 96', 'Objective: -0.039268519681261285', 'Train Acc: 0.9950666666666667', 'Test Acc: 0.9913', 'Train LL: -0.016204015946164226', 'Test LL: -0.02791804283706532', 'Epoch Time (s): 170.88804565789178')
('Epoch 97', 'Objective: -0.0389969170980304', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.9913', 'Train LL: -0.015947266827509663', 'Test LL: -0.028119839547346145', 'Epoch Time (s): 170.98111597215757')
('Epoch 98', 'Objective: -0.03915680248224236', 'Train Acc: 0.9949333333333333', 'Test Acc: 0.9909', 'Train LL: -0.0161252542838532', 'Test LL: -0.02857554564963709', 'Epoch Time (s): 170.88094684900716')
('Epoch 99', 'Objective: -0.03923674755542087', 'Train Acc: 0.99495', 'Test Acc: 0.9906', 'Train LL: -0.016151007423643116', 'Test LL: -0.029944161949474347', 'Epoch Time (s): 170.9373937449418')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.038903337211465126
Final Train Accuracy: £0.9949666666666667
Final Train LL: £-0.015868754419675016
Final Test Accuracy: £0.9906
Final Test LL: £-0.02984956026746811
