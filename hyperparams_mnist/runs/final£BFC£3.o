dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: BFC
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.4493513491911652', 'Train Acc: 0.50655', 'Test Acc: 0.6918', 'Train LL: -1.3501780150258234', 'Test LL: -0.8908755770576472', 'Epoch Time (s): 162.72350777103566')
('Epoch 1', 'Objective: -0.6999608103918569', 'Train Acc: 0.7844833333333333', 'Test Acc: 0.83', 'Train LL: -0.6250775134679244', 'Test LL: -0.49279495176017307', 'Epoch Time (s): 162.74435263499618')
('Epoch 2', 'Objective: -0.4084686686554393', 'Train Acc: 0.8906833333333334', 'Test Acc: 0.9347', 'Train LL: -0.33951223331949043', 'Test LL: -0.21363863874939326', 'Epoch Time (s): 162.7572355561424')
('Epoch 3', 'Objective: -0.2923755280161815', 'Train Acc: 0.9288', 'Test Acc: 0.9577', 'Train LL: -0.22960790735114187', 'Test LL: -0.13685304007756757', 'Epoch Time (s): 162.72364415391348')
('Epoch 4', 'Objective: -0.2398807125400704', 'Train Acc: 0.94355', 'Test Acc: 0.9566', 'Train LL: -0.18313266829007777', 'Test LL: -0.13646697732118485', 'Epoch Time (s): 162.7540324011352')
('Epoch 5', 'Objective: -0.21407030066857238', 'Train Acc: 0.95095', 'Test Acc: 0.9462', 'Train LL: -0.16044580084733268', 'Test LL: -0.16728965097274745', 'Epoch Time (s): 162.78779352200218')
('Epoch 6', 'Objective: -0.19896805461381883', 'Train Acc: 0.9551333333333333', 'Test Acc: 0.9614', 'Train LL: -0.14762131680868648', 'Test LL: -0.12417640542424527', 'Epoch Time (s): 162.71081228600815')
('Epoch 7', 'Objective: -0.1842915809762277', 'Train Acc: 0.9584333333333334', 'Test Acc: 0.9619', 'Train LL: -0.13457575936353275', 'Test LL: -0.11241318233633', 'Epoch Time (s): 162.71560410712846')
('Epoch 8', 'Objective: -0.17379249874246933', 'Train Acc: 0.9613', 'Test Acc: 0.946', 'Train LL: -0.12512161766041868', 'Test LL: -0.17298334230570045', 'Epoch Time (s): 162.7251193751581')
('Epoch 9', 'Objective: -0.16628584543324493', 'Train Acc: 0.9633666666666667', 'Test Acc: 0.9722', 'Train LL: -0.11921549364868803', 'Test LL: -0.09226807256346162', 'Epoch Time (s): 162.72565227514133')
('Epoch 10', 'Objective: -0.15769210017577573', 'Train Acc: 0.9650666666666666', 'Test Acc: 0.9649', 'Train LL: -0.11143451876795528', 'Test LL: -0.10292771865232014', 'Epoch Time (s): 162.76124906609766')
('Epoch 11', 'Objective: -0.1527117620691099', 'Train Acc: 0.9664166666666667', 'Test Acc: 0.9633', 'Train LL: -0.10685689589249837', 'Test LL: -0.11041000926401191', 'Epoch Time (s): 162.73894409206696')
('Epoch 12', 'Objective: -0.14681344350140071', 'Train Acc: 0.9682333333333333', 'Test Acc: 0.9647', 'Train LL: -0.10169368938996158', 'Test LL: -0.10833766722483361', 'Epoch Time (s): 162.7646018618252')
('Epoch 13', 'Objective: -0.14249782001127329', 'Train Acc: 0.96845', 'Test Acc: 0.9772', 'Train LL: -0.09777891292535187', 'Test LL: -0.0703263060861795', 'Epoch Time (s): 162.7355141849257')
('Epoch 14', 'Objective: -0.1390612908288918', 'Train Acc: 0.9701333333333333', 'Test Acc: 0.9757', 'Train LL: -0.09500143748987668', 'Test LL: -0.07783898166082429', 'Epoch Time (s): 162.76099800900556')
('Epoch 15', 'Objective: -0.13344735265356428', 'Train Acc: 0.9723833333333334', 'Test Acc: 0.9765', 'Train LL: -0.0896642459631088', 'Test LL: -0.06953455756834469', 'Epoch Time (s): 162.76733058108948')
('Epoch 16', 'Objective: -0.1301191698661361', 'Train Acc: 0.97305', 'Test Acc: 0.9684', 'Train LL: -0.08693154002547182', 'Test LL: -0.094639044802208', 'Epoch Time (s): 162.75544313597493')
('Epoch 17', 'Objective: -0.12891125719473107', 'Train Acc: 0.9736166666666667', 'Test Acc: 0.9733', 'Train LL: -0.08602459627484213', 'Test LL: -0.08306098656513446', 'Epoch Time (s): 162.72579293185845')
('Epoch 18', 'Objective: -0.12437773808989257', 'Train Acc: 0.9742', 'Test Acc: 0.9765', 'Train LL: -0.082140006596274', 'Test LL: -0.0728446707637023', 'Epoch Time (s): 162.75035244901665')
('Epoch 19', 'Objective: -0.12210071577564131', 'Train Acc: 0.9745666666666667', 'Test Acc: 0.9776', 'Train LL: -0.08011221509437501', 'Test LL: -0.06518527699924957', 'Epoch Time (s): 162.75660199811682')
('Epoch 20', 'Objective: -0.11915130325241254', 'Train Acc: 0.9756166666666667', 'Test Acc: 0.9774', 'Train LL: -0.0775237205940024', 'Test LL: -0.07020438811204086', 'Epoch Time (s): 162.753590131877')
('Epoch 21', 'Objective: -0.11551983971196941', 'Train Acc: 0.9760833333333333', 'Test Acc: 0.9749', 'Train LL: -0.07433710943876004', 'Test LL: -0.07190900051147851', 'Epoch Time (s): 162.74703912017867')
('Epoch 22', 'Objective: -0.11556099071034844', 'Train Acc: 0.9759666666666666', 'Test Acc: 0.9754', 'Train LL: -0.07478660874562372', 'Test LL: -0.07288508419377156', 'Epoch Time (s): 162.7023855180014')
('Epoch 23', 'Objective: -0.11301499448782386', 'Train Acc: 0.9775333333333334', 'Test Acc: 0.9777', 'Train LL: -0.07259511552136688', 'Test LL: -0.07090074117286413', 'Epoch Time (s): 162.75779369217344')
('Epoch 24', 'Objective: -0.10986625930048963', 'Train Acc: 0.9776166666666667', 'Test Acc: 0.9834', 'Train LL: -0.06999257771808078', 'Test LL: -0.047654732891924165', 'Epoch Time (s): 162.74520784802735')
('Epoch 25', 'Objective: -0.10747291624734323', 'Train Acc: 0.9784166666666667', 'Test Acc: 0.9802', 'Train LL: -0.0679972336406097', 'Test LL: -0.058604295847114386', 'Epoch Time (s): 162.7571924580261')
('Epoch 26', 'Objective: -0.10548744614591045', 'Train Acc: 0.97895', 'Test Acc: 0.9793', 'Train LL: -0.06602239236634581', 'Test LL: -0.06376046088827927', 'Epoch Time (s): 162.74469513795339')
('Epoch 27', 'Objective: -0.10688926057419558', 'Train Acc: 0.9789166666666667', 'Test Acc: 0.9813', 'Train LL: -0.06778639693034379', 'Test LL: -0.05741486839270947', 'Epoch Time (s): 162.70103613100946')
('Epoch 28', 'Objective: -0.10443320430720647', 'Train Acc: 0.97925', 'Test Acc: 0.9796', 'Train LL: -0.0656713775416391', 'Test LL: -0.06618785520508944', 'Epoch Time (s): 162.69616733398288')
('Epoch 29', 'Objective: -0.10122860673077334', 'Train Acc: 0.9802', 'Test Acc: 0.9721', 'Train LL: -0.06289912817999936', 'Test LL: -0.08725951782647308', 'Epoch Time (s): 162.68775007408112')
('Epoch 30', 'Objective: -0.0991512584843964', 'Train Acc: 0.9808333333333333', 'Test Acc: 0.9847', 'Train LL: -0.06121859586721091', 'Test LL: -0.04794600775367681', 'Epoch Time (s): 162.71119238203391')
('Epoch 31', 'Objective: -0.09787943620606017', 'Train Acc: 0.9813333333333333', 'Test Acc: 0.9847', 'Train LL: -0.060098069951002524', 'Test LL: -0.04567583970848163', 'Epoch Time (s): 162.7221585959196')
('Epoch 32', 'Objective: -0.0978943085294653', 'Train Acc: 0.9809666666666667', 'Test Acc: 0.9816', 'Train LL: -0.060217727625580836', 'Test LL: -0.05769626509974423', 'Epoch Time (s): 162.72397973993793')
('Epoch 33', 'Objective: -0.09657214698646845', 'Train Acc: 0.9811666666666666', 'Test Acc: 0.9793', 'Train LL: -0.05936987754893342', 'Test LL: -0.06338907052321464', 'Epoch Time (s): 162.73929197597317')
('Epoch 34', 'Objective: -0.09700870230031798', 'Train Acc: 0.9804333333333334', 'Test Acc: 0.9861', 'Train LL: -0.0600521789401344', 'Test LL: -0.04718877765785635', 'Epoch Time (s): 162.69780591293238')
('Epoch 35', 'Objective: -0.09622372862491033', 'Train Acc: 0.9812', 'Test Acc: 0.9804', 'Train LL: -0.05953844203037699', 'Test LL: -0.057156175791622195', 'Epoch Time (s): 162.71493649692275')
('Epoch 36', 'Objective: -0.09510241542171123', 'Train Acc: 0.9813166666666666', 'Test Acc: 0.9861', 'Train LL: -0.05866619431861811', 'Test LL: -0.04274631420536922', 'Epoch Time (s): 162.72207165299915')
('Epoch 37', 'Objective: -0.0924738666738043', 'Train Acc: 0.9817833333333333', 'Test Acc: 0.9856', 'Train LL: -0.05623637497043525', 'Test LL: -0.04316519943518879', 'Epoch Time (s): 162.70950446208008')
('Epoch 38', 'Objective: -0.09203993975045721', 'Train Acc: 0.9816666666666667', 'Test Acc: 0.9825', 'Train LL: -0.055849087028771706', 'Test LL: -0.051345459845923175', 'Epoch Time (s): 162.7130995108746')
('Epoch 39', 'Objective: -0.09117399292454595', 'Train Acc: 0.9826333333333334', 'Test Acc: 0.9858', 'Train LL: -0.05554625512293149', 'Test LL: -0.04751077695885722', 'Epoch Time (s): 162.73746460606344')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06843144889595568', 'Train Acc: 0.9889666666666667', 'Test Acc: 0.9899', 'Train LL: -0.03496402274627838', 'Test LL: -0.031031380575076588', 'Epoch Time (s): 162.71854478912428')
('Epoch 41', 'Objective: -0.06286541264203402', 'Train Acc: 0.9905666666666667', 'Test Acc: 0.9893', 'Train LL: -0.030751903426722803', 'Test LL: -0.032585685072139395', 'Epoch Time (s): 162.72117274510674')
('Epoch 42', 'Objective: -0.06185828211203892', 'Train Acc: 0.9907', 'Test Acc: 0.9904', 'Train LL: -0.030406565447155122', 'Test LL: -0.028740431633474953', 'Epoch Time (s): 162.72196077299304')
('Epoch 43', 'Objective: -0.059484521696638086', 'Train Acc: 0.9908333333333333', 'Test Acc: 0.9905', 'Train LL: -0.028312380165544784', 'Test LL: -0.027790443192970013', 'Epoch Time (s): 162.69781205803156')
('Epoch 44', 'Objective: -0.058825731023121684', 'Train Acc: 0.9911333333333333', 'Test Acc: 0.9911', 'Train LL: -0.02798100719306658', 'Test LL: -0.02717038036339421', 'Epoch Time (s): 162.75229048007168')
('Epoch 45', 'Objective: -0.05879341864062164', 'Train Acc: 0.9911166666666666', 'Test Acc: 0.9901', 'Train LL: -0.028141473645481092', 'Test LL: -0.02925134886877908', 'Epoch Time (s): 162.71090180287138')
('Epoch 46', 'Objective: -0.05753747733218319', 'Train Acc: 0.9911666666666666', 'Test Acc: 0.9903', 'Train LL: -0.02702686948593146', 'Test LL: -0.027363475603290804', 'Epoch Time (s): 162.7140706430655')
('Epoch 47', 'Objective: -0.05655754116809619', 'Train Acc: 0.9914833333333334', 'Test Acc: 0.9899', 'Train LL: -0.02641553436862865', 'Test LL: -0.028951567671015414', 'Epoch Time (s): 162.72740065096878')
('Epoch 48', 'Objective: -0.056449677355744396', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9908', 'Train LL: -0.026393946911043246', 'Test LL: -0.02735132469603868', 'Epoch Time (s): 162.75316104199737')
('Epoch 49', 'Objective: -0.05591311607644419', 'Train Acc: 0.99165', 'Test Acc: 0.9895', 'Train LL: -0.026086692700127867', 'Test LL: -0.03169435872358226', 'Epoch Time (s): 162.72690136311576')
('Epoch 50', 'Objective: -0.0561829563380068', 'Train Acc: 0.9919333333333333', 'Test Acc: 0.9912', 'Train LL: -0.02652208833027791', 'Test LL: -0.026140932010856734', 'Epoch Time (s): 162.81755498214625')
('Epoch 51', 'Objective: -0.054578699801361236', 'Train Acc: 0.99215', 'Test Acc: 0.991', 'Train LL: -0.025053040501332568', 'Test LL: -0.02600924628788872', 'Epoch Time (s): 162.70937495213002')
('Epoch 52', 'Objective: -0.05550065584771859', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.9908', 'Train LL: -0.026028793875907775', 'Test LL: -0.026342318768553884', 'Epoch Time (s): 162.7647258050274')
('Epoch 53', 'Objective: -0.05482910366277489', 'Train Acc: 0.9919', 'Test Acc: 0.9898', 'Train LL: -0.025547792352974816', 'Test LL: -0.029416228744980982', 'Epoch Time (s): 162.73216645396315')
('Epoch 54', 'Objective: -0.05389919434176219', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9911', 'Train LL: -0.02470679983347927', 'Test LL: -0.02792006151432369', 'Epoch Time (s): 162.7346798449289')
('Epoch 55', 'Objective: -0.054079727734322354', 'Train Acc: 0.9924333333333333', 'Test Acc: 0.9894', 'Train LL: -0.024981803573945978', 'Test LL: -0.029874308917625773', 'Epoch Time (s): 162.74889747216366')
('Epoch 56', 'Objective: -0.0542311292686674', 'Train Acc: 0.9920333333333333', 'Test Acc: 0.9892', 'Train LL: -0.02510368955551168', 'Test LL: -0.03081937795117658', 'Epoch Time (s): 162.7219224909786')
('Epoch 57', 'Objective: -0.05422948499742593', 'Train Acc: 0.9924', 'Test Acc: 0.9909', 'Train LL: -0.025215541826328028', 'Test LL: -0.026947387397127046', 'Epoch Time (s): 162.7200947459787')
('Epoch 58', 'Objective: -0.05311436449048235', 'Train Acc: 0.9922166666666666', 'Test Acc: 0.9909', 'Train LL: -0.024294746599725536', 'Test LL: -0.02629250560766651', 'Epoch Time (s): 162.73588810907677')
('Epoch 59', 'Objective: -0.05321834107053146', 'Train Acc: 0.99215', 'Test Acc: 0.9913', 'Train LL: -0.024343100502554303', 'Test LL: -0.026281005983478885', 'Epoch Time (s): 162.7238626431208')
('Epoch 60', 'Objective: -0.05275546337991348', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9903', 'Train LL: -0.02392223534955367', 'Test LL: -0.02996501727867327', 'Epoch Time (s): 162.72086088894866')
('Epoch 61', 'Objective: -0.053630164710822145', 'Train Acc: 0.99235', 'Test Acc: 0.9918', 'Train LL: -0.025000307796934955', 'Test LL: -0.024241863517528002', 'Epoch Time (s): 162.73168830899522')
('Epoch 62', 'Objective: -0.05241851116938644', 'Train Acc: 0.99235', 'Test Acc: 0.9905', 'Train LL: -0.0239114594004612', 'Test LL: -0.028555487655260215', 'Epoch Time (s): 162.75357108283788')
('Epoch 63', 'Objective: -0.051890802655422556', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9915', 'Train LL: -0.023385241903724006', 'Test LL: -0.0255794090427772', 'Epoch Time (s): 162.74822890898213')
('Epoch 64', 'Objective: -0.051995132397405545', 'Train Acc: 0.99235', 'Test Acc: 0.991', 'Train LL: -0.023635220435123862', 'Test LL: -0.028171884135856105', 'Epoch Time (s): 162.74584500002675')
('Epoch 65', 'Objective: -0.05204627423072854', 'Train Acc: 0.9925', 'Test Acc: 0.9914', 'Train LL: -0.023620740146830552', 'Test LL: -0.027327951476282572', 'Epoch Time (s): 162.73253683187068')
('Epoch 66', 'Objective: -0.05156022278445623', 'Train Acc: 0.9926', 'Test Acc: 0.9919', 'Train LL: -0.023253742291888438', 'Test LL: -0.02617268983612441', 'Epoch Time (s): 162.75504829199053')
('Epoch 67', 'Objective: -0.051468753695216925', 'Train Acc: 0.9927', 'Test Acc: 0.9917', 'Train LL: -0.023215173801372044', 'Test LL: -0.027305495170212225', 'Epoch Time (s): 162.727863232838')
('Epoch 68', 'Objective: -0.050841941328904926', 'Train Acc: 0.99275', 'Test Acc: 0.9913', 'Train LL: -0.02269682661073066', 'Test LL: -0.025941194733393576', 'Epoch Time (s): 162.72154635516927')
('Epoch 69', 'Objective: -0.05097941651425454', 'Train Acc: 0.9930333333333333', 'Test Acc: 0.9916', 'Train LL: -0.02300883570078873', 'Test LL: -0.02583411083480996', 'Epoch Time (s): 162.72014490817674')
('Epoch 70', 'Objective: -0.05132074619943722', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9906', 'Train LL: -0.023432048646116376', 'Test LL: -0.02697640254725102', 'Epoch Time (s): 162.72726692911237')
('Epoch 71', 'Objective: -0.05069152098013939', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9904', 'Train LL: -0.022828003186013843', 'Test LL: -0.028060375791112552', 'Epoch Time (s): 162.72268577292562')
('Epoch 72', 'Objective: -0.051024697445856436', 'Train Acc: 0.9927333333333334', 'Test Acc: 0.9904', 'Train LL: -0.023078566124810997', 'Test LL: -0.02753610139655657', 'Epoch Time (s): 162.718581689056')
('Epoch 73', 'Objective: -0.05094602882393908', 'Train Acc: 0.9928333333333333', 'Test Acc: 0.9896', 'Train LL: -0.022998294920996917', 'Test LL: -0.030906688294221135', 'Epoch Time (s): 162.72731260210276')
('Epoch 74', 'Objective: -0.050802856924153296', 'Train Acc: 0.9926', 'Test Acc: 0.992', 'Train LL: -0.0229669953781371', 'Test LL: -0.024590728284929957', 'Epoch Time (s): 162.73496815701947')
('Epoch 75', 'Objective: -0.05017035360120134', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9891', 'Train LL: -0.022380530010120272', 'Test LL: -0.030752459247195538', 'Epoch Time (s): 162.72111194208264')
('Epoch 76', 'Objective: -0.05025910443339385', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9909', 'Train LL: -0.022578925401322912', 'Test LL: -0.0273262794521591', 'Epoch Time (s): 162.74765526503325')
('Epoch 77', 'Objective: -0.05087572286333381', 'Train Acc: 0.9926166666666667', 'Test Acc: 0.9911', 'Train LL: -0.023120850209825742', 'Test LL: -0.027712361783564735', 'Epoch Time (s): 162.74024098785594')
('Epoch 78', 'Objective: -0.050216528747194095', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9918', 'Train LL: -0.022643045072045627', 'Test LL: -0.025827927307336438', 'Epoch Time (s): 162.72847960982472')
('Epoch 79', 'Objective: -0.04920480648184025', 'Train Acc: 0.99315', 'Test Acc: 0.99', 'Train LL: -0.02167142820743438', 'Test LL: -0.03041211089676194', 'Epoch Time (s): 162.7387443529442')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.0479881232609109', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.991', 'Train LL: -0.020738319251546764', 'Test LL: -0.02662271279480699', 'Epoch Time (s): 162.7216558419168')
('Epoch 81', 'Objective: -0.046592188501053115', 'Train Acc: 0.9936833333333334', 'Test Acc: 0.9913', 'Train LL: -0.01952039550764926', 'Test LL: -0.02599110112783972', 'Epoch Time (s): 162.75539567088708')
('Epoch 82', 'Objective: -0.04629554412132578', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.9913', 'Train LL: -0.019216639164270653', 'Test LL: -0.027009501929686316', 'Epoch Time (s): 162.72212841105647')
('Epoch 83', 'Objective: -0.04655438852438847', 'Train Acc: 0.9939833333333333', 'Test Acc: 0.991', 'Train LL: -0.019356097055044767', 'Test LL: -0.026885155420817534', 'Epoch Time (s): 162.76375417294912')
('Epoch 84', 'Objective: -0.046424662899994626', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.991', 'Train LL: -0.01930938781731843', 'Test LL: -0.026756814304596907', 'Epoch Time (s): 162.81790881208144')
('Epoch 85', 'Objective: -0.04571798355453072', 'Train Acc: 0.9943333333333333', 'Test Acc: 0.9915', 'Train LL: -0.018708169762664283', 'Test LL: -0.02598915463198125', 'Epoch Time (s): 162.8058746617753')
('Epoch 86', 'Objective: -0.04614835797952907', 'Train Acc: 0.9941666666666666', 'Test Acc: 0.9912', 'Train LL: -0.01905074583952239', 'Test LL: -0.026633074737653813', 'Epoch Time (s): 162.76441543200053')
('Epoch 87', 'Objective: -0.04563985798506713', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9911', 'Train LL: -0.018583707592084258', 'Test LL: -0.02600937097503601', 'Epoch Time (s): 162.82257784507237')
('Epoch 88', 'Objective: -0.04567505556989942', 'Train Acc: 0.9942333333333333', 'Test Acc: 0.9909', 'Train LL: -0.01860752724819449', 'Test LL: -0.027144328004100323', 'Epoch Time (s): 162.76637834100984')
('Epoch 89', 'Objective: -0.045363192937844854', 'Train Acc: 0.9944666666666667', 'Test Acc: 0.9908', 'Train LL: -0.018420346792098682', 'Test LL: -0.026587879708298984', 'Epoch Time (s): 162.77248906879686')
('Epoch 90', 'Objective: -0.04621734027190637', 'Train Acc: 0.9941', 'Test Acc: 0.9912', 'Train LL: -0.019121805286192624', 'Test LL: -0.02654393895314178', 'Epoch Time (s): 163.09051909088157')
('Epoch 91', 'Objective: -0.04632142792803369', 'Train Acc: 0.994', 'Test Acc: 0.9913', 'Train LL: -0.019214339200533913', 'Test LL: -0.026357007325036545', 'Epoch Time (s): 163.1686713451054')
('Epoch 92', 'Objective: -0.04580264574924082', 'Train Acc: 0.9940833333333333', 'Test Acc: 0.9911', 'Train LL: -0.018755395595297143', 'Test LL: -0.026936606584947936', 'Epoch Time (s): 162.8196153419558')
('Epoch 93', 'Objective: -0.04497513048020246', 'Train Acc: 0.9942666666666666', 'Test Acc: 0.9912', 'Train LL: -0.017938708763701572', 'Test LL: -0.02649128185821802', 'Epoch Time (s): 162.85245418199338')
('Epoch 94', 'Objective: -0.04611704703187062', 'Train Acc: 0.9941', 'Test Acc: 0.9913', 'Train LL: -0.01903573896217637', 'Test LL: -0.025988284752087226', 'Epoch Time (s): 162.84820632613264')
('Epoch 95', 'Objective: -0.04579844165304488', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9915', 'Train LL: -0.01880455198504576', 'Test LL: -0.025595635541305572', 'Epoch Time (s): 162.8266275001224')
('Epoch 96', 'Objective: -0.04593470092506764', 'Train Acc: 0.9941833333333333', 'Test Acc: 0.9914', 'Train LL: -0.018947917231090284', 'Test LL: -0.02587872405234796', 'Epoch Time (s): 162.81532016396523')
('Epoch 97', 'Objective: -0.04515501016929293', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9911', 'Train LL: -0.01817773149763132', 'Test LL: -0.026589953505994583', 'Epoch Time (s): 162.8398386761546')
('Epoch 98', 'Objective: -0.04550977995946027', 'Train Acc: 0.9940666666666667', 'Test Acc: 0.9914', 'Train LL: -0.01849895641129656', 'Test LL: -0.025889062737285178', 'Epoch Time (s): 162.8359395971056')
('Epoch 99', 'Objective: -0.04546422349881738', 'Train Acc: 0.9941166666666666', 'Test Acc: 0.9916', 'Train LL: -0.01848974426789767', 'Test LL: -0.025717004654434873', 'Epoch Time (s): 162.84635384008288')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.04511806768312243
Final Train Accuracy: £0.9943
Final Train LL: £-0.01816892644945728
Final Test Accuracy: £0.9916
Final Test LL: £-0.025712032982279493
