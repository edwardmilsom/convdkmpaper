dataset: MNIST
dtype: float64
dof: 10.0
init_lr: 0.01
seed: 3
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.4314625775502372', 'Train Acc: 0.51805', 'Test Acc: 0.724', 'Train LL: -1.3324431297266952', 'Test LL: -0.8184624777446284', 'Epoch Time (s): 171.7929772110656')
('Epoch 1', 'Objective: -0.7569064073792168', 'Train Acc: 0.7826333333333333', 'Test Acc: 0.8198', 'Train LL: -0.6434995639767871', 'Test LL: -0.5551305318522701', 'Epoch Time (s): 170.82545613404363')
('Epoch 2', 'Objective: -0.4967664017620852', 'Train Acc: 0.8785833333333334', 'Test Acc: 0.9007', 'Train LL: -0.3829861569832622', 'Test LL: -0.31126015087377035', 'Epoch Time (s): 170.78403145587072')
('Epoch 3', 'Objective: -0.3983412859878645', 'Train Acc: 0.91025', 'Test Acc: 0.9358', 'Train LL: -0.287284845349581', 'Test LL: -0.2080824991924181', 'Epoch Time (s): 170.79061764571816')
('Epoch 4', 'Objective: -0.35130517099063363', 'Train Acc: 0.9258', 'Test Acc: 0.9354', 'Train LL: -0.24365575557725722', 'Test LL: -0.20605665853027577', 'Epoch Time (s): 170.81819769041613')
('Epoch 5', 'Objective: -0.30921267145769993', 'Train Acc: 0.9363166666666667', 'Test Acc: 0.8888', 'Train LL: -0.20416050377575262', 'Test LL: -0.34831332204181764', 'Epoch Time (s): 170.80196032999083')
('Epoch 6', 'Objective: -0.2864903867340053', 'Train Acc: 0.9429166666666666', 'Test Acc: 0.9359', 'Train LL: -0.1854478160843752', 'Test LL: -0.19983584642875069', 'Epoch Time (s): 170.77564225206152')
('Epoch 7', 'Objective: -0.271943993293145', 'Train Acc: 0.9457333333333333', 'Test Acc: 0.9563', 'Train LL: -0.17455360558762512', 'Test LL: -0.14123585168799271', 'Epoch Time (s): 170.77151502436027')
('Epoch 8', 'Objective: -0.25887559573196783', 'Train Acc: 0.94915', 'Test Acc: 0.9378', 'Train LL: -0.16358499492125117', 'Test LL: -0.1971587968159752', 'Epoch Time (s): 170.77807340305299')
('Epoch 9', 'Objective: -0.24912072219181403', 'Train Acc: 0.95145', 'Test Acc: 0.9617', 'Train LL: -0.1569715284300299', 'Test LL: -0.11960789678388853', 'Epoch Time (s): 170.76391694229096')
('Epoch 10', 'Objective: -0.23756318464129708', 'Train Acc: 0.9540666666666666', 'Test Acc: 0.9476', 'Train LL: -0.14702631580745132', 'Test LL: -0.16103885281552757', 'Epoch Time (s): 170.7661031940952')
('Epoch 11', 'Objective: -0.2302468218502241', 'Train Acc: 0.95595', 'Test Acc: 0.957', 'Train LL: -0.14171848452221675', 'Test LL: -0.1398120534706098', 'Epoch Time (s): 170.7606740477495')
('Epoch 12', 'Objective: -0.22207041957772744', 'Train Acc: 0.9588666666666666', 'Test Acc: 0.9533', 'Train LL: -0.13507293991827923', 'Test LL: -0.13827363522917635', 'Epoch Time (s): 170.76679033506662')
('Epoch 13', 'Objective: -0.21714012283860823', 'Train Acc: 0.9596', 'Test Acc: 0.9628', 'Train LL: -0.13092999220153279', 'Test LL: -0.11954432377208686', 'Epoch Time (s): 170.82984710577875')
('Epoch 14', 'Objective: -0.21048143268882966', 'Train Acc: 0.9607', 'Test Acc: 0.9658', 'Train LL: -0.12581187046198697', 'Test LL: -0.10468620005221771', 'Epoch Time (s): 170.7896344247274')
('Epoch 15', 'Objective: -0.20838542772879154', 'Train Acc: 0.96135', 'Test Acc: 0.9662', 'Train LL: -0.12407946456641189', 'Test LL: -0.10896656982582176', 'Epoch Time (s): 170.7117600813508')
('Epoch 16', 'Objective: -0.20356679840971076', 'Train Acc: 0.9638', 'Test Acc: 0.9572', 'Train LL: -0.11989061304870328', 'Test LL: -0.13118009184040544', 'Epoch Time (s): 170.90046017011628')
('Epoch 17', 'Objective: -0.20071387029516619', 'Train Acc: 0.9634833333333334', 'Test Acc: 0.9663', 'Train LL: -0.11798047688864195', 'Test LL: -0.10597657087544075', 'Epoch Time (s): 170.76782884215936')
('Epoch 18', 'Objective: -0.19383905435531867', 'Train Acc: 0.9644166666666667', 'Test Acc: 0.9663', 'Train LL: -0.11209518973356261', 'Test LL: -0.10112144050965699', 'Epoch Time (s): 170.75435583572835')
('Epoch 19', 'Objective: -0.19246820302598744', 'Train Acc: 0.9658', 'Test Acc: 0.971', 'Train LL: -0.110833320741763', 'Test LL: -0.09315324925828593', 'Epoch Time (s): 170.73574898997322')
('Epoch 20', 'Objective: -0.1908061222966584', 'Train Acc: 0.9661166666666666', 'Test Acc: 0.9661', 'Train LL: -0.11010250766910328', 'Test LL: -0.10085606077454833', 'Epoch Time (s): 170.75769739691168')
('Epoch 21', 'Objective: -0.18519179637266933', 'Train Acc: 0.9672333333333333', 'Test Acc: 0.9679', 'Train LL: -0.10523528208590661', 'Test LL: -0.10322848020762303', 'Epoch Time (s): 170.73933434905484')
('Epoch 22', 'Objective: -0.18715070195635525', 'Train Acc: 0.9667', 'Test Acc: 0.9684', 'Train LL: -0.10722058230665886', 'Test LL: -0.0955126028830536', 'Epoch Time (s): 170.78130668168887')
('Epoch 23', 'Objective: -0.18128722153368093', 'Train Acc: 0.9678333333333333', 'Test Acc: 0.9673', 'Train LL: -0.10177442006342763', 'Test LL: -0.09984686235487465', 'Epoch Time (s): 170.71680085314438')
('Epoch 24', 'Objective: -0.17657717052189434', 'Train Acc: 0.9685333333333334', 'Test Acc: 0.9754', 'Train LL: -0.09829049184026596', 'Test LL: -0.07439011350422266', 'Epoch Time (s): 170.78659365698695')
('Epoch 25', 'Objective: -0.1755042347757524', 'Train Acc: 0.9690833333333333', 'Test Acc: 0.9766', 'Train LL: -0.09715776436057151', 'Test LL: -0.07300454011691598', 'Epoch Time (s): 170.75829081377015')
('Epoch 26', 'Objective: -0.17378424599388104', 'Train Acc: 0.9703166666666667', 'Test Acc: 0.9673', 'Train LL: -0.09550173042729557', 'Test LL: -0.10807070598737582', 'Epoch Time (s): 170.71720261778682')
('Epoch 27', 'Objective: -0.1710897408825793', 'Train Acc: 0.9710166666666666', 'Test Acc: 0.9704', 'Train LL: -0.09391352664196963', 'Test LL: -0.09246722739201711', 'Epoch Time (s): 170.703400562983')
('Epoch 28', 'Objective: -0.16748831452389804', 'Train Acc: 0.9709333333333333', 'Test Acc: 0.9755', 'Train LL: -0.09115806537399476', 'Test LL: -0.07804044137439202', 'Epoch Time (s): 170.73061442002654')
('Epoch 29', 'Objective: -0.1646423661390975', 'Train Acc: 0.9721', 'Test Acc: 0.9677', 'Train LL: -0.08885544983983112', 'Test LL: -0.10050901346896665', 'Epoch Time (s): 170.745265559759')
('Epoch 30', 'Objective: -0.1624537617799511', 'Train Acc: 0.9727166666666667', 'Test Acc: 0.9817', 'Train LL: -0.08715428270420195', 'Test LL: -0.06000976425335026', 'Epoch Time (s): 170.75512092607096')
('Epoch 31', 'Objective: -0.15801643298150003', 'Train Acc: 0.9740333333333333', 'Test Acc: 0.9781', 'Train LL: -0.08333744666854849', 'Test LL: -0.06767867254746848', 'Epoch Time (s): 170.78539277939126')
('Epoch 32', 'Objective: -0.1583634998632157', 'Train Acc: 0.97305', 'Test Acc: 0.9762', 'Train LL: -0.08429671054911586', 'Test LL: -0.0773170738361388', 'Epoch Time (s): 170.80570428958163')
('Epoch 33', 'Objective: -0.15729559424862666', 'Train Acc: 0.9735', 'Test Acc: 0.9732', 'Train LL: -0.08409743576456181', 'Test LL: -0.08197190589362122', 'Epoch Time (s): 170.7714012800716')
('Epoch 34', 'Objective: -0.15468852783537015', 'Train Acc: 0.9740666666666666', 'Test Acc: 0.9744', 'Train LL: -0.08185285481870777', 'Test LL: -0.07939677249573981', 'Epoch Time (s): 170.76374599616975')
('Epoch 35', 'Objective: -0.15094290674101457', 'Train Acc: 0.97545', 'Test Acc: 0.978', 'Train LL: -0.07841378223382574', 'Test LL: -0.06639901007516717', 'Epoch Time (s): 170.74379212828353')
('Epoch 36', 'Objective: -0.15050857280230776', 'Train Acc: 0.9752833333333333', 'Test Acc: 0.9784', 'Train LL: -0.07899539316109642', 'Test LL: -0.06845206541335531', 'Epoch Time (s): 170.73943982599303')
('Epoch 37', 'Objective: -0.14754196016518356', 'Train Acc: 0.9757166666666667', 'Test Acc: 0.9788', 'Train LL: -0.07651959508901131', 'Test LL: -0.06720521853037004', 'Epoch Time (s): 170.77679301099852')
('Epoch 38', 'Objective: -0.14745416230654693', 'Train Acc: 0.9759833333333333', 'Test Acc: 0.9805', 'Train LL: -0.07687104094435769', 'Test LL: -0.06238333742117417', 'Epoch Time (s): 170.7805393440649')
('Epoch 39', 'Objective: -0.14572880454176781', 'Train Acc: 0.9758333333333333', 'Test Acc: 0.9743', 'Train LL: -0.07554694766611829', 'Test LL: -0.07956381438864153', 'Epoch Time (s): 170.76960552716628')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.11722044223571879', 'Train Acc: 0.9837333333333333', 'Test Acc: 0.9851', 'Train LL: -0.05161337669065486', 'Test LL: -0.04299438532807104', 'Epoch Time (s): 170.8044832679443')
('Epoch 41', 'Objective: -0.10908311202065746', 'Train Acc: 0.9854166666666667', 'Test Acc: 0.9852', 'Train LL: -0.04630073559039212', 'Test LL: -0.04534431215513586', 'Epoch Time (s): 170.82285799784586')
('Epoch 42', 'Objective: -0.10800743479128558', 'Train Acc: 0.9852833333333333', 'Test Acc: 0.9849', 'Train LL: -0.04629116870319123', 'Test LL: -0.04197284628713469', 'Epoch Time (s): 170.77718918211758')
('Epoch 43', 'Objective: -0.10649496962208345', 'Train Acc: 0.9857333333333334', 'Test Acc: 0.985', 'Train LL: -0.04544181388441161', 'Test LL: -0.04507599213696827', 'Epoch Time (s): 170.78189571015537')
('Epoch 44', 'Objective: -0.10519684589901188', 'Train Acc: 0.9856166666666667', 'Test Acc: 0.9876', 'Train LL: -0.04484878622038676', 'Test LL: -0.03852056628397679', 'Epoch Time (s): 170.7816141997464')
('Epoch 45', 'Objective: -0.1051903546890898', 'Train Acc: 0.98595', 'Test Acc: 0.986', 'Train LL: -0.045438004951931316', 'Test LL: -0.04185365529067044', 'Epoch Time (s): 170.77788862027228')
('Epoch 46', 'Objective: -0.10355687146934381', 'Train Acc: 0.98555', 'Test Acc: 0.9854', 'Train LL: -0.0441051057344421', 'Test LL: -0.04503584514387498', 'Epoch Time (s): 170.74426070787013')
('Epoch 47', 'Objective: -0.10233649293097355', 'Train Acc: 0.9860666666666666', 'Test Acc: 0.9866', 'Train LL: -0.04332012722278684', 'Test LL: -0.04044227150114707', 'Epoch Time (s): 170.76195413712412')
('Epoch 48', 'Objective: -0.10249189174383842', 'Train Acc: 0.9859666666666667', 'Test Acc: 0.9857', 'Train LL: -0.04374199519351305', 'Test LL: -0.04360483647700037', 'Epoch Time (s): 170.79730329615995')
('Epoch 49', 'Objective: -0.10193196311551266', 'Train Acc: 0.9858833333333333', 'Test Acc: 0.9848', 'Train LL: -0.04363483106034179', 'Test LL: -0.044943487909550155', 'Epoch Time (s): 170.79035493498668')
('Epoch 50', 'Objective: -0.10158437564794262', 'Train Acc: 0.9864', 'Test Acc: 0.987', 'Train LL: -0.04375895142098754', 'Test LL: -0.03864130710890525', 'Epoch Time (s): 170.81846795976162')
('Epoch 51', 'Objective: -0.10094860560718617', 'Train Acc: 0.9862', 'Test Acc: 0.9866', 'Train LL: -0.04336614525631647', 'Test LL: -0.04055198371149954', 'Epoch Time (s): 170.85130000300705')
('Epoch 52', 'Objective: -0.10131516075093217', 'Train Acc: 0.9857666666666667', 'Test Acc: 0.9868', 'Train LL: -0.04381411704091652', 'Test LL: -0.039688416060339855', 'Epoch Time (s): 170.81100701913238')
('Epoch 53', 'Objective: -0.10094704217100967', 'Train Acc: 0.9859333333333333', 'Test Acc: 0.9871', 'Train LL: -0.04389379867037921', 'Test LL: -0.040192621828657175', 'Epoch Time (s): 170.7574344240129')
('Epoch 54', 'Objective: -0.09999258010175925', 'Train Acc: 0.9861166666666666', 'Test Acc: 0.9857', 'Train LL: -0.04329910160293466', 'Test LL: -0.04384910385350867', 'Epoch Time (s): 170.81299938401207')
('Epoch 55', 'Objective: -0.09894515563203973', 'Train Acc: 0.9865166666666667', 'Test Acc: 0.9856', 'Train LL: -0.042485839325222846', 'Test LL: -0.04451674920804227', 'Epoch Time (s): 170.77313681086525')
('Epoch 56', 'Objective: -0.09968064285247549', 'Train Acc: 0.9862166666666666', 'Test Acc: 0.9839', 'Train LL: -0.043271402711464416', 'Test LL: -0.04665815560894355', 'Epoch Time (s): 170.76981763215736')
('Epoch 57', 'Objective: -0.09976183009811614', 'Train Acc: 0.9863', 'Test Acc: 0.9871', 'Train LL: -0.043642494021512726', 'Test LL: -0.03848845543329669', 'Epoch Time (s): 170.7715989239514')
('Epoch 58', 'Objective: -0.09880649223645775', 'Train Acc: 0.9861166666666666', 'Test Acc: 0.9864', 'Train LL: -0.042868835999345246', 'Test LL: -0.040538494440955024', 'Epoch Time (s): 170.74695760430768')
('Epoch 59', 'Objective: -0.09913446023623908', 'Train Acc: 0.98595', 'Test Acc: 0.9868', 'Train LL: -0.04333251168898076', 'Test LL: -0.04006848081151488', 'Epoch Time (s): 170.75901094218716')
('Epoch 60', 'Objective: -0.09846603817107039', 'Train Acc: 0.9860666666666666', 'Test Acc: 0.9852', 'Train LL: -0.042887408362697214', 'Test LL: -0.04282202885697557', 'Epoch Time (s): 170.7088524461724')
('Epoch 61', 'Objective: -0.09790864040259385', 'Train Acc: 0.9863333333333333', 'Test Acc: 0.9866', 'Train LL: -0.04261111207075929', 'Test LL: -0.04019244784869319', 'Epoch Time (s): 170.7928994349204')
('Epoch 62', 'Objective: -0.09821956453646472', 'Train Acc: 0.9860333333333333', 'Test Acc: 0.986', 'Train LL: -0.043087033686519796', 'Test LL: -0.04241506620701251', 'Epoch Time (s): 170.7804235238582')
('Epoch 63', 'Objective: -0.09781196609938089', 'Train Acc: 0.9856833333333334', 'Test Acc: 0.9863', 'Train LL: -0.04262421754393884', 'Test LL: -0.04103850391725341', 'Epoch Time (s): 170.74705736897886')
('Epoch 64', 'Objective: -0.09639341203803188', 'Train Acc: 0.9865166666666667', 'Test Acc: 0.9866', 'Train LL: -0.04153994709038128', 'Test LL: -0.043966519675755544', 'Epoch Time (s): 170.73964244080707')
('Epoch 65', 'Objective: -0.09787870569004252', 'Train Acc: 0.98565', 'Test Acc: 0.9852', 'Train LL: -0.043017294202254766', 'Test LL: -0.0424539952678899', 'Epoch Time (s): 170.74814984202385')
('Epoch 66', 'Objective: -0.09643319034315194', 'Train Acc: 0.98605', 'Test Acc: 0.9885', 'Train LL: -0.041699768441906954', 'Test LL: -0.03812572991280764', 'Epoch Time (s): 170.77687298506498')
('Epoch 67', 'Objective: -0.09702449587522236', 'Train Acc: 0.98585', 'Test Acc: 0.9873', 'Train LL: -0.04244089788356453', 'Test LL: -0.03921504963389628', 'Epoch Time (s): 170.67895888909698')
('Epoch 68', 'Objective: -0.09597177913124672', 'Train Acc: 0.9867', 'Test Acc: 0.986', 'Train LL: -0.04181859488740894', 'Test LL: -0.04217849942354295', 'Epoch Time (s): 170.73783901706338')
('Epoch 69', 'Objective: -0.0964996930163193', 'Train Acc: 0.98595', 'Test Acc: 0.9877', 'Train LL: -0.04226474486892489', 'Test LL: -0.037511622347173715', 'Epoch Time (s): 170.70564490603283')
('Epoch 70', 'Objective: -0.09594733972563739', 'Train Acc: 0.9860833333333333', 'Test Acc: 0.9875', 'Train LL: -0.04188840928601487', 'Test LL: -0.03888348662139431', 'Epoch Time (s): 170.6882468611002')
('Epoch 71', 'Objective: -0.09563453176602742', 'Train Acc: 0.9865333333333334', 'Test Acc: 0.9864', 'Train LL: -0.041849413057829625', 'Test LL: -0.04095283402619617', 'Epoch Time (s): 170.67545739095658')
('Epoch 72', 'Objective: -0.09675154331632035', 'Train Acc: 0.9859833333333333', 'Test Acc: 0.9872', 'Train LL: -0.043022755192730584', 'Test LL: -0.03922778560341951', 'Epoch Time (s): 170.61511107394472')
('Epoch 73', 'Objective: -0.09594211883151234', 'Train Acc: 0.9865333333333334', 'Test Acc: 0.9863', 'Train LL: -0.04221037844069053', 'Test LL: -0.041535129803792856', 'Epoch Time (s): 170.60309430537745')
('Epoch 74', 'Objective: -0.09537269160881243', 'Train Acc: 0.9862', 'Test Acc: 0.9883', 'Train LL: -0.04187283750441848', 'Test LL: -0.03578936785825547', 'Epoch Time (s): 170.62577772932127')
('Epoch 75', 'Objective: -0.09564590680231089', 'Train Acc: 0.9865833333333334', 'Test Acc: 0.9858', 'Train LL: -0.04207176183398426', 'Test LL: -0.041847143973486475', 'Epoch Time (s): 170.61739015113562')
('Epoch 76', 'Objective: -0.0952658415820325', 'Train Acc: 0.98645', 'Test Acc: 0.9861', 'Train LL: -0.04197157757065854', 'Test LL: -0.039838278000917854', 'Epoch Time (s): 170.60149633372203')
('Epoch 77', 'Objective: -0.09640537566411013', 'Train Acc: 0.9859333333333333', 'Test Acc: 0.9865', 'Train LL: -0.0430013477268325', 'Test LL: -0.0419468798895803', 'Epoch Time (s): 170.59981616586447')
('Epoch 78', 'Objective: -0.09450342296626654', 'Train Acc: 0.9865666666666667', 'Test Acc: 0.9876', 'Train LL: -0.0414517018494071', 'Test LL: -0.03747612157271398', 'Epoch Time (s): 170.70471324725077')
('Epoch 79', 'Objective: -0.09452856501298515', 'Train Acc: 0.9864', 'Test Acc: 0.9868', 'Train LL: -0.04149950181640923', 'Test LL: -0.040098974403539114', 'Epoch Time (s): 170.6118589839898')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.09167289857062064', 'Train Acc: 0.9878166666666667', 'Test Acc: 0.9886', 'Train LL: -0.039227747620613776', 'Test LL: -0.03756119797240753', 'Epoch Time (s): 170.63101270468906')
('Epoch 81', 'Objective: -0.08992661056649291', 'Train Acc: 0.9879666666666667', 'Test Acc: 0.9885', 'Train LL: -0.03764925972861808', 'Test LL: -0.037213376805350126', 'Epoch Time (s): 170.6558302422054')
('Epoch 82', 'Objective: -0.08979492179602659', 'Train Acc: 0.9878833333333333', 'Test Acc: 0.9876', 'Train LL: -0.0375334567853693', 'Test LL: -0.03905907810082028', 'Epoch Time (s): 170.58735104696825')
('Epoch 83', 'Objective: -0.08893719841766365', 'Train Acc: 0.9880333333333333', 'Test Acc: 0.9872', 'Train LL: -0.03675409743827499', 'Test LL: -0.039055220524182935', 'Epoch Time (s): 170.62242154125124')
('Epoch 84', 'Objective: -0.08967876085031708', 'Train Acc: 0.9881', 'Test Acc: 0.9875', 'Train LL: -0.03754990323143965', 'Test LL: -0.038224334356310445', 'Epoch Time (s): 170.61930850008503')
('Epoch 85', 'Objective: -0.0886913490593858', 'Train Acc: 0.9876333333333334', 'Test Acc: 0.9878', 'Train LL: -0.036565578100104024', 'Test LL: -0.03787084974656535', 'Epoch Time (s): 170.62552303168923')
('Epoch 86', 'Objective: -0.08960405232565236', 'Train Acc: 0.9879166666666667', 'Test Acc: 0.9873', 'Train LL: -0.03749324118333836', 'Test LL: -0.03876917098361571', 'Epoch Time (s): 170.59978803573176')
('Epoch 87', 'Objective: -0.08895375282031087', 'Train Acc: 0.9880666666666666', 'Test Acc: 0.9881', 'Train LL: -0.036900059533737185', 'Test LL: -0.037130389611424196', 'Epoch Time (s): 170.64113264903426')
('Epoch 88', 'Objective: -0.08897395776512665', 'Train Acc: 0.9879833333333333', 'Test Acc: 0.9875', 'Train LL: -0.036915064651739445', 'Test LL: -0.03775120149785775', 'Epoch Time (s): 170.63984536007047')
('Epoch 89', 'Objective: -0.08796390801457178', 'Train Acc: 0.9881', 'Test Acc: 0.9877', 'Train LL: -0.03599822794204029', 'Test LL: -0.03752119696222136', 'Epoch Time (s): 170.58452664408833')
('Epoch 90', 'Objective: -0.08948500944171348', 'Train Acc: 0.9876333333333334', 'Test Acc: 0.9871', 'Train LL: -0.037364670135324136', 'Test LL: -0.03815791962468129', 'Epoch Time (s): 170.58360258676112')
('Epoch 91', 'Objective: -0.08857896177746793', 'Train Acc: 0.9883166666666666', 'Test Acc: 0.9874', 'Train LL: -0.03663012360338425', 'Test LL: -0.03805112975511928', 'Epoch Time (s): 170.57654152205214')
('Epoch 92', 'Objective: -0.08872214469773443', 'Train Acc: 0.9882666666666666', 'Test Acc: 0.9873', 'Train LL: -0.0367504607566894', 'Test LL: -0.038373826522512866', 'Epoch Time (s): 170.61911955708638')
('Epoch 93', 'Objective: -0.08805477049354905', 'Train Acc: 0.9885', 'Test Acc: 0.9877', 'Train LL: -0.03612946270270349', 'Test LL: -0.0386133800203148', 'Epoch Time (s): 170.58592397719622')
('Epoch 94', 'Objective: -0.08889071101221395', 'Train Acc: 0.9880333333333333', 'Test Acc: 0.988', 'Train LL: -0.03697704520717719', 'Test LL: -0.03819794046146456', 'Epoch Time (s): 170.62047402188182')
('Epoch 95', 'Objective: -0.08848350209064122', 'Train Acc: 0.9881', 'Test Acc: 0.9884', 'Train LL: -0.03667046670720555', 'Test LL: -0.03703324260511473', 'Epoch Time (s): 170.61031130887568')
('Epoch 96', 'Objective: -0.08839904175509068', 'Train Acc: 0.9882833333333333', 'Test Acc: 0.9885', 'Train LL: -0.036520577918095966', 'Test LL: -0.03691813865691094', 'Epoch Time (s): 170.53794120019302')
('Epoch 97', 'Objective: -0.08837413430088815', 'Train Acc: 0.9882666666666666', 'Test Acc: 0.9877', 'Train LL: -0.036501992315343144', 'Test LL: -0.03818219310788708', 'Epoch Time (s): 170.57356812991202')
('Epoch 98', 'Objective: -0.08908793326878198', 'Train Acc: 0.98795', 'Test Acc: 0.9876', 'Train LL: -0.03719751347822233', 'Test LL: -0.03807838707643222', 'Epoch Time (s): 170.64267840282992')
('Epoch 99', 'Objective: -0.0884564947431045', 'Train Acc: 0.9882833333333333', 'Test Acc: 0.988', 'Train LL: -0.03659445745414505', 'Test LL: -0.037312048425729244', 'Epoch Time (s): 170.5555168800056')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.08828486782485659
Final Train Accuracy: £0.98825
Final Train LL: £-0.03642880149883687
Final Test Accuracy: £0.9879
Final Test LL: £-0.03723736249732164
