dataset: MNIST
dtype: float64
dof: 1000.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -2.1492200730067994', 'Train Acc: 0.24036666666666667', 'Test Acc: 0.2136', 'Train LL: -2.028616740885434', 'Test LL: -2.0148643673235207', 'Epoch Time (s): 164.43981207115576')
('Epoch 1', 'Objective: -1.8733430517672638', 'Train Acc: 0.3883666666666667', 'Test Acc: 0.6171', 'Train LL: -1.6951283172732674', 'Test LL: -1.2245584947306833', 'Epoch Time (s): 164.5047438950278')
('Epoch 2', 'Objective: -1.4361901045162215', 'Train Acc: 0.62845', 'Test Acc: 0.6201', 'Train LL: -1.0789753396491242', 'Test LL: -1.1138304450439676', 'Epoch Time (s): 164.470348485047')
('Epoch 3', 'Objective: -1.222365543469487', 'Train Acc: 0.71895', 'Test Acc: 0.7779', 'Train LL: -0.8457871879414777', 'Test LL: -0.6985392296625842', 'Epoch Time (s): 164.45099618495442')
('Epoch 4', 'Objective: -1.101124900936943', 'Train Acc: 0.7605166666666666', 'Test Acc: 0.8024', 'Train LL: -0.7275648064062697', 'Test LL: -0.6062272042245263', 'Epoch Time (s): 164.3575143229682')
('Epoch 5', 'Objective: -1.0446766913910177', 'Train Acc: 0.7771', 'Test Acc: 0.7953', 'Train LL: -0.6763242844928424', 'Test LL: -0.6237467066015308', 'Epoch Time (s): 164.29696255386807')
('Epoch 6', 'Objective: -0.9945041682080171', 'Train Acc: 0.7940666666666667', 'Test Acc: 0.7922', 'Train LL: -0.6272105881068335', 'Test LL: -0.6455491803831857', 'Epoch Time (s): 164.2993553909473')
('Epoch 7', 'Objective: -0.9637969084109984', 'Train Acc: 0.80455', 'Test Acc: 0.8034', 'Train LL: -0.5978409332204183', 'Test LL: -0.5914703541997', 'Epoch Time (s): 164.32308314787224')
('Epoch 8', 'Objective: -0.9310273320317005', 'Train Acc: 0.8180333333333333', 'Test Acc: 0.8135', 'Train LL: -0.5655642258781035', 'Test LL: -0.5716654457103476', 'Epoch Time (s): 164.29295516083948')
('Epoch 9', 'Objective: -0.9095770199553962', 'Train Acc: 0.8248', 'Test Acc: 0.8526', 'Train LL: -0.5466255170058054', 'Test LL: -0.4724930307973389', 'Epoch Time (s): 164.28977894200943')
('Epoch 10', 'Objective: -0.8868749283501911', 'Train Acc: 0.83355', 'Test Acc: 0.8336', 'Train LL: -0.5245752924219277', 'Test LL: -0.5216724653308044', 'Epoch Time (s): 164.29050612496212')
('Epoch 11', 'Objective: -0.8647464530513', 'Train Acc: 0.8390833333333333', 'Test Acc: 0.8546', 'Train LL: -0.5090150443896599', 'Test LL: -0.46514488590274594', 'Epoch Time (s): 164.32821157597937')
('Epoch 12', 'Objective: -0.8373154834787337', 'Train Acc: 0.8451166666666666', 'Test Acc: 0.8368', 'Train LL: -0.48827601172601354', 'Test LL: -0.4961762322420913', 'Epoch Time (s): 164.43305747397244')
('Epoch 13', 'Objective: -0.8152070803290772', 'Train Acc: 0.8517333333333333', 'Test Acc: 0.8173', 'Train LL: -0.4699066305823811', 'Test LL: -0.5580173468373726', 'Epoch Time (s): 164.0205563569907')
('Epoch 14', 'Objective: -0.8012068559893399', 'Train Acc: 0.8588666666666667', 'Test Acc: 0.8744', 'Train LL: -0.45696436359942466', 'Test LL: -0.4085426753451169', 'Epoch Time (s): 164.06485373689793')
('Epoch 15', 'Objective: -0.7831255038285233', 'Train Acc: 0.8645', 'Test Acc: 0.8728', 'Train LL: -0.4385486336198559', 'Test LL: -0.396997928367246', 'Epoch Time (s): 164.01633140514605')
('Epoch 16', 'Objective: -0.7703815384456363', 'Train Acc: 0.8691833333333333', 'Test Acc: 0.8628', 'Train LL: -0.4241392931475435', 'Test LL: -0.42578716473894673', 'Epoch Time (s): 163.89006552100182')
('Epoch 17', 'Objective: -0.7604193817756032', 'Train Acc: 0.8731333333333333', 'Test Acc: 0.8819', 'Train LL: -0.4148595306081162', 'Test LL: -0.37733139208730443', 'Epoch Time (s): 164.04959943704307')
('Epoch 18', 'Objective: -0.7479762112961154', 'Train Acc: 0.87605', 'Test Acc: 0.8842', 'Train LL: -0.40276936195549473', 'Test LL: -0.38037646304020417', 'Epoch Time (s): 164.037827960914')
('Epoch 19', 'Objective: -0.7401433963113276', 'Train Acc: 0.8816', 'Test Acc: 0.8736', 'Train LL: -0.39413671252462407', 'Test LL: -0.39330533717322613', 'Epoch Time (s): 164.02756050298922')
('Epoch 20', 'Objective: -0.7374177876443978', 'Train Acc: 0.8838166666666667', 'Test Acc: 0.8856', 'Train LL: -0.3891843688228665', 'Test LL: -0.3514951190711362', 'Epoch Time (s): 164.01329841697589')
('Epoch 21', 'Objective: -0.7302185422600703', 'Train Acc: 0.8856833333333334', 'Test Acc: 0.8948', 'Train LL: -0.381075612214974', 'Test LL: -0.33633137292421617', 'Epoch Time (s): 163.99616985511966')
('Epoch 22', 'Objective: -0.7244419154200421', 'Train Acc: 0.8884', 'Test Acc: 0.8783', 'Train LL: -0.37352840944096255', 'Test LL: -0.3882051275819734', 'Epoch Time (s): 163.9952176772058')
('Epoch 23', 'Objective: -0.7211418074345276', 'Train Acc: 0.8890333333333333', 'Test Acc: 0.9015', 'Train LL: -0.3712921478856183', 'Test LL: -0.3194251054653694', 'Epoch Time (s): 163.99998934194446')
('Epoch 24', 'Objective: -0.7158935284881064', 'Train Acc: 0.8921', 'Test Acc: 0.8961', 'Train LL: -0.3658006538707543', 'Test LL: -0.34631330399079324', 'Epoch Time (s): 163.97632454894483')
('Epoch 25', 'Objective: -0.7084136874798858', 'Train Acc: 0.8936666666666667', 'Test Acc: 0.8738', 'Train LL: -0.3573074567454809', 'Test LL: -0.39164553111570194', 'Epoch Time (s): 163.98687380505726')
('Epoch 26', 'Objective: -0.7034451135715626', 'Train Acc: 0.8952333333333333', 'Test Acc: 0.9022', 'Train LL: -0.3525520779891502', 'Test LL: -0.3184282633777697', 'Epoch Time (s): 163.98695818288252')
('Epoch 27', 'Objective: -0.7006417719605079', 'Train Acc: 0.8972833333333333', 'Test Acc: 0.8986', 'Train LL: -0.34938429613100075', 'Test LL: -0.3202613897153331', 'Epoch Time (s): 164.01453934889287')
('Epoch 28', 'Objective: -0.6983294929260501', 'Train Acc: 0.8972333333333333', 'Test Acc: 0.885', 'Train LL: -0.34637195755359873', 'Test LL: -0.35417566523359256', 'Epoch Time (s): 164.11654662480578')
('Epoch 29', 'Objective: -0.697908139091598', 'Train Acc: 0.8971', 'Test Acc: 0.9075', 'Train LL: -0.34779498795086533', 'Test LL: -0.2964214378325942', 'Epoch Time (s): 163.99657167098485')
('Epoch 30', 'Objective: -0.6924180264082973', 'Train Acc: 0.8995166666666666', 'Test Acc: 0.8785', 'Train LL: -0.3417323902910067', 'Test LL: -0.3861350907814358', 'Epoch Time (s): 163.98582574515603')
('Epoch 31', 'Objective: -0.6901834722180942', 'Train Acc: 0.9009833333333334', 'Test Acc: 0.9067', 'Train LL: -0.33964719386789505', 'Test LL: -0.2990435285043266', 'Epoch Time (s): 163.98953128186986')
('Epoch 32', 'Objective: -0.6865848189642437', 'Train Acc: 0.9020333333333334', 'Test Acc: 0.8914', 'Train LL: -0.33566191303927895', 'Test LL: -0.35767649228204673', 'Epoch Time (s): 163.93998853093944')
('Epoch 33', 'Objective: -0.6839957679541283', 'Train Acc: 0.9020666666666667', 'Test Acc: 0.911', 'Train LL: -0.33278130361332947', 'Test LL: -0.30303864310494666', 'Epoch Time (s): 163.94878277904354')
('Epoch 34', 'Objective: -0.6821907293106643', 'Train Acc: 0.90215', 'Test Acc: 0.8991', 'Train LL: -0.3323656650584865', 'Test LL: -0.32282233471118854', 'Epoch Time (s): 163.9613221399486')
('Epoch 35', 'Objective: -0.682264461328362', 'Train Acc: 0.90275', 'Test Acc: 0.905', 'Train LL: -0.33213823516676455', 'Test LL: -0.3064130048046048', 'Epoch Time (s): 163.93453796789981')
('Epoch 36', 'Objective: -0.6779808806335639', 'Train Acc: 0.9042', 'Test Acc: 0.9097', 'Train LL: -0.3281807652016593', 'Test LL: -0.2983018698700863', 'Epoch Time (s): 163.974309616955')
('Epoch 37', 'Objective: -0.6760531356537699', 'Train Acc: 0.9049', 'Test Acc: 0.9114', 'Train LL: -0.32646301886060913', 'Test LL: -0.2902550614179345', 'Epoch Time (s): 163.90113324392587')
('Epoch 38', 'Objective: -0.6742138556447189', 'Train Acc: 0.90425', 'Test Acc: 0.9081', 'Train LL: -0.3245817221653092', 'Test LL: -0.2920192483665439', 'Epoch Time (s): 163.85994685301557')
('Epoch 39', 'Objective: -0.6720852452641972', 'Train Acc: 0.9048333333333334', 'Test Acc: 0.9097', 'Train LL: -0.3223317978999438', 'Test LL: -0.2940684959510021', 'Epoch Time (s): 163.84424019721337')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.6130121404836164', 'Train Acc: 0.9181166666666667', 'Test Acc: 0.9252', 'Train LL: -0.29117232706153146', 'Test LL: -0.2549512918223502', 'Epoch Time (s): 163.8931129530538')
('Epoch 41', 'Objective: -0.5999594259172005', 'Train Acc: 0.9202833333333333', 'Test Acc: 0.9234', 'Train LL: -0.28012926166695434', 'Test LL: -0.2579074990717535', 'Epoch Time (s): 163.70001275092363')
('Epoch 42', 'Objective: -0.5983183728680129', 'Train Acc: 0.9205833333333333', 'Test Acc: 0.9245', 'Train LL: -0.2792019400727799', 'Test LL: -0.2568331330356475', 'Epoch Time (s): 163.90846573398449')
('Epoch 43', 'Objective: -0.5976263499673856', 'Train Acc: 0.9211166666666667', 'Test Acc: 0.922', 'Train LL: -0.2783403023827673', 'Test LL: -0.2595275550273037', 'Epoch Time (s): 164.00265716714785')
('Epoch 44', 'Objective: -0.5945375532623747', 'Train Acc: 0.9221833333333334', 'Test Acc: 0.9256', 'Train LL: -0.2750974368654599', 'Test LL: -0.2531217508829001', 'Epoch Time (s): 163.74061798094772')
('Epoch 45', 'Objective: -0.5950538199640482', 'Train Acc: 0.9226166666666666', 'Test Acc: 0.9259', 'Train LL: -0.2751286925949555', 'Test LL: -0.2531531092896676', 'Epoch Time (s): 163.91409244085662')
('Epoch 46', 'Objective: -0.5947659414621274', 'Train Acc: 0.9215333333333333', 'Test Acc: 0.9253', 'Train LL: -0.27508719839200996', 'Test LL: -0.2509070629527594', 'Epoch Time (s): 164.15485223405994')
('Epoch 47', 'Objective: -0.596537371400758', 'Train Acc: 0.9215333333333333', 'Test Acc: 0.9261', 'Train LL: -0.2763301780592854', 'Test LL: -0.24882379612996192', 'Epoch Time (s): 164.04961134609766')
('Epoch 48', 'Objective: -0.5955278266301923', 'Train Acc: 0.9231', 'Test Acc: 0.9262', 'Train LL: -0.27506381367237787', 'Test LL: -0.24953850612733913', 'Epoch Time (s): 163.96338541107252')
('Epoch 49', 'Objective: -0.5916861259903025', 'Train Acc: 0.9227', 'Test Acc: 0.9246', 'Train LL: -0.27117939162080484', 'Test LL: -0.25465982206164023', 'Epoch Time (s): 163.73231810401194')
('Epoch 50', 'Objective: -0.5949540054932633', 'Train Acc: 0.9215166666666667', 'Test Acc: 0.9253', 'Train LL: -0.2743729206420399', 'Test LL: -0.25152284703079036', 'Epoch Time (s): 163.49164130003192')
('Epoch 51', 'Objective: -0.5942947566316426', 'Train Acc: 0.9229166666666667', 'Test Acc: 0.9284', 'Train LL: -0.273622879766891', 'Test LL: -0.24840032985694738', 'Epoch Time (s): 164.06190399220213')
('Epoch 52', 'Objective: -0.5951216825570397', 'Train Acc: 0.9227333333333333', 'Test Acc: 0.9283', 'Train LL: -0.2745474785963457', 'Test LL: -0.2484131597340546', 'Epoch Time (s): 163.81901967106387')
('Epoch 53', 'Objective: -0.5932433663361416', 'Train Acc: 0.9237666666666666', 'Test Acc: 0.927', 'Train LL: -0.272794770358405', 'Test LL: -0.25021660577077576', 'Epoch Time (s): 164.32953131617978')
('Epoch 54', 'Objective: -0.5900645899347978', 'Train Acc: 0.92445', 'Test Acc: 0.9265', 'Train LL: -0.2691226865013982', 'Test LL: -0.2533220897301036', 'Epoch Time (s): 164.73910227185115')
('Epoch 55', 'Objective: -0.5919506118695822', 'Train Acc: 0.9234333333333333', 'Test Acc: 0.9256', 'Train LL: -0.2715322360519912', 'Test LL: -0.25211645285533496', 'Epoch Time (s): 164.68776457593776')
('Epoch 56', 'Objective: -0.5915223717478674', 'Train Acc: 0.9238', 'Test Acc: 0.9241', 'Train LL: -0.27027274447344524', 'Test LL: -0.2559646893925717', 'Epoch Time (s): 164.64744134014472')
('Epoch 57', 'Objective: -0.5908840620803819', 'Train Acc: 0.9234166666666667', 'Test Acc: 0.9269', 'Train LL: -0.27037817007640336', 'Test LL: -0.25053938818094956', 'Epoch Time (s): 164.20432763011195')
('Epoch 58', 'Objective: -0.591487264141411', 'Train Acc: 0.9238166666666666', 'Test Acc: 0.927', 'Train LL: -0.2704745626971281', 'Test LL: -0.24867923624989036', 'Epoch Time (s): 163.76890307408758')
('Epoch 59', 'Objective: -0.5916044271853561', 'Train Acc: 0.9242333333333334', 'Test Acc: 0.9286', 'Train LL: -0.2711340531569195', 'Test LL: -0.24875800424753278', 'Epoch Time (s): 163.75909251789562')
('Epoch 60', 'Objective: -0.589651401270562', 'Train Acc: 0.9247', 'Test Acc: 0.9254', 'Train LL: -0.2691607172081867', 'Test LL: -0.25341110538216227', 'Epoch Time (s): 163.695938621182')
('Epoch 61', 'Objective: -0.5899505796888129', 'Train Acc: 0.9249166666666667', 'Test Acc: 0.9275', 'Train LL: -0.2685250199194951', 'Test LL: -0.2494505523683998', 'Epoch Time (s): 163.83947363309562')
('Epoch 62', 'Objective: -0.5893390640710123', 'Train Acc: 0.9244333333333333', 'Test Acc: 0.9252', 'Train LL: -0.2690329554203369', 'Test LL: -0.25343025237139466', 'Epoch Time (s): 163.76460765791126')
('Epoch 63', 'Objective: -0.5907059349779742', 'Train Acc: 0.9240333333333334', 'Test Acc: 0.9244', 'Train LL: -0.27021997055886793', 'Test LL: -0.25322573012431765', 'Epoch Time (s): 163.8233930049464')
('Epoch 64', 'Objective: -0.5891540612184463', 'Train Acc: 0.9241666666666667', 'Test Acc: 0.926', 'Train LL: -0.2682156942946537', 'Test LL: -0.24877384852150097', 'Epoch Time (s): 163.78591987979598')
('Epoch 65', 'Objective: -0.5888937148104074', 'Train Acc: 0.92435', 'Test Acc: 0.9292', 'Train LL: -0.26861728585251865', 'Test LL: -0.2419593267543848', 'Epoch Time (s): 163.77943552308716')
('Epoch 66', 'Objective: -0.5907192411595016', 'Train Acc: 0.9232333333333334', 'Test Acc: 0.9256', 'Train LL: -0.26919200158621365', 'Test LL: -0.24986182454105202', 'Epoch Time (s): 163.79634526511654')
('Epoch 67', 'Objective: -0.5892601826670836', 'Train Acc: 0.9246833333333333', 'Test Acc: 0.9269', 'Train LL: -0.26917394518933246', 'Test LL: -0.24451046189367734', 'Epoch Time (s): 163.78989360900596')
('Epoch 68', 'Objective: -0.5890263080861896', 'Train Acc: 0.9252333333333334', 'Test Acc: 0.9242', 'Train LL: -0.26883490824356754', 'Test LL: -0.2544333905867593', 'Epoch Time (s): 163.87577019492164')
('Epoch 69', 'Objective: -0.5886839506212678', 'Train Acc: 0.9239666666666667', 'Test Acc: 0.9257', 'Train LL: -0.2680872693631134', 'Test LL: -0.24925176913553354', 'Epoch Time (s): 163.93832094105892')
('Epoch 70', 'Objective: -0.5890566596395245', 'Train Acc: 0.9241833333333334', 'Test Acc: 0.9284', 'Train LL: -0.26901211059051056', 'Test LL: -0.2466714862599185', 'Epoch Time (s): 163.97738661197945')
('Epoch 71', 'Objective: -0.5875643944520347', 'Train Acc: 0.9247666666666666', 'Test Acc: 0.9272', 'Train LL: -0.26712853781958396', 'Test LL: -0.24734862367376573', 'Epoch Time (s): 164.18676854204386')
('Epoch 72', 'Objective: -0.5892996817679337', 'Train Acc: 0.92305', 'Test Acc: 0.9298', 'Train LL: -0.2679950562939285', 'Test LL: -0.2505976833961869', 'Epoch Time (s): 164.16297180997208')
('Epoch 73', 'Objective: -0.5860202417935805', 'Train Acc: 0.9253', 'Test Acc: 0.9245', 'Train LL: -0.26605504022895415', 'Test LL: -0.2514627182533483', 'Epoch Time (s): 164.17773110885173')
('Epoch 74', 'Objective: -0.5894778211179328', 'Train Acc: 0.9241333333333334', 'Test Acc: 0.9273', 'Train LL: -0.2684871335259651', 'Test LL: -0.2507036014331405', 'Epoch Time (s): 164.21975880884565')
('Epoch 75', 'Objective: -0.5852310239976267', 'Train Acc: 0.92535', 'Test Acc: 0.9272', 'Train LL: -0.2654152306227573', 'Test LL: -0.2445770292469203', 'Epoch Time (s): 164.21057795803063')
('Epoch 76', 'Objective: -0.5859754569949678', 'Train Acc: 0.9257333333333333', 'Test Acc: 0.9261', 'Train LL: -0.26540929178899464', 'Test LL: -0.2501018888117261', 'Epoch Time (s): 164.18252564989962')
('Epoch 77', 'Objective: -0.5880432274209949', 'Train Acc: 0.9249833333333334', 'Test Acc: 0.9262', 'Train LL: -0.2670336851902749', 'Test LL: -0.25134293995013096', 'Epoch Time (s): 164.19637509202585')
('Epoch 78', 'Objective: -0.5878554183001587', 'Train Acc: 0.9261166666666667', 'Test Acc: 0.9279', 'Train LL: -0.26773360356076115', 'Test LL: -0.24643382457506988', 'Epoch Time (s): 164.0718677029945')
('Epoch 79', 'Objective: -0.5857007427297979', 'Train Acc: 0.9256666666666666', 'Test Acc: 0.9278', 'Train LL: -0.2652361075371249', 'Test LL: -0.24913147006278233', 'Epoch Time (s): 163.89098421414383')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.5789626500297431', 'Train Acc: 0.9269333333333334', 'Test Acc: 0.9295', 'Train LL: -0.261611969114489', 'Test LL: -0.24578594018973898', 'Epoch Time (s): 163.89370393194258')
('Epoch 81', 'Objective: -0.5805398576283962', 'Train Acc: 0.9258833333333333', 'Test Acc: 0.93', 'Train LL: -0.2630683473998479', 'Test LL: -0.2443823547241408', 'Epoch Time (s): 163.5441595269367')
('Epoch 82', 'Objective: -0.5778110682896901', 'Train Acc: 0.9270666666666667', 'Test Acc: 0.9303', 'Train LL: -0.2607421439864094', 'Test LL: -0.24306852538653503', 'Epoch Time (s): 163.96652887295932')
('Epoch 83', 'Objective: -0.5796056591846566', 'Train Acc: 0.9263333333333333', 'Test Acc: 0.9284', 'Train LL: -0.26216532834078743', 'Test LL: -0.245295576289375', 'Epoch Time (s): 163.9575865669176')
('Epoch 84', 'Objective: -0.5765573017383345', 'Train Acc: 0.9284333333333333', 'Test Acc: 0.9293', 'Train LL: -0.2602624563779108', 'Test LL: -0.2439014856826092', 'Epoch Time (s): 163.88465708307922')
('Epoch 85', 'Objective: -0.5779657183893352', 'Train Acc: 0.9275666666666667', 'Test Acc: 0.9291', 'Train LL: -0.26075015071668906', 'Test LL: -0.24392537318233568', 'Epoch Time (s): 163.80147321498953')
('Epoch 86', 'Objective: -0.5764081880697727', 'Train Acc: 0.9275166666666667', 'Test Acc: 0.9284', 'Train LL: -0.2594442898794132', 'Test LL: -0.2448391437025058', 'Epoch Time (s): 163.77124038594775')
('Epoch 87', 'Objective: -0.57737806243802', 'Train Acc: 0.92685', 'Test Acc: 0.9302', 'Train LL: -0.25997076580258155', 'Test LL: -0.2405403700371529', 'Epoch Time (s): 163.78327225195244')
('Epoch 88', 'Objective: -0.57551016100738', 'Train Acc: 0.9285166666666667', 'Test Acc: 0.9287', 'Train LL: -0.2586911266537672', 'Test LL: -0.24267239380219235', 'Epoch Time (s): 163.76546908705495')
('Epoch 89', 'Objective: -0.5769509018386062', 'Train Acc: 0.9281333333333334', 'Test Acc: 0.9284', 'Train LL: -0.2595077467252777', 'Test LL: -0.2440655809349501', 'Epoch Time (s): 163.71274095610715')
('Epoch 90', 'Objective: -0.5770723223732729', 'Train Acc: 0.9269666666666667', 'Test Acc: 0.9287', 'Train LL: -0.25989120958407513', 'Test LL: -0.24201319207255206', 'Epoch Time (s): 164.00365144899115')
('Epoch 91', 'Objective: -0.5767899512320482', 'Train Acc: 0.9279833333333334', 'Test Acc: 0.9294', 'Train LL: -0.2591421425480084', 'Test LL: -0.24097298352145108', 'Epoch Time (s): 164.00904120411724')
('Epoch 92', 'Objective: -0.5772266952734674', 'Train Acc: 0.9274333333333333', 'Test Acc: 0.9285', 'Train LL: -0.2598676594405737', 'Test LL: -0.2424329409537944', 'Epoch Time (s): 163.85306777292863')
('Epoch 93', 'Objective: -0.5757238830748637', 'Train Acc: 0.9281333333333334', 'Test Acc: 0.9288', 'Train LL: -0.2587292464111241', 'Test LL: -0.24327432995802287', 'Epoch Time (s): 163.76352083589882')
('Epoch 94', 'Objective: -0.5761892656181876', 'Train Acc: 0.9272666666666667', 'Test Acc: 0.9302', 'Train LL: -0.2588756668099532', 'Test LL: -0.24071919538206657', 'Epoch Time (s): 163.78745255991817')
('Epoch 95', 'Objective: -0.5766950543701793', 'Train Acc: 0.9291', 'Test Acc: 0.9308', 'Train LL: -0.2592906637870396', 'Test LL: -0.24056960632111649', 'Epoch Time (s): 163.7918780199252')
('Epoch 96', 'Objective: -0.5755593097997596', 'Train Acc: 0.9281833333333334', 'Test Acc: 0.93', 'Train LL: -0.258332560720889', 'Test LL: -0.2418484369643348', 'Epoch Time (s): 163.7921056970954')
('Epoch 97', 'Objective: -0.5790906283860153', 'Train Acc: 0.9268833333333333', 'Test Acc: 0.9297', 'Train LL: -0.2610310154435242', 'Test LL: -0.2416897187411254', 'Epoch Time (s): 163.75490621686913')
('Epoch 98', 'Objective: -0.5766576229396582', 'Train Acc: 0.9271666666666667', 'Test Acc: 0.93', 'Train LL: -0.2594712591850245', 'Test LL: -0.2415993864520968', 'Epoch Time (s): 163.77666291501373')
('Epoch 99', 'Objective: -0.5763576961670909', 'Train Acc: 0.92835', 'Test Acc: 0.9287', 'Train LL: -0.25896078581423976', 'Test LL: -0.24467219350836486', 'Epoch Time (s): 163.76821311400272')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.5762500825192297
Final Train Accuracy: £0.9278
Final Train LL: £-0.2584260970778835
Final Test Accuracy: £0.9287
Final Test LL: £-0.24469018031855921
