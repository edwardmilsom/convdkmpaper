dataset: MNIST
dtype: float64
dof: 0.0
init_lr: 0.01
seed: 2
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2165442758672063', 'Train Acc: 0.5731', 'Test Acc: 0.8354', 'Train LL: -1.1838995339155665', 'Test LL: -0.4897267449628518', 'Epoch Time (s): 163.48537337593734')
('Epoch 1', 'Objective: -0.41375312201200065', 'Train Acc: 0.8646666666666667', 'Test Acc: 0.8818', 'Train LL: -0.39905180047259986', 'Test LL: -0.3625989237536239', 'Epoch Time (s): 163.54535231203772')
('Epoch 2', 'Objective: -0.23811665647655458', 'Train Acc: 0.9284333333333333', 'Test Acc: 0.9462', 'Train LL: -0.22852659503269934', 'Test LL: -0.16963317205698536', 'Epoch Time (s): 163.49101958982646')
('Epoch 3', 'Objective: -0.17566606315465788', 'Train Acc: 0.9474666666666667', 'Test Acc: 0.964', 'Train LL: -0.168115370394886', 'Test LL: -0.11720432703207445', 'Epoch Time (s): 163.49186551617458')
('Epoch 4', 'Objective: -0.14756516041233186', 'Train Acc: 0.95525', 'Test Acc: 0.957', 'Train LL: -0.14101706970399233', 'Test LL: -0.13375952313016143', 'Epoch Time (s): 163.52974111307412')
('Epoch 5', 'Objective: -0.12774659479703315', 'Train Acc: 0.9619', 'Test Acc: 0.966', 'Train LL: -0.12203021349899004', 'Test LL: -0.10668185482804245', 'Epoch Time (s): 163.54191914200783')
('Epoch 6', 'Objective: -0.11514503211639643', 'Train Acc: 0.9656333333333333', 'Test Acc: 0.9721', 'Train LL: -0.10993015436274721', 'Test LL: -0.0855813027204915', 'Epoch Time (s): 163.6087561401073')
('Epoch 7', 'Objective: -0.10437160029510358', 'Train Acc: 0.96805', 'Test Acc: 0.9704', 'Train LL: -0.09951204381826334', 'Test LL: -0.09145553071829453', 'Epoch Time (s): 163.5545304659754')
('Epoch 8', 'Objective: -0.09573270453834758', 'Train Acc: 0.9711', 'Test Acc: 0.9757', 'Train LL: -0.09122942385009504', 'Test LL: -0.0787359575322126', 'Epoch Time (s): 163.53664630302228')
('Epoch 9', 'Objective: -0.09171753778261678', 'Train Acc: 0.9720666666666666', 'Test Acc: 0.9753', 'Train LL: -0.08750480918701396', 'Test LL: -0.07094111758614007', 'Epoch Time (s): 163.4990839730017')
('Epoch 10', 'Objective: -0.08595103992356357', 'Train Acc: 0.97425', 'Test Acc: 0.9763', 'Train LL: -0.08197390766809515', 'Test LL: -0.07370686917920012', 'Epoch Time (s): 163.54791203001514')
('Epoch 11', 'Objective: -0.08070332060997278', 'Train Acc: 0.9756', 'Test Acc: 0.9719', 'Train LL: -0.07690470590645555', 'Test LL: -0.08808027991954295', 'Epoch Time (s): 163.55328611610457')
('Epoch 12', 'Objective: -0.078807210425946', 'Train Acc: 0.9763166666666667', 'Test Acc: 0.9795', 'Train LL: -0.075237843975213', 'Test LL: -0.06407860807892121', 'Epoch Time (s): 163.56286425096914')
('Epoch 13', 'Objective: -0.0732124296257731', 'Train Acc: 0.9774', 'Test Acc: 0.9802', 'Train LL: -0.06973463221661927', 'Test LL: -0.058431335130370916', 'Epoch Time (s): 163.5524329780601')
('Epoch 14', 'Objective: -0.07115606494071791', 'Train Acc: 0.9778833333333333', 'Test Acc: 0.9795', 'Train LL: -0.0678743395209931', 'Test LL: -0.06799579353661177', 'Epoch Time (s): 163.58167355018668')
('Epoch 15', 'Objective: -0.06812591744531019', 'Train Acc: 0.9793666666666667', 'Test Acc: 0.9771', 'Train LL: -0.06502485554069845', 'Test LL: -0.07006513473423151', 'Epoch Time (s): 163.56808493402787')
('Epoch 16', 'Objective: -0.06598337640691979', 'Train Acc: 0.9804666666666667', 'Test Acc: 0.9841', 'Train LL: -0.06301381770398415', 'Test LL: -0.0493440840472892', 'Epoch Time (s): 163.57042336906306')
('Epoch 17', 'Objective: -0.06417402694897009', 'Train Acc: 0.9803666666666667', 'Test Acc: 0.9837', 'Train LL: -0.06123546718908301', 'Test LL: -0.05079967739146972', 'Epoch Time (s): 163.57189950696193')
('Epoch 18', 'Objective: -0.06328895338455455', 'Train Acc: 0.9810666666666666', 'Test Acc: 0.9823', 'Train LL: -0.060502888101514905', 'Test LL: -0.05178104053301683', 'Epoch Time (s): 163.55527187511325')
('Epoch 19', 'Objective: -0.06151753872268091', 'Train Acc: 0.98095', 'Test Acc: 0.9852', 'Train LL: -0.05879327621657992', 'Test LL: -0.044985897480252675', 'Epoch Time (s): 163.59878960810602')
('Epoch 20', 'Objective: -0.058147162576610234', 'Train Acc: 0.98235', 'Test Acc: 0.9822', 'Train LL: -0.055544475414363234', 'Test LL: -0.052452062480313894', 'Epoch Time (s): 163.57951497798786')
('Epoch 21', 'Objective: -0.05885835613950786', 'Train Acc: 0.98225', 'Test Acc: 0.9848', 'Train LL: -0.05635874147280051', 'Test LL: -0.04860106536307121', 'Epoch Time (s): 163.61401762091555')
('Epoch 22', 'Objective: -0.05566539602342422', 'Train Acc: 0.9830833333333333', 'Test Acc: 0.9817', 'Train LL: -0.05326819326416245', 'Test LL: -0.0549667136199585', 'Epoch Time (s): 163.57559978915378')
('Epoch 23', 'Objective: -0.05521250104042168', 'Train Acc: 0.9831666666666666', 'Test Acc: 0.9819', 'Train LL: -0.052798595706109945', 'Test LL: -0.05359625857612045', 'Epoch Time (s): 163.57815156597644')
('Epoch 24', 'Objective: -0.053374621771923966', 'Train Acc: 0.9833666666666666', 'Test Acc: 0.9869', 'Train LL: -0.051049059469487935', 'Test LL: -0.0438060757220126', 'Epoch Time (s): 163.58334106113762')
('Epoch 25', 'Objective: -0.05327056023081616', 'Train Acc: 0.9841666666666666', 'Test Acc: 0.9816', 'Train LL: -0.05099179440039765', 'Test LL: -0.051439253078628656', 'Epoch Time (s): 163.59830723889172')
('Epoch 26', 'Objective: -0.051264833832050605', 'Train Acc: 0.9847166666666667', 'Test Acc: 0.9874', 'Train LL: -0.0490486269884428', 'Test LL: -0.04126869452924603', 'Epoch Time (s): 163.60807234514505')
('Epoch 27', 'Objective: -0.05102861279016667', 'Train Acc: 0.9836333333333334', 'Test Acc: 0.9878', 'Train LL: -0.048890859148823795', 'Test LL: -0.036990646761891614', 'Epoch Time (s): 163.61041284212843')
('Epoch 28', 'Objective: -0.0504131777304603', 'Train Acc: 0.9850333333333333', 'Test Acc: 0.9705', 'Train LL: -0.04831481407573787', 'Test LL: -0.08309530081940554', 'Epoch Time (s): 163.59374484606087')
('Epoch 29', 'Objective: -0.0490200001223937', 'Train Acc: 0.9848333333333333', 'Test Acc: 0.9842', 'Train LL: -0.046955187110061164', 'Test LL: -0.04668909212962517', 'Epoch Time (s): 163.60950051411055')
('Epoch 30', 'Objective: -0.046919868935411', 'Train Acc: 0.9856166666666667', 'Test Acc: 0.9831', 'Train LL: -0.044935046166251776', 'Test LL: -0.04899306172932268', 'Epoch Time (s): 163.59427946899086')
('Epoch 31', 'Objective: -0.0476124870889796', 'Train Acc: 0.9851333333333333', 'Test Acc: 0.9874', 'Train LL: -0.045640517675593614', 'Test LL: -0.03897281307118368', 'Epoch Time (s): 163.5999051409308')
('Epoch 32', 'Objective: -0.046681008287749924', 'Train Acc: 0.9860666666666666', 'Test Acc: 0.9861', 'Train LL: -0.044771783691748536', 'Test LL: -0.04264051968483442', 'Epoch Time (s): 163.58404265600257')
('Epoch 33', 'Objective: -0.04615759300847773', 'Train Acc: 0.9859666666666667', 'Test Acc: 0.9859', 'Train LL: -0.04427981576789763', 'Test LL: -0.04248920872001333', 'Epoch Time (s): 163.6018591269385')
('Epoch 34', 'Objective: -0.04487038918552645', 'Train Acc: 0.9858833333333333', 'Test Acc: 0.9865', 'Train LL: -0.04301320311537723', 'Test LL: -0.03904783965763122', 'Epoch Time (s): 163.5885225578677')
('Epoch 35', 'Objective: -0.04468892283710668', 'Train Acc: 0.9862', 'Test Acc: 0.9867', 'Train LL: -0.04290979216164797', 'Test LL: -0.039822164201933984', 'Epoch Time (s): 163.6038509090431')
('Epoch 36', 'Objective: -0.04329595495581421', 'Train Acc: 0.9865333333333334', 'Test Acc: 0.9896', 'Train LL: -0.041536664097203954', 'Test LL: -0.03233560760354093', 'Epoch Time (s): 163.58686841093004')
('Epoch 37', 'Objective: -0.04299087946730259', 'Train Acc: 0.98695', 'Test Acc: 0.9863', 'Train LL: -0.041221851955279845', 'Test LL: -0.04060101406102492', 'Epoch Time (s): 163.5890011980664')
('Epoch 38', 'Objective: -0.04343063191649306', 'Train Acc: 0.9871833333333333', 'Test Acc: 0.9852', 'Train LL: -0.041726603478567846', 'Test LL: -0.043631405952434574', 'Epoch Time (s): 163.59317197999917')
('Epoch 39', 'Objective: -0.041171613905716824', 'Train Acc: 0.98725', 'Test Acc: 0.98', 'Train LL: -0.03952619962712021', 'Test LL: -0.05961543627912682', 'Epoch Time (s): 163.60444598598406')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.027179803053287127', 'Train Acc: 0.9918666666666667', 'Test Acc: 0.9912', 'Train LL: -0.025694479917594295', 'Test LL: -0.026262357562333968', 'Epoch Time (s): 163.63808782794513')
('Epoch 41', 'Objective: -0.02077089724919405', 'Train Acc: 0.99385', 'Test Acc: 0.9927', 'Train LL: -0.019399826245424683', 'Test LL: -0.025151245143273895', 'Epoch Time (s): 163.60753476200625')
('Epoch 42', 'Objective: -0.019855965101139968', 'Train Acc: 0.9938333333333333', 'Test Acc: 0.9916', 'Train LL: -0.01848992974096905', 'Test LL: -0.026312231387427977', 'Epoch Time (s): 163.627383134095')
('Epoch 43', 'Objective: -0.017798163173479202', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9923', 'Train LL: -0.016445993501003366', 'Test LL: -0.02387973910281616', 'Epoch Time (s): 163.6444463210646')
('Epoch 44', 'Objective: -0.01778387340771945', 'Train Acc: 0.9947', 'Test Acc: 0.9913', 'Train LL: -0.01643670853467612', 'Test LL: -0.025287741341649333', 'Epoch Time (s): 163.58821317297406')
('Epoch 45', 'Objective: -0.01765297825423734', 'Train Acc: 0.9947333333333334', 'Test Acc: 0.992', 'Train LL: -0.01632128385229837', 'Test LL: -0.023766803974624134', 'Epoch Time (s): 163.59694848908111')
('Epoch 46', 'Objective: -0.016606876421586377', 'Train Acc: 0.9953333333333333', 'Test Acc: 0.9922', 'Train LL: -0.015302566447771539', 'Test LL: -0.023482565527582166', 'Epoch Time (s): 163.60716384393163')
('Epoch 47', 'Objective: -0.016240817895047947', 'Train Acc: 0.9954', 'Test Acc: 0.9918', 'Train LL: -0.01494492119599886', 'Test LL: -0.026805242853638292', 'Epoch Time (s): 163.6112075438723')
('Epoch 48', 'Objective: -0.015524060662412036', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.992', 'Train LL: -0.014193191894331809', 'Test LL: -0.025550012485956092', 'Epoch Time (s): 163.61294932989404')
('Epoch 49', 'Objective: -0.01481472291013709', 'Train Acc: 0.9955666666666667', 'Test Acc: 0.9926', 'Train LL: -0.013511295195360045', 'Test LL: -0.022934132044864133', 'Epoch Time (s): 163.5395717411302')
('Epoch 50', 'Objective: -0.015006047615797016', 'Train Acc: 0.9955166666666667', 'Test Acc: 0.9924', 'Train LL: -0.013689106210247602', 'Test LL: -0.022373416250036637', 'Epoch Time (s): 163.50553696905263')
('Epoch 51', 'Objective: -0.014451910098490417', 'Train Acc: 0.9956666666666667', 'Test Acc: 0.9927', 'Train LL: -0.01313637491959088', 'Test LL: -0.02499815679084292', 'Epoch Time (s): 163.50933341588825')
('Epoch 52', 'Objective: -0.013710990093348351', 'Train Acc: 0.9956333333333334', 'Test Acc: 0.9909', 'Train LL: -0.01240529886690869', 'Test LL: -0.02488561809641978', 'Epoch Time (s): 163.54847591696307')
('Epoch 53', 'Objective: -0.013898797994322597', 'Train Acc: 0.99575', 'Test Acc: 0.9917', 'Train LL: -0.012594152287072493', 'Test LL: -0.025827361858238775', 'Epoch Time (s): 163.57523114304058')
('Epoch 54', 'Objective: -0.013711458055651932', 'Train Acc: 0.9958833333333333', 'Test Acc: 0.9919', 'Train LL: -0.01239379351813481', 'Test LL: -0.02479342961348774', 'Epoch Time (s): 163.49513179901987')
('Epoch 55', 'Objective: -0.013027403629436215', 'Train Acc: 0.9960833333333333', 'Test Acc: 0.9919', 'Train LL: -0.011730461582641377', 'Test LL: -0.02416888397095025', 'Epoch Time (s): 163.50700661190785')
('Epoch 56', 'Objective: -0.012858855296100168', 'Train Acc: 0.9962666666666666', 'Test Acc: 0.9923', 'Train LL: -0.011575108146844626', 'Test LL: -0.022805777057474615', 'Epoch Time (s): 163.48655239492655')
('Epoch 57', 'Objective: -0.013019588992051285', 'Train Acc: 0.9962833333333333', 'Test Acc: 0.9908', 'Train LL: -0.011725760758839519', 'Test LL: -0.025159825422220047', 'Epoch Time (s): 163.46193916304037')
('Epoch 58', 'Objective: -0.011809645876399301', 'Train Acc: 0.99635', 'Test Acc: 0.9913', 'Train LL: -0.01053508362366771', 'Test LL: -0.02772049141237685', 'Epoch Time (s): 163.54799507092685')
('Epoch 59', 'Objective: -0.012436635354485514', 'Train Acc: 0.9964166666666666', 'Test Acc: 0.9921', 'Train LL: -0.011140596698442903', 'Test LL: -0.024035943342574657', 'Epoch Time (s): 163.53750955406576')
('Epoch 60', 'Objective: -0.011352965947871945', 'Train Acc: 0.9965166666666667', 'Test Acc: 0.9902', 'Train LL: -0.010065961188480797', 'Test LL: -0.02850902536651006', 'Epoch Time (s): 163.50061365612783')
('Epoch 61', 'Objective: -0.010929778322694471', 'Train Acc: 0.9966333333333334', 'Test Acc: 0.9909', 'Train LL: -0.009656260102841305', 'Test LL: -0.028479260855369695', 'Epoch Time (s): 163.49788363999687')
('Epoch 62', 'Objective: -0.011352926044059622', 'Train Acc: 0.9963333333333333', 'Test Acc: 0.9912', 'Train LL: -0.010059138576614716', 'Test LL: -0.027919101776224697', 'Epoch Time (s): 163.50607646699063')
('Epoch 63', 'Objective: nan', 'Train Acc: 0.99655', 'Test Acc: 0.9912', 'Train LL: -0.010147755673180072', 'Test LL: -0.028658588285933154', 'Epoch Time (s): 163.48376443004236')
('Epoch 64', 'Objective: -0.01068082081607898', 'Train Acc: 0.9967166666666667', 'Test Acc: 0.9895', 'Train LL: -0.00940433561432394', 'Test LL: -0.031028363175686774', 'Epoch Time (s): 163.49148846999742')
('Epoch 65', 'Objective: -0.010722698103111668', 'Train Acc: 0.9968166666666667', 'Test Acc: 0.9915', 'Train LL: -0.009415925998797703', 'Test LL: -0.028473662344657827', 'Epoch Time (s): 163.4884070509579')
('Epoch 66', 'Objective: -0.010011052122123927', 'Train Acc: 0.9971166666666667', 'Test Acc: 0.9917', 'Train LL: -0.008752787096142314', 'Test LL: -0.02705059744167716', 'Epoch Time (s): 163.47802848392166')
('Epoch 67', 'Objective: -0.009863352651275645', 'Train Acc: 0.9971833333333333', 'Test Acc: 0.9889', 'Train LL: -0.00860418621941104', 'Test LL: -0.035104313933973126', 'Epoch Time (s): 163.49280806188472')
('Epoch 68', 'Objective: -0.010213572058758866', 'Train Acc: 0.997', 'Test Acc: 0.9902', 'Train LL: -0.008932438061012822', 'Test LL: -0.03291979776997576', 'Epoch Time (s): 163.5028427010402')
('Epoch 69', 'Objective: -0.009712720815978126', 'Train Acc: 0.9971', 'Test Acc: 0.9912', 'Train LL: -0.008462255059135643', 'Test LL: -0.02797202411206279', 'Epoch Time (s): 163.48765451204963')
('Epoch 70', 'Objective: -0.009493413397338358', 'Train Acc: 0.9971833333333333', 'Test Acc: 0.9919', 'Train LL: -0.008237577836011605', 'Test LL: -0.02671536789577562', 'Epoch Time (s): 163.49960417696275')
('Epoch 71', 'Objective: -0.009328816808792334', 'Train Acc: 0.9972', 'Test Acc: 0.9909', 'Train LL: -0.008054536916151881', 'Test LL: -0.03145543425905133', 'Epoch Time (s): 163.48956832801923')
('Epoch 72', 'Objective: -0.009389329192054137', 'Train Acc: 0.99705', 'Test Acc: 0.9909', 'Train LL: -0.008126395707108611', 'Test LL: -0.030171805611023415', 'Epoch Time (s): 163.5064415279776')
('Epoch 73', 'Objective: -0.0085778872765185', 'Train Acc: 0.99755', 'Test Acc: 0.9928', 'Train LL: -0.007341450933782123', 'Test LL: -0.027702212913648567', 'Epoch Time (s): 163.5403463980183')
('Epoch 74', 'Objective: -0.008942177162150058', 'Train Acc: 0.9976666666666667', 'Test Acc: 0.9909', 'Train LL: -0.007720619146770904', 'Test LL: -0.03015138089357427', 'Epoch Time (s): 163.54543611593544')
('Epoch 75', 'Objective: -0.008816851394892588', 'Train Acc: 0.9974666666666666', 'Test Acc: 0.9911', 'Train LL: -0.007571734488012112', 'Test LL: -0.03063148690046201', 'Epoch Time (s): 163.54861333686858')
('Epoch 76', 'Objective: -0.008746165928620216', 'Train Acc: 0.9974833333333334', 'Test Acc: 0.9898', 'Train LL: -0.007516030369882387', 'Test LL: -0.034211240637223854', 'Epoch Time (s): 163.53357374318875')
('Epoch 77', 'Objective: -0.008431088884872878', 'Train Acc: 0.9976', 'Test Acc: 0.9903', 'Train LL: -0.007215675538703914', 'Test LL: -0.03277115640774631', 'Epoch Time (s): 163.51193658891134')
('Epoch 78', 'Objective: -0.008561893125076792', 'Train Acc: 0.9974666666666666', 'Test Acc: 0.9907', 'Train LL: -0.007348145814265357', 'Test LL: -0.03209024536519169', 'Epoch Time (s): 163.54498229781166')
('Epoch 79', 'Objective: -0.00865557680204971', 'Train Acc: 0.9973833333333333', 'Test Acc: 0.9901', 'Train LL: -0.007417323993278512', 'Test LL: -0.03444405549323257', 'Epoch Time (s): 163.54972383589484')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.006107482196681812', 'Train Acc: 0.99835', 'Test Acc: 0.9905', 'Train LL: -0.004982652829063064', 'Test LL: -0.03283298892819416', 'Epoch Time (s): 163.5184760959819')
('Epoch 81', 'Objective: -0.005838079120298868', 'Train Acc: 0.9985833333333334', 'Test Acc: 0.9912', 'Train LL: -0.00471903301066286', 'Test LL: -0.03186760368481197', 'Epoch Time (s): 163.56779924896546')
('Epoch 82', 'Objective: -0.005650542749987532', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9915', 'Train LL: -0.004556439986042755', 'Test LL: -0.03179980137457213', 'Epoch Time (s): 163.5994290630333')
('Epoch 83', 'Objective: -0.005026567962150872', 'Train Acc: 0.9987666666666667', 'Test Acc: 0.9915', 'Train LL: -0.003932847469838428', 'Test LL: -0.03202494720254756', 'Epoch Time (s): 163.5871135899797')
('Epoch 84', 'Objective: -0.004965659651616196', 'Train Acc: 0.9987333333333334', 'Test Acc: 0.9915', 'Train LL: -0.0038675968475001448', 'Test LL: -0.033022441187687004', 'Epoch Time (s): 163.6032706790138')
('Epoch 85', 'Objective: -0.00544987295339767', 'Train Acc: 0.9987833333333334', 'Test Acc: 0.9911', 'Train LL: -0.00432912568012574', 'Test LL: -0.03309712609705274', 'Epoch Time (s): 163.64518409082666')
('Epoch 86', 'Objective: -0.005469489429507485', 'Train Acc: 0.9985833333333334', 'Test Acc: 0.9912', 'Train LL: -0.004339467803540293', 'Test LL: -0.032805568370077774', 'Epoch Time (s): 163.58563706208952')
('Epoch 87', 'Objective: -0.005291340300792418', 'Train Acc: 0.9986333333333334', 'Test Acc: 0.9903', 'Train LL: -0.004170018314319781', 'Test LL: -0.0346071110874752', 'Epoch Time (s): 163.55035486188717')
('Epoch 88', 'Objective: -0.0050231214770753005', 'Train Acc: 0.9987166666666667', 'Test Acc: 0.9912', 'Train LL: -0.0038987587238183677', 'Test LL: -0.03300131137672829', 'Epoch Time (s): 163.57273591915146')
('Epoch 89', 'Objective: -0.0047026934603244495', 'Train Acc: 0.9988333333333334', 'Test Acc: 0.9907', 'Train LL: -0.003604051956344705', 'Test LL: -0.035624964164364954', 'Epoch Time (s): 163.63878385489807')
('Epoch 90', 'Objective: -0.004968760062160216', 'Train Acc: 0.9988166666666667', 'Test Acc: 0.991', 'Train LL: -0.003837177069069415', 'Test LL: -0.034085471649517765', 'Epoch Time (s): 163.63824499421753')
('Epoch 91', 'Objective: -0.004344961513447752', 'Train Acc: 0.9990666666666667', 'Test Acc: 0.9907', 'Train LL: -0.003242334706415727', 'Test LL: -0.03523806400468021', 'Epoch Time (s): 163.4726536211092')
('Epoch 92', 'Objective: -0.004545483213875988', 'Train Acc: 0.9991166666666667', 'Test Acc: 0.9905', 'Train LL: -0.0034375908025965746', 'Test LL: -0.03497788464973038', 'Epoch Time (s): 163.44663606095128')
('Epoch 93', 'Objective: -0.0044415201915457515', 'Train Acc: 0.9990333333333333', 'Test Acc: 0.9908', 'Train LL: -0.00333317316099049', 'Test LL: -0.035680379960363204', 'Epoch Time (s): 163.47066122083925')
('Epoch 94', 'Objective: -0.004941722862251398', 'Train Acc: 0.9989', 'Test Acc: 0.9907', 'Train LL: -0.0037952126358344676', 'Test LL: -0.03510329333701283', 'Epoch Time (s): 163.45075717801228')
('Epoch 95', 'Objective: -0.004415671551714151', 'Train Acc: 0.9989333333333333', 'Test Acc: 0.9908', 'Train LL: -0.003298869612585955', 'Test LL: -0.035473187623632864', 'Epoch Time (s): 163.46760451002046')
('Epoch 96', 'Objective: -0.005031554289246259', 'Train Acc: 0.9986833333333334', 'Test Acc: 0.9908', 'Train LL: -0.0038736659698513053', 'Test LL: -0.03580246140659303', 'Epoch Time (s): 163.53004997200333')
('Epoch 97', 'Objective: -0.004440126017194506', 'Train Acc: 0.9989666666666667', 'Test Acc: 0.9907', 'Train LL: -0.0033306536310370315', 'Test LL: -0.03652879812740028', 'Epoch Time (s): 163.48576711886562')
('Epoch 98', 'Objective: -0.00403359905923352', 'Train Acc: 0.99915', 'Test Acc: 0.9905', 'Train LL: -0.0029269053766023444', 'Test LL: -0.037870513772213385', 'Epoch Time (s): 163.49466527299955')
('Epoch 99', 'Objective: -0.003916613199213728', 'Train Acc: 0.9990833333333333', 'Test Acc: 0.9913', 'Train LL: -0.0028159119063017792', 'Test LL: -0.03654197184704813', 'Epoch Time (s): 163.51433946192265')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.003894732676854245
Final Train Accuracy: £0.99915
Final Train LL: £-0.0027754539254943762
Final Test Accuracy: £0.9913
Final Test LL: £-0.03626221395151329
