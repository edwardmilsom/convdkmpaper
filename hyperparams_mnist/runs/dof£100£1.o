dataset: MNIST
dtype: float64
dof: 100.0
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.8235579401929676', 'Train Acc: 0.37901666666666667', 'Test Acc: 0.6447', 'Train LL: -1.6749950637425297', 'Test LL: -1.0522127198981837', 'Epoch Time (s): 163.55594365205616')
('Epoch 1', 'Objective: -1.1645513082452679', 'Train Acc: 0.6632333333333333', 'Test Acc: 0.7443', 'Train LL: -0.9630789657777313', 'Test LL: -0.6909970939824395', 'Epoch Time (s): 163.7254878040403')
('Epoch 2', 'Objective: -0.8500971526596468', 'Train Acc: 0.7788166666666667', 'Test Acc: 0.8352', 'Train LL: -0.6442080380436092', 'Test LL: -0.5049346812288713', 'Epoch Time (s): 163.6466035360936')
('Epoch 3', 'Objective: -0.7331315875043793', 'Train Acc: 0.8238166666666666', 'Test Acc: 0.8276', 'Train LL: -0.5253750291455318', 'Test LL: -0.5382118760272832', 'Epoch Time (s): 163.63563954085112')
('Epoch 4', 'Objective: -0.6563144065181291', 'Train Acc: 0.8553666666666667', 'Test Acc: 0.8778', 'Train LL: -0.4467402032295186', 'Test LL: -0.38708307071727993', 'Epoch Time (s): 163.79959149006754')
('Epoch 5', 'Objective: -0.602664374963665', 'Train Acc: 0.8725666666666667', 'Test Acc: 0.8622', 'Train LL: -0.3963991096645729', 'Test LL: -0.4364870564201854', 'Epoch Time (s): 163.75325347692706')
('Epoch 6', 'Objective: -0.5714100485422461', 'Train Acc: 0.88375', 'Test Acc: 0.89', 'Train LL: -0.3683400952123366', 'Test LL: -0.3439916511468679', 'Epoch Time (s): 164.11318090185523')
('Epoch 7', 'Objective: -0.5389038276275868', 'Train Acc: 0.8931333333333333', 'Test Acc: 0.899', 'Train LL: -0.3413066164294825', 'Test LL: -0.32366179766168635', 'Epoch Time (s): 164.14502989291213')
('Epoch 8', 'Objective: -0.5053403781317345', 'Train Acc: 0.9024666666666666', 'Test Acc: 0.8776', 'Train LL: -0.312795541122337', 'Test LL: -0.380036595150414', 'Epoch Time (s): 164.2349783189129')
('Epoch 9', 'Objective: -0.4843713159744628', 'Train Acc: 0.9074166666666666', 'Test Acc: 0.9172', 'Train LL: -0.2977609393660884', 'Test LL: -0.2689286378040716', 'Epoch Time (s): 164.16212019394152')
('Epoch 10', 'Objective: -0.46212070673492156', 'Train Acc: 0.9135833333333333', 'Test Acc: 0.8954', 'Train LL: -0.2799652810792417', 'Test LL: -0.311174475679672', 'Epoch Time (s): 164.16604387992993')
('Epoch 11', 'Objective: -0.4512702815654695', 'Train Acc: 0.9168333333333333', 'Test Acc: 0.9168', 'Train LL: -0.2708351834830916', 'Test LL: -0.27270753881725956', 'Epoch Time (s): 164.1738928349223')
('Epoch 12', 'Objective: -0.44327180952714995', 'Train Acc: 0.9185333333333333', 'Test Acc: 0.9173', 'Train LL: -0.26257396922698123', 'Test LL: -0.26050188616153785', 'Epoch Time (s): 164.16660861298442')
('Epoch 13', 'Objective: -0.4312395497951353', 'Train Acc: 0.9222', 'Test Acc: 0.9249', 'Train LL: -0.2522934434493459', 'Test LL: -0.2415388624698797', 'Epoch Time (s): 164.17522719106637')
('Epoch 14', 'Objective: -0.4217692133935506', 'Train Acc: 0.92565', 'Test Acc: 0.9004', 'Train LL: -0.24340249135001293', 'Test LL: -0.321092552643334', 'Epoch Time (s): 163.8345037039835')
('Epoch 15', 'Objective: -0.41860689355569564', 'Train Acc: 0.9265166666666667', 'Test Acc: 0.9262', 'Train LL: -0.2400022351982185', 'Test LL: -0.2411544318438394', 'Epoch Time (s): 164.6711693671532')
('Epoch 16', 'Objective: -0.4097286957509019', 'Train Acc: 0.9295833333333333', 'Test Acc: 0.9314', 'Train LL: -0.23307476552024817', 'Test LL: -0.21173030609727175', 'Epoch Time (s): 164.67063943389803')
('Epoch 17', 'Objective: -0.40594405422068264', 'Train Acc: 0.9301833333333334', 'Test Acc: 0.9296', 'Train LL: -0.22825333436771592', 'Test LL: -0.2351979584337942', 'Epoch Time (s): 164.48291195789352')
('Epoch 18', 'Objective: -0.39877044685265156', 'Train Acc: 0.9318', 'Test Acc: 0.939', 'Train LL: -0.2221365688651731', 'Test LL: -0.21146483187077647', 'Epoch Time (s): 164.3452615190763')
('Epoch 19', 'Objective: -0.3945048038059649', 'Train Acc: 0.9336666666666666', 'Test Acc: 0.9433', 'Train LL: -0.21775436588426392', 'Test LL: -0.18821975450019118', 'Epoch Time (s): 163.97482355800457')
('Epoch 20', 'Objective: -0.39178114509856327', 'Train Acc: 0.9361', 'Test Acc: 0.9365', 'Train LL: -0.2147933771911261', 'Test LL: -0.20245809722575453', 'Epoch Time (s): 163.55886412598193')
('Epoch 21', 'Objective: -0.38167907187935224', 'Train Acc: 0.93715', 'Test Acc: 0.9461', 'Train LL: -0.20602326561197193', 'Test LL: -0.17023714872315973', 'Epoch Time (s): 163.62678454001434')
('Epoch 22', 'Objective: -0.3836241596548862', 'Train Acc: 0.93865', 'Test Acc: 0.942', 'Train LL: -0.20727914478497256', 'Test LL: -0.19148731740222982', 'Epoch Time (s): 163.70435551693663')
('Epoch 23', 'Objective: -0.3780170249266032', 'Train Acc: 0.9391666666666667', 'Test Acc: 0.9386', 'Train LL: -0.20163885719490493', 'Test LL: -0.18986849340408507', 'Epoch Time (s): 163.81622899207287')
('Epoch 24', 'Objective: -0.3726077074846867', 'Train Acc: 0.9405833333333333', 'Test Acc: 0.9435', 'Train LL: -0.1971789619867823', 'Test LL: -0.18256498603945384', 'Epoch Time (s): 163.87541100010276')
('Epoch 25', 'Objective: -0.3684443888868634', 'Train Acc: 0.94155', 'Test Acc: 0.9467', 'Train LL: -0.19394036778114537', 'Test LL: -0.1696459470400578', 'Epoch Time (s): 163.92837543180212')
('Epoch 26', 'Objective: -0.3687632847601563', 'Train Acc: 0.9416833333333333', 'Test Acc: 0.9402', 'Train LL: -0.19308123737961252', 'Test LL: -0.1808770314568759', 'Epoch Time (s): 163.88830796512775')
('Epoch 27', 'Objective: -0.36225462728535573', 'Train Acc: 0.9439333333333333', 'Test Acc: 0.9451', 'Train LL: -0.18692790758889333', 'Test LL: -0.1721979792092337', 'Epoch Time (s): 163.86293558892794')
('Epoch 28', 'Objective: -0.36124096154623686', 'Train Acc: 0.94405', 'Test Acc: 0.9464', 'Train LL: -0.1850782849199191', 'Test LL: -0.17044125889947595', 'Epoch Time (s): 163.85541681200266')
('Epoch 29', 'Objective: -0.3588871316145157', 'Train Acc: 0.9456833333333333', 'Test Acc: 0.9449', 'Train LL: -0.1822035510842079', 'Test LL: -0.17841410009980846', 'Epoch Time (s): 163.87011273391545')
('Epoch 30', 'Objective: -0.3550509707855522', 'Train Acc: 0.9466833333333333', 'Test Acc: 0.951', 'Train LL: -0.17961738266973293', 'Test LL: -0.15961926084760455', 'Epoch Time (s): 163.8934695739299')
('Epoch 31', 'Objective: -0.3543198316640998', 'Train Acc: 0.9467166666666667', 'Test Acc: 0.9584', 'Train LL: -0.17777139902237898', 'Test LL: -0.13867466658545685', 'Epoch Time (s): 163.88460854487494')
('Epoch 32', 'Objective: -0.34965071348133697', 'Train Acc: 0.9474166666666667', 'Test Acc: 0.9509', 'Train LL: -0.1748717503309201', 'Test LL: -0.15136235905819803', 'Epoch Time (s): 163.73585996194743')
('Epoch 33', 'Objective: -0.3471155378207161', 'Train Acc: 0.9482333333333334', 'Test Acc: 0.951', 'Train LL: -0.1711135224639206', 'Test LL: -0.15241046805106084', 'Epoch Time (s): 163.4665270659607')
('Epoch 34', 'Objective: -0.3446256851044668', 'Train Acc: 0.9485333333333333', 'Test Acc: 0.9512', 'Train LL: -0.16917502737205978', 'Test LL: -0.1533491531666194', 'Epoch Time (s): 163.56394919613376')
('Epoch 35', 'Objective: -0.3450159485016717', 'Train Acc: 0.94915', 'Test Acc: 0.9521', 'Train LL: -0.16906675586162528', 'Test LL: -0.15587661075938183', 'Epoch Time (s): 163.67829340999015')
('Epoch 36', 'Objective: -0.3376544992280731', 'Train Acc: 0.9512166666666667', 'Test Acc: 0.9555', 'Train LL: -0.16252368326431502', 'Test LL: -0.13793167867701114', 'Epoch Time (s): 163.73364348500036')
('Epoch 37', 'Objective: -0.3420662632597856', 'Train Acc: 0.95065', 'Test Acc: 0.9472', 'Train LL: -0.16638261861926418', 'Test LL: -0.16519510122491507', 'Epoch Time (s): 163.57327570510097')
('Epoch 38', 'Objective: -0.33695180043305883', 'Train Acc: 0.9518166666666666', 'Test Acc: 0.9472', 'Train LL: -0.16259402629360628', 'Test LL: -0.16358318646937783', 'Epoch Time (s): 163.80108110583387')
('Epoch 39', 'Objective: -0.33523196573932157', 'Train Acc: 0.9523666666666667', 'Test Acc: 0.9585', 'Train LL: -0.15935461969449166', 'Test LL: -0.1370888201581445', 'Epoch Time (s): 163.7631387540605')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.2936278022968292', 'Train Acc: 0.9614', 'Test Acc: 0.9666', 'Train LL: -0.13050892768103337', 'Test LL: -0.10827113562544073', 'Epoch Time (s): 163.78894497314468')
('Epoch 41', 'Objective: -0.28440662301678443', 'Train Acc: 0.9633333333333334', 'Test Acc: 0.9669', 'Train LL: -0.12486704015634273', 'Test LL: -0.1086559981710104', 'Epoch Time (s): 163.5299635580741')
('Epoch 42', 'Objective: -0.28194752233795334', 'Train Acc: 0.9637833333333333', 'Test Acc: 0.965', 'Train LL: -0.12260042625805277', 'Test LL: -0.11023106815445625', 'Epoch Time (s): 163.61606904887594')
('Epoch 43', 'Objective: -0.2804246188080605', 'Train Acc: 0.9641333333333333', 'Test Acc: 0.9654', 'Train LL: -0.12210489674062276', 'Test LL: -0.10827089528794044', 'Epoch Time (s): 163.82963944599032')
('Epoch 44', 'Objective: -0.2790573471731021', 'Train Acc: 0.9646666666666667', 'Test Acc: 0.9679', 'Train LL: -0.12074459461885585', 'Test LL: -0.10412062775350805', 'Epoch Time (s): 163.7209382231813')
('Epoch 45', 'Objective: -0.2787086246210108', 'Train Acc: 0.9648', 'Test Acc: 0.9666', 'Train LL: -0.12089636547706856', 'Test LL: -0.1056790369804052', 'Epoch Time (s): 163.68668768391944')
('Epoch 46', 'Objective: -0.27828159618440623', 'Train Acc: 0.9648166666666667', 'Test Acc: 0.9655', 'Train LL: -0.12081270092843173', 'Test LL: -0.10814452585992344', 'Epoch Time (s): 163.74950873386115')
('Epoch 47', 'Objective: -0.27571595136046595', 'Train Acc: 0.9652666666666667', 'Test Acc: 0.9684', 'Train LL: -0.11846286775591632', 'Test LL: -0.10347620524507459', 'Epoch Time (s): 163.71479118894786')
('Epoch 48', 'Objective: -0.2764470277901581', 'Train Acc: 0.96455', 'Test Acc: 0.9657', 'Train LL: -0.1190118409056944', 'Test LL: -0.10635330566221406', 'Epoch Time (s): 163.68864605785348')
('Epoch 49', 'Objective: -0.27658674218022655', 'Train Acc: 0.9651166666666666', 'Test Acc: 0.9663', 'Train LL: -0.1191921496024376', 'Test LL: -0.10727445300791454', 'Epoch Time (s): 163.68864590488374')
('Epoch 50', 'Objective: -0.27490647486768016', 'Train Acc: 0.9647333333333333', 'Test Acc: 0.9655', 'Train LL: -0.11790713810659778', 'Test LL: -0.10987076289778175', 'Epoch Time (s): 163.72395209316164')
('Epoch 51', 'Objective: -0.2752614359779707', 'Train Acc: 0.9658', 'Test Acc: 0.9665', 'Train LL: -0.11842180210587354', 'Test LL: -0.09959230030118986', 'Epoch Time (s): 163.736011731904')
('Epoch 52', 'Objective: -0.2744723647262992', 'Train Acc: 0.9652833333333334', 'Test Acc: 0.967', 'Train LL: -0.11773047211984573', 'Test LL: -0.10504624575979501', 'Epoch Time (s): 163.69890359486453')
('Epoch 53', 'Objective: -0.2739178247734284', 'Train Acc: 0.9658333333333333', 'Test Acc: 0.9664', 'Train LL: -0.11697707829910386', 'Test LL: -0.10444885383417975', 'Epoch Time (s): 163.71184009616263')
('Epoch 54', 'Objective: -0.2750478097979998', 'Train Acc: 0.9652666666666667', 'Test Acc: 0.9669', 'Train LL: -0.11853858001834239', 'Test LL: -0.10350253636788669', 'Epoch Time (s): 163.71386269317009')
('Epoch 55', 'Objective: -0.2738551641958446', 'Train Acc: 0.9659166666666666', 'Test Acc: 0.9653', 'Train LL: -0.11690649626501233', 'Test LL: -0.10825097017354451', 'Epoch Time (s): 163.71856765798293')
('Epoch 56', 'Objective: -0.27486268278382664', 'Train Acc: 0.9649666666666666', 'Test Acc: 0.967', 'Train LL: -0.11812123026526285', 'Test LL: -0.10371326102187198', 'Epoch Time (s): 163.7146104190033')
('Epoch 57', 'Objective: -0.2725326350904019', 'Train Acc: 0.96555', 'Test Acc: 0.9681', 'Train LL: -0.11626581881673625', 'Test LL: -0.0995138995957102', 'Epoch Time (s): 163.703655251069')
('Epoch 58', 'Objective: -0.2726092865884959', 'Train Acc: 0.9655833333333333', 'Test Acc: 0.967', 'Train LL: -0.11596600862793113', 'Test LL: -0.10156027818152592', 'Epoch Time (s): 163.72622061497532')
('Epoch 59', 'Objective: -0.27365627842333734', 'Train Acc: 0.9652666666666667', 'Test Acc: 0.9675', 'Train LL: -0.11723521828638679', 'Test LL: -0.10038969549355524', 'Epoch Time (s): 163.69522202108055')
('Epoch 60', 'Objective: -0.272045510385544', 'Train Acc: 0.96565', 'Test Acc: 0.9673', 'Train LL: -0.11604566221910684', 'Test LL: -0.101231868022623', 'Epoch Time (s): 163.69484238908626')
('Epoch 61', 'Objective: -0.2707729074190876', 'Train Acc: 0.966', 'Test Acc: 0.9699', 'Train LL: -0.11477232477487535', 'Test LL: -0.09874238612553199', 'Epoch Time (s): 163.80165894702077')
('Epoch 62', 'Objective: -0.27270992272267197', 'Train Acc: 0.9661', 'Test Acc: 0.9674', 'Train LL: -0.11678110111637446', 'Test LL: -0.10246063032553611', 'Epoch Time (s): 163.67383609316312')
('Epoch 63', 'Objective: -0.27295630756133327', 'Train Acc: 0.9651666666666666', 'Test Acc: 0.967', 'Train LL: -0.1170054017908048', 'Test LL: -0.10386852735703649', 'Epoch Time (s): 163.66727514192462')
('Epoch 64', 'Objective: -0.2701355182993649', 'Train Acc: 0.9661333333333333', 'Test Acc: 0.9684', 'Train LL: -0.11432512015678375', 'Test LL: -0.10150408472431299', 'Epoch Time (s): 163.65693806298077')
('Epoch 65', 'Objective: -0.2717541384289171', 'Train Acc: 0.9654', 'Test Acc: 0.968', 'Train LL: -0.11583120830767314', 'Test LL: -0.10104687828255553', 'Epoch Time (s): 163.64733684295788')
('Epoch 66', 'Objective: -0.27155120623684664', 'Train Acc: 0.9661666666666666', 'Test Acc: 0.9662', 'Train LL: -0.11581142826111764', 'Test LL: -0.10602786613649619', 'Epoch Time (s): 163.60543746710755')
('Epoch 67', 'Objective: -0.2697356201181494', 'Train Acc: 0.9659833333333333', 'Test Acc: 0.9675', 'Train LL: -0.11459266517135257', 'Test LL: -0.10235432911885493', 'Epoch Time (s): 163.7065034059342')
('Epoch 68', 'Objective: -0.26949595182834235', 'Train Acc: 0.9659166666666666', 'Test Acc: 0.9693', 'Train LL: -0.1140090303847994', 'Test LL: -0.09940901586263108', 'Epoch Time (s): 163.55810215394013')
('Epoch 69', 'Objective: -0.271125153911912', 'Train Acc: 0.9661833333333333', 'Test Acc: 0.9669', 'Train LL: -0.11610174223691334', 'Test LL: -0.10374068282334083', 'Epoch Time (s): 163.53542483993806')
('Epoch 70', 'Objective: -0.27194807578989644', 'Train Acc: 0.9654166666666667', 'Test Acc: 0.9676', 'Train LL: -0.11614135660040845', 'Test LL: -0.10225812380809576', 'Epoch Time (s): 163.60966578312218')
('Epoch 71', 'Objective: -0.2702463415041207', 'Train Acc: 0.9665666666666667', 'Test Acc: 0.9683', 'Train LL: -0.11475837785639799', 'Test LL: -0.09884225630972594', 'Epoch Time (s): 163.69914371799678')
('Epoch 72', 'Objective: -0.27042839567395505', 'Train Acc: 0.9661166666666666', 'Test Acc: 0.9667', 'Train LL: -0.11501034967394784', 'Test LL: -0.10614378223186224', 'Epoch Time (s): 163.82679508789442')
('Epoch 73', 'Objective: -0.271351159744843', 'Train Acc: 0.9661166666666666', 'Test Acc: 0.9689', 'Train LL: -0.11573429689980776', 'Test LL: -0.09992314031770025', 'Epoch Time (s): 163.81793138710782')
('Epoch 74', 'Objective: -0.2693193818031838', 'Train Acc: 0.9662166666666666', 'Test Acc: 0.9672', 'Train LL: -0.11418137203747876', 'Test LL: -0.10202658758189362', 'Epoch Time (s): 163.862541268114')
('Epoch 75', 'Objective: -0.2684161193194867', 'Train Acc: 0.9668666666666667', 'Test Acc: 0.9676', 'Train LL: -0.11318317172295804', 'Test LL: -0.10050372199276339', 'Epoch Time (s): 163.841444788035')
('Epoch 76', 'Objective: -0.2706169962148453', 'Train Acc: 0.9665', 'Test Acc: 0.9674', 'Train LL: -0.11521950433093213', 'Test LL: -0.09882137658631741', 'Epoch Time (s): 163.92603010102175')
('Epoch 77', 'Objective: -0.2676569499344191', 'Train Acc: 0.9664666666666667', 'Test Acc: 0.9666', 'Train LL: -0.11259667391830316', 'Test LL: -0.10968880924116763', 'Epoch Time (s): 163.8660100309644')
('Epoch 78', 'Objective: -0.26884079979548403', 'Train Acc: 0.9662833333333334', 'Test Acc: 0.9674', 'Train LL: -0.11344132709928884', 'Test LL: -0.10350755148826402', 'Epoch Time (s): 163.82818194199353')
('Epoch 79', 'Objective: -0.2678956565835704', 'Train Acc: 0.9665166666666667', 'Test Acc: 0.9673', 'Train LL: -0.11298897559378344', 'Test LL: -0.10203158469823494', 'Epoch Time (s): 163.82454795204103')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.26297668851733746', 'Train Acc: 0.9678', 'Test Acc: 0.9678', 'Train LL: -0.10848810512675612', 'Test LL: -0.09735449892877295', 'Epoch Time (s): 163.87492633704096')
('Epoch 81', 'Objective: -0.2631557819461574', 'Train Acc: 0.9684166666666667', 'Test Acc: 0.9675', 'Train LL: -0.10928468552242636', 'Test LL: -0.09759863392479555', 'Epoch Time (s): 163.68665424291976')
('Epoch 82', 'Objective: -0.2613511837341558', 'Train Acc: 0.9685166666666667', 'Test Acc: 0.9694', 'Train LL: -0.1079463411843923', 'Test LL: -0.09712525955795083', 'Epoch Time (s): 163.37990701314993')
('Epoch 83', 'Objective: -0.26142250914178666', 'Train Acc: 0.9680333333333333', 'Test Acc: 0.9684', 'Train LL: -0.1079856999504025', 'Test LL: -0.09723486203582361', 'Epoch Time (s): 163.55933975591324')
('Epoch 84', 'Objective: -0.26136604276022585', 'Train Acc: 0.9677833333333333', 'Test Acc: 0.9685', 'Train LL: -0.10817793111291546', 'Test LL: -0.0971960120718632', 'Epoch Time (s): 163.67753509711474')
('Epoch 85', 'Objective: -0.26067463868018326', 'Train Acc: 0.9688666666666667', 'Test Acc: 0.969', 'Train LL: -0.10746507374985659', 'Test LL: -0.09615161292990354', 'Epoch Time (s): 163.6847934939433')
('Epoch 86', 'Objective: -0.2610029113525105', 'Train Acc: 0.96885', 'Test Acc: 0.9686', 'Train LL: -0.10791145803384969', 'Test LL: -0.09788187114410347', 'Epoch Time (s): 163.62798786908388')
('Epoch 87', 'Objective: -0.2601856397876351', 'Train Acc: 0.9686166666666667', 'Test Acc: 0.9699', 'Train LL: -0.1070688722375624', 'Test LL: -0.09718583220388176', 'Epoch Time (s): 163.61084475088865')
('Epoch 88', 'Objective: -0.2604310894984336', 'Train Acc: 0.9687833333333333', 'Test Acc: 0.9684', 'Train LL: -0.10733376058359306', 'Test LL: -0.0970491293491061', 'Epoch Time (s): 163.79137705778703')
('Epoch 89', 'Objective: -0.261067246726784', 'Train Acc: 0.9687333333333333', 'Test Acc: 0.9697', 'Train LL: -0.10786883804355306', 'Test LL: -0.09687962215822095', 'Epoch Time (s): 163.702447719872')
('Epoch 90', 'Objective: -0.25973640229596207', 'Train Acc: 0.9686666666666667', 'Test Acc: 0.9682', 'Train LL: -0.10661216133366047', 'Test LL: -0.09663475763153538', 'Epoch Time (s): 163.71897687506862')
('Epoch 91', 'Objective: -0.2605407589811231', 'Train Acc: 0.9686166666666667', 'Test Acc: 0.9694', 'Train LL: -0.10752731742745525', 'Test LL: -0.09680124267259226', 'Epoch Time (s): 163.82492897706106')
('Epoch 92', 'Objective: -0.259556284437141', 'Train Acc: 0.9689166666666666', 'Test Acc: 0.9695', 'Train LL: -0.10685350588667164', 'Test LL: -0.09635271439972425', 'Epoch Time (s): 163.85240758187138')
('Epoch 93', 'Objective: -0.26116375674208', 'Train Acc: 0.9683166666666667', 'Test Acc: 0.9696', 'Train LL: -0.10797108640809217', 'Test LL: -0.0961985438648618', 'Epoch Time (s): 163.85115572507493')
('Epoch 94', 'Objective: -0.25995133823897126', 'Train Acc: 0.9684', 'Test Acc: 0.9686', 'Train LL: -0.10693247436446991', 'Test LL: -0.09649961553939461', 'Epoch Time (s): 163.88166263699532')
('Epoch 95', 'Objective: -0.2601545777203251', 'Train Acc: 0.9682666666666667', 'Test Acc: 0.9683', 'Train LL: -0.106996285960892', 'Test LL: -0.096983182501821', 'Epoch Time (s): 163.8297109119594')
('Epoch 96', 'Objective: -0.25926918213422', 'Train Acc: 0.9687666666666667', 'Test Acc: 0.9687', 'Train LL: -0.1067220474453438', 'Test LL: -0.09646794815245287', 'Epoch Time (s): 163.86081083794124')
('Epoch 97', 'Objective: -0.26030241582870245', 'Train Acc: 0.9684666666666667', 'Test Acc: 0.9686', 'Train LL: -0.10709519476814718', 'Test LL: -0.09656255248150064', 'Epoch Time (s): 163.81436507496983')
('Epoch 98', 'Objective: -0.26037838206461833', 'Train Acc: 0.9684166666666667', 'Test Acc: 0.9684', 'Train LL: -0.107084474150039', 'Test LL: -0.09615644241500043', 'Epoch Time (s): 163.86823282181285')
('Epoch 99', 'Objective: -0.26041108089434645', 'Train Acc: 0.9683333333333334', 'Test Acc: 0.9691', 'Train LL: -0.10744537101080451', 'Test LL: -0.09618658663109171', 'Epoch Time (s): 163.86142623098567')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.25791593862210127
Final Train Accuracy: £0.9693
Final Train LL: £-0.10530803190655703
Final Test Accuracy: £0.9693
Final Test LL: £-0.09616201001098838
