dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 3
bn_indnorm: none
bn_tnorm: none
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.6168237193587776', 'Train Acc: 0.42215', 'Test Acc: 0.6583', 'Train LL: -1.5805868918231984', 'Test LL: -1.0237020939199941', 'Epoch Time (s): 169.83415406988934')
('Epoch 1', 'Objective: -0.7507049826504785', 'Train Acc: 0.7599', 'Test Acc: 0.6776', 'Train LL: -0.6991393691526304', 'Test LL: -0.9069516910776463', 'Epoch Time (s): 168.7785142129287')
('Epoch 2', 'Objective: -0.4441061013387588', 'Train Acc: 0.8718666666666667', 'Test Acc: 0.8977', 'Train LL: -0.3924398425404539', 'Test LL: -0.31252556875110304', 'Epoch Time (s): 168.70137309329584')
('Epoch 3', 'Objective: -0.31569902517269893', 'Train Acc: 0.9183333333333333', 'Test Acc: 0.9269', 'Train LL: -0.2657274136699516', 'Test LL: -0.225830602774017', 'Epoch Time (s): 168.73818517383188')
('Epoch 4', 'Objective: -0.26063840122337634', 'Train Acc: 0.9344166666666667', 'Test Acc: 0.946', 'Train LL: -0.213049369656669', 'Test LL: -0.17947577834177164', 'Epoch Time (s): 168.75379493599758')
('Epoch 5', 'Objective: -0.22156274354020947', 'Train Acc: 0.9449833333333333', 'Test Acc: 0.9383', 'Train LL: -0.17644547546153316', 'Test LL: -0.19655753945470472', 'Epoch Time (s): 168.78034467296675')
('Epoch 6', 'Objective: -0.19648081840260329', 'Train Acc: 0.9529', 'Test Acc: 0.9498', 'Train LL: -0.15439398042091382', 'Test LL: -0.14757298436456134', 'Epoch Time (s): 168.73294043494388')
('Epoch 7', 'Objective: -0.1796818159451874', 'Train Acc: 0.9563333333333334', 'Test Acc: 0.9717', 'Train LL: -0.13954638209281078', 'Test LL: -0.09132078284264344', 'Epoch Time (s): 168.76581803709269')
('Epoch 8', 'Objective: -0.16689820159104748', 'Train Acc: 0.9601333333333333', 'Test Acc: 0.9308', 'Train LL: -0.1274920235449041', 'Test LL: -0.20967015505291237', 'Epoch Time (s): 168.7094207070768')
('Epoch 9', 'Objective: -0.15374589128824911', 'Train Acc: 0.9640666666666666', 'Test Acc: 0.9669', 'Train LL: -0.11578802432001786', 'Test LL: -0.09735527591061946', 'Epoch Time (s): 168.75339558487758')
('Epoch 10', 'Objective: -0.14481928199901797', 'Train Acc: 0.9672', 'Test Acc: 0.955', 'Train LL: -0.10766782127505908', 'Test LL: -0.13729245861494063', 'Epoch Time (s): 168.79732814896852')
('Epoch 11', 'Objective: -0.13420440370990241', 'Train Acc: 0.9689666666666666', 'Test Acc: 0.9702', 'Train LL: -0.0979454574571332', 'Test LL: -0.08846985798797258', 'Epoch Time (s): 168.7733401460573')
('Epoch 12', 'Objective: -0.12783073938331113', 'Train Acc: 0.9714', 'Test Acc: 0.9667', 'Train LL: -0.09214061322540795', 'Test LL: -0.10080837794830334', 'Epoch Time (s): 168.77056870702654')
('Epoch 13', 'Objective: -0.1245604566673556', 'Train Acc: 0.9716666666666667', 'Test Acc: 0.977', 'Train LL: -0.0896449822872625', 'Test LL: -0.0705246709310618', 'Epoch Time (s): 168.72992773307487')
('Epoch 14', 'Objective: -0.12194251031789638', 'Train Acc: 0.9732166666666666', 'Test Acc: 0.9801', 'Train LL: -0.08732211399473555', 'Test LL: -0.05929036649215384', 'Epoch Time (s): 168.7555295219645')
('Epoch 15', 'Objective: -0.11564795698665914', 'Train Acc: 0.974', 'Test Acc: 0.9699', 'Train LL: -0.08166393093385689', 'Test LL: -0.09182623803654531', 'Epoch Time (s): 168.79267303226516')
('Epoch 16', 'Objective: -0.11277318928097889', 'Train Acc: 0.9754666666666667', 'Test Acc: 0.9765', 'Train LL: -0.07910677920127827', 'Test LL: -0.07195240846786269', 'Epoch Time (s): 168.77582757687196')
('Epoch 17', 'Objective: -0.11107589446842565', 'Train Acc: 0.9756833333333333', 'Test Acc: 0.981', 'Train LL: -0.07770283114308103', 'Test LL: -0.06914930218164239', 'Epoch Time (s): 168.79587603313848')
('Epoch 18', 'Objective: -0.10775265589998834', 'Train Acc: 0.9750833333333333', 'Test Acc: 0.9845', 'Train LL: -0.07473190446698688', 'Test LL: -0.0593223120431269', 'Epoch Time (s): 168.7490408839658')
('Epoch 19', 'Objective: -0.10593196354683894', 'Train Acc: 0.9769833333333333', 'Test Acc: 0.976', 'Train LL: -0.07335549174707637', 'Test LL: -0.07712162797352594', 'Epoch Time (s): 168.77832700684667')
('Epoch 20', 'Objective: -0.10225789718854131', 'Train Acc: 0.9775833333333334', 'Test Acc: 0.9775', 'Train LL: -0.07000041660926137', 'Test LL: -0.07542073704049113', 'Epoch Time (s): 168.73355096392334')
('Epoch 21', 'Objective: -0.09988160574648423', 'Train Acc: 0.9785333333333334', 'Test Acc: 0.9799', 'Train LL: -0.06803421721402836', 'Test LL: -0.061070977169719376', 'Epoch Time (s): 168.7147223041393')
('Epoch 22', 'Objective: -0.09899435077358615', 'Train Acc: 0.9786', 'Test Acc: 0.9809', 'Train LL: -0.06738820062709815', 'Test LL: -0.054176807767312506', 'Epoch Time (s): 168.7461823951453')
('Epoch 23', 'Objective: -0.09666594911567249', 'Train Acc: 0.97995', 'Test Acc: 0.9788', 'Train LL: -0.06538689001722477', 'Test LL: -0.06513783181487229', 'Epoch Time (s): 168.727929005865')
('Epoch 24', 'Objective: -0.09550071871246758', 'Train Acc: 0.9800666666666666', 'Test Acc: 0.9756', 'Train LL: -0.06457580530770585', 'Test LL: -0.07129942184864353', 'Epoch Time (s): 168.79005905473605')
('Epoch 25', 'Objective: -0.094387450792398', 'Train Acc: 0.97995', 'Test Acc: 0.9855', 'Train LL: -0.06363640267572791', 'Test LL: -0.043022091076725784', 'Epoch Time (s): 168.78512625675648')
('Epoch 26', 'Objective: -0.09225622937999646', 'Train Acc: 0.9806166666666667', 'Test Acc: 0.9795', 'Train LL: -0.06163963183512351', 'Test LL: -0.05943921260967062', 'Epoch Time (s): 168.7416360201314')
('Epoch 27', 'Objective: -0.09088444171164685', 'Train Acc: 0.9810333333333333', 'Test Acc: 0.9867', 'Train LL: -0.06087973434809245', 'Test LL: -0.04493483418942899', 'Epoch Time (s): 168.73813204374164')
('Epoch 28', 'Objective: -0.08880732730189998', 'Train Acc: 0.9814', 'Test Acc: 0.978', 'Train LL: -0.058756455831972004', 'Test LL: -0.06994433943906159', 'Epoch Time (s): 168.80788008030504')
('Epoch 29', 'Objective: -0.08730677183362182', 'Train Acc: 0.9818166666666667', 'Test Acc: 0.9809', 'Train LL: -0.05770055753637706', 'Test LL: -0.062226177321592226', 'Epoch Time (s): 168.73559061577544')
('Epoch 30', 'Objective: -0.0867944695747767', 'Train Acc: 0.9825666666666667', 'Test Acc: 0.9883', 'Train LL: -0.05739449344963702', 'Test LL: -0.03956193379659472', 'Epoch Time (s): 168.77364533767104')
('Epoch 31', 'Objective: -0.0863169875646374', 'Train Acc: 0.9822333333333333', 'Test Acc: 0.9816', 'Train LL: -0.05715407923694247', 'Test LL: -0.057840131625738936', 'Epoch Time (s): 168.73075004015118')
('Epoch 32', 'Objective: -0.08629604420467585', 'Train Acc: 0.9820833333333333', 'Test Acc: 0.9862', 'Train LL: -0.05714975654559312', 'Test LL: -0.04308145261491207', 'Epoch Time (s): 168.7154409158975')
('Epoch 33', 'Objective: -0.0842765919566211', 'Train Acc: 0.9824333333333334', 'Test Acc: 0.9833', 'Train LL: -0.05524329630695117', 'Test LL: -0.04872192571705242', 'Epoch Time (s): 168.74934408301488')
('Epoch 34', 'Objective: -0.0847485418159555', 'Train Acc: 0.9818166666666667', 'Test Acc: 0.9846', 'Train LL: -0.055855808245133295', 'Test LL: -0.0466038647430553', 'Epoch Time (s): 168.76804178999737')
('Epoch 35', 'Objective: -0.08482125470569629', 'Train Acc: 0.9824666666666667', 'Test Acc: 0.9776', 'Train LL: -0.05615328669463867', 'Test LL: -0.06483601130978904', 'Epoch Time (s): 168.74156511202455')
('Epoch 36', 'Objective: -0.08064745081718973', 'Train Acc: 0.9834833333333334', 'Test Acc: 0.9865', 'Train LL: -0.052327795328672835', 'Test LL: -0.04542966604380854', 'Epoch Time (s): 168.72025067731738')
('Epoch 37', 'Objective: -0.08058403374000933', 'Train Acc: 0.98315', 'Test Acc: 0.9849', 'Train LL: -0.05208790559497195', 'Test LL: -0.047310859288337045', 'Epoch Time (s): 168.80212535103783')
('Epoch 38', 'Objective: -0.08103153085944832', 'Train Acc: 0.9833333333333333', 'Test Acc: 0.9872', 'Train LL: -0.05288607176860391', 'Test LL: -0.04503954876679272', 'Epoch Time (s): 168.7377937338315')
('Epoch 39', 'Objective: -0.08022587631794068', 'Train Acc: 0.9842', 'Test Acc: 0.9833', 'Train LL: -0.05220483200506503', 'Test LL: -0.04749090558383913', 'Epoch Time (s): 168.779459932819')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.058612439856326984', 'Train Acc: 0.9900333333333333', 'Test Acc: 0.9898', 'Train LL: -0.03210444559460583', 'Test LL: -0.029590724126883405', 'Epoch Time (s): 168.76796382525936')
('Epoch 41', 'Objective: -0.05357811448235371', 'Train Acc: 0.9909333333333333', 'Test Acc: 0.9903', 'Train LL: -0.027997585149564665', 'Test LL: -0.030621417296737632', 'Epoch Time (s): 168.7478626901284')
('Epoch 42', 'Objective: -0.05254487430774907', 'Train Acc: 0.9911833333333333', 'Test Acc: 0.9907', 'Train LL: -0.02743105225555966', 'Test LL: -0.028485198266729118', 'Epoch Time (s): 168.79667588416487')
('Epoch 43', 'Objective: -0.0504256457873202', 'Train Acc: 0.9917333333333334', 'Test Acc: 0.9916', 'Train LL: -0.025584624058747056', 'Test LL: -0.02729392378009757', 'Epoch Time (s): 168.8021114198491')
('Epoch 44', 'Objective: -0.05022429439891716', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.9914', 'Train LL: -0.02561430440711093', 'Test LL: -0.026959385776045508', 'Epoch Time (s): 168.78160885395482')
('Epoch 45', 'Objective: -0.0492266750509791', 'Train Acc: 0.9920166666666667', 'Test Acc: 0.99', 'Train LL: -0.024776469200558704', 'Test LL: -0.029890973556508754', 'Epoch Time (s): 168.76635100413114')
('Epoch 46', 'Objective: -0.04883847804447986', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9913', 'Train LL: -0.024569506476906765', 'Test LL: -0.026415811242128166', 'Epoch Time (s): 168.7798875477165')
('Epoch 47', 'Objective: -0.047866723003150105', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9917', 'Train LL: -0.023734182810465215', 'Test LL: -0.027329220853332937', 'Epoch Time (s): 168.7307080947794')
('Epoch 48', 'Objective: -0.048060150636724676', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9911', 'Train LL: -0.024142596566339356', 'Test LL: -0.028685553363154457', 'Epoch Time (s): 168.74885481595993')
('Epoch 49', 'Objective: -0.047384990984658946', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9902', 'Train LL: -0.02355090256191135', 'Test LL: -0.02949993219236474', 'Epoch Time (s): 168.78275044169277')
('Epoch 50', 'Objective: -0.04663497638181718', 'Train Acc: 0.9927666666666667', 'Test Acc: 0.9915', 'Train LL: -0.022991229786474107', 'Test LL: -0.026020084643841652', 'Epoch Time (s): 168.78139009373263')
('Epoch 51', 'Objective: -0.046318398511423935', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.992', 'Train LL: -0.022752874056067254', 'Test LL: -0.02630575262922276', 'Epoch Time (s): 168.77991446014494')
('Epoch 52', 'Objective: -0.04670306173522487', 'Train Acc: 0.99265', 'Test Acc: 0.9912', 'Train LL: -0.02315191025337166', 'Test LL: -0.026713575006491363', 'Epoch Time (s): 168.7161279823631')
('Epoch 53', 'Objective: -0.04670888641243893', 'Train Acc: 0.99255', 'Test Acc: 0.991', 'Train LL: -0.02338650623385879', 'Test LL: -0.028460732178466088', 'Epoch Time (s): 168.81232176627964')
('Epoch 54', 'Objective: -0.04535702912236685', 'Train Acc: 0.9928666666666667', 'Test Acc: 0.9914', 'Train LL: -0.022074339553904025', 'Test LL: -0.027502314517728832', 'Epoch Time (s): 168.76030625309795')
('Epoch 55', 'Objective: -0.04546451045700866', 'Train Acc: 0.993', 'Test Acc: 0.9897', 'Train LL: -0.02230443035106876', 'Test LL: -0.031117886271059002', 'Epoch Time (s): 168.79937716107816')
('Epoch 56', 'Objective: -0.045753810376264956', 'Train Acc: 0.9924833333333334', 'Test Acc: 0.9897', 'Train LL: -0.022574848964664124', 'Test LL: -0.030736660101951214', 'Epoch Time (s): 168.74422212596983')
('Epoch 57', 'Objective: -0.04538857819644844', 'Train Acc: 0.9928833333333333', 'Test Acc: 0.9909', 'Train LL: -0.022384172017150313', 'Test LL: -0.028054790742943838', 'Epoch Time (s): 168.74076914601028')
('Epoch 58', 'Objective: -0.04474226734736586', 'Train Acc: 0.99305', 'Test Acc: 0.9918', 'Train LL: -0.02186336789712881', 'Test LL: -0.02563834128666326', 'Epoch Time (s): 168.7688443181105')
('Epoch 59', 'Objective: -0.04518798239922344', 'Train Acc: 0.9924666666666667', 'Test Acc: 0.9922', 'Train LL: -0.022292690952780782', 'Test LL: -0.02580698682036089', 'Epoch Time (s): 168.81297820573673')
('Epoch 60', 'Objective: -0.04436083857635196', 'Train Acc: 0.9927833333333334', 'Test Acc: 0.9896', 'Train LL: -0.021510403843418378', 'Test LL: -0.031189684675213897', 'Epoch Time (s): 168.69514969317243')
('Epoch 61', 'Objective: -0.044563384022679516', 'Train Acc: 0.993', 'Test Acc: 0.9915', 'Train LL: -0.021862874895475587', 'Test LL: -0.02550959541817689', 'Epoch Time (s): 168.76172680873424')
('Epoch 62', 'Objective: -0.04423502121190149', 'Train Acc: 0.9930166666666667', 'Test Acc: 0.9904', 'Train LL: -0.02156535038190648', 'Test LL: -0.030105565691202617', 'Epoch Time (s): 168.81219743890688')
('Epoch 63', 'Objective: -0.043846645330202015', 'Train Acc: 0.9933666666666666', 'Test Acc: 0.9923', 'Train LL: -0.021194460352023974', 'Test LL: -0.02481801346105343', 'Epoch Time (s): 168.68027289025486')
('Epoch 64', 'Objective: -0.04346685375333128', 'Train Acc: 0.99335', 'Test Acc: 0.9912', 'Train LL: -0.020985964445512074', 'Test LL: -0.028227211325740745', 'Epoch Time (s): 168.67553273029625')
('Epoch 65', 'Objective: -0.043745214021535854', 'Train Acc: 0.9933166666666666', 'Test Acc: 0.991', 'Train LL: -0.02124002088497483', 'Test LL: -0.026793050789102473', 'Epoch Time (s): 168.67032197583467')
('Epoch 66', 'Objective: -0.04359110441991964', 'Train Acc: 0.9933333333333333', 'Test Acc: 0.9921', 'Train LL: -0.02115627234487742', 'Test LL: -0.025642303649595254', 'Epoch Time (s): 168.64818965969607')
('Epoch 67', 'Objective: -0.04291214380745186', 'Train Acc: 0.9931333333333333', 'Test Acc: 0.9917', 'Train LL: -0.020523875421915277', 'Test LL: -0.026097272757243696', 'Epoch Time (s): 168.61811833875254')
('Epoch 68', 'Objective: -0.04266616240254761', 'Train Acc: 0.99335', 'Test Acc: 0.9914', 'Train LL: -0.02039285368202538', 'Test LL: -0.026429624604120277', 'Epoch Time (s): 168.6547352182679')
('Epoch 69', 'Objective: -0.04327057803410302', 'Train Acc: 0.9934333333333333', 'Test Acc: 0.9925', 'Train LL: -0.021079632228081742', 'Test LL: -0.025818407553759318', 'Epoch Time (s): 168.62546642124653')
('Epoch 70', 'Objective: -0.042985595282384624', 'Train Acc: 0.99335', 'Test Acc: 0.9925', 'Train LL: -0.020781032319815245', 'Test LL: -0.0253061155965911', 'Epoch Time (s): 168.63385467929766')
('Epoch 71', 'Objective: -0.042405940546509535', 'Train Acc: 0.9937', 'Test Acc: 0.9917', 'Train LL: -0.02028466810722642', 'Test LL: -0.030019996468813766', 'Epoch Time (s): 168.69022609014064')
('Epoch 72', 'Objective: -0.042634030863053084', 'Train Acc: 0.9935666666666667', 'Test Acc: 0.9917', 'Train LL: -0.02057409055543594', 'Test LL: -0.02694135298819775', 'Epoch Time (s): 168.6816635010764')
('Epoch 73', 'Objective: -0.042782617816430876', 'Train Acc: 0.9935333333333334', 'Test Acc: 0.9909', 'Train LL: -0.020749782411677277', 'Test LL: -0.02930970033327818', 'Epoch Time (s): 168.64908431190997')
('Epoch 74', 'Objective: -0.04143865392049315', 'Train Acc: 0.9937833333333334', 'Test Acc: 0.9928', 'Train LL: -0.019418361954827938', 'Test LL: -0.023746998406375938', 'Epoch Time (s): 168.5804953747429')
('Epoch 75', 'Objective: -0.041879040348597546', 'Train Acc: 0.9936', 'Test Acc: 0.9913', 'Train LL: -0.0199628195864235', 'Test LL: -0.0289996504753406', 'Epoch Time (s): 168.6238451586105')
('Epoch 76', 'Objective: -0.04156054473998113', 'Train Acc: 0.99355', 'Test Acc: 0.9923', 'Train LL: -0.019664509276044642', 'Test LL: -0.025255305829685513', 'Epoch Time (s): 168.66127444570884')
('Epoch 77', 'Objective: -0.04192397110893663', 'Train Acc: 0.994', 'Test Acc: 0.9913', 'Train LL: -0.02012806026616128', 'Test LL: -0.02733794984660944', 'Epoch Time (s): 168.64351697592065')
('Epoch 78', 'Objective: -0.04161583288344958', 'Train Acc: 0.9934833333333334', 'Test Acc: 0.993', 'Train LL: -0.019800756695002038', 'Test LL: -0.024963370683059583', 'Epoch Time (s): 168.66231739101931')
('Epoch 79', 'Objective: -0.04093496011735197', 'Train Acc: 0.9938666666666667', 'Test Acc: 0.9912', 'Train LL: -0.019166770164078542', 'Test LL: -0.029495911512761756', 'Epoch Time (s): 168.68269605794922')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.039336528772521744', 'Train Acc: 0.99435', 'Test Acc: 0.9922', 'Train LL: -0.017693345337476896', 'Test LL: -0.02638485955083646', 'Epoch Time (s): 168.6449949312955')
('Epoch 81', 'Objective: -0.03769147055145415', 'Train Acc: 0.9948', 'Test Acc: 0.9924', 'Train LL: -0.01621937215677173', 'Test LL: -0.025691167923634704', 'Epoch Time (s): 168.70350995101035')
('Epoch 82', 'Objective: -0.03763148895007021', 'Train Acc: 0.995', 'Test Acc: 0.992', 'Train LL: -0.016094415432362553', 'Test LL: -0.026837553918881474', 'Epoch Time (s): 168.74389738822356')
('Epoch 83', 'Objective: -0.0376805229766454', 'Train Acc: 0.99485', 'Test Acc: 0.9924', 'Train LL: -0.01616078292800419', 'Test LL: -0.026235722661118815', 'Epoch Time (s): 168.64210826531053')
('Epoch 84', 'Objective: -0.03735936381011257', 'Train Acc: 0.9948', 'Test Acc: 0.9921', 'Train LL: -0.015897307714097815', 'Test LL: -0.026340707183630938', 'Epoch Time (s): 168.68404651992023')
('Epoch 85', 'Objective: -0.0376514849145518', 'Train Acc: 0.9947833333333334', 'Test Acc: 0.9924', 'Train LL: -0.016183484314913944', 'Test LL: -0.026026612622956042', 'Epoch Time (s): 168.6491379979998')
('Epoch 86', 'Objective: -0.03780212273544522', 'Train Acc: 0.9948333333333333', 'Test Acc: 0.9919', 'Train LL: -0.01630092155336745', 'Test LL: -0.026774833005526785', 'Epoch Time (s): 168.6558331027627')
('Epoch 87', 'Objective: -0.03723002493249501', 'Train Acc: 0.995', 'Test Acc: 0.9923', 'Train LL: -0.015810180081687768', 'Test LL: -0.02613905378129456', 'Epoch Time (s): 168.70400429004803')
('Epoch 88', 'Objective: -0.03754019542772604', 'Train Acc: 0.995', 'Test Acc: 0.9918', 'Train LL: -0.016017460614243365', 'Test LL: -0.02741476223095364', 'Epoch Time (s): 168.77625072328374')
('Epoch 89', 'Objective: -0.037072044570211446', 'Train Acc: 0.99505', 'Test Acc: 0.9917', 'Train LL: -0.01564613565890021', 'Test LL: -0.027142950084054946', 'Epoch Time (s): 168.6503643533215')
('Epoch 90', 'Objective: -0.03759450749630425', 'Train Acc: 0.99465', 'Test Acc: 0.9925', 'Train LL: -0.016146335897420334', 'Test LL: -0.026172512780585175', 'Epoch Time (s): 168.6576928771101')
('Epoch 91', 'Objective: -0.03788564144443541', 'Train Acc: 0.9951', 'Test Acc: 0.9917', 'Train LL: -0.01645674415326108', 'Test LL: -0.026772742844608764', 'Epoch Time (s): 168.6806021532975')
('Epoch 92', 'Objective: -0.03676561030695344', 'Train Acc: 0.9951833333333333', 'Test Acc: 0.9921', 'Train LL: -0.01542077147269992', 'Test LL: -0.027656927584179494', 'Epoch Time (s): 168.6445283438079')
('Epoch 93', 'Objective: -0.03695777816111745', 'Train Acc: 0.9952333333333333', 'Test Acc: 0.992', 'Train LL: -0.015485799400353906', 'Test LL: -0.027168984658923506', 'Epoch Time (s): 168.65382309490815')
('Epoch 94', 'Objective: -0.037414239253871454', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.9923', 'Train LL: -0.016006705963043554', 'Test LL: -0.026511033722219832', 'Epoch Time (s): 168.69088947074488')
('Epoch 95', 'Objective: -0.037324651951226064', 'Train Acc: 0.9947666666666667', 'Test Acc: 0.9926', 'Train LL: -0.01592391048010142', 'Test LL: -0.026198065034106516', 'Epoch Time (s): 168.66175334714353')
('Epoch 96', 'Objective: -0.03706251215969669', 'Train Acc: 0.99525', 'Test Acc: 0.9925', 'Train LL: -0.015670889802121304', 'Test LL: -0.02658248525734092', 'Epoch Time (s): 168.6619206201285')
('Epoch 97', 'Objective: -0.03719765679715875', 'Train Acc: 0.99475', 'Test Acc: 0.9921', 'Train LL: -0.015733233856487592', 'Test LL: -0.02665490089623529', 'Epoch Time (s): 168.66089630499482')
('Epoch 98', 'Objective: -0.03741326194019792', 'Train Acc: 0.9951333333333333', 'Test Acc: 0.9922', 'Train LL: -0.01600127341358466', 'Test LL: -0.026113664048496105', 'Epoch Time (s): 168.64375556539744')
('Epoch 99', 'Objective: -0.03711232296880381', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.9925', 'Train LL: -0.01573880447821123', 'Test LL: -0.02628867708242537', 'Epoch Time (s): 168.64077700627968')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03641104709613928
Final Train Accuracy: £0.9952833333333333
Final Train LL: £-0.0151600619068818
Final Test Accuracy: £0.9925
Final Test LL: £-0.026312964651759876
