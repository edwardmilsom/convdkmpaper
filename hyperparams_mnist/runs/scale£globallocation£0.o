dataset: MNIST
dtype: float64
dof: 1.0
init_lr: 0.01
seed: 0
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: location
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.4332759773374206', 'Train Acc: 0.4865333333333333', 'Test Acc: 0.7718', 'Train LL: -1.3890982411345447', 'Test LL: -0.6722025306701447', 'Epoch Time (s): 163.5461123290006')
('Epoch 1', 'Objective: -0.5891666396431997', 'Train Acc: 0.8146833333333333', 'Test Acc: 0.8868', 'Train LL: -0.5427590439334917', 'Test LL: -0.34550390386072205', 'Epoch Time (s): 163.65079214796424')
('Epoch 2', 'Objective: -0.3438539182045373', 'Train Acc: 0.9065833333333333', 'Test Acc: 0.9211', 'Train LL: -0.2971826882995825', 'Test LL: -0.237436934263846', 'Epoch Time (s): 163.6376464809291')
('Epoch 3', 'Objective: -0.26840219742251215', 'Train Acc: 0.9304833333333333', 'Test Acc: 0.9416', 'Train LL: -0.22434897493588005', 'Test LL: -0.18085628893163885', 'Epoch Time (s): 163.63218853902072')
('Epoch 4', 'Objective: -0.22646034746626426', 'Train Acc: 0.94215', 'Test Acc: 0.9505', 'Train LL: -0.1842505230541306', 'Test LL: -0.15893884836298272', 'Epoch Time (s): 163.67505173408426')
('Epoch 5', 'Objective: -0.20080399109781497', 'Train Acc: 0.9512666666666667', 'Test Acc: 0.9632', 'Train LL: -0.15980143337325345', 'Test LL: -0.11465499277983693', 'Epoch Time (s): 163.6561254260596')
('Epoch 6', 'Objective: -0.18130142442151972', 'Train Acc: 0.9558', 'Test Acc: 0.9649', 'Train LL: -0.14132395595242153', 'Test LL: -0.11098306873550826', 'Epoch Time (s): 163.6176287229173')
('Epoch 7', 'Objective: -0.1695746495548143', 'Train Acc: 0.9591666666666666', 'Test Acc: 0.9659', 'Train LL: -0.1303986824041526', 'Test LL: -0.10350756792018205', 'Epoch Time (s): 163.6337533639744')
('Epoch 8', 'Objective: -0.1581707698279195', 'Train Acc: 0.96215', 'Test Acc: 0.9553', 'Train LL: -0.12010988461832692', 'Test LL: -0.13073586274594237', 'Epoch Time (s): 163.61566851311363')
('Epoch 9', 'Objective: -0.15024983239624537', 'Train Acc: 0.9643333333333334', 'Test Acc: 0.9718', 'Train LL: -0.11281622160479615', 'Test LL: -0.09003971037343218', 'Epoch Time (s): 163.61001443304121')
('Epoch 10', 'Objective: -0.14265211693626315', 'Train Acc: 0.9665333333333334', 'Test Acc: 0.9692', 'Train LL: -0.10609319833173472', 'Test LL: -0.09816324586674224', 'Epoch Time (s): 163.6007796600461')
('Epoch 11', 'Objective: -0.13471696259538213', 'Train Acc: 0.9684666666666667', 'Test Acc: 0.9705', 'Train LL: -0.09866160891494304', 'Test LL: -0.0899681157735503', 'Epoch Time (s): 163.67919462104328')
('Epoch 12', 'Objective: -0.1301206611720494', 'Train Acc: 0.9702333333333333', 'Test Acc: 0.9715', 'Train LL: -0.09474731112540641', 'Test LL: -0.09363258559102178', 'Epoch Time (s): 163.63978351396509')
('Epoch 13', 'Objective: -0.12469606868306031', 'Train Acc: 0.9711833333333333', 'Test Acc: 0.9757', 'Train LL: -0.09007440871310153', 'Test LL: -0.07691185497417323', 'Epoch Time (s): 163.59468096587807')
('Epoch 14', 'Objective: -0.12379428094623297', 'Train Acc: 0.9717333333333333', 'Test Acc: 0.9694', 'Train LL: -0.08954725301151067', 'Test LL: -0.09818995258664781', 'Epoch Time (s): 163.6067122099921')
('Epoch 15', 'Objective: -0.11719109064438114', 'Train Acc: 0.974', 'Test Acc: 0.9768', 'Train LL: -0.08363255439325655', 'Test LL: -0.07170513671001663', 'Epoch Time (s): 163.6301162079908')
('Epoch 16', 'Objective: -0.1137699948741102', 'Train Acc: 0.97415', 'Test Acc: 0.9802', 'Train LL: -0.08095934808176339', 'Test LL: -0.05987117818475927', 'Epoch Time (s): 163.60444771498442')
('Epoch 17', 'Objective: -0.11419882002135372', 'Train Acc: 0.9745', 'Test Acc: 0.982', 'Train LL: -0.08173240176419443', 'Test LL: -0.05771215383278757', 'Epoch Time (s): 163.65569903887808')
('Epoch 18', 'Objective: -0.11109824346797317', 'Train Acc: 0.97515', 'Test Acc: 0.9671', 'Train LL: -0.07912581026918171', 'Test LL: -0.09965944363802362', 'Epoch Time (s): 163.5999068969395')
('Epoch 19', 'Objective: -0.10949073112219213', 'Train Acc: 0.9749333333333333', 'Test Acc: 0.9761', 'Train LL: -0.07762146620870475', 'Test LL: -0.07322684545999561', 'Epoch Time (s): 163.61136563611217')
('Epoch 20', 'Objective: -0.10568970203945811', 'Train Acc: 0.97675', 'Test Acc: 0.9709', 'Train LL: -0.07447501770810813', 'Test LL: -0.08964258315624482', 'Epoch Time (s): 163.58493895083666')
('Epoch 21', 'Objective: -0.10388269567111497', 'Train Acc: 0.977', 'Test Acc: 0.9808', 'Train LL: -0.07275635823979482', 'Test LL: -0.06098496892606112', 'Epoch Time (s): 163.6122009488754')
('Epoch 22', 'Objective: -0.10130799523285924', 'Train Acc: 0.9774', 'Test Acc: 0.9826', 'Train LL: -0.07085362794640905', 'Test LL: -0.057883251999028426', 'Epoch Time (s): 163.62386360182427')
('Epoch 23', 'Objective: -0.10048798310880687', 'Train Acc: 0.9777', 'Test Acc: 0.9767', 'Train LL: -0.07026968058734898', 'Test LL: -0.07379340697188981', 'Epoch Time (s): 163.60053467284888')
('Epoch 24', 'Objective: -0.10011497064347695', 'Train Acc: 0.9777666666666667', 'Test Acc: 0.9792', 'Train LL: -0.06988294887850789', 'Test LL: -0.06157597527208512', 'Epoch Time (s): 163.6122543020174')
('Epoch 25', 'Objective: -0.09722444241471176', 'Train Acc: 0.9785333333333334', 'Test Acc: 0.9733', 'Train LL: -0.06739372974058107', 'Test LL: -0.07429049840856383', 'Epoch Time (s): 163.6343496059999')
('Epoch 26', 'Objective: -0.0985097785159049', 'Train Acc: 0.97855', 'Test Acc: 0.9816', 'Train LL: -0.06885649422441911', 'Test LL: -0.060447101122691096', 'Epoch Time (s): 163.5959668380674')
('Epoch 27', 'Objective: -0.09439785012552014', 'Train Acc: 0.9795333333333334', 'Test Acc: 0.9816', 'Train LL: -0.06514088199852744', 'Test LL: -0.06249120969269081', 'Epoch Time (s): 163.59782032296062')
('Epoch 28', 'Objective: -0.09443760664598139', 'Train Acc: 0.9796333333333334', 'Test Acc: 0.9709', 'Train LL: -0.0655030435684755', 'Test LL: -0.08766242769025392', 'Epoch Time (s): 163.6150927809067')
('Epoch 29', 'Objective: -0.09316235853934297', 'Train Acc: 0.9793', 'Test Acc: 0.9792', 'Train LL: -0.06431017429664578', 'Test LL: -0.06061696629728529', 'Epoch Time (s): 163.5971442121081')
('Epoch 30', 'Objective: -0.09252541404389669', 'Train Acc: 0.9794333333333334', 'Test Acc: 0.9832', 'Train LL: -0.0640545725735957', 'Test LL: -0.05738630951630261', 'Epoch Time (s): 163.59634262905456')
('Epoch 31', 'Objective: -0.0911389537605748', 'Train Acc: 0.9797', 'Test Acc: 0.9784', 'Train LL: -0.06281358024675757', 'Test LL: -0.07298735377838679', 'Epoch Time (s): 163.6137570119463')
('Epoch 32', 'Objective: -0.09021175917780255', 'Train Acc: 0.97995', 'Test Acc: 0.9788', 'Train LL: -0.0620859483216605', 'Test LL: -0.060200939318202244', 'Epoch Time (s): 163.61354466411285')
('Epoch 33', 'Objective: -0.08869728116249713', 'Train Acc: 0.9804166666666667', 'Test Acc: 0.9849', 'Train LL: -0.060769804493389645', 'Test LL: -0.04460617869403054', 'Epoch Time (s): 163.63488503498957')
('Epoch 34', 'Objective: -0.08630773050215641', 'Train Acc: 0.9809666666666667', 'Test Acc: 0.9812', 'Train LL: -0.058694452395571986', 'Test LL: -0.058001053375907385', 'Epoch Time (s): 163.60555914300494')
('Epoch 35', 'Objective: -0.08537054899983831', 'Train Acc: 0.9818666666666667', 'Test Acc: 0.9754', 'Train LL: -0.05824413700291276', 'Test LL: -0.07420623143248384', 'Epoch Time (s): 163.6053320809733')
('Epoch 36', 'Objective: -0.08491209568057852', 'Train Acc: 0.9811666666666666', 'Test Acc: 0.9841', 'Train LL: -0.05800044204122126', 'Test LL: -0.04754822201294312', 'Epoch Time (s): 163.68724758992903')
('Epoch 37', 'Objective: -0.08433828269840235', 'Train Acc: 0.98145', 'Test Acc: 0.9797', 'Train LL: -0.057568720921648574', 'Test LL: -0.058872773356671654', 'Epoch Time (s): 163.63471963093616')
('Epoch 38', 'Objective: -0.08344448140101808', 'Train Acc: 0.9814166666666667', 'Test Acc: 0.9896', 'Train LL: -0.05676354070207658', 'Test LL: -0.03440890067088155', 'Epoch Time (s): 163.6193578769453')
('Epoch 39', 'Objective: -0.08099079564886837', 'Train Acc: 0.9827333333333333', 'Test Acc: 0.9826', 'Train LL: -0.054736758331226744', 'Test LL: -0.05394889751249032', 'Epoch Time (s): 163.60043416381814')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.06126720240290709', 'Train Acc: 0.9883333333333333', 'Test Acc: 0.9901', 'Train LL: -0.03682244287018024', 'Test LL: -0.03296159687796152', 'Epoch Time (s): 163.5829304479994')
('Epoch 41', 'Objective: -0.05478192761517988', 'Train Acc: 0.9898', 'Test Acc: 0.9906', 'Train LL: -0.031216495156542796', 'Test LL: -0.029593027221962154', 'Epoch Time (s): 163.59800188918598')
('Epoch 42', 'Objective: -0.0527681201353336', 'Train Acc: 0.9901333333333333', 'Test Acc: 0.9895', 'Train LL: -0.029594105951379474', 'Test LL: -0.03205028238637589', 'Epoch Time (s): 163.58693722705357')
('Epoch 43', 'Objective: -0.051754152716688935', 'Train Acc: 0.9904833333333334', 'Test Acc: 0.99', 'Train LL: -0.0287610497095055', 'Test LL: -0.031998074805537076', 'Epoch Time (s): 163.57419242104515')
('Epoch 44', 'Objective: -0.05203192331632711', 'Train Acc: 0.9900666666666667', 'Test Acc: 0.9907', 'Train LL: -0.029207716861161154', 'Test LL: -0.030781059124979866', 'Epoch Time (s): 163.56771436403506')
('Epoch 45', 'Objective: -0.049696431004948534', 'Train Acc: 0.9912', 'Test Acc: 0.9894', 'Train LL: -0.027183576671424473', 'Test LL: -0.03292962121229172', 'Epoch Time (s): 163.5967322050128')
('Epoch 46', 'Objective: -0.05013154860430197', 'Train Acc: 0.9910166666666667', 'Test Acc: 0.989', 'Train LL: -0.027747313808283425', 'Test LL: -0.033567392094756086', 'Epoch Time (s): 163.59354091086425')
('Epoch 47', 'Objective: -0.05006212389816834', 'Train Acc: 0.9910833333333333', 'Test Acc: 0.9893', 'Train LL: -0.027783498126305203', 'Test LL: -0.03154185652319511', 'Epoch Time (s): 163.58403010410257')
('Epoch 48', 'Objective: -0.049391391971816884', 'Train Acc: 0.9910666666666667', 'Test Acc: 0.9908', 'Train LL: -0.02727361005074283', 'Test LL: -0.029634407773895116', 'Epoch Time (s): 163.6174909491092')
('Epoch 49', 'Objective: -0.04856182230152243', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9895', 'Train LL: -0.026600590294588982', 'Test LL: -0.034391006457642155', 'Epoch Time (s): 163.60976632405072')
('Epoch 50', 'Objective: -0.04813404426365562', 'Train Acc: 0.9916166666666667', 'Test Acc: 0.991', 'Train LL: -0.02629768320587177', 'Test LL: -0.029165152127908583', 'Epoch Time (s): 163.57787507679313')
('Epoch 51', 'Objective: -0.04754246986334704', 'Train Acc: 0.9916666666666667', 'Test Acc: 0.9881', 'Train LL: -0.025731294305684434', 'Test LL: -0.03483810586695935', 'Epoch Time (s): 163.6001678351313')
('Epoch 52', 'Objective: -0.047243308517291166', 'Train Acc: 0.9915333333333334', 'Test Acc: 0.9903', 'Train LL: -0.025532674282655692', 'Test LL: -0.02906929990021894', 'Epoch Time (s): 163.61124987108633')
('Epoch 53', 'Objective: -0.04664176937684459', 'Train Acc: 0.9917833333333334', 'Test Acc: 0.9909', 'Train LL: -0.025144998441157956', 'Test LL: -0.02833976710930086', 'Epoch Time (s): 163.62559905997477')
('Epoch 54', 'Objective: -0.04708430719802206', 'Train Acc: 0.9916833333333334', 'Test Acc: 0.9905', 'Train LL: -0.02560777684265701', 'Test LL: -0.02928828287449667', 'Epoch Time (s): 163.62916817096993')
('Epoch 55', 'Objective: -0.0463443268994909', 'Train Acc: 0.9915666666666667', 'Test Acc: 0.9903', 'Train LL: -0.02486793660000853', 'Test LL: -0.03088017985522646', 'Epoch Time (s): 163.61236098990776')
('Epoch 56', 'Objective: -0.04581083076082007', 'Train Acc: 0.992', 'Test Acc: 0.9906', 'Train LL: -0.02446601802960294', 'Test LL: -0.029905978305453874', 'Epoch Time (s): 163.6240900720004')
('Epoch 57', 'Objective: -0.045105370457329375', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9897', 'Train LL: -0.0238247515846715', 'Test LL: -0.031850759322640324', 'Epoch Time (s): 163.6148552489467')
('Epoch 58', 'Objective: -0.045397930392773754', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9907', 'Train LL: -0.024189899777181813', 'Test LL: -0.03103309991721307', 'Epoch Time (s): 163.57546227495186')
('Epoch 59', 'Objective: -0.04574797694215708', 'Train Acc: 0.9919666666666667', 'Test Acc: 0.9907', 'Train LL: -0.024666763579866028', 'Test LL: -0.031480631531169596', 'Epoch Time (s): 163.62223430210724')
('Epoch 60', 'Objective: -0.04641302839437516', 'Train Acc: 0.9914166666666666', 'Test Acc: 0.9897', 'Train LL: -0.025344149529664045', 'Test LL: -0.030754363911247997', 'Epoch Time (s): 163.569114419166')
('Epoch 61', 'Objective: -0.045060315095303775', 'Train Acc: 0.99195', 'Test Acc: 0.9896', 'Train LL: -0.024109812076136616', 'Test LL: -0.032613369650690394', 'Epoch Time (s): 163.641918807989')
('Epoch 62', 'Objective: -0.044795751168935125', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.991', 'Train LL: -0.023898546678572254', 'Test LL: -0.03061634349055264', 'Epoch Time (s): 163.5750010102056')
('Epoch 63', 'Objective: -0.04436110067933398', 'Train Acc: 0.9921666666666666', 'Test Acc: 0.9903', 'Train LL: -0.02358083227616325', 'Test LL: -0.03141503332809141', 'Epoch Time (s): 163.5742057489697')
('Epoch 64', 'Objective: -0.044779083075419994', 'Train Acc: 0.99245', 'Test Acc: 0.9907', 'Train LL: -0.024024452988821735', 'Test LL: -0.028460727015329326', 'Epoch Time (s): 163.6023740801029')
('Epoch 65', 'Objective: -0.04469763764185984', 'Train Acc: 0.9922833333333333', 'Test Acc: 0.9911', 'Train LL: -0.02406983712577092', 'Test LL: -0.02781672338161045', 'Epoch Time (s): 164.22282579517923')
('Epoch 66', 'Objective: -0.04424437011169308', 'Train Acc: 0.9925166666666667', 'Test Acc: 0.9903', 'Train LL: -0.023592858964573762', 'Test LL: -0.031262774826632485', 'Epoch Time (s): 163.4547360141296')
('Epoch 67', 'Objective: -0.04433954634207003', 'Train Acc: 0.9923333333333333', 'Test Acc: 0.9907', 'Train LL: -0.023754373294317763', 'Test LL: -0.02821471744237624', 'Epoch Time (s): 163.42483622790314')
('Epoch 68', 'Objective: -0.04400945747460976', 'Train Acc: 0.9921333333333333', 'Test Acc: 0.9905', 'Train LL: -0.023469114963620745', 'Test LL: -0.02985642476207614', 'Epoch Time (s): 163.41069195815362')
('Epoch 69', 'Objective: -0.042795641100089196', 'Train Acc: 0.9926', 'Test Acc: 0.9899', 'Train LL: -0.022336865398373894', 'Test LL: -0.030112123081382607', 'Epoch Time (s): 163.40622917190194')
('Epoch 70', 'Objective: -0.04336733184122014', 'Train Acc: 0.9923666666666666', 'Test Acc: 0.9902', 'Train LL: -0.02286195726197638', 'Test LL: -0.028198786479594094', 'Epoch Time (s): 163.37696052901447')
('Epoch 71', 'Objective: -0.04357500749850091', 'Train Acc: 0.9923166666666666', 'Test Acc: 0.9902', 'Train LL: -0.02312045014203984', 'Test LL: -0.031128769968268695', 'Epoch Time (s): 163.38710149982944')
('Epoch 72', 'Objective: -0.04283900799987089', 'Train Acc: 0.9928', 'Test Acc: 0.9888', 'Train LL: -0.02249654966562029', 'Test LL: -0.03153646851812811', 'Epoch Time (s): 163.40800317400135')
('Epoch 73', 'Objective: -0.04237377990585496', 'Train Acc: 0.9929333333333333', 'Test Acc: 0.9894', 'Train LL: -0.02203100474751983', 'Test LL: -0.033093014767636944', 'Epoch Time (s): 163.4117466218304')
('Epoch 74', 'Objective: -0.0428911778715597', 'Train Acc: 0.9924166666666666', 'Test Acc: 0.9904', 'Train LL: -0.02255743905813604', 'Test LL: -0.03020848180786806', 'Epoch Time (s): 163.3821295700036')
('Epoch 75', 'Objective: -0.0424269903321874', 'Train Acc: 0.99245', 'Test Acc: 0.9901', 'Train LL: -0.022183759003034372', 'Test LL: -0.03086484040125007', 'Epoch Time (s): 163.39526332099922')
('Epoch 76', 'Objective: -0.04277714332614768', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9899', 'Train LL: -0.02259077098016753', 'Test LL: -0.02876772269536623', 'Epoch Time (s): 163.40083358390257')
('Epoch 77', 'Objective: -0.042766218745346245', 'Train Acc: 0.9925333333333334', 'Test Acc: 0.9894', 'Train LL: -0.022536997415200138', 'Test LL: -0.0321653378499195', 'Epoch Time (s): 163.4057952449657')
('Epoch 78', 'Objective: -0.04288012310391058', 'Train Acc: 0.9927166666666667', 'Test Acc: 0.9907', 'Train LL: -0.022761163607815518', 'Test LL: -0.03062815030520274', 'Epoch Time (s): 163.38555171503685')
('Epoch 79', 'Objective: -0.04308770802351997', 'Train Acc: 0.9923833333333333', 'Test Acc: 0.9914', 'Train LL: -0.02300128821361449', 'Test LL: -0.02813240700972889', 'Epoch Time (s): 163.4034883119166')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.03990225071128037', 'Train Acc: 0.99355', 'Test Acc: 0.9906', 'Train LL: -0.020174684610339607', 'Test LL: -0.028663831187239863', 'Epoch Time (s): 163.46425889991224')
('Epoch 81', 'Objective: -0.03892504154060755', 'Train Acc: 0.9938', 'Test Acc: 0.9909', 'Train LL: -0.019187116421703527', 'Test LL: -0.028725944544358267', 'Epoch Time (s): 163.36329001700506')
('Epoch 82', 'Objective: -0.03881205869613827', 'Train Acc: 0.9937', 'Test Acc: 0.9907', 'Train LL: -0.019043448611583077', 'Test LL: -0.028545734977128836', 'Epoch Time (s): 163.389215269126')
('Epoch 83', 'Objective: -0.038929545782207246', 'Train Acc: 0.9935833333333334', 'Test Acc: 0.991', 'Train LL: -0.019151718459988726', 'Test LL: -0.02904711291034601', 'Epoch Time (s): 163.3769784439355')
('Epoch 84', 'Objective: -0.038334185394697975', 'Train Acc: 0.9939', 'Test Acc: 0.9909', 'Train LL: -0.01858448463763505', 'Test LL: -0.029186340116533233', 'Epoch Time (s): 163.38789145299233')
('Epoch 85', 'Objective: -0.038027486592876615', 'Train Acc: 0.9938666666666667', 'Test Acc: 0.9904', 'Train LL: -0.018271305040767516', 'Test LL: -0.02848777547791223', 'Epoch Time (s): 163.45740655087866')
('Epoch 86', 'Objective: -0.038427873988377693', 'Train Acc: 0.9936666666666667', 'Test Acc: 0.9903', 'Train LL: -0.01862967098128189', 'Test LL: -0.02964297798304068', 'Epoch Time (s): 163.4030862171203')
('Epoch 87', 'Objective: -0.03830453657613248', 'Train Acc: 0.99425', 'Test Acc: 0.9907', 'Train LL: -0.018556726394787094', 'Test LL: -0.02910368012641951', 'Epoch Time (s): 163.41180633404292')
('Epoch 88', 'Objective: -0.03849613088125281', 'Train Acc: 0.9937666666666667', 'Test Acc: 0.9912', 'Train LL: -0.018723177478966582', 'Test LL: -0.0290999806940538', 'Epoch Time (s): 163.3716115129646')
('Epoch 89', 'Objective: -0.03840036945032376', 'Train Acc: 0.9939833333333333', 'Test Acc: 0.9909', 'Train LL: -0.018607308813778586', 'Test LL: -0.029233689886975178', 'Epoch Time (s): 163.40044923406094')
('Epoch 90', 'Objective: -0.038545662448245435', 'Train Acc: 0.9938333333333333', 'Test Acc: 0.9912', 'Train LL: -0.01874782338371363', 'Test LL: -0.027820709155049837', 'Epoch Time (s): 163.40675083710812')
('Epoch 91', 'Objective: -0.03852736171352694', 'Train Acc: 0.994', 'Test Acc: 0.9911', 'Train LL: -0.018745922427782027', 'Test LL: -0.02851551330588701', 'Epoch Time (s): 163.35274584498256')
('Epoch 92', 'Objective: -0.03770128851746347', 'Train Acc: 0.9940833333333333', 'Test Acc: 0.9907', 'Train LL: -0.017982785220746412', 'Test LL: -0.02976398229174925', 'Epoch Time (s): 163.35658602812327')
('Epoch 93', 'Objective: -0.038379880345073995', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.9905', 'Train LL: -0.018628845402796742', 'Test LL: -0.028907557833039436', 'Epoch Time (s): 163.3518055351451')
('Epoch 94', 'Objective: -0.0375789287698203', 'Train Acc: 0.9940333333333333', 'Test Acc: 0.9912', 'Train LL: -0.017885650332437174', 'Test LL: -0.028216895851239668', 'Epoch Time (s): 163.37170694512315')
('Epoch 95', 'Objective: -0.037589268431915436', 'Train Acc: 0.99415', 'Test Acc: 0.9911', 'Train LL: -0.01786062889152539', 'Test LL: -0.028870345139579524', 'Epoch Time (s): 163.36291192588396')
('Epoch 96', 'Objective: -0.037720803784716976', 'Train Acc: 0.99415', 'Test Acc: 0.9911', 'Train LL: -0.018015446091499823', 'Test LL: -0.029539189714609324', 'Epoch Time (s): 163.3933046630118')
('Epoch 97', 'Objective: -0.037951265364648', 'Train Acc: 0.9940166666666667', 'Test Acc: 0.991', 'Train LL: -0.01819143325225184', 'Test LL: -0.029451284514908495', 'Epoch Time (s): 163.37214401783422')
('Epoch 98', 'Objective: -0.03794766544746207', 'Train Acc: 0.9939833333333333', 'Test Acc: 0.9912', 'Train LL: -0.018188149927830917', 'Test LL: -0.02827138339578895', 'Epoch Time (s): 163.36747034196742')
('Epoch 99', 'Objective: -0.0380358793196134', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9912', 'Train LL: -0.018309992711523764', 'Test LL: -0.027861382185169117', 'Epoch Time (s): 163.4009603660088')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.03702607272150061
Final Train Accuracy: £0.9944333333333333
Final Train LL: £-0.01738806402957083
Final Test Accuracy: £0.9914
Final Test LL: £-0.02769649028002632
