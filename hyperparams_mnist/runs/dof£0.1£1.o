dataset: MNIST
dtype: float64
dof: 0.1
init_lr: 0.01
seed: 1
bn_indnorm: global
bn_tnorm: global
bn_indscale: global
bn_tscale: global
final_layer: GAP
likelihood: categorical
n_ind_scale: 8
x_ind shape: torch.Size([128, 1, 3, 3])
Inducing inputs learned: True
Model in CUDA: True
('Epoch 0', 'Objective: -1.2548198120389975', 'Train Acc: 0.5643166666666667', 'Test Acc: 0.8344', 'Train LL: -1.219560054783018', 'Test LL: -0.49188462436681896', 'Epoch Time (s): 171.57622193126008')
('Epoch 1', 'Objective: -0.44096829639257096', 'Train Acc: 0.8633333333333333', 'Test Acc: 0.91', 'Train LL: -0.4122436292973561', 'Test LL: -0.28014363986139196', 'Epoch Time (s): 170.57050423603505')
('Epoch 2', 'Objective: -0.27564995490333327', 'Train Acc: 0.9216333333333333', 'Test Acc: 0.9398', 'Train LL: -0.24894382192429682', 'Test LL: -0.19141240788796085', 'Epoch Time (s): 170.58813669113442')
('Epoch 3', 'Objective: -0.21161564943593603', 'Train Acc: 0.9419166666666666', 'Test Acc: 0.9457', 'Train LL: -0.18695280388016836', 'Test LL: -0.16978697289783948', 'Epoch Time (s): 170.55662854295224')
('Epoch 4', 'Objective: -0.17754421328641734', 'Train Acc: 0.9519166666666666', 'Test Acc: 0.9556', 'Train LL: -0.15474447718621923', 'Test LL: -0.14716047712006003', 'Epoch Time (s): 170.57049755379558')
('Epoch 5', 'Objective: -0.15351395664607292', 'Train Acc: 0.9588666666666666', 'Test Acc: 0.9682', 'Train LL: -0.13230156503516835', 'Test LL: -0.09819567076434164', 'Epoch Time (s): 170.5893550622277')
('Epoch 6', 'Objective: -0.13880304108214275', 'Train Acc: 0.9632833333333334', 'Test Acc: 0.9642', 'Train LL: -0.11882908196645893', 'Test LL: -0.10818811514973092', 'Epoch Time (s): 170.5137901478447')
('Epoch 7', 'Objective: -0.12456195068033103', 'Train Acc: 0.9671333333333333', 'Test Acc: 0.9674', 'Train LL: -0.10561773855867836', 'Test LL: -0.10489587376969398', 'Epoch Time (s): 170.5343536590226')
('Epoch 8', 'Objective: -0.11884323443844245', 'Train Acc: 0.9688666666666667', 'Test Acc: 0.9782', 'Train LL: -0.10050709611679479', 'Test LL: -0.06838626888913327', 'Epoch Time (s): 170.5000072051771')
('Epoch 9', 'Objective: -0.11171953658398556', 'Train Acc: 0.9702333333333333', 'Test Acc: 0.9696', 'Train LL: -0.09425399049629063', 'Test LL: -0.08946711625105619', 'Epoch Time (s): 170.58157469332218')
('Epoch 10', 'Objective: -0.10481579424136801', 'Train Acc: 0.9724', 'Test Acc: 0.9791', 'Train LL: -0.0880726675953673', 'Test LL: -0.06289677013600546', 'Epoch Time (s): 170.5751007529907')
('Epoch 11', 'Objective: -0.09857679335407586', 'Train Acc: 0.9743833333333334', 'Test Acc: 0.9774', 'Train LL: -0.082389921324932', 'Test LL: -0.06852645863601001', 'Epoch Time (s): 170.55659752199426')
('Epoch 12', 'Objective: -0.09451013449819637', 'Train Acc: 0.9741833333333333', 'Test Acc: 0.9802', 'Train LL: -0.07878906132669551', 'Test LL: -0.06429439510708176', 'Epoch Time (s): 170.57348595466465')
('Epoch 13', 'Objective: -0.09257247856693138', 'Train Acc: 0.97625', 'Test Acc: 0.9825', 'Train LL: -0.07730012996043227', 'Test LL: -0.055285014747195625', 'Epoch Time (s): 170.53211507108063')
('Epoch 14', 'Objective: -0.08947469426292658', 'Train Acc: 0.97725', 'Test Acc: 0.9776', 'Train LL: -0.0746040419799519', 'Test LL: -0.06588398634492128', 'Epoch Time (s): 170.48273669974878')
('Epoch 15', 'Objective: -0.08468150109863565', 'Train Acc: 0.9776', 'Test Acc: 0.9801', 'Train LL: -0.07006062568880657', 'Test LL: -0.05923317484149991', 'Epoch Time (s): 170.55833984306082')
('Epoch 16', 'Objective: -0.0823536213512034', 'Train Acc: 0.9783666666666667', 'Test Acc: 0.9795', 'Train LL: -0.06802440330758507', 'Test LL: -0.06069239078806063', 'Epoch Time (s): 170.56707219406962')
('Epoch 17', 'Objective: -0.08111317013445812', 'Train Acc: 0.9788166666666667', 'Test Acc: 0.9809', 'Train LL: -0.06708333753617139', 'Test LL: -0.058119126490109294', 'Epoch Time (s): 170.56337236892432')
('Epoch 18', 'Objective: -0.07946121269764934', 'Train Acc: 0.9790833333333333', 'Test Acc: 0.978', 'Train LL: -0.06566321234672347', 'Test LL: -0.06921361595340161', 'Epoch Time (s): 170.5207257908769')
('Epoch 19', 'Objective: -0.07689043168256388', 'Train Acc: 0.98015', 'Test Acc: 0.9832', 'Train LL: -0.063428457182427', 'Test LL: -0.054122137523910624', 'Epoch Time (s): 170.495831055101')
('Epoch 20', 'Objective: -0.07487607050230234', 'Train Acc: 0.9799166666666667', 'Test Acc: 0.9772', 'Train LL: -0.061513052158662956', 'Test LL: -0.06636702452492654', 'Epoch Time (s): 170.62189173977822')
('Epoch 21', 'Objective: -0.07368530052330882', 'Train Acc: 0.9807', 'Test Acc: 0.9799', 'Train LL: -0.06063968381803569', 'Test LL: -0.06164396135495902', 'Epoch Time (s): 170.5178644307889')
('Epoch 22', 'Objective: -0.07228215558997461', 'Train Acc: 0.9809', 'Test Acc: 0.9861', 'Train LL: -0.05948129498843042', 'Test LL: -0.04093539012589618', 'Epoch Time (s): 170.51880159322172')
('Epoch 23', 'Objective: -0.06992321590140449', 'Train Acc: 0.9813', 'Test Acc: 0.9839', 'Train LL: -0.05726515050925006', 'Test LL: -0.050417980029558204', 'Epoch Time (s): 170.52760564303026')
('Epoch 24', 'Objective: -0.0687846366344267', 'Train Acc: 0.9821', 'Test Acc: 0.9829', 'Train LL: -0.05635001308638678', 'Test LL: -0.05430471390032376', 'Epoch Time (s): 170.51693260390311')
('Epoch 25', 'Objective: -0.0683540759908595', 'Train Acc: 0.9829333333333333', 'Test Acc: 0.9821', 'Train LL: -0.05606015759467764', 'Test LL: -0.05503636599540018', 'Epoch Time (s): 170.5340371890925')
('Epoch 26', 'Objective: -0.06685734932274837', 'Train Acc: 0.9830333333333333', 'Test Acc: 0.9848', 'Train LL: -0.0545952356446253', 'Test LL: -0.04804112700865756', 'Epoch Time (s): 170.56483725691214')
('Epoch 27', 'Objective: -0.0649893633208155', 'Train Acc: 0.9828666666666667', 'Test Acc: 0.9841', 'Train LL: -0.05285260062708603', 'Test LL: -0.04821714528939278', 'Epoch Time (s): 170.52920452086255')
('Epoch 28', 'Objective: -0.06412984704087629', 'Train Acc: 0.983', 'Test Acc: 0.9882', 'Train LL: -0.05205820818046797', 'Test LL: -0.04099111772772079', 'Epoch Time (s): 170.5956091247499')
('Epoch 29', 'Objective: -0.06359941572086329', 'Train Acc: 0.98345', 'Test Acc: 0.9828', 'Train LL: -0.051681634551258425', 'Test LL: -0.05235914102622435', 'Epoch Time (s): 170.56173972133547')
('Epoch 30', 'Objective: -0.06160329647840884', 'Train Acc: 0.98395', 'Test Acc: 0.9883', 'Train LL: -0.04983198847448717', 'Test LL: -0.03700134824441486', 'Epoch Time (s): 170.54002687195316')
('Epoch 31', 'Objective: -0.06343823971407576', 'Train Acc: 0.9836833333333334', 'Test Acc: 0.9849', 'Train LL: -0.05179052255126496', 'Test LL: -0.04617755430215807', 'Epoch Time (s): 170.5831100018695')
('Epoch 32', 'Objective: -0.06132963309729237', 'Train Acc: 0.9844166666666667', 'Test Acc: 0.987', 'Train LL: -0.04980674637121481', 'Test LL: -0.04047018763208368', 'Epoch Time (s): 170.5296687008813')
('Epoch 33', 'Objective: -0.06030348704579861', 'Train Acc: 0.9842', 'Test Acc: 0.9851', 'Train LL: -0.048717551961230794', 'Test LL: -0.04794416295794212', 'Epoch Time (s): 170.5792025490664')
('Epoch 34', 'Objective: -0.05845902387794019', 'Train Acc: 0.98535', 'Test Acc: 0.9791', 'Train LL: -0.04719619905936224', 'Test LL: -0.06803399192871011', 'Epoch Time (s): 170.54917852999642')
('Epoch 35', 'Objective: -0.059100115511337974', 'Train Acc: 0.9848', 'Test Acc: 0.9846', 'Train LL: -0.04779095263015293', 'Test LL: -0.04462712636682497', 'Epoch Time (s): 170.5533953178674')
('Epoch 36', 'Objective: -0.0573402750718386', 'Train Acc: 0.9850666666666666', 'Test Acc: 0.9875', 'Train LL: -0.04609365298113753', 'Test LL: -0.037724883643432905', 'Epoch Time (s): 170.52919992012903')
('Epoch 37', 'Objective: -0.05781810194193777', 'Train Acc: 0.9847833333333333', 'Test Acc: 0.98', 'Train LL: -0.04658119908137215', 'Test LL: -0.06323244178335437', 'Epoch Time (s): 170.55179569497705')
('Epoch 38', 'Objective: -0.05748778695052441', 'Train Acc: 0.98535', 'Test Acc: 0.9871', 'Train LL: -0.04634645974790759', 'Test LL: -0.038823776504431536', 'Epoch Time (s): 170.5527548189275')
('Epoch 39', 'Objective: -0.056368746117351674', 'Train Acc: 0.98555', 'Test Acc: 0.9846', 'Train LL: -0.045256848812244684', 'Test LL: -0.045436175301047245', 'Epoch Time (s): 170.56398630701005')
LEARNING RATE HAS CHANGED TO 0.001
('Epoch 40', 'Objective: -0.03872491400718565', 'Train Acc: 0.9910666666666667', 'Test Acc: 0.9919', 'Train LL: -0.02846019697966754', 'Test LL: -0.025983030393330716', 'Epoch Time (s): 170.50634477520362')
('Epoch 41', 'Objective: -0.033469141832393606', 'Train Acc: 0.9925833333333334', 'Test Acc: 0.9911', 'Train LL: -0.02361315371419761', 'Test LL: -0.025912729148833177', 'Epoch Time (s): 170.5518334330991')
('Epoch 42', 'Objective: -0.031548744673715406', 'Train Acc: 0.9933166666666666', 'Test Acc: 0.9922', 'Train LL: -0.021865277916516067', 'Test LL: -0.024960326474295833', 'Epoch Time (s): 170.50975706800818')
('Epoch 43', 'Objective: -0.030062662261922484', 'Train Acc: 0.9936833333333334', 'Test Acc: 0.9913', 'Train LL: -0.02050112620279943', 'Test LL: -0.02811489613178763', 'Epoch Time (s): 170.52681435225531')
('Epoch 44', 'Objective: -0.02854733725554574', 'Train Acc: 0.9938', 'Test Acc: 0.9915', 'Train LL: -0.01903784600198248', 'Test LL: -0.02497232466093019', 'Epoch Time (s): 170.5469185570255')
('Epoch 45', 'Objective: -0.02865453437803541', 'Train Acc: 0.99375', 'Test Acc: 0.9908', 'Train LL: -0.019237513680299342', 'Test LL: -0.029658144196160596', 'Epoch Time (s): 170.54279411118478')
('Epoch 46', 'Objective: -0.029499498097231708', 'Train Acc: 0.9938', 'Test Acc: 0.9917', 'Train LL: -0.020053780130412136', 'Test LL: -0.02633511034531841', 'Epoch Time (s): 170.4803080423735')
('Epoch 47', 'Objective: -0.02795666830597294', 'Train Acc: 0.9939833333333333', 'Test Acc: 0.992', 'Train LL: -0.018573985603488385', 'Test LL: -0.024046120835632026', 'Epoch Time (s): 170.57356608984992')
('Epoch 48', 'Objective: -0.027220687875476716', 'Train Acc: 0.9943666666666666', 'Test Acc: 0.9915', 'Train LL: -0.017890076165158607', 'Test LL: -0.024922045704839132', 'Epoch Time (s): 170.54711762163788')
('Epoch 49', 'Objective: -0.026419523194692155', 'Train Acc: 0.9946333333333334', 'Test Acc: 0.991', 'Train LL: -0.017117432235512257', 'Test LL: -0.028267538129832348', 'Epoch Time (s): 170.52598358597606')
('Epoch 50', 'Objective: -0.027102288935603003', 'Train Acc: 0.99435', 'Test Acc: 0.9927', 'Train LL: -0.017790119738099533', 'Test LL: -0.02270288589999787', 'Epoch Time (s): 170.50886942166835')
('Epoch 51', 'Objective: -0.026177743667134625', 'Train Acc: 0.9942833333333333', 'Test Acc: 0.9918', 'Train LL: -0.016920953055432664', 'Test LL: -0.02615039698673607', 'Epoch Time (s): 170.53290528198704')
('Epoch 52', 'Objective: -0.025919507591601797', 'Train Acc: 0.99475', 'Test Acc: 0.9914', 'Train LL: -0.016684753523562523', 'Test LL: -0.027146403029493418', 'Epoch Time (s): 170.53567835502326')
('Epoch 53', 'Objective: -0.02547740992410979', 'Train Acc: 0.9949666666666667', 'Test Acc: 0.9924', 'Train LL: -0.01621608515644372', 'Test LL: -0.023885368126786304', 'Epoch Time (s): 170.5345476581715')
('Epoch 54', 'Objective: -0.02512615132107736', 'Train Acc: 0.99475', 'Test Acc: 0.9918', 'Train LL: -0.015869106753214693', 'Test LL: -0.025564372154182634', 'Epoch Time (s): 170.51453361893073')
('Epoch 55', 'Objective: -0.025257321089715807', 'Train Acc: 0.9945833333333334', 'Test Acc: 0.9911', 'Train LL: -0.016018129807989046', 'Test LL: -0.026672462027118694', 'Epoch Time (s): 170.50923024583608')
('Epoch 56', 'Objective: -0.024497491144432185', 'Train Acc: 0.9951333333333333', 'Test Acc: 0.9917', 'Train LL: -0.015338893802661967', 'Test LL: -0.027090423875344424', 'Epoch Time (s): 170.38581478828564')
('Epoch 57', 'Objective: -0.024743954917504498', 'Train Acc: 0.9950666666666667', 'Test Acc: 0.9923', 'Train LL: -0.01552964482594106', 'Test LL: -0.024442249534262214', 'Epoch Time (s): 170.41334353480488')
('Epoch 58', 'Objective: -0.024354527946882896', 'Train Acc: 0.9952333333333333', 'Test Acc: 0.9911', 'Train LL: -0.015130459087064082', 'Test LL: -0.027697728630371513', 'Epoch Time (s): 170.43916578497738')
('Epoch 59', 'Objective: -0.02365213646971524', 'Train Acc: 0.9950166666666667', 'Test Acc: 0.9905', 'Train LL: -0.01446129247844269', 'Test LL: -0.02849514175056994', 'Epoch Time (s): 170.41457249037921')
('Epoch 60', 'Objective: -0.024583472843573942', 'Train Acc: 0.99485', 'Test Acc: 0.9903', 'Train LL: -0.015389443006532305', 'Test LL: -0.028851025786444325', 'Epoch Time (s): 170.39835057687014')
('Epoch 61', 'Objective: -0.02353073356667542', 'Train Acc: 0.9952166666666666', 'Test Acc: 0.9901', 'Train LL: -0.014356359399153744', 'Test LL: -0.03062268237346691', 'Epoch Time (s): 170.44520897278562')
('Epoch 62', 'Objective: -0.02290914057774524', 'Train Acc: 0.9955833333333334', 'Test Acc: 0.9909', 'Train LL: -0.01375081984358244', 'Test LL: -0.028007608367007025', 'Epoch Time (s): 170.42846323829144')
('Epoch 63', 'Objective: -0.023695854625932572', 'Train Acc: 0.9950833333333333', 'Test Acc: 0.9913', 'Train LL: -0.014510808390200367', 'Test LL: -0.02733294610205266', 'Epoch Time (s): 170.4532214780338')
('Epoch 64', 'Objective: -0.022755976336173368', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.9921', 'Train LL: -0.013599183454079788', 'Test LL: -0.023151687983188566', 'Epoch Time (s): 170.47524058399722')
('Epoch 65', 'Objective: -0.023166109058022643', 'Train Acc: 0.99535', 'Test Acc: 0.9915', 'Train LL: -0.014067861697461508', 'Test LL: -0.026878233448641636', 'Epoch Time (s): 170.42754166480154')
('Epoch 66', 'Objective: -0.022853823768530426', 'Train Acc: 0.99545', 'Test Acc: 0.9908', 'Train LL: -0.013791746893920098', 'Test LL: -0.027481192730681437', 'Epoch Time (s): 170.39989281306043')
('Epoch 67', 'Objective: -0.02236855616776416', 'Train Acc: 0.9954333333333333', 'Test Acc: 0.9905', 'Train LL: -0.013274202887811167', 'Test LL: -0.028454014393079312', 'Epoch Time (s): 170.41473228111863')
('Epoch 68', 'Objective: -0.022705014892838393', 'Train Acc: 0.9952666666666666', 'Test Acc: 0.9906', 'Train LL: -0.01361967259223319', 'Test LL: -0.028432521495327604', 'Epoch Time (s): 170.42082076892257')
('Epoch 69', 'Objective: -0.021057698268317163', 'Train Acc: 0.9958166666666667', 'Test Acc: 0.9894', 'Train LL: -0.011990621019447149', 'Test LL: -0.03292742613294322', 'Epoch Time (s): 170.40135461697355')
('Epoch 70', 'Objective: -0.022112719684584274', 'Train Acc: 0.9957333333333334', 'Test Acc: 0.9912', 'Train LL: -0.013015591112878547', 'Test LL: -0.028056724084184997', 'Epoch Time (s): 170.44825772708282')
('Epoch 71', 'Objective: -0.02197377944740832', 'Train Acc: 0.9957666666666667', 'Test Acc: 0.9911', 'Train LL: -0.01293180673627762', 'Test LL: -0.02828516833066862', 'Epoch Time (s): 170.4268284328282')
('Epoch 72', 'Objective: -0.021469728689027308', 'Train Acc: 0.99575', 'Test Acc: 0.9904', 'Train LL: -0.012442453476974773', 'Test LL: -0.02716372905991172', 'Epoch Time (s): 170.42467733984813')
('Epoch 73', 'Objective: -0.022099464575259086', 'Train Acc: 0.99555', 'Test Acc: 0.9911', 'Train LL: -0.013084582660175587', 'Test LL: -0.02829495938411442', 'Epoch Time (s): 170.4320686091669')
('Epoch 74', 'Objective: -0.021518632884275562', 'Train Acc: 0.99605', 'Test Acc: 0.9911', 'Train LL: -0.012518381982878473', 'Test LL: -0.030044180116167343', 'Epoch Time (s): 170.38723428407684')
('Epoch 75', 'Objective: -0.02064233987128395', 'Train Acc: 0.99585', 'Test Acc: 0.9908', 'Train LL: -0.011652533144497709', 'Test LL: -0.029552534379188398', 'Epoch Time (s): 170.41585572529584')
('Epoch 76', 'Objective: -0.02090534796055847', 'Train Acc: 0.9962166666666666', 'Test Acc: 0.9915', 'Train LL: -0.011950380696178512', 'Test LL: -0.028343744464448286', 'Epoch Time (s): 170.46413497580215')
('Epoch 77', 'Objective: -0.02077775091813839', 'Train Acc: 0.99595', 'Test Acc: 0.9905', 'Train LL: -0.011758159284625825', 'Test LL: -0.03006293684571167', 'Epoch Time (s): 170.44599177502096')
('Epoch 78', 'Objective: -0.020328673731413126', 'Train Acc: 0.9962333333333333', 'Test Acc: 0.9912', 'Train LL: -0.011343713855788607', 'Test LL: -0.027296361092084366', 'Epoch Time (s): 170.41832990711555')
('Epoch 79', 'Objective: -0.020313215798762753', 'Train Acc: 0.9962833333333333', 'Test Acc: 0.991', 'Train LL: -0.011332040002688582', 'Test LL: -0.03006032123287345', 'Epoch Time (s): 170.40450862282887')
LEARNING RATE HAS CHANGED TO 0.0001
('Epoch 80', 'Objective: -0.018283979407650114', 'Train Acc: 0.9968833333333333', 'Test Acc: 0.9907', 'Train LL: -0.009433017729602337', 'Test LL: -0.02974629376791399', 'Epoch Time (s): 170.45337182516232')
('Epoch 81', 'Objective: -0.018101845433853958', 'Train Acc: 0.9970833333333333', 'Test Acc: 0.9914', 'Train LL: -0.009283414377332315', 'Test LL: -0.02793033007289265', 'Epoch Time (s): 170.4181365519762')
('Epoch 82', 'Objective: -0.017449793655804215', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9915', 'Train LL: -0.00866623848781262', 'Test LL: -0.02725658859074129', 'Epoch Time (s): 170.4293985958211')
('Epoch 83', 'Objective: -0.017371303491207878', 'Train Acc: 0.9973', 'Test Acc: 0.9915', 'Train LL: -0.008615061124532421', 'Test LL: -0.029490809083299756', 'Epoch Time (s): 170.44570447690785')
('Epoch 84', 'Objective: -0.017818726816211914', 'Train Acc: 0.9971', 'Test Acc: 0.9911', 'Train LL: -0.00899779851361799', 'Test LL: -0.028232837792552066', 'Epoch Time (s): 170.44972013495862')
('Epoch 85', 'Objective: -0.017494897167246046', 'Train Acc: 0.9972833333333333', 'Test Acc: 0.9914', 'Train LL: -0.008713225804753522', 'Test LL: -0.028526209837785216', 'Epoch Time (s): 170.43714373093098')
('Epoch 86', 'Objective: -0.017122434163113053', 'Train Acc: 0.9975', 'Test Acc: 0.9911', 'Train LL: -0.008372036087782732', 'Test LL: -0.02939197523891184', 'Epoch Time (s): 170.45144476322457')
('Epoch 87', 'Objective: -0.017243707024708465', 'Train Acc: 0.9974333333333333', 'Test Acc: 0.991', 'Train LL: -0.008466862091958315', 'Test LL: -0.02913189337926015', 'Epoch Time (s): 170.42367809917778')
('Epoch 88', 'Objective: -0.01712692257857194', 'Train Acc: 0.9973166666666666', 'Test Acc: 0.9915', 'Train LL: -0.008327169689147526', 'Test LL: -0.027794013868205587', 'Epoch Time (s): 170.40059716813266')
('Epoch 89', 'Objective: -0.01747017419071106', 'Train Acc: 0.9971666666666666', 'Test Acc: 0.9907', 'Train LL: -0.008643409627631217', 'Test LL: -0.030291602993151322', 'Epoch Time (s): 170.42119110981002')
('Epoch 90', 'Objective: -0.01693879876550901', 'Train Acc: 0.9974', 'Test Acc: 0.991', 'Train LL: -0.008182133525134501', 'Test LL: -0.029292599766453088', 'Epoch Time (s): 170.39916817704216')
('Epoch 91', 'Objective: -0.016834284427861456', 'Train Acc: 0.9973666666666666', 'Test Acc: 0.9919', 'Train LL: -0.00807988094199542', 'Test LL: -0.027725693345895974', 'Epoch Time (s): 170.43513033073395')
('Epoch 92', 'Objective: -0.01708378717987865', 'Train Acc: 0.9976833333333334', 'Test Acc: 0.9915', 'Train LL: -0.008321020444811365', 'Test LL: -0.029103081316969735', 'Epoch Time (s): 170.4407627992332')
('Epoch 93', 'Objective: -0.017139427489996837', 'Train Acc: 0.9974833333333334', 'Test Acc: 0.9907', 'Train LL: -0.008331975057932383', 'Test LL: -0.030135027108070245', 'Epoch Time (s): 170.41190700698644')
('Epoch 94', 'Objective: -0.01667104425674632', 'Train Acc: 0.9977333333333334', 'Test Acc: 0.991', 'Train LL: -0.00790341429902022', 'Test LL: -0.030099304029681292', 'Epoch Time (s): 170.43582003796473')
('Epoch 95', 'Objective: -0.017061686190215464', 'Train Acc: 0.9976166666666667', 'Test Acc: 0.9913', 'Train LL: -0.008250568064216776', 'Test LL: -0.029575935075583856', 'Epoch Time (s): 170.41870560729876')
('Epoch 96', 'Objective: -0.016330251452058266', 'Train Acc: 0.9976', 'Test Acc: 0.9908', 'Train LL: -0.00757296063873674', 'Test LL: -0.029291137017147303', 'Epoch Time (s): 170.44315010402352')
('Epoch 97', 'Objective: -0.016525595354251323', 'Train Acc: 0.99765', 'Test Acc: 0.9916', 'Train LL: -0.007738756022966892', 'Test LL: -0.02876436383828335', 'Epoch Time (s): 170.4456276590936')
('Epoch 98', 'Objective: -0.016451584323935738', 'Train Acc: 0.9978', 'Test Acc: 0.9906', 'Train LL: -0.007671758848060401', 'Test LL: -0.03065653781143959', 'Epoch Time (s): 170.40715893683955')
('Epoch 99', 'Objective: -0.01642402016752764', 'Train Acc: 0.9976166666666667', 'Test Acc: 0.9906', 'Train LL: -0.007647444001992337', 'Test LL: -0.030872380758508143', 'Epoch Time (s): 170.44683658191934')
(Pound symbols for easy extraction of metrics)
Final Train Objective: £-0.016393160166460648
Final Train Accuracy: £0.9976166666666667
Final Train LL: £-0.007604293699356285
Final Test Accuracy: £0.9907
Final Test LL: £-0.030891177236079887
